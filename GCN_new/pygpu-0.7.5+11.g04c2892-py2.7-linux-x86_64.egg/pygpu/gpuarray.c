/* Generated by Cython 0.27.3 */

/* BEGIN: Cython Metadata
{
    "distutils": {
        "define_macros": [
            [
                "GPUARRAY_SHARED", 
                null
            ]
        ], 
        "depends": [
            "/usr/local/lib/python2.7/dist-packages/numpy/core/include/numpy/arrayobject.h", 
            "/usr/local/lib/python2.7/dist-packages/numpy/core/include/numpy/ufuncobject.h"
        ], 
        "include_dirs": [
            "/usr/local/lib/python2.7/dist-packages/numpy/core/include"
        ], 
        "libraries": [
            "gpuarray"
        ], 
        "name": "pygpu.gpuarray", 
        "sources": [
            "pygpu/gpuarray.pyx"
        ]
    }, 
    "module_name": "pygpu.gpuarray"
}
END: Cython Metadata */

#define PY_SSIZE_T_CLEAN
#include "Python.h"
#ifndef Py_PYTHON_H
    #error Python headers needed to compile C extensions, please install development version of Python.
#elif PY_VERSION_HEX < 0x02060000 || (0x03000000 <= PY_VERSION_HEX && PY_VERSION_HEX < 0x03030000)
    #error Cython requires Python 2.6+ or Python 3.3+.
#else
#define CYTHON_ABI "0_27_3"
#define CYTHON_FUTURE_DIVISION 0
#include <stddef.h>
#ifndef offsetof
  #define offsetof(type, member) ( (size_t) & ((type*)0) -> member )
#endif
#if !defined(WIN32) && !defined(MS_WINDOWS)
  #ifndef __stdcall
    #define __stdcall
  #endif
  #ifndef __cdecl
    #define __cdecl
  #endif
  #ifndef __fastcall
    #define __fastcall
  #endif
#endif
#ifndef DL_IMPORT
  #define DL_IMPORT(t) t
#endif
#ifndef DL_EXPORT
  #define DL_EXPORT(t) t
#endif
#define __PYX_COMMA ,
#ifndef HAVE_LONG_LONG
  #if PY_VERSION_HEX >= 0x02070000
    #define HAVE_LONG_LONG
  #endif
#endif
#ifndef PY_LONG_LONG
  #define PY_LONG_LONG LONG_LONG
#endif
#ifndef Py_HUGE_VAL
  #define Py_HUGE_VAL HUGE_VAL
#endif
#ifdef PYPY_VERSION
  #define CYTHON_COMPILING_IN_PYPY 1
  #define CYTHON_COMPILING_IN_PYSTON 0
  #define CYTHON_COMPILING_IN_CPYTHON 0
  #undef CYTHON_USE_TYPE_SLOTS
  #define CYTHON_USE_TYPE_SLOTS 0
  #undef CYTHON_USE_PYTYPE_LOOKUP
  #define CYTHON_USE_PYTYPE_LOOKUP 0
  #if PY_VERSION_HEX < 0x03050000
    #undef CYTHON_USE_ASYNC_SLOTS
    #define CYTHON_USE_ASYNC_SLOTS 0
  #elif !defined(CYTHON_USE_ASYNC_SLOTS)
    #define CYTHON_USE_ASYNC_SLOTS 1
  #endif
  #undef CYTHON_USE_PYLIST_INTERNALS
  #define CYTHON_USE_PYLIST_INTERNALS 0
  #undef CYTHON_USE_UNICODE_INTERNALS
  #define CYTHON_USE_UNICODE_INTERNALS 0
  #undef CYTHON_USE_UNICODE_WRITER
  #define CYTHON_USE_UNICODE_WRITER 0
  #undef CYTHON_USE_PYLONG_INTERNALS
  #define CYTHON_USE_PYLONG_INTERNALS 0
  #undef CYTHON_AVOID_BORROWED_REFS
  #define CYTHON_AVOID_BORROWED_REFS 1
  #undef CYTHON_ASSUME_SAFE_MACROS
  #define CYTHON_ASSUME_SAFE_MACROS 0
  #undef CYTHON_UNPACK_METHODS
  #define CYTHON_UNPACK_METHODS 0
  #undef CYTHON_FAST_THREAD_STATE
  #define CYTHON_FAST_THREAD_STATE 0
  #undef CYTHON_FAST_PYCALL
  #define CYTHON_FAST_PYCALL 0
  #undef CYTHON_PEP489_MULTI_PHASE_INIT
  #define CYTHON_PEP489_MULTI_PHASE_INIT 0
  #undef CYTHON_USE_TP_FINALIZE
  #define CYTHON_USE_TP_FINALIZE 0
#elif defined(PYSTON_VERSION)
  #define CYTHON_COMPILING_IN_PYPY 0
  #define CYTHON_COMPILING_IN_PYSTON 1
  #define CYTHON_COMPILING_IN_CPYTHON 0
  #ifndef CYTHON_USE_TYPE_SLOTS
    #define CYTHON_USE_TYPE_SLOTS 1
  #endif
  #undef CYTHON_USE_PYTYPE_LOOKUP
  #define CYTHON_USE_PYTYPE_LOOKUP 0
  #undef CYTHON_USE_ASYNC_SLOTS
  #define CYTHON_USE_ASYNC_SLOTS 0
  #undef CYTHON_USE_PYLIST_INTERNALS
  #define CYTHON_USE_PYLIST_INTERNALS 0
  #ifndef CYTHON_USE_UNICODE_INTERNALS
    #define CYTHON_USE_UNICODE_INTERNALS 1
  #endif
  #undef CYTHON_USE_UNICODE_WRITER
  #define CYTHON_USE_UNICODE_WRITER 0
  #undef CYTHON_USE_PYLONG_INTERNALS
  #define CYTHON_USE_PYLONG_INTERNALS 0
  #ifndef CYTHON_AVOID_BORROWED_REFS
    #define CYTHON_AVOID_BORROWED_REFS 0
  #endif
  #ifndef CYTHON_ASSUME_SAFE_MACROS
    #define CYTHON_ASSUME_SAFE_MACROS 1
  #endif
  #ifndef CYTHON_UNPACK_METHODS
    #define CYTHON_UNPACK_METHODS 1
  #endif
  #undef CYTHON_FAST_THREAD_STATE
  #define CYTHON_FAST_THREAD_STATE 0
  #undef CYTHON_FAST_PYCALL
  #define CYTHON_FAST_PYCALL 0
  #undef CYTHON_PEP489_MULTI_PHASE_INIT
  #define CYTHON_PEP489_MULTI_PHASE_INIT 0
  #undef CYTHON_USE_TP_FINALIZE
  #define CYTHON_USE_TP_FINALIZE 0
#else
  #define CYTHON_COMPILING_IN_PYPY 0
  #define CYTHON_COMPILING_IN_PYSTON 0
  #define CYTHON_COMPILING_IN_CPYTHON 1
  #ifndef CYTHON_USE_TYPE_SLOTS
    #define CYTHON_USE_TYPE_SLOTS 1
  #endif
  #if PY_VERSION_HEX < 0x02070000
    #undef CYTHON_USE_PYTYPE_LOOKUP
    #define CYTHON_USE_PYTYPE_LOOKUP 0
  #elif !defined(CYTHON_USE_PYTYPE_LOOKUP)
    #define CYTHON_USE_PYTYPE_LOOKUP 1
  #endif
  #if PY_MAJOR_VERSION < 3
    #undef CYTHON_USE_ASYNC_SLOTS
    #define CYTHON_USE_ASYNC_SLOTS 0
  #elif !defined(CYTHON_USE_ASYNC_SLOTS)
    #define CYTHON_USE_ASYNC_SLOTS 1
  #endif
  #if PY_VERSION_HEX < 0x02070000
    #undef CYTHON_USE_PYLONG_INTERNALS
    #define CYTHON_USE_PYLONG_INTERNALS 0
  #elif !defined(CYTHON_USE_PYLONG_INTERNALS)
    #define CYTHON_USE_PYLONG_INTERNALS 1
  #endif
  #ifndef CYTHON_USE_PYLIST_INTERNALS
    #define CYTHON_USE_PYLIST_INTERNALS 1
  #endif
  #ifndef CYTHON_USE_UNICODE_INTERNALS
    #define CYTHON_USE_UNICODE_INTERNALS 1
  #endif
  #if PY_VERSION_HEX < 0x030300F0
    #undef CYTHON_USE_UNICODE_WRITER
    #define CYTHON_USE_UNICODE_WRITER 0
  #elif !defined(CYTHON_USE_UNICODE_WRITER)
    #define CYTHON_USE_UNICODE_WRITER 1
  #endif
  #ifndef CYTHON_AVOID_BORROWED_REFS
    #define CYTHON_AVOID_BORROWED_REFS 0
  #endif
  #ifndef CYTHON_ASSUME_SAFE_MACROS
    #define CYTHON_ASSUME_SAFE_MACROS 1
  #endif
  #ifndef CYTHON_UNPACK_METHODS
    #define CYTHON_UNPACK_METHODS 1
  #endif
  #ifndef CYTHON_FAST_THREAD_STATE
    #define CYTHON_FAST_THREAD_STATE 1
  #endif
  #ifndef CYTHON_FAST_PYCALL
    #define CYTHON_FAST_PYCALL 1
  #endif
  #ifndef CYTHON_PEP489_MULTI_PHASE_INIT
    #define CYTHON_PEP489_MULTI_PHASE_INIT (0 && PY_VERSION_HEX >= 0x03050000)
  #endif
  #ifndef CYTHON_USE_TP_FINALIZE
    #define CYTHON_USE_TP_FINALIZE (PY_VERSION_HEX >= 0x030400a1)
  #endif
#endif
#if !defined(CYTHON_FAST_PYCCALL)
#define CYTHON_FAST_PYCCALL  (CYTHON_FAST_PYCALL && PY_VERSION_HEX >= 0x030600B1)
#endif
#if CYTHON_USE_PYLONG_INTERNALS
  #include "longintrepr.h"
  #undef SHIFT
  #undef BASE
  #undef MASK
#endif
#if CYTHON_COMPILING_IN_PYPY && PY_VERSION_HEX < 0x02070600 && !defined(Py_OptimizeFlag)
  #define Py_OptimizeFlag 0
#endif
#define __PYX_BUILD_PY_SSIZE_T "n"
#define CYTHON_FORMAT_SSIZE_T "z"
#if PY_MAJOR_VERSION < 3
  #define __Pyx_BUILTIN_MODULE_NAME "__builtin__"
  #define __Pyx_PyCode_New(a, k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)\
          PyCode_New(a+k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)
  #define __Pyx_DefaultClassType PyClass_Type
#else
  #define __Pyx_BUILTIN_MODULE_NAME "builtins"
  #define __Pyx_PyCode_New(a, k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)\
          PyCode_New(a, k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)
  #define __Pyx_DefaultClassType PyType_Type
#endif
#ifndef Py_TPFLAGS_CHECKTYPES
  #define Py_TPFLAGS_CHECKTYPES 0
#endif
#ifndef Py_TPFLAGS_HAVE_INDEX
  #define Py_TPFLAGS_HAVE_INDEX 0
#endif
#ifndef Py_TPFLAGS_HAVE_NEWBUFFER
  #define Py_TPFLAGS_HAVE_NEWBUFFER 0
#endif
#ifndef Py_TPFLAGS_HAVE_FINALIZE
  #define Py_TPFLAGS_HAVE_FINALIZE 0
#endif
#if PY_VERSION_HEX < 0x030700A0 || !defined(METH_FASTCALL)
  #ifndef METH_FASTCALL
     #define METH_FASTCALL 0x80
  #endif
  typedef PyObject *(*__Pyx_PyCFunctionFast) (PyObject *self, PyObject **args, Py_ssize_t nargs);
  typedef PyObject *(*__Pyx_PyCFunctionFastWithKeywords) (PyObject *self, PyObject **args,
                                                          Py_ssize_t nargs, PyObject *kwnames);
#else
  #define __Pyx_PyCFunctionFast _PyCFunctionFast
  #define __Pyx_PyCFunctionFastWithKeywords _PyCFunctionFastWithKeywords
#endif
#if CYTHON_FAST_PYCCALL
#define __Pyx_PyFastCFunction_Check(func)\
    ((PyCFunction_Check(func) && (METH_FASTCALL == (PyCFunction_GET_FLAGS(func) & ~(METH_CLASS | METH_STATIC | METH_COEXIST | METH_KEYWORDS)))))
#else
#define __Pyx_PyFastCFunction_Check(func) 0
#endif
#if !CYTHON_FAST_THREAD_STATE || PY_VERSION_HEX < 0x02070000
  #define __Pyx_PyThreadState_Current PyThreadState_GET()
#elif PY_VERSION_HEX >= 0x03060000
  #define __Pyx_PyThreadState_Current _PyThreadState_UncheckedGet()
#elif PY_VERSION_HEX >= 0x03000000
  #define __Pyx_PyThreadState_Current PyThreadState_GET()
#else
  #define __Pyx_PyThreadState_Current _PyThreadState_Current
#endif
#if CYTHON_COMPILING_IN_CPYTHON || defined(_PyDict_NewPresized)
#define __Pyx_PyDict_NewPresized(n)  ((n <= 8) ? PyDict_New() : _PyDict_NewPresized(n))
#else
#define __Pyx_PyDict_NewPresized(n)  PyDict_New()
#endif
#if PY_MAJOR_VERSION >= 3 || CYTHON_FUTURE_DIVISION
  #define __Pyx_PyNumber_Divide(x,y)         PyNumber_TrueDivide(x,y)
  #define __Pyx_PyNumber_InPlaceDivide(x,y)  PyNumber_InPlaceTrueDivide(x,y)
#else
  #define __Pyx_PyNumber_Divide(x,y)         PyNumber_Divide(x,y)
  #define __Pyx_PyNumber_InPlaceDivide(x,y)  PyNumber_InPlaceDivide(x,y)
#endif
#if PY_VERSION_HEX > 0x03030000 && defined(PyUnicode_KIND)
  #define CYTHON_PEP393_ENABLED 1
  #define __Pyx_PyUnicode_READY(op)       (likely(PyUnicode_IS_READY(op)) ?\
                                              0 : _PyUnicode_Ready((PyObject *)(op)))
  #define __Pyx_PyUnicode_GET_LENGTH(u)   PyUnicode_GET_LENGTH(u)
  #define __Pyx_PyUnicode_READ_CHAR(u, i) PyUnicode_READ_CHAR(u, i)
  #define __Pyx_PyUnicode_MAX_CHAR_VALUE(u)   PyUnicode_MAX_CHAR_VALUE(u)
  #define __Pyx_PyUnicode_KIND(u)         PyUnicode_KIND(u)
  #define __Pyx_PyUnicode_DATA(u)         PyUnicode_DATA(u)
  #define __Pyx_PyUnicode_READ(k, d, i)   PyUnicode_READ(k, d, i)
  #define __Pyx_PyUnicode_WRITE(k, d, i, ch)  PyUnicode_WRITE(k, d, i, ch)
  #define __Pyx_PyUnicode_IS_TRUE(u)      (0 != (likely(PyUnicode_IS_READY(u)) ? PyUnicode_GET_LENGTH(u) : PyUnicode_GET_SIZE(u)))
#else
  #define CYTHON_PEP393_ENABLED 0
  #define PyUnicode_1BYTE_KIND  1
  #define PyUnicode_2BYTE_KIND  2
  #define PyUnicode_4BYTE_KIND  4
  #define __Pyx_PyUnicode_READY(op)       (0)
  #define __Pyx_PyUnicode_GET_LENGTH(u)   PyUnicode_GET_SIZE(u)
  #define __Pyx_PyUnicode_READ_CHAR(u, i) ((Py_UCS4)(PyUnicode_AS_UNICODE(u)[i]))
  #define __Pyx_PyUnicode_MAX_CHAR_VALUE(u)   ((sizeof(Py_UNICODE) == 2) ? 65535 : 1114111)
  #define __Pyx_PyUnicode_KIND(u)         (sizeof(Py_UNICODE))
  #define __Pyx_PyUnicode_DATA(u)         ((void*)PyUnicode_AS_UNICODE(u))
  #define __Pyx_PyUnicode_READ(k, d, i)   ((void)(k), (Py_UCS4)(((Py_UNICODE*)d)[i]))
  #define __Pyx_PyUnicode_WRITE(k, d, i, ch)  (((void)(k)), ((Py_UNICODE*)d)[i] = ch)
  #define __Pyx_PyUnicode_IS_TRUE(u)      (0 != PyUnicode_GET_SIZE(u))
#endif
#if CYTHON_COMPILING_IN_PYPY
  #define __Pyx_PyUnicode_Concat(a, b)      PyNumber_Add(a, b)
  #define __Pyx_PyUnicode_ConcatSafe(a, b)  PyNumber_Add(a, b)
#else
  #define __Pyx_PyUnicode_Concat(a, b)      PyUnicode_Concat(a, b)
  #define __Pyx_PyUnicode_ConcatSafe(a, b)  ((unlikely((a) == Py_None) || unlikely((b) == Py_None)) ?\
      PyNumber_Add(a, b) : __Pyx_PyUnicode_Concat(a, b))
#endif
#if CYTHON_COMPILING_IN_PYPY && !defined(PyUnicode_Contains)
  #define PyUnicode_Contains(u, s)  PySequence_Contains(u, s)
#endif
#if CYTHON_COMPILING_IN_PYPY && !defined(PyByteArray_Check)
  #define PyByteArray_Check(obj)  PyObject_TypeCheck(obj, &PyByteArray_Type)
#endif
#if CYTHON_COMPILING_IN_PYPY && !defined(PyObject_Format)
  #define PyObject_Format(obj, fmt)  PyObject_CallMethod(obj, "__format__", "O", fmt)
#endif
#if CYTHON_COMPILING_IN_PYPY && !defined(PyObject_Malloc)
  #define PyObject_Malloc(s)   PyMem_Malloc(s)
  #define PyObject_Free(p)     PyMem_Free(p)
  #define PyObject_Realloc(p)  PyMem_Realloc(p)
#endif
#if CYTHON_COMPILING_IN_PYSTON
  #define __Pyx_PyCode_HasFreeVars(co)  PyCode_HasFreeVars(co)
  #define __Pyx_PyFrame_SetLineNumber(frame, lineno) PyFrame_SetLineNumber(frame, lineno)
#else
  #define __Pyx_PyCode_HasFreeVars(co)  (PyCode_GetNumFree(co) > 0)
  #define __Pyx_PyFrame_SetLineNumber(frame, lineno)  (frame)->f_lineno = (lineno)
#endif
#define __Pyx_PyString_FormatSafe(a, b)   ((unlikely((a) == Py_None)) ? PyNumber_Remainder(a, b) : __Pyx_PyString_Format(a, b))
#define __Pyx_PyUnicode_FormatSafe(a, b)  ((unlikely((a) == Py_None)) ? PyNumber_Remainder(a, b) : PyUnicode_Format(a, b))
#if PY_MAJOR_VERSION >= 3
  #define __Pyx_PyString_Format(a, b)  PyUnicode_Format(a, b)
#else
  #define __Pyx_PyString_Format(a, b)  PyString_Format(a, b)
#endif
#if PY_MAJOR_VERSION < 3 && !defined(PyObject_ASCII)
  #define PyObject_ASCII(o)            PyObject_Repr(o)
#endif
#if PY_MAJOR_VERSION >= 3
  #define PyBaseString_Type            PyUnicode_Type
  #define PyStringObject               PyUnicodeObject
  #define PyString_Type                PyUnicode_Type
  #define PyString_Check               PyUnicode_Check
  #define PyString_CheckExact          PyUnicode_CheckExact
#endif
#if PY_MAJOR_VERSION >= 3
  #define __Pyx_PyBaseString_Check(obj) PyUnicode_Check(obj)
  #define __Pyx_PyBaseString_CheckExact(obj) PyUnicode_CheckExact(obj)
#else
  #define __Pyx_PyBaseString_Check(obj) (PyString_Check(obj) || PyUnicode_Check(obj))
  #define __Pyx_PyBaseString_CheckExact(obj) (PyString_CheckExact(obj) || PyUnicode_CheckExact(obj))
#endif
#ifndef PySet_CheckExact
  #define PySet_CheckExact(obj)        (Py_TYPE(obj) == &PySet_Type)
#endif
#define __Pyx_PyException_Check(obj) __Pyx_TypeCheck(obj, PyExc_Exception)
#if PY_MAJOR_VERSION >= 3
  #define PyIntObject                  PyLongObject
  #define PyInt_Type                   PyLong_Type
  #define PyInt_Check(op)              PyLong_Check(op)
  #define PyInt_CheckExact(op)         PyLong_CheckExact(op)
  #define PyInt_FromString             PyLong_FromString
  #define PyInt_FromUnicode            PyLong_FromUnicode
  #define PyInt_FromLong               PyLong_FromLong
  #define PyInt_FromSize_t             PyLong_FromSize_t
  #define PyInt_FromSsize_t            PyLong_FromSsize_t
  #define PyInt_AsLong                 PyLong_AsLong
  #define PyInt_AS_LONG                PyLong_AS_LONG
  #define PyInt_AsSsize_t              PyLong_AsSsize_t
  #define PyInt_AsUnsignedLongMask     PyLong_AsUnsignedLongMask
  #define PyInt_AsUnsignedLongLongMask PyLong_AsUnsignedLongLongMask
  #define PyNumber_Int                 PyNumber_Long
#endif
#if PY_MAJOR_VERSION >= 3
  #define PyBoolObject                 PyLongObject
#endif
#if PY_MAJOR_VERSION >= 3 && CYTHON_COMPILING_IN_PYPY
  #ifndef PyUnicode_InternFromString
    #define PyUnicode_InternFromString(s) PyUnicode_FromString(s)
  #endif
#endif
#if PY_VERSION_HEX < 0x030200A4
  typedef long Py_hash_t;
  #define __Pyx_PyInt_FromHash_t PyInt_FromLong
  #define __Pyx_PyInt_AsHash_t   PyInt_AsLong
#else
  #define __Pyx_PyInt_FromHash_t PyInt_FromSsize_t
  #define __Pyx_PyInt_AsHash_t   PyInt_AsSsize_t
#endif
#if PY_MAJOR_VERSION >= 3
  #define __Pyx_PyMethod_New(func, self, klass) ((self) ? PyMethod_New(func, self) : PyInstanceMethod_New(func))
#else
  #define __Pyx_PyMethod_New(func, self, klass) PyMethod_New(func, self, klass)
#endif
#ifndef __has_attribute
  #define __has_attribute(x) 0
#endif
#ifndef __has_cpp_attribute
  #define __has_cpp_attribute(x) 0
#endif
#if CYTHON_USE_ASYNC_SLOTS
  #if PY_VERSION_HEX >= 0x030500B1
    #define __Pyx_PyAsyncMethodsStruct PyAsyncMethods
    #define __Pyx_PyType_AsAsync(obj) (Py_TYPE(obj)->tp_as_async)
  #else
    #define __Pyx_PyType_AsAsync(obj) ((__Pyx_PyAsyncMethodsStruct*) (Py_TYPE(obj)->tp_reserved))
  #endif
#else
  #define __Pyx_PyType_AsAsync(obj) NULL
#endif
#ifndef __Pyx_PyAsyncMethodsStruct
    typedef struct {
        unaryfunc am_await;
        unaryfunc am_aiter;
        unaryfunc am_anext;
    } __Pyx_PyAsyncMethodsStruct;
#endif
#ifndef CYTHON_RESTRICT
  #if defined(__GNUC__)
    #define CYTHON_RESTRICT __restrict__
  #elif defined(_MSC_VER) && _MSC_VER >= 1400
    #define CYTHON_RESTRICT __restrict
  #elif defined (__STDC_VERSION__) && __STDC_VERSION__ >= 199901L
    #define CYTHON_RESTRICT restrict
  #else
    #define CYTHON_RESTRICT
  #endif
#endif
#ifndef CYTHON_UNUSED
# if defined(__GNUC__)
#   if !(defined(__cplusplus)) || (__GNUC__ > 3 || (__GNUC__ == 3 && __GNUC_MINOR__ >= 4))
#     define CYTHON_UNUSED __attribute__ ((__unused__))
#   else
#     define CYTHON_UNUSED
#   endif
# elif defined(__ICC) || (defined(__INTEL_COMPILER) && !defined(_MSC_VER))
#   define CYTHON_UNUSED __attribute__ ((__unused__))
# else
#   define CYTHON_UNUSED
# endif
#endif
#ifndef CYTHON_MAYBE_UNUSED_VAR
#  if defined(__cplusplus)
     template<class T> void CYTHON_MAYBE_UNUSED_VAR( const T& ) { }
#  else
#    define CYTHON_MAYBE_UNUSED_VAR(x) (void)(x)
#  endif
#endif
#ifndef CYTHON_NCP_UNUSED
# if CYTHON_COMPILING_IN_CPYTHON
#  define CYTHON_NCP_UNUSED
# else
#  define CYTHON_NCP_UNUSED CYTHON_UNUSED
# endif
#endif
#define __Pyx_void_to_None(void_result) ((void)(void_result), Py_INCREF(Py_None), Py_None)
#ifdef _MSC_VER
    #ifndef _MSC_STDINT_H_
        #if _MSC_VER < 1300
           typedef unsigned char     uint8_t;
           typedef unsigned int      uint32_t;
        #else
           typedef unsigned __int8   uint8_t;
           typedef unsigned __int32  uint32_t;
        #endif
    #endif
#else
   #include <stdint.h>
#endif
#ifndef CYTHON_FALLTHROUGH
  #if defined(__cplusplus) && __cplusplus >= 201103L
    #if __has_cpp_attribute(fallthrough)
      #define CYTHON_FALLTHROUGH [[fallthrough]]
    #elif __has_cpp_attribute(clang::fallthrough)
      #define CYTHON_FALLTHROUGH [[clang::fallthrough]]
    #elif __has_cpp_attribute(gnu::fallthrough)
      #define CYTHON_FALLTHROUGH [[gnu::fallthrough]]
    #endif
  #endif
  #ifndef CYTHON_FALLTHROUGH
    #if __has_attribute(fallthrough)
      #define CYTHON_FALLTHROUGH __attribute__((fallthrough))
    #else
      #define CYTHON_FALLTHROUGH
    #endif
  #endif
  #if defined(__clang__ ) && defined(__apple_build_version__)
    #if __apple_build_version__ < 7000000
      #undef  CYTHON_FALLTHROUGH
      #define CYTHON_FALLTHROUGH
    #endif
  #endif
#endif

#ifndef CYTHON_INLINE
  #if defined(__clang__)
    #define CYTHON_INLINE __inline__ __attribute__ ((__unused__))
  #elif defined(__GNUC__)
    #define CYTHON_INLINE __inline__
  #elif defined(_MSC_VER)
    #define CYTHON_INLINE __inline
  #elif defined (__STDC_VERSION__) && __STDC_VERSION__ >= 199901L
    #define CYTHON_INLINE inline
  #else
    #define CYTHON_INLINE
  #endif
#endif

#if defined(WIN32) || defined(MS_WINDOWS)
  #define _USE_MATH_DEFINES
#endif
#include <math.h>
#ifdef NAN
#define __PYX_NAN() ((float) NAN)
#else
static CYTHON_INLINE float __PYX_NAN() {
  float value;
  memset(&value, 0xFF, sizeof(value));
  return value;
}
#endif
#if defined(__CYGWIN__) && defined(_LDBL_EQ_DBL)
#define __Pyx_truncl trunc
#else
#define __Pyx_truncl truncl
#endif


#define __PYX_ERR(f_index, lineno, Ln_error) \
{ \
  __pyx_filename = __pyx_f[f_index]; __pyx_lineno = lineno; __pyx_clineno = __LINE__; goto Ln_error; \
}

#ifndef __PYX_EXTERN_C
  #ifdef __cplusplus
    #define __PYX_EXTERN_C extern "C"
  #else
    #define __PYX_EXTERN_C extern
  #endif
#endif

#define __PYX_HAVE__pygpu__gpuarray
#define __PYX_HAVE_API__pygpu__gpuarray
#include "stdlib.h"
#include <string.h>
#include <stdio.h>
#include "numpy/arrayobject.h"
#include "numpy/ufuncobject.h"
#include "gpuarray/config.h"
#include "gpuarray/types.h"
#include "gpuarray/util.h"
#include "gpuarray/error.h"
#include "gpuarray/buffer.h"
#include "gpuarray/kernel.h"
#include "gpuarray/array.h"
#include "gpuarray/extension.h"
#include <stdlib.h>
#include "pythread.h"
#ifdef _OPENMP
#include <omp.h>
#endif /* _OPENMP */

#if defined(PYREX_WITHOUT_ASSERTIONS) && !defined(CYTHON_WITHOUT_ASSERTIONS)
#define CYTHON_WITHOUT_ASSERTIONS
#endif

typedef struct {PyObject **p; const char *s; const Py_ssize_t n; const char* encoding;
                const char is_unicode; const char is_str; const char intern; } __Pyx_StringTabEntry;

#define __PYX_DEFAULT_STRING_ENCODING_IS_ASCII 0
#define __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT 0
#define __PYX_DEFAULT_STRING_ENCODING ""
#define __Pyx_PyObject_FromString __Pyx_PyBytes_FromString
#define __Pyx_PyObject_FromStringAndSize __Pyx_PyBytes_FromStringAndSize
#define __Pyx_uchar_cast(c) ((unsigned char)c)
#define __Pyx_long_cast(x) ((long)x)
#define __Pyx_fits_Py_ssize_t(v, type, is_signed)  (\
    (sizeof(type) < sizeof(Py_ssize_t))  ||\
    (sizeof(type) > sizeof(Py_ssize_t) &&\
          likely(v < (type)PY_SSIZE_T_MAX ||\
                 v == (type)PY_SSIZE_T_MAX)  &&\
          (!is_signed || likely(v > (type)PY_SSIZE_T_MIN ||\
                                v == (type)PY_SSIZE_T_MIN)))  ||\
    (sizeof(type) == sizeof(Py_ssize_t) &&\
          (is_signed || likely(v < (type)PY_SSIZE_T_MAX ||\
                               v == (type)PY_SSIZE_T_MAX)))  )
#if defined (__cplusplus) && __cplusplus >= 201103L
    #include <cstdlib>
    #define __Pyx_sst_abs(value) std::abs(value)
#elif SIZEOF_INT >= SIZEOF_SIZE_T
    #define __Pyx_sst_abs(value) abs(value)
#elif SIZEOF_LONG >= SIZEOF_SIZE_T
    #define __Pyx_sst_abs(value) labs(value)
#elif defined (_MSC_VER)
    #define __Pyx_sst_abs(value) ((Py_ssize_t)_abs64(value))
#elif defined (__STDC_VERSION__) && __STDC_VERSION__ >= 199901L
    #define __Pyx_sst_abs(value) llabs(value)
#elif defined (__GNUC__)
    #define __Pyx_sst_abs(value) __builtin_llabs(value)
#else
    #define __Pyx_sst_abs(value) ((value<0) ? -value : value)
#endif
static CYTHON_INLINE const char* __Pyx_PyObject_AsString(PyObject*);
static CYTHON_INLINE const char* __Pyx_PyObject_AsStringAndSize(PyObject*, Py_ssize_t* length);
#define __Pyx_PyByteArray_FromString(s) PyByteArray_FromStringAndSize((const char*)s, strlen((const char*)s))
#define __Pyx_PyByteArray_FromStringAndSize(s, l) PyByteArray_FromStringAndSize((const char*)s, l)
#define __Pyx_PyBytes_FromString        PyBytes_FromString
#define __Pyx_PyBytes_FromStringAndSize PyBytes_FromStringAndSize
static CYTHON_INLINE PyObject* __Pyx_PyUnicode_FromString(const char*);
#if PY_MAJOR_VERSION < 3
    #define __Pyx_PyStr_FromString        __Pyx_PyBytes_FromString
    #define __Pyx_PyStr_FromStringAndSize __Pyx_PyBytes_FromStringAndSize
#else
    #define __Pyx_PyStr_FromString        __Pyx_PyUnicode_FromString
    #define __Pyx_PyStr_FromStringAndSize __Pyx_PyUnicode_FromStringAndSize
#endif
#define __Pyx_PyBytes_AsWritableString(s)     ((char*) PyBytes_AS_STRING(s))
#define __Pyx_PyBytes_AsWritableSString(s)    ((signed char*) PyBytes_AS_STRING(s))
#define __Pyx_PyBytes_AsWritableUString(s)    ((unsigned char*) PyBytes_AS_STRING(s))
#define __Pyx_PyBytes_AsString(s)     ((const char*) PyBytes_AS_STRING(s))
#define __Pyx_PyBytes_AsSString(s)    ((const signed char*) PyBytes_AS_STRING(s))
#define __Pyx_PyBytes_AsUString(s)    ((const unsigned char*) PyBytes_AS_STRING(s))
#define __Pyx_PyObject_AsWritableString(s)    ((char*) __Pyx_PyObject_AsString(s))
#define __Pyx_PyObject_AsWritableSString(s)    ((signed char*) __Pyx_PyObject_AsString(s))
#define __Pyx_PyObject_AsWritableUString(s)    ((unsigned char*) __Pyx_PyObject_AsString(s))
#define __Pyx_PyObject_AsSString(s)    ((const signed char*) __Pyx_PyObject_AsString(s))
#define __Pyx_PyObject_AsUString(s)    ((const unsigned char*) __Pyx_PyObject_AsString(s))
#define __Pyx_PyObject_FromCString(s)  __Pyx_PyObject_FromString((const char*)s)
#define __Pyx_PyBytes_FromCString(s)   __Pyx_PyBytes_FromString((const char*)s)
#define __Pyx_PyByteArray_FromCString(s)   __Pyx_PyByteArray_FromString((const char*)s)
#define __Pyx_PyStr_FromCString(s)     __Pyx_PyStr_FromString((const char*)s)
#define __Pyx_PyUnicode_FromCString(s) __Pyx_PyUnicode_FromString((const char*)s)
static CYTHON_INLINE size_t __Pyx_Py_UNICODE_strlen(const Py_UNICODE *u) {
    const Py_UNICODE *u_end = u;
    while (*u_end++) ;
    return (size_t)(u_end - u - 1);
}
#define __Pyx_PyUnicode_FromUnicode(u)       PyUnicode_FromUnicode(u, __Pyx_Py_UNICODE_strlen(u))
#define __Pyx_PyUnicode_FromUnicodeAndLength PyUnicode_FromUnicode
#define __Pyx_PyUnicode_AsUnicode            PyUnicode_AsUnicode
#define __Pyx_NewRef(obj) (Py_INCREF(obj), obj)
#define __Pyx_Owned_Py_None(b) __Pyx_NewRef(Py_None)
#define __Pyx_PyBool_FromLong(b) ((b) ? __Pyx_NewRef(Py_True) : __Pyx_NewRef(Py_False))
static CYTHON_INLINE int __Pyx_PyObject_IsTrue(PyObject*);
static CYTHON_INLINE PyObject* __Pyx_PyNumber_IntOrLong(PyObject* x);
#define __Pyx_PySequence_Tuple(obj)\
    (likely(PyTuple_CheckExact(obj)) ? __Pyx_NewRef(obj) : PySequence_Tuple(obj))
static CYTHON_INLINE Py_ssize_t __Pyx_PyIndex_AsSsize_t(PyObject*);
static CYTHON_INLINE PyObject * __Pyx_PyInt_FromSize_t(size_t);
#if CYTHON_ASSUME_SAFE_MACROS
#define __pyx_PyFloat_AsDouble(x) (PyFloat_CheckExact(x) ? PyFloat_AS_DOUBLE(x) : PyFloat_AsDouble(x))
#else
#define __pyx_PyFloat_AsDouble(x) PyFloat_AsDouble(x)
#endif
#define __pyx_PyFloat_AsFloat(x) ((float) __pyx_PyFloat_AsDouble(x))
#if PY_MAJOR_VERSION >= 3
#define __Pyx_PyNumber_Int(x) (PyLong_CheckExact(x) ? __Pyx_NewRef(x) : PyNumber_Long(x))
#else
#define __Pyx_PyNumber_Int(x) (PyInt_CheckExact(x) ? __Pyx_NewRef(x) : PyNumber_Int(x))
#endif
#define __Pyx_PyNumber_Float(x) (PyFloat_CheckExact(x) ? __Pyx_NewRef(x) : PyNumber_Float(x))
#if PY_MAJOR_VERSION < 3 && __PYX_DEFAULT_STRING_ENCODING_IS_ASCII
static int __Pyx_sys_getdefaultencoding_not_ascii;
static int __Pyx_init_sys_getdefaultencoding_params(void) {
    PyObject* sys;
    PyObject* default_encoding = NULL;
    PyObject* ascii_chars_u = NULL;
    PyObject* ascii_chars_b = NULL;
    const char* default_encoding_c;
    sys = PyImport_ImportModule("sys");
    if (!sys) goto bad;
    default_encoding = PyObject_CallMethod(sys, (char*) "getdefaultencoding", NULL);
    Py_DECREF(sys);
    if (!default_encoding) goto bad;
    default_encoding_c = PyBytes_AsString(default_encoding);
    if (!default_encoding_c) goto bad;
    if (strcmp(default_encoding_c, "ascii") == 0) {
        __Pyx_sys_getdefaultencoding_not_ascii = 0;
    } else {
        char ascii_chars[128];
        int c;
        for (c = 0; c < 128; c++) {
            ascii_chars[c] = c;
        }
        __Pyx_sys_getdefaultencoding_not_ascii = 1;
        ascii_chars_u = PyUnicode_DecodeASCII(ascii_chars, 128, NULL);
        if (!ascii_chars_u) goto bad;
        ascii_chars_b = PyUnicode_AsEncodedString(ascii_chars_u, default_encoding_c, NULL);
        if (!ascii_chars_b || !PyBytes_Check(ascii_chars_b) || memcmp(ascii_chars, PyBytes_AS_STRING(ascii_chars_b), 128) != 0) {
            PyErr_Format(
                PyExc_ValueError,
                "This module compiled with c_string_encoding=ascii, but default encoding '%.200s' is not a superset of ascii.",
                default_encoding_c);
            goto bad;
        }
        Py_DECREF(ascii_chars_u);
        Py_DECREF(ascii_chars_b);
    }
    Py_DECREF(default_encoding);
    return 0;
bad:
    Py_XDECREF(default_encoding);
    Py_XDECREF(ascii_chars_u);
    Py_XDECREF(ascii_chars_b);
    return -1;
}
#endif
#if __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT && PY_MAJOR_VERSION >= 3
#define __Pyx_PyUnicode_FromStringAndSize(c_str, size) PyUnicode_DecodeUTF8(c_str, size, NULL)
#else
#define __Pyx_PyUnicode_FromStringAndSize(c_str, size) PyUnicode_Decode(c_str, size, __PYX_DEFAULT_STRING_ENCODING, NULL)
#if __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT
static char* __PYX_DEFAULT_STRING_ENCODING;
static int __Pyx_init_sys_getdefaultencoding_params(void) {
    PyObject* sys;
    PyObject* default_encoding = NULL;
    char* default_encoding_c;
    sys = PyImport_ImportModule("sys");
    if (!sys) goto bad;
    default_encoding = PyObject_CallMethod(sys, (char*) (const char*) "getdefaultencoding", NULL);
    Py_DECREF(sys);
    if (!default_encoding) goto bad;
    default_encoding_c = PyBytes_AsString(default_encoding);
    if (!default_encoding_c) goto bad;
    __PYX_DEFAULT_STRING_ENCODING = (char*) malloc(strlen(default_encoding_c));
    if (!__PYX_DEFAULT_STRING_ENCODING) goto bad;
    strcpy(__PYX_DEFAULT_STRING_ENCODING, default_encoding_c);
    Py_DECREF(default_encoding);
    return 0;
bad:
    Py_XDECREF(default_encoding);
    return -1;
}
#endif
#endif


/* Test for GCC > 2.95 */
#if defined(__GNUC__)     && (__GNUC__ > 2 || (__GNUC__ == 2 && (__GNUC_MINOR__ > 95)))
  #define likely(x)   __builtin_expect(!!(x), 1)
  #define unlikely(x) __builtin_expect(!!(x), 0)
#else /* !__GNUC__ or GCC < 2.95 */
  #define likely(x)   (x)
  #define unlikely(x) (x)
#endif /* __GNUC__ */
static CYTHON_INLINE void __Pyx_pretend_to_initialize(void* ptr) { (void)ptr; }

static PyObject *__pyx_m = NULL;
static PyObject *__pyx_d;
static PyObject *__pyx_b;
static PyObject *__pyx_cython_runtime;
static PyObject *__pyx_empty_tuple;
static PyObject *__pyx_empty_bytes;
static PyObject *__pyx_empty_unicode;
static int __pyx_lineno;
static int __pyx_clineno = 0;
static const char * __pyx_cfilenm= __FILE__;
static const char *__pyx_filename;

/* Header.proto */
#if !defined(CYTHON_CCOMPLEX)
  #if defined(__cplusplus)
    #define CYTHON_CCOMPLEX 1
  #elif defined(_Complex_I)
    #define CYTHON_CCOMPLEX 1
  #else
    #define CYTHON_CCOMPLEX 0
  #endif
#endif
#if CYTHON_CCOMPLEX
  #ifdef __cplusplus
    #include <complex>
  #else
    #include <complex.h>
  #endif
#endif
#if CYTHON_CCOMPLEX && !defined(__cplusplus) && defined(__sun__) && defined(__GNUC__)
  #undef _Complex_I
  #define _Complex_I 1.0fj
#endif


static const char *__pyx_f[] = {
  "pygpu/gpuarray.pyx",
  "__init__.pxd",
  "type.pxd",
  "bool.pxd",
  "complex.pxd",
};
/* NoFastGil.proto */
#define __Pyx_PyGILState_Ensure PyGILState_Ensure
#define __Pyx_PyGILState_Release PyGILState_Release
#define __Pyx_FastGIL_Remember()
#define __Pyx_FastGIL_Forget()
#define __Pyx_FastGilFuncInit()

/* ForceInitThreads.proto */
#ifndef __PYX_FORCE_INIT_THREADS
  #define __PYX_FORCE_INIT_THREADS 0
#endif


/* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":743
 * # in Cython to enable them only on the right systems.
 * 
 * ctypedef npy_int8       int8_t             # <<<<<<<<<<<<<<
 * ctypedef npy_int16      int16_t
 * ctypedef npy_int32      int32_t
 */
typedef npy_int8 __pyx_t_5numpy_int8_t;

/* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":744
 * 
 * ctypedef npy_int8       int8_t
 * ctypedef npy_int16      int16_t             # <<<<<<<<<<<<<<
 * ctypedef npy_int32      int32_t
 * ctypedef npy_int64      int64_t
 */
typedef npy_int16 __pyx_t_5numpy_int16_t;

/* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":745
 * ctypedef npy_int8       int8_t
 * ctypedef npy_int16      int16_t
 * ctypedef npy_int32      int32_t             # <<<<<<<<<<<<<<
 * ctypedef npy_int64      int64_t
 * #ctypedef npy_int96      int96_t
 */
typedef npy_int32 __pyx_t_5numpy_int32_t;

/* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":746
 * ctypedef npy_int16      int16_t
 * ctypedef npy_int32      int32_t
 * ctypedef npy_int64      int64_t             # <<<<<<<<<<<<<<
 * #ctypedef npy_int96      int96_t
 * #ctypedef npy_int128     int128_t
 */
typedef npy_int64 __pyx_t_5numpy_int64_t;

/* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":750
 * #ctypedef npy_int128     int128_t
 * 
 * ctypedef npy_uint8      uint8_t             # <<<<<<<<<<<<<<
 * ctypedef npy_uint16     uint16_t
 * ctypedef npy_uint32     uint32_t
 */
typedef npy_uint8 __pyx_t_5numpy_uint8_t;

/* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":751
 * 
 * ctypedef npy_uint8      uint8_t
 * ctypedef npy_uint16     uint16_t             # <<<<<<<<<<<<<<
 * ctypedef npy_uint32     uint32_t
 * ctypedef npy_uint64     uint64_t
 */
typedef npy_uint16 __pyx_t_5numpy_uint16_t;

/* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":752
 * ctypedef npy_uint8      uint8_t
 * ctypedef npy_uint16     uint16_t
 * ctypedef npy_uint32     uint32_t             # <<<<<<<<<<<<<<
 * ctypedef npy_uint64     uint64_t
 * #ctypedef npy_uint96     uint96_t
 */
typedef npy_uint32 __pyx_t_5numpy_uint32_t;

/* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":753
 * ctypedef npy_uint16     uint16_t
 * ctypedef npy_uint32     uint32_t
 * ctypedef npy_uint64     uint64_t             # <<<<<<<<<<<<<<
 * #ctypedef npy_uint96     uint96_t
 * #ctypedef npy_uint128    uint128_t
 */
typedef npy_uint64 __pyx_t_5numpy_uint64_t;

/* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":757
 * #ctypedef npy_uint128    uint128_t
 * 
 * ctypedef npy_float32    float32_t             # <<<<<<<<<<<<<<
 * ctypedef npy_float64    float64_t
 * #ctypedef npy_float80    float80_t
 */
typedef npy_float32 __pyx_t_5numpy_float32_t;

/* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":758
 * 
 * ctypedef npy_float32    float32_t
 * ctypedef npy_float64    float64_t             # <<<<<<<<<<<<<<
 * #ctypedef npy_float80    float80_t
 * #ctypedef npy_float128   float128_t
 */
typedef npy_float64 __pyx_t_5numpy_float64_t;

/* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":767
 * # The int types are mapped a bit surprising --
 * # numpy.int corresponds to 'l' and numpy.long to 'q'
 * ctypedef npy_long       int_t             # <<<<<<<<<<<<<<
 * ctypedef npy_longlong   long_t
 * ctypedef npy_longlong   longlong_t
 */
typedef npy_long __pyx_t_5numpy_int_t;

/* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":768
 * # numpy.int corresponds to 'l' and numpy.long to 'q'
 * ctypedef npy_long       int_t
 * ctypedef npy_longlong   long_t             # <<<<<<<<<<<<<<
 * ctypedef npy_longlong   longlong_t
 * 
 */
typedef npy_longlong __pyx_t_5numpy_long_t;

/* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":769
 * ctypedef npy_long       int_t
 * ctypedef npy_longlong   long_t
 * ctypedef npy_longlong   longlong_t             # <<<<<<<<<<<<<<
 * 
 * ctypedef npy_ulong      uint_t
 */
typedef npy_longlong __pyx_t_5numpy_longlong_t;

/* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":771
 * ctypedef npy_longlong   longlong_t
 * 
 * ctypedef npy_ulong      uint_t             # <<<<<<<<<<<<<<
 * ctypedef npy_ulonglong  ulong_t
 * ctypedef npy_ulonglong  ulonglong_t
 */
typedef npy_ulong __pyx_t_5numpy_uint_t;

/* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":772
 * 
 * ctypedef npy_ulong      uint_t
 * ctypedef npy_ulonglong  ulong_t             # <<<<<<<<<<<<<<
 * ctypedef npy_ulonglong  ulonglong_t
 * 
 */
typedef npy_ulonglong __pyx_t_5numpy_ulong_t;

/* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":773
 * ctypedef npy_ulong      uint_t
 * ctypedef npy_ulonglong  ulong_t
 * ctypedef npy_ulonglong  ulonglong_t             # <<<<<<<<<<<<<<
 * 
 * ctypedef npy_intp       intp_t
 */
typedef npy_ulonglong __pyx_t_5numpy_ulonglong_t;

/* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":775
 * ctypedef npy_ulonglong  ulonglong_t
 * 
 * ctypedef npy_intp       intp_t             # <<<<<<<<<<<<<<
 * ctypedef npy_uintp      uintp_t
 * 
 */
typedef npy_intp __pyx_t_5numpy_intp_t;

/* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":776
 * 
 * ctypedef npy_intp       intp_t
 * ctypedef npy_uintp      uintp_t             # <<<<<<<<<<<<<<
 * 
 * ctypedef npy_double     float_t
 */
typedef npy_uintp __pyx_t_5numpy_uintp_t;

/* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":778
 * ctypedef npy_uintp      uintp_t
 * 
 * ctypedef npy_double     float_t             # <<<<<<<<<<<<<<
 * ctypedef npy_double     double_t
 * ctypedef npy_longdouble longdouble_t
 */
typedef npy_double __pyx_t_5numpy_float_t;

/* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":779
 * 
 * ctypedef npy_double     float_t
 * ctypedef npy_double     double_t             # <<<<<<<<<<<<<<
 * ctypedef npy_longdouble longdouble_t
 * 
 */
typedef npy_double __pyx_t_5numpy_double_t;

/* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":780
 * ctypedef npy_double     float_t
 * ctypedef npy_double     double_t
 * ctypedef npy_longdouble longdouble_t             # <<<<<<<<<<<<<<
 * 
 * ctypedef npy_cfloat      cfloat_t
 */
typedef npy_longdouble __pyx_t_5numpy_longdouble_t;
/* Declarations.proto */
#if CYTHON_CCOMPLEX
  #ifdef __cplusplus
    typedef ::std::complex< float > __pyx_t_float_complex;
  #else
    typedef float _Complex __pyx_t_float_complex;
  #endif
#else
    typedef struct { float real, imag; } __pyx_t_float_complex;
#endif
static CYTHON_INLINE __pyx_t_float_complex __pyx_t_float_complex_from_parts(float, float);

/* Declarations.proto */
#if CYTHON_CCOMPLEX
  #ifdef __cplusplus
    typedef ::std::complex< double > __pyx_t_double_complex;
  #else
    typedef double _Complex __pyx_t_double_complex;
  #endif
#else
    typedef struct { double real, imag; } __pyx_t_double_complex;
#endif
static CYTHON_INLINE __pyx_t_double_complex __pyx_t_double_complex_from_parts(double, double);


/*--- Type declarations ---*/
struct PyGpuContextObject;
struct PyGpuArrayObject;
struct PyGpuKernelObject;
struct __pyx_obj_5pygpu_8gpuarray_flags;
struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct__genexpr;
struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_1___repr__;
struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_2_genexpr;
struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_3___getitem__;
struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_4_genexpr;
struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_5_genexpr;
struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_6_genexpr;
struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_7___setitem__;
struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_8_genexpr;
struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_9_genexpr;
struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_10_genexpr;

/* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":782
 * ctypedef npy_longdouble longdouble_t
 * 
 * ctypedef npy_cfloat      cfloat_t             # <<<<<<<<<<<<<<
 * ctypedef npy_cdouble     cdouble_t
 * ctypedef npy_clongdouble clongdouble_t
 */
typedef npy_cfloat __pyx_t_5numpy_cfloat_t;

/* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":783
 * 
 * ctypedef npy_cfloat      cfloat_t
 * ctypedef npy_cdouble     cdouble_t             # <<<<<<<<<<<<<<
 * ctypedef npy_clongdouble clongdouble_t
 * 
 */
typedef npy_cdouble __pyx_t_5numpy_cdouble_t;

/* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":784
 * ctypedef npy_cfloat      cfloat_t
 * ctypedef npy_cdouble     cdouble_t
 * ctypedef npy_clongdouble clongdouble_t             # <<<<<<<<<<<<<<
 * 
 * ctypedef npy_cdouble     complex_t
 */
typedef npy_clongdouble __pyx_t_5numpy_clongdouble_t;

/* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":786
 * ctypedef npy_clongdouble clongdouble_t
 * 
 * ctypedef npy_cdouble     complex_t             # <<<<<<<<<<<<<<
 * 
 * cdef inline object PyArray_MultiIterNew1(a):
 */
typedef npy_cdouble __pyx_t_5numpy_complex_t;

/* "pygpu/gpuarray.pxd":321
 *                                     object cls, GpuContext context)
 * 
 * cdef api class GpuContext [type PyGpuContextType, object PyGpuContextObject]:             # <<<<<<<<<<<<<<
 *     cdef dict __dict__
 *     cdef gpucontext* ctx
 */
struct PyGpuContextObject {
  PyObject_HEAD
  PyObject *__dict__;
  gpucontext *ctx;
  PyObject *kind;
  PyObject *__weakref__;
};


/* "pygpu/gpuarray.pxd":329
 * cdef GpuArray new_GpuArray(object cls, GpuContext ctx, object base)
 * 
 * cdef api class GpuArray [type PyGpuArrayType, object PyGpuArrayObject]:             # <<<<<<<<<<<<<<
 *     cdef _GpuArray ga
 *     cdef readonly GpuContext context
 */
struct PyGpuArrayObject {
  PyObject_HEAD
  struct __pyx_vtabstruct_5pygpu_8gpuarray_GpuArray *__pyx_vtab;
  GpuArray ga;
  struct PyGpuContextObject *context;
  PyObject *base;
  PyObject *__weakref__;
};


/* "pygpu/gpuarray.pxd":339
 *     cdef __cgetitem__(self, idx)
 * 
 * cdef api class GpuKernel [type PyGpuKernelType, object PyGpuKernelObject]:             # <<<<<<<<<<<<<<
 *     cdef _GpuKernel k
 *     cdef readonly GpuContext context
 */
struct PyGpuKernelObject {
  PyObject_HEAD
  struct __pyx_vtabstruct_5pygpu_8gpuarray_GpuKernel *__pyx_vtab;
  GpuKernel k;
  struct PyGpuContextObject *context;
  void **callbuf;
  PyObject *__weakref__;
};


/* "pygpu/gpuarray.pyx":1190
 * 
 * 
 * cdef class flags(object):             # <<<<<<<<<<<<<<
 *     cdef int fl
 * 
 */
struct __pyx_obj_5pygpu_8gpuarray_flags {
  PyObject_HEAD
  int fl;
};


/* "pygpu/gpuarray.pyx":118
 * }
 * 
 * cdef dict TYPE_TO_NP = dict((v, k) for k, v in NP_TO_TYPE.iteritems())             # <<<<<<<<<<<<<<
 * 
 * def register_dtype(np.dtype dtype, cname):
 */
struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct__genexpr {
  PyObject_HEAD
  PyObject *__pyx_v_k;
  PyObject *__pyx_v_v;
};


/* "pygpu/gpuarray.pyx":1268
 *         raise KeyError, "Unknown flag"
 * 
 *     def __repr__(self):             # <<<<<<<<<<<<<<
 *         return '\n'.join(" %s : %s" % (name.upper(), getattr(self, name))
 *                          for name in ["c_contiguous", "f_contiguous",
 */
struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_1___repr__ {
  PyObject_HEAD
  struct __pyx_obj_5pygpu_8gpuarray_flags *__pyx_v_self;
};


/* "pygpu/gpuarray.pyx":1269
 * 
 *     def __repr__(self):
 *         return '\n'.join(" %s : %s" % (name.upper(), getattr(self, name))             # <<<<<<<<<<<<<<
 *                          for name in ["c_contiguous", "f_contiguous",
 *                                       "owndata", "writeable", "aligned",
 */
struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_2_genexpr {
  PyObject_HEAD
  struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_1___repr__ *__pyx_outer_scope;
  PyObject *__pyx_v_name;
  PyObject *__pyx_t_0;
  Py_ssize_t __pyx_t_1;
};


/* "pygpu/gpuarray.pyx":1928
 *             raise TypeError, "len() of unsized object"
 * 
 *     def __getitem__(self, key):             # <<<<<<<<<<<<<<
 *         cdef unsigned int i
 * 
 */
struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_3___getitem__ {
  PyObject_HEAD
  PyObject *__pyx_v_key;
};


/* "pygpu/gpuarray.pyx":1939
 *         # the same as a tuple.
 *         if isinstance(key, list):
 *             if any(isinstance(k, slice) or k is Ellipsis for k in key):             # <<<<<<<<<<<<<<
 *                 return self.__getitem__(tuple(key))
 *             else:
 */
struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_4_genexpr {
  PyObject_HEAD
  struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_3___getitem__ *__pyx_outer_scope;
  PyObject *__pyx_v_k;
};


/* "pygpu/gpuarray.pyx":1949
 *             key = (key,)
 *         else:
 *             if all(isinstance(k, list) for k in key):             # <<<<<<<<<<<<<<
 *                 raise NotImplementedError, "fancy indexing not supported"
 * 
 */
struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_5_genexpr {
  PyObject_HEAD
  struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_3___getitem__ *__pyx_outer_scope;
  PyObject *__pyx_v_k;
};


/* "pygpu/gpuarray.pyx":1975
 * 
 *         # Remove the None entries for indexing
 *         getitem_idcs = tuple(k for k in key if k is not None)             # <<<<<<<<<<<<<<
 * 
 *         # For less than 1 index, fill up with slice(None) to the right.
 */
struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_6_genexpr {
  PyObject_HEAD
  struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_3___getitem__ *__pyx_outer_scope;
  PyObject *__pyx_v_k;
  PyObject *__pyx_t_0;
  Py_ssize_t __pyx_t_1;
  PyObject *(*__pyx_t_2)(PyObject *);
};


/* "pygpu/gpuarray.pyx":2071
 *             free(steps)
 * 
 *     def __setitem__(self, idx, v):             # <<<<<<<<<<<<<<
 *         cdef GpuArray tmp, gv
 * 
 */
struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_7___setitem__ {
  PyObject_HEAD
  PyObject *__pyx_v_idx;
};


/* "pygpu/gpuarray.pyx":2075
 * 
 *         if isinstance(idx, list):
 *             if any(isinstance(i, slice) or i is Ellipsis for i in idx):             # <<<<<<<<<<<<<<
 *                 self.__setitem__(tuple(idx), v)
 *             else:
 */
struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_8_genexpr {
  PyObject_HEAD
  struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_7___setitem__ *__pyx_outer_scope;
  PyObject *__pyx_v_i;
};


/* "pygpu/gpuarray.pyx":2084
 *             idx = (idx,)
 *         else:
 *             if all(isinstance(i, list) for i in idx):             # <<<<<<<<<<<<<<
 *                 raise NotImplementedError, "fancy indexing not supported"
 * 
 */
struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_9_genexpr {
  PyObject_HEAD
  struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_7___setitem__ *__pyx_outer_scope;
  PyObject *__pyx_v_i;
};


/* "pygpu/gpuarray.pyx":2093
 * 
 *         # Remove None entries, they should be ignored (as in Numpy)
 *         idx = tuple(i for i in idx if i is not None)             # <<<<<<<<<<<<<<
 *         tmp = self.__cgetitem__(idx)
 *         gv = carray(v, self.ga.typecode, False, 'A', 0, self.context, GpuArray)
 */
struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_10_genexpr {
  PyObject_HEAD
  struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_7___setitem__ *__pyx_outer_scope;
  PyObject *__pyx_v_i;
  PyObject *__pyx_t_0;
  Py_ssize_t __pyx_t_1;
  PyObject *(*__pyx_t_2)(PyObject *);
};



/* "pygpu/gpuarray.pyx":1558
 *     return <size_t>d
 * 
 * cdef class GpuArray:             # <<<<<<<<<<<<<<
 *     """
 *     Device array
 */

struct __pyx_vtabstruct_5pygpu_8gpuarray_GpuArray {
  PyObject *(*__pyx___index_helper)(struct PyGpuArrayObject *, PyObject *, unsigned int, Py_ssize_t *, Py_ssize_t *, Py_ssize_t *);
  PyObject *(*__pyx___cgetitem__)(struct PyGpuArrayObject *, PyObject *);
};
static struct __pyx_vtabstruct_5pygpu_8gpuarray_GpuArray *__pyx_vtabptr_5pygpu_8gpuarray_GpuArray;


/* "pygpu/gpuarray.pyx":2269
 * 
 * 
 * cdef class GpuKernel:             # <<<<<<<<<<<<<<
 *     """
 *     GpuKernel(source, name, types, context=None, have_double=False, have_small=False, have_complex=False, have_half=False, cuda=False, opencl=False)
 */

struct __pyx_vtabstruct_5pygpu_8gpuarray_GpuKernel {
  PyObject *(*do_call)(struct PyGpuKernelObject *, PyObject *, PyObject *, PyObject *, PyObject *, size_t);
  PyObject *(*_setarg)(struct PyGpuKernelObject *, unsigned int, int, PyObject *);
};
static struct __pyx_vtabstruct_5pygpu_8gpuarray_GpuKernel *__pyx_vtabptr_5pygpu_8gpuarray_GpuKernel;

/* --- Runtime support code (head) --- */
/* Refnanny.proto */
#ifndef CYTHON_REFNANNY
  #define CYTHON_REFNANNY 0
#endif
#if CYTHON_REFNANNY
  typedef struct {
    void (*INCREF)(void*, PyObject*, int);
    void (*DECREF)(void*, PyObject*, int);
    void (*GOTREF)(void*, PyObject*, int);
    void (*GIVEREF)(void*, PyObject*, int);
    void* (*SetupContext)(const char*, int, const char*);
    void (*FinishContext)(void**);
  } __Pyx_RefNannyAPIStruct;
  static __Pyx_RefNannyAPIStruct *__Pyx_RefNanny = NULL;
  static __Pyx_RefNannyAPIStruct *__Pyx_RefNannyImportAPI(const char *modname);
  #define __Pyx_RefNannyDeclarations void *__pyx_refnanny = NULL;
#ifdef WITH_THREAD
  #define __Pyx_RefNannySetupContext(name, acquire_gil)\
          if (acquire_gil) {\
              PyGILState_STATE __pyx_gilstate_save = PyGILState_Ensure();\
              __pyx_refnanny = __Pyx_RefNanny->SetupContext((name), __LINE__, __FILE__);\
              PyGILState_Release(__pyx_gilstate_save);\
          } else {\
              __pyx_refnanny = __Pyx_RefNanny->SetupContext((name), __LINE__, __FILE__);\
          }
#else
  #define __Pyx_RefNannySetupContext(name, acquire_gil)\
          __pyx_refnanny = __Pyx_RefNanny->SetupContext((name), __LINE__, __FILE__)
#endif
  #define __Pyx_RefNannyFinishContext()\
          __Pyx_RefNanny->FinishContext(&__pyx_refnanny)
  #define __Pyx_INCREF(r)  __Pyx_RefNanny->INCREF(__pyx_refnanny, (PyObject *)(r), __LINE__)
  #define __Pyx_DECREF(r)  __Pyx_RefNanny->DECREF(__pyx_refnanny, (PyObject *)(r), __LINE__)
  #define __Pyx_GOTREF(r)  __Pyx_RefNanny->GOTREF(__pyx_refnanny, (PyObject *)(r), __LINE__)
  #define __Pyx_GIVEREF(r) __Pyx_RefNanny->GIVEREF(__pyx_refnanny, (PyObject *)(r), __LINE__)
  #define __Pyx_XINCREF(r)  do { if((r) != NULL) {__Pyx_INCREF(r); }} while(0)
  #define __Pyx_XDECREF(r)  do { if((r) != NULL) {__Pyx_DECREF(r); }} while(0)
  #define __Pyx_XGOTREF(r)  do { if((r) != NULL) {__Pyx_GOTREF(r); }} while(0)
  #define __Pyx_XGIVEREF(r) do { if((r) != NULL) {__Pyx_GIVEREF(r);}} while(0)
#else
  #define __Pyx_RefNannyDeclarations
  #define __Pyx_RefNannySetupContext(name, acquire_gil)
  #define __Pyx_RefNannyFinishContext()
  #define __Pyx_INCREF(r) Py_INCREF(r)
  #define __Pyx_DECREF(r) Py_DECREF(r)
  #define __Pyx_GOTREF(r)
  #define __Pyx_GIVEREF(r)
  #define __Pyx_XINCREF(r) Py_XINCREF(r)
  #define __Pyx_XDECREF(r) Py_XDECREF(r)
  #define __Pyx_XGOTREF(r)
  #define __Pyx_XGIVEREF(r)
#endif
#define __Pyx_XDECREF_SET(r, v) do {\
        PyObject *tmp = (PyObject *) r;\
        r = v; __Pyx_XDECREF(tmp);\
    } while (0)
#define __Pyx_DECREF_SET(r, v) do {\
        PyObject *tmp = (PyObject *) r;\
        r = v; __Pyx_DECREF(tmp);\
    } while (0)
#define __Pyx_CLEAR(r)    do { PyObject* tmp = ((PyObject*)(r)); r = NULL; __Pyx_DECREF(tmp);} while(0)
#define __Pyx_XCLEAR(r)   do { if((r) != NULL) {PyObject* tmp = ((PyObject*)(r)); r = NULL; __Pyx_DECREF(tmp);}} while(0)

/* PyObjectGetAttrStr.proto */
#if CYTHON_USE_TYPE_SLOTS
static CYTHON_INLINE PyObject* __Pyx_PyObject_GetAttrStr(PyObject* obj, PyObject* attr_name) {
    PyTypeObject* tp = Py_TYPE(obj);
    if (likely(tp->tp_getattro))
        return tp->tp_getattro(obj, attr_name);
#if PY_MAJOR_VERSION < 3
    if (likely(tp->tp_getattr))
        return tp->tp_getattr(obj, PyString_AS_STRING(attr_name));
#endif
    return PyObject_GetAttr(obj, attr_name);
}
#else
#define __Pyx_PyObject_GetAttrStr(o,n) PyObject_GetAttr(o,n)
#endif

/* GetBuiltinName.proto */
static PyObject *__Pyx_GetBuiltinName(PyObject *name);

/* IterFinish.proto */
static CYTHON_INLINE int __Pyx_IterFinish(void);

/* PyFunctionFastCall.proto */
#if CYTHON_FAST_PYCALL
#define __Pyx_PyFunction_FastCall(func, args, nargs)\
    __Pyx_PyFunction_FastCallDict((func), (args), (nargs), NULL)
#if 1 || PY_VERSION_HEX < 0x030600B1
static PyObject *__Pyx_PyFunction_FastCallDict(PyObject *func, PyObject **args, int nargs, PyObject *kwargs);
#else
#define __Pyx_PyFunction_FastCallDict(func, args, nargs, kwargs) _PyFunction_FastCallDict(func, args, nargs, kwargs)
#endif
#endif

/* PyObjectCall.proto */
#if CYTHON_COMPILING_IN_CPYTHON
static CYTHON_INLINE PyObject* __Pyx_PyObject_Call(PyObject *func, PyObject *arg, PyObject *kw);
#else
#define __Pyx_PyObject_Call(func, arg, kw) PyObject_Call(func, arg, kw)
#endif

/* PyObjectCallMethO.proto */
#if CYTHON_COMPILING_IN_CPYTHON
static CYTHON_INLINE PyObject* __Pyx_PyObject_CallMethO(PyObject *func, PyObject *arg);
#endif

/* PyObjectCallNoArg.proto */
#if CYTHON_COMPILING_IN_CPYTHON
static CYTHON_INLINE PyObject* __Pyx_PyObject_CallNoArg(PyObject *func);
#else
#define __Pyx_PyObject_CallNoArg(func) __Pyx_PyObject_Call(func, __pyx_empty_tuple, NULL)
#endif

/* PyCFunctionFastCall.proto */
#if CYTHON_FAST_PYCCALL
static CYTHON_INLINE PyObject *__Pyx_PyCFunction_FastCall(PyObject *func, PyObject **args, Py_ssize_t nargs);
#else
#define __Pyx_PyCFunction_FastCall(func, args, nargs)  (assert(0), NULL)
#endif

/* PyObjectCallOneArg.proto */
static CYTHON_INLINE PyObject* __Pyx_PyObject_CallOneArg(PyObject *func, PyObject *arg);

/* PyObjectCallMethod0.proto */
static PyObject* __Pyx_PyObject_CallMethod0(PyObject* obj, PyObject* method_name);

/* RaiseNeedMoreValuesToUnpack.proto */
static CYTHON_INLINE void __Pyx_RaiseNeedMoreValuesError(Py_ssize_t index);

/* RaiseTooManyValuesToUnpack.proto */
static CYTHON_INLINE void __Pyx_RaiseTooManyValuesError(Py_ssize_t expected);

/* UnpackItemEndCheck.proto */
static int __Pyx_IternextUnpackEndCheck(PyObject *retval, Py_ssize_t expected);

/* RaiseNoneIterError.proto */
static CYTHON_INLINE void __Pyx_RaiseNoneNotIterableError(void);

/* UnpackTupleError.proto */
static void __Pyx_UnpackTupleError(PyObject *, Py_ssize_t index);

/* UnpackTuple2.proto */
#define __Pyx_unpack_tuple2(tuple, value1, value2, is_tuple, has_known_size, decref_tuple)\
    (likely(is_tuple || PyTuple_Check(tuple)) ?\
        (likely(has_known_size || PyTuple_GET_SIZE(tuple) == 2) ?\
            __Pyx_unpack_tuple2_exact(tuple, value1, value2, decref_tuple) :\
            (__Pyx_UnpackTupleError(tuple, 2), -1)) :\
        __Pyx_unpack_tuple2_generic(tuple, value1, value2, has_known_size, decref_tuple))
static CYTHON_INLINE int __Pyx_unpack_tuple2_exact(
    PyObject* tuple, PyObject** value1, PyObject** value2, int decref_tuple);
static int __Pyx_unpack_tuple2_generic(
    PyObject* tuple, PyObject** value1, PyObject** value2, int has_known_size, int decref_tuple);

/* dict_iter.proto */
static CYTHON_INLINE PyObject* __Pyx_dict_iterator(PyObject* dict, int is_dict, PyObject* method_name,
                                                   Py_ssize_t* p_orig_length, int* p_is_dict);
static CYTHON_INLINE int __Pyx_dict_iter_next(PyObject* dict_or_iter, Py_ssize_t orig_length, Py_ssize_t* ppos,
                                              PyObject** pkey, PyObject** pvalue, PyObject** pitem, int is_dict);

/* None.proto */
static CYTHON_INLINE long __Pyx_div_long(long, long);

/* None.proto */
static CYTHON_INLINE long __Pyx_mod_long(long, long);

/* PyThreadStateGet.proto */
#if CYTHON_FAST_THREAD_STATE
#define __Pyx_PyThreadState_declare  PyThreadState *__pyx_tstate;
#define __Pyx_PyThreadState_assign  __pyx_tstate = __Pyx_PyThreadState_Current;
#define __Pyx_PyErr_Occurred()  __pyx_tstate->curexc_type
#else
#define __Pyx_PyThreadState_declare
#define __Pyx_PyThreadState_assign
#define __Pyx_PyErr_Occurred()  PyErr_Occurred()
#endif

/* PyErrFetchRestore.proto */
#if CYTHON_FAST_THREAD_STATE
#define __Pyx_PyErr_Clear() __Pyx_ErrRestore(NULL, NULL, NULL)
#define __Pyx_ErrRestoreWithState(type, value, tb)  __Pyx_ErrRestoreInState(PyThreadState_GET(), type, value, tb)
#define __Pyx_ErrFetchWithState(type, value, tb)    __Pyx_ErrFetchInState(PyThreadState_GET(), type, value, tb)
#define __Pyx_ErrRestore(type, value, tb)  __Pyx_ErrRestoreInState(__pyx_tstate, type, value, tb)
#define __Pyx_ErrFetch(type, value, tb)    __Pyx_ErrFetchInState(__pyx_tstate, type, value, tb)
static CYTHON_INLINE void __Pyx_ErrRestoreInState(PyThreadState *tstate, PyObject *type, PyObject *value, PyObject *tb);
static CYTHON_INLINE void __Pyx_ErrFetchInState(PyThreadState *tstate, PyObject **type, PyObject **value, PyObject **tb);
#if CYTHON_COMPILING_IN_CPYTHON
#define __Pyx_PyErr_SetNone(exc) (Py_INCREF(exc), __Pyx_ErrRestore((exc), NULL, NULL))
#else
#define __Pyx_PyErr_SetNone(exc) PyErr_SetNone(exc)
#endif
#else
#define __Pyx_PyErr_Clear() PyErr_Clear()
#define __Pyx_PyErr_SetNone(exc) PyErr_SetNone(exc)
#define __Pyx_ErrRestoreWithState(type, value, tb)  PyErr_Restore(type, value, tb)
#define __Pyx_ErrFetchWithState(type, value, tb)  PyErr_Fetch(type, value, tb)
#define __Pyx_ErrRestoreInState(tstate, type, value, tb)  PyErr_Restore(type, value, tb)
#define __Pyx_ErrFetchInState(tstate, type, value, tb)  PyErr_Fetch(type, value, tb)
#define __Pyx_ErrRestore(type, value, tb)  PyErr_Restore(type, value, tb)
#define __Pyx_ErrFetch(type, value, tb)  PyErr_Fetch(type, value, tb)
#endif

/* RaiseException.proto */
static void __Pyx_Raise(PyObject *type, PyObject *value, PyObject *tb, PyObject *cause);

/* GetItemInt.proto */
#define __Pyx_GetItemInt(o, i, type, is_signed, to_py_func, is_list, wraparound, boundscheck)\
    (__Pyx_fits_Py_ssize_t(i, type, is_signed) ?\
    __Pyx_GetItemInt_Fast(o, (Py_ssize_t)i, is_list, wraparound, boundscheck) :\
    (is_list ? (PyErr_SetString(PyExc_IndexError, "list index out of range"), (PyObject*)NULL) :\
               __Pyx_GetItemInt_Generic(o, to_py_func(i))))
#define __Pyx_GetItemInt_List(o, i, type, is_signed, to_py_func, is_list, wraparound, boundscheck)\
    (__Pyx_fits_Py_ssize_t(i, type, is_signed) ?\
    __Pyx_GetItemInt_List_Fast(o, (Py_ssize_t)i, wraparound, boundscheck) :\
    (PyErr_SetString(PyExc_IndexError, "list index out of range"), (PyObject*)NULL))
static CYTHON_INLINE PyObject *__Pyx_GetItemInt_List_Fast(PyObject *o, Py_ssize_t i,
                                                              int wraparound, int boundscheck);
#define __Pyx_GetItemInt_Tuple(o, i, type, is_signed, to_py_func, is_list, wraparound, boundscheck)\
    (__Pyx_fits_Py_ssize_t(i, type, is_signed) ?\
    __Pyx_GetItemInt_Tuple_Fast(o, (Py_ssize_t)i, wraparound, boundscheck) :\
    (PyErr_SetString(PyExc_IndexError, "tuple index out of range"), (PyObject*)NULL))
static CYTHON_INLINE PyObject *__Pyx_GetItemInt_Tuple_Fast(PyObject *o, Py_ssize_t i,
                                                              int wraparound, int boundscheck);
static PyObject *__Pyx_GetItemInt_Generic(PyObject *o, PyObject* j);
static CYTHON_INLINE PyObject *__Pyx_GetItemInt_Fast(PyObject *o, Py_ssize_t i,
                                                     int is_list, int wraparound, int boundscheck);

/* WriteUnraisableException.proto */
static void __Pyx_WriteUnraisable(const char *name, int clineno,
                                  int lineno, const char *filename,
                                  int full_traceback, int nogil);

/* ExtTypeTest.proto */
static CYTHON_INLINE int __Pyx_TypeTest(PyObject *obj, PyTypeObject *type);

/* RaiseArgTupleInvalid.proto */
static void __Pyx_RaiseArgtupleInvalid(const char* func_name, int exact,
    Py_ssize_t num_min, Py_ssize_t num_max, Py_ssize_t num_found);

/* RaiseDoubleKeywords.proto */
static void __Pyx_RaiseDoubleKeywordsError(const char* func_name, PyObject* kw_name);

/* ParseKeywords.proto */
static int __Pyx_ParseOptionalKeywords(PyObject *kwds, PyObject **argnames[],\
    PyObject *kwds2, PyObject *values[], Py_ssize_t num_pos_args,\
    const char* function_name);

/* ArgTypeTest.proto */
#define __Pyx_ArgTypeTest(obj, type, none_allowed, name, exact)\
    ((likely((Py_TYPE(obj) == type) | (none_allowed && (obj == Py_None)))) ? 1 :\
        __Pyx__ArgTypeTest(obj, type, name, exact))
static int __Pyx__ArgTypeTest(PyObject *obj, PyTypeObject *type, const char *name, int exact);

/* dict_getitem_default.proto */
static PyObject* __Pyx_PyDict_GetItemDefault(PyObject* d, PyObject* key, PyObject* default_value);

/* SaveResetException.proto */
#if CYTHON_FAST_THREAD_STATE
#define __Pyx_ExceptionSave(type, value, tb)  __Pyx__ExceptionSave(__pyx_tstate, type, value, tb)
static CYTHON_INLINE void __Pyx__ExceptionSave(PyThreadState *tstate, PyObject **type, PyObject **value, PyObject **tb);
#define __Pyx_ExceptionReset(type, value, tb)  __Pyx__ExceptionReset(__pyx_tstate, type, value, tb)
static CYTHON_INLINE void __Pyx__ExceptionReset(PyThreadState *tstate, PyObject *type, PyObject *value, PyObject *tb);
#else
#define __Pyx_ExceptionSave(type, value, tb)   PyErr_GetExcInfo(type, value, tb)
#define __Pyx_ExceptionReset(type, value, tb)  PyErr_SetExcInfo(type, value, tb)
#endif

/* PyErrExceptionMatches.proto */
#if CYTHON_FAST_THREAD_STATE
#define __Pyx_PyErr_ExceptionMatches(err) __Pyx_PyErr_ExceptionMatchesInState(__pyx_tstate, err)
static CYTHON_INLINE int __Pyx_PyErr_ExceptionMatchesInState(PyThreadState* tstate, PyObject* err);
#else
#define __Pyx_PyErr_ExceptionMatches(err)  PyErr_ExceptionMatches(err)
#endif

/* decode_c_string_utf16.proto */
static CYTHON_INLINE PyObject *__Pyx_PyUnicode_DecodeUTF16(const char *s, Py_ssize_t size, const char *errors) {
    int byteorder = 0;
    return PyUnicode_DecodeUTF16(s, size, errors, &byteorder);
}
static CYTHON_INLINE PyObject *__Pyx_PyUnicode_DecodeUTF16LE(const char *s, Py_ssize_t size, const char *errors) {
    int byteorder = -1;
    return PyUnicode_DecodeUTF16(s, size, errors, &byteorder);
}
static CYTHON_INLINE PyObject *__Pyx_PyUnicode_DecodeUTF16BE(const char *s, Py_ssize_t size, const char *errors) {
    int byteorder = 1;
    return PyUnicode_DecodeUTF16(s, size, errors, &byteorder);
}

/* decode_c_bytes.proto */
static CYTHON_INLINE PyObject* __Pyx_decode_c_bytes(
         const char* cstring, Py_ssize_t length, Py_ssize_t start, Py_ssize_t stop,
         const char* encoding, const char* errors,
         PyObject* (*decode_func)(const char *s, Py_ssize_t size, const char *errors));

/* decode_bytes.proto */
static CYTHON_INLINE PyObject* __Pyx_decode_bytes(
         PyObject* string, Py_ssize_t start, Py_ssize_t stop,
         const char* encoding, const char* errors,
         PyObject* (*decode_func)(const char *s, Py_ssize_t size, const char *errors)) {
    return __Pyx_decode_c_bytes(
        PyBytes_AS_STRING(string), PyBytes_GET_SIZE(string),
        start, stop, encoding, errors, decode_func);
}

/* IncludeStringH.proto */
#include <string.h>

/* BytesEquals.proto */
static CYTHON_INLINE int __Pyx_PyBytes_Equals(PyObject* s1, PyObject* s2, int equals);

/* UnicodeEquals.proto */
static CYTHON_INLINE int __Pyx_PyUnicode_Equals(PyObject* s1, PyObject* s2, int equals);

/* StrEquals.proto */
#if PY_MAJOR_VERSION >= 3
#define __Pyx_PyString_Equals __Pyx_PyUnicode_Equals
#else
#define __Pyx_PyString_Equals __Pyx_PyBytes_Equals
#endif

/* GetModuleGlobalName.proto */
static CYTHON_INLINE PyObject *__Pyx_GetModuleGlobalName(PyObject *name);

/* decode_c_string.proto */
static CYTHON_INLINE PyObject* __Pyx_decode_c_string(
         const char* cstring, Py_ssize_t start, Py_ssize_t stop,
         const char* encoding, const char* errors,
         PyObject* (*decode_func)(const char *s, Py_ssize_t size, const char *errors));

/* GetException.proto */
#if CYTHON_FAST_THREAD_STATE
#define __Pyx_GetException(type, value, tb)  __Pyx__GetException(__pyx_tstate, type, value, tb)
static int __Pyx__GetException(PyThreadState *tstate, PyObject **type, PyObject **value, PyObject **tb);
#else
static int __Pyx_GetException(PyObject **type, PyObject **value, PyObject **tb);
#endif

/* SwapException.proto */
#if CYTHON_FAST_THREAD_STATE
#define __Pyx_ExceptionSwap(type, value, tb)  __Pyx__ExceptionSwap(__pyx_tstate, type, value, tb)
static CYTHON_INLINE void __Pyx__ExceptionSwap(PyThreadState *tstate, PyObject **type, PyObject **value, PyObject **tb);
#else
static CYTHON_INLINE void __Pyx_ExceptionSwap(PyObject **type, PyObject **value, PyObject **tb);
#endif

/* SliceObject.proto */
static CYTHON_INLINE PyObject* __Pyx_PyObject_GetSlice(
        PyObject* obj, Py_ssize_t cstart, Py_ssize_t cstop,
        PyObject** py_start, PyObject** py_stop, PyObject** py_slice,
        int has_cstart, int has_cstop, int wraparound);

/* PyIntBinop.proto */
#if !CYTHON_COMPILING_IN_PYPY
static PyObject* __Pyx_PyInt_AddObjC(PyObject *op1, PyObject *op2, long intval, int inplace);
#else
#define __Pyx_PyInt_AddObjC(op1, op2, intval, inplace)\
    (inplace ? PyNumber_InPlaceAdd(op1, op2) : PyNumber_Add(op1, op2))
#endif

/* None.proto */
static CYTHON_INLINE void __Pyx_RaiseUnboundLocalError(const char *varname);

/* KeywordStringCheck.proto */
static int __Pyx_CheckKeywordStrings(PyObject *kwdict, const char* function_name, int kw_allowed);

/* None.proto */
static CYTHON_INLINE void __Pyx_RaiseClosureNameError(const char *varname);

/* GetAttr.proto */
static CYTHON_INLINE PyObject *__Pyx_GetAttr(PyObject *, PyObject *);

/* StringJoin.proto */
#if PY_MAJOR_VERSION < 3
#define __Pyx_PyString_Join __Pyx_PyBytes_Join
#define __Pyx_PyBaseString_Join(s, v) (PyUnicode_CheckExact(s) ? PyUnicode_Join(s, v) : __Pyx_PyBytes_Join(s, v))
#else
#define __Pyx_PyString_Join PyUnicode_Join
#define __Pyx_PyBaseString_Join PyUnicode_Join
#endif
#if CYTHON_COMPILING_IN_CPYTHON
    #if PY_MAJOR_VERSION < 3
    #define __Pyx_PyBytes_Join _PyString_Join
    #else
    #define __Pyx_PyBytes_Join _PyBytes_Join
    #endif
#else
static CYTHON_INLINE PyObject* __Pyx_PyBytes_Join(PyObject* sep, PyObject* values);
#endif

/* SetItemInt.proto */
#define __Pyx_SetItemInt(o, i, v, type, is_signed, to_py_func, is_list, wraparound, boundscheck)\
    (__Pyx_fits_Py_ssize_t(i, type, is_signed) ?\
    __Pyx_SetItemInt_Fast(o, (Py_ssize_t)i, v, is_list, wraparound, boundscheck) :\
    (is_list ? (PyErr_SetString(PyExc_IndexError, "list assignment index out of range"), -1) :\
               __Pyx_SetItemInt_Generic(o, to_py_func(i), v)))
static int __Pyx_SetItemInt_Generic(PyObject *o, PyObject *j, PyObject *v);
static CYTHON_INLINE int __Pyx_SetItemInt_Fast(PyObject *o, Py_ssize_t i, PyObject *v,
                                               int is_list, int wraparound, int boundscheck);

/* PyIntBinop.proto */
#if !CYTHON_COMPILING_IN_PYPY
static PyObject* __Pyx_PyInt_EqObjC(PyObject *op1, PyObject *op2, long intval, int inplace);
#else
#define __Pyx_PyInt_EqObjC(op1, op2, intval, inplace)\
    PyObject_RichCompare(op1, op2, Py_EQ)
    #endif

/* PySequenceContains.proto */
static CYTHON_INLINE int __Pyx_PySequence_ContainsTF(PyObject* item, PyObject* seq, int eq) {
    int result = PySequence_Contains(seq, item);
    return unlikely(result < 0) ? result : (result == (eq == Py_EQ));
}

/* ListAppend.proto */
#if CYTHON_USE_PYLIST_INTERNALS && CYTHON_ASSUME_SAFE_MACROS
static CYTHON_INLINE int __Pyx_PyList_Append(PyObject* list, PyObject* x) {
    PyListObject* L = (PyListObject*) list;
    Py_ssize_t len = Py_SIZE(list);
    if (likely(L->allocated > len) & likely(len > (L->allocated >> 1))) {
        Py_INCREF(x);
        PyList_SET_ITEM(list, len, x);
        Py_SIZE(list) = len+1;
        return 0;
    }
    return PyList_Append(list, x);
}
#else
#define __Pyx_PyList_Append(L,x) PyList_Append(L,x)
#endif

/* ListExtend.proto */
static CYTHON_INLINE int __Pyx_PyList_Extend(PyObject* L, PyObject* v) {
#if CYTHON_COMPILING_IN_CPYTHON
    PyObject* none = _PyList_Extend((PyListObject*)L, v);
    if (unlikely(!none))
        return -1;
    Py_DECREF(none);
    return 0;
#else
    return PyList_SetSlice(L, PY_SSIZE_T_MAX, PY_SSIZE_T_MAX, v);
#endif
}

/* DictGetItem.proto */
#if PY_MAJOR_VERSION >= 3 && !CYTHON_COMPILING_IN_PYPY
static PyObject *__Pyx_PyDict_GetItem(PyObject *d, PyObject* key) {
    PyObject *value;
    value = PyDict_GetItemWithError(d, key);
    if (unlikely(!value)) {
        if (!PyErr_Occurred()) {
            PyObject* args = PyTuple_Pack(1, key);
            if (likely(args))
                PyErr_SetObject(PyExc_KeyError, args);
            Py_XDECREF(args);
        }
        return NULL;
    }
    Py_INCREF(value);
    return value;
}
#else
    #define __Pyx_PyDict_GetItem(d, key) PyObject_GetItem(d, key)
#endif

/* SetVTable.proto */
static int __Pyx_SetVtable(PyObject *dict, void *vtable);

/* Import.proto */
static PyObject *__Pyx_Import(PyObject *name, PyObject *from_list, int level);

/* CalculateMetaclass.proto */
static PyObject *__Pyx_CalculateMetaclass(PyTypeObject *metaclass, PyObject *bases);

/* Py3ClassCreate.proto */
static PyObject *__Pyx_Py3MetaclassPrepare(PyObject *metaclass, PyObject *bases, PyObject *name, PyObject *qualname,
                                           PyObject *mkw, PyObject *modname, PyObject *doc);
static PyObject *__Pyx_Py3ClassCreate(PyObject *metaclass, PyObject *name, PyObject *bases, PyObject *dict,
                                      PyObject *mkw, int calculate_metaclass, int allow_py2_metaclass);

/* CLineInTraceback.proto */
#ifdef CYTHON_CLINE_IN_TRACEBACK
#define __Pyx_CLineForTraceback(tstate, c_line)  (((CYTHON_CLINE_IN_TRACEBACK)) ? c_line : 0)
#else
static int __Pyx_CLineForTraceback(PyThreadState *tstate, int c_line);
#endif

/* CodeObjectCache.proto */
typedef struct {
    PyCodeObject* code_object;
    int code_line;
} __Pyx_CodeObjectCacheEntry;
struct __Pyx_CodeObjectCache {
    int count;
    int max_count;
    __Pyx_CodeObjectCacheEntry* entries;
};
static struct __Pyx_CodeObjectCache __pyx_code_cache = {0,0,NULL};
static int __pyx_bisect_code_objects(__Pyx_CodeObjectCacheEntry* entries, int count, int code_line);
static PyCodeObject *__pyx_find_code_object(int code_line);
static void __pyx_insert_code_object(int code_line, PyCodeObject* code_object);

/* AddTraceback.proto */
static void __Pyx_AddTraceback(const char *funcname, int c_line,
                               int py_line, const char *filename);

/* CIntToPy.proto */
static CYTHON_INLINE PyObject* __Pyx_PyInt_From_enum__GPUARRAY_TYPES(enum GPUARRAY_TYPES value);

/* CIntToPy.proto */
static CYTHON_INLINE PyObject* __Pyx_PyInt_From_int(int value);

/* CIntToPy.proto */
static CYTHON_INLINE PyObject* __Pyx_PyInt_From_long(long value);

/* CIntToPy.proto */
static CYTHON_INLINE PyObject* __Pyx_PyInt_From_unsigned_int(unsigned int value);

/* RealImag.proto */
#if CYTHON_CCOMPLEX
  #ifdef __cplusplus
    #define __Pyx_CREAL(z) ((z).real())
    #define __Pyx_CIMAG(z) ((z).imag())
  #else
    #define __Pyx_CREAL(z) (__real__(z))
    #define __Pyx_CIMAG(z) (__imag__(z))
  #endif
#else
    #define __Pyx_CREAL(z) ((z).real)
    #define __Pyx_CIMAG(z) ((z).imag)
#endif
#if defined(__cplusplus) && CYTHON_CCOMPLEX\
        && (defined(_WIN32) || defined(__clang__) || (defined(__GNUC__) && (__GNUC__ >= 5 || __GNUC__ == 4 && __GNUC_MINOR__ >= 4 )) || __cplusplus >= 201103)
    #define __Pyx_SET_CREAL(z,x) ((z).real(x))
    #define __Pyx_SET_CIMAG(z,y) ((z).imag(y))
#else
    #define __Pyx_SET_CREAL(z,x) __Pyx_CREAL(z) = (x)
    #define __Pyx_SET_CIMAG(z,y) __Pyx_CIMAG(z) = (y)
#endif

/* Arithmetic.proto */
#if CYTHON_CCOMPLEX
    #define __Pyx_c_eq_float(a, b)   ((a)==(b))
    #define __Pyx_c_sum_float(a, b)  ((a)+(b))
    #define __Pyx_c_diff_float(a, b) ((a)-(b))
    #define __Pyx_c_prod_float(a, b) ((a)*(b))
    #define __Pyx_c_quot_float(a, b) ((a)/(b))
    #define __Pyx_c_neg_float(a)     (-(a))
  #ifdef __cplusplus
    #define __Pyx_c_is_zero_float(z) ((z)==(float)0)
    #define __Pyx_c_conj_float(z)    (::std::conj(z))
    #if 1
        #define __Pyx_c_abs_float(z)     (::std::abs(z))
        #define __Pyx_c_pow_float(a, b)  (::std::pow(a, b))
    #endif
  #else
    #define __Pyx_c_is_zero_float(z) ((z)==0)
    #define __Pyx_c_conj_float(z)    (conjf(z))
    #if 1
        #define __Pyx_c_abs_float(z)     (cabsf(z))
        #define __Pyx_c_pow_float(a, b)  (cpowf(a, b))
    #endif
 #endif
#else
    static CYTHON_INLINE int __Pyx_c_eq_float(__pyx_t_float_complex, __pyx_t_float_complex);
    static CYTHON_INLINE __pyx_t_float_complex __Pyx_c_sum_float(__pyx_t_float_complex, __pyx_t_float_complex);
    static CYTHON_INLINE __pyx_t_float_complex __Pyx_c_diff_float(__pyx_t_float_complex, __pyx_t_float_complex);
    static CYTHON_INLINE __pyx_t_float_complex __Pyx_c_prod_float(__pyx_t_float_complex, __pyx_t_float_complex);
    static CYTHON_INLINE __pyx_t_float_complex __Pyx_c_quot_float(__pyx_t_float_complex, __pyx_t_float_complex);
    static CYTHON_INLINE __pyx_t_float_complex __Pyx_c_neg_float(__pyx_t_float_complex);
    static CYTHON_INLINE int __Pyx_c_is_zero_float(__pyx_t_float_complex);
    static CYTHON_INLINE __pyx_t_float_complex __Pyx_c_conj_float(__pyx_t_float_complex);
    #if 1
        static CYTHON_INLINE float __Pyx_c_abs_float(__pyx_t_float_complex);
        static CYTHON_INLINE __pyx_t_float_complex __Pyx_c_pow_float(__pyx_t_float_complex, __pyx_t_float_complex);
    #endif
#endif

/* Arithmetic.proto */
#if CYTHON_CCOMPLEX
    #define __Pyx_c_eq_double(a, b)   ((a)==(b))
    #define __Pyx_c_sum_double(a, b)  ((a)+(b))
    #define __Pyx_c_diff_double(a, b) ((a)-(b))
    #define __Pyx_c_prod_double(a, b) ((a)*(b))
    #define __Pyx_c_quot_double(a, b) ((a)/(b))
    #define __Pyx_c_neg_double(a)     (-(a))
  #ifdef __cplusplus
    #define __Pyx_c_is_zero_double(z) ((z)==(double)0)
    #define __Pyx_c_conj_double(z)    (::std::conj(z))
    #if 1
        #define __Pyx_c_abs_double(z)     (::std::abs(z))
        #define __Pyx_c_pow_double(a, b)  (::std::pow(a, b))
    #endif
  #else
    #define __Pyx_c_is_zero_double(z) ((z)==0)
    #define __Pyx_c_conj_double(z)    (conj(z))
    #if 1
        #define __Pyx_c_abs_double(z)     (cabs(z))
        #define __Pyx_c_pow_double(a, b)  (cpow(a, b))
    #endif
 #endif
#else
    static CYTHON_INLINE int __Pyx_c_eq_double(__pyx_t_double_complex, __pyx_t_double_complex);
    static CYTHON_INLINE __pyx_t_double_complex __Pyx_c_sum_double(__pyx_t_double_complex, __pyx_t_double_complex);
    static CYTHON_INLINE __pyx_t_double_complex __Pyx_c_diff_double(__pyx_t_double_complex, __pyx_t_double_complex);
    static CYTHON_INLINE __pyx_t_double_complex __Pyx_c_prod_double(__pyx_t_double_complex, __pyx_t_double_complex);
    static CYTHON_INLINE __pyx_t_double_complex __Pyx_c_quot_double(__pyx_t_double_complex, __pyx_t_double_complex);
    static CYTHON_INLINE __pyx_t_double_complex __Pyx_c_neg_double(__pyx_t_double_complex);
    static CYTHON_INLINE int __Pyx_c_is_zero_double(__pyx_t_double_complex);
    static CYTHON_INLINE __pyx_t_double_complex __Pyx_c_conj_double(__pyx_t_double_complex);
    #if 1
        static CYTHON_INLINE double __Pyx_c_abs_double(__pyx_t_double_complex);
        static CYTHON_INLINE __pyx_t_double_complex __Pyx_c_pow_double(__pyx_t_double_complex, __pyx_t_double_complex);
    #endif
#endif

/* CIntToPy.proto */
static CYTHON_INLINE PyObject* __Pyx_PyInt_From_enum__NPY_TYPES(enum NPY_TYPES value);

/* CIntFromPy.proto */
static CYTHON_INLINE size_t __Pyx_PyInt_As_size_t(PyObject *);

/* CIntFromPy.proto */
static CYTHON_INLINE unsigned int __Pyx_PyInt_As_unsigned_int(PyObject *);

/* CIntFromPy.proto */
static CYTHON_INLINE int __Pyx_PyInt_As_int(PyObject *);

/* CIntFromPy.proto */
static CYTHON_INLINE signed char __Pyx_PyInt_As_signed__char(PyObject *);

/* CIntFromPy.proto */
static CYTHON_INLINE unsigned char __Pyx_PyInt_As_unsigned_char(PyObject *);

/* CIntFromPy.proto */
static CYTHON_INLINE short __Pyx_PyInt_As_short(PyObject *);

/* CIntFromPy.proto */
static CYTHON_INLINE unsigned short __Pyx_PyInt_As_unsigned_short(PyObject *);

/* CIntFromPy.proto */
static CYTHON_INLINE long __Pyx_PyInt_As_long(PyObject *);

/* CIntFromPy.proto */
static CYTHON_INLINE unsigned long __Pyx_PyInt_As_unsigned_long(PyObject *);

/* FastTypeChecks.proto */
#if CYTHON_COMPILING_IN_CPYTHON
#define __Pyx_TypeCheck(obj, type) __Pyx_IsSubtype(Py_TYPE(obj), (PyTypeObject *)type)
static CYTHON_INLINE int __Pyx_IsSubtype(PyTypeObject *a, PyTypeObject *b);
static CYTHON_INLINE int __Pyx_PyErr_GivenExceptionMatches(PyObject *err, PyObject *type);
static CYTHON_INLINE int __Pyx_PyErr_GivenExceptionMatches2(PyObject *err, PyObject *type1, PyObject *type2);
#else
#define __Pyx_TypeCheck(obj, type) PyObject_TypeCheck(obj, (PyTypeObject *)type)
#define __Pyx_PyErr_GivenExceptionMatches(err, type) PyErr_GivenExceptionMatches(err, type)
#define __Pyx_PyErr_GivenExceptionMatches2(err, type1, type2) (PyErr_GivenExceptionMatches(err, type1) || PyErr_GivenExceptionMatches(err, type2))
#endif

/* FetchCommonType.proto */
static PyTypeObject* __Pyx_FetchCommonType(PyTypeObject* type);

/* PyObjectCallMethod1.proto */
static PyObject* __Pyx_PyObject_CallMethod1(PyObject* obj, PyObject* method_name, PyObject* arg);
static PyObject* __Pyx__PyObject_CallMethod1(PyObject* method, PyObject* arg);

/* CoroutineBase.proto */
typedef PyObject *(*__pyx_coroutine_body_t)(PyObject *, PyThreadState *, PyObject *);
typedef struct {
    PyObject_HEAD
    __pyx_coroutine_body_t body;
    PyObject *closure;
    PyObject *exc_type;
    PyObject *exc_value;
    PyObject *exc_traceback;
    PyObject *gi_weakreflist;
    PyObject *classobj;
    PyObject *yieldfrom;
    PyObject *gi_name;
    PyObject *gi_qualname;
    PyObject *gi_modulename;
    int resume_label;
    char is_running;
} __pyx_CoroutineObject;
static __pyx_CoroutineObject *__Pyx__Coroutine_New(
    PyTypeObject *type, __pyx_coroutine_body_t body, PyObject *closure,
    PyObject *name, PyObject *qualname, PyObject *module_name);
static __pyx_CoroutineObject *__Pyx__Coroutine_NewInit(
            __pyx_CoroutineObject *gen, __pyx_coroutine_body_t body, PyObject *closure,
            PyObject *name, PyObject *qualname, PyObject *module_name);
static int __Pyx_Coroutine_clear(PyObject *self);
static PyObject *__Pyx_Coroutine_Send(PyObject *self, PyObject *value);
static PyObject *__Pyx_Coroutine_Close(PyObject *self);
static PyObject *__Pyx_Coroutine_Throw(PyObject *gen, PyObject *args);
#define __Pyx_Coroutine_SwapException(self) {\
    __Pyx_ExceptionSwap(&(self)->exc_type, &(self)->exc_value, &(self)->exc_traceback);\
    __Pyx_Coroutine_ResetFrameBackpointer(self);\
    }
#define __Pyx_Coroutine_ResetAndClearException(self) {\
    __Pyx_ExceptionReset((self)->exc_type, (self)->exc_value, (self)->exc_traceback);\
    (self)->exc_type = (self)->exc_value = (self)->exc_traceback = NULL;\
    }
#if CYTHON_FAST_THREAD_STATE
#define __Pyx_PyGen_FetchStopIterationValue(pvalue)\
    __Pyx_PyGen__FetchStopIterationValue(__pyx_tstate, pvalue)
#else
#define __Pyx_PyGen_FetchStopIterationValue(pvalue)\
    __Pyx_PyGen__FetchStopIterationValue(__Pyx_PyThreadState_Current, pvalue)
#endif
static int __Pyx_PyGen__FetchStopIterationValue(PyThreadState *tstate, PyObject **pvalue);
static CYTHON_INLINE void __Pyx_Coroutine_ResetFrameBackpointer(__pyx_CoroutineObject *self);

/* PatchModuleWithCoroutine.proto */
static PyObject* __Pyx_Coroutine_patch_module(PyObject* module, const char* py_code);

/* PatchGeneratorABC.proto */
static int __Pyx_patch_abc(void);

/* Generator.proto */
#define __Pyx_Generator_USED
static PyTypeObject *__pyx_GeneratorType = 0;
#define __Pyx_Generator_CheckExact(obj) (Py_TYPE(obj) == __pyx_GeneratorType)
#define __Pyx_Generator_New(body, closure, name, qualname, module_name)\
    __Pyx__Coroutine_New(__pyx_GeneratorType, body, closure, name, qualname, module_name)
static PyObject *__Pyx_Generator_Next(PyObject *self);
static int __pyx_Generator_init(void);

/* CheckBinaryVersion.proto */
static int __Pyx_check_binary_version(void);

/* FunctionExport.proto */
static int __Pyx_ExportFunction(const char *name, void (*f)(void), const char *sig);

/* PyIdentifierFromString.proto */
#if !defined(__Pyx_PyIdentifier_FromString)
#if PY_MAJOR_VERSION < 3
  #define __Pyx_PyIdentifier_FromString(s) PyString_FromString(s)
#else
  #define __Pyx_PyIdentifier_FromString(s) PyUnicode_FromString(s)
#endif
#endif

/* ModuleImport.proto */
static PyObject *__Pyx_ImportModule(const char *name);

/* TypeImport.proto */
static PyTypeObject *__Pyx_ImportType(const char *module_name, const char *class_name, size_t size, int strict);

/* InitStrings.proto */
static int __Pyx_InitStrings(__Pyx_StringTabEntry *t);

static PyObject *__pyx_f_5pygpu_8gpuarray_8GpuArray___index_helper(struct PyGpuArrayObject *__pyx_v_self, PyObject *__pyx_v_key, unsigned int __pyx_v_i, Py_ssize_t *__pyx_v_start, Py_ssize_t *__pyx_v_stop, Py_ssize_t *__pyx_v_step); /* proto*/
static PyObject *__pyx_f_5pygpu_8gpuarray_8GpuArray___cgetitem__(struct PyGpuArrayObject *__pyx_v_self, PyObject *__pyx_v_key); /* proto*/
static PyObject *__pyx_f_5pygpu_8gpuarray_9GpuKernel_do_call(struct PyGpuKernelObject *__pyx_v_self, PyObject *__pyx_v_py_n, PyObject *__pyx_v_py_gs, PyObject *__pyx_v_py_ls, PyObject *__pyx_v_py_args, size_t __pyx_v_shared); /* proto*/
static PyObject *__pyx_f_5pygpu_8gpuarray_9GpuKernel__setarg(struct PyGpuKernelObject *__pyx_v_self, unsigned int __pyx_v_index, int __pyx_v_typecode, PyObject *__pyx_v_o); /* proto*/

/* Module declarations from 'libc.string' */

/* Module declarations from 'libc.stdio' */

/* Module declarations from 'libc' */

/* Module declarations from 'cpython.buffer' */

/* Module declarations from '__builtin__' */

/* Module declarations from 'cpython.type' */
static PyTypeObject *__pyx_ptype_7cpython_4type_type = 0;

/* Module declarations from 'cpython.version' */

/* Module declarations from 'cpython.exc' */

/* Module declarations from 'cpython.module' */

/* Module declarations from 'cpython.mem' */

/* Module declarations from 'cpython.tuple' */

/* Module declarations from 'cpython.list' */

/* Module declarations from 'cpython.sequence' */

/* Module declarations from 'cpython.mapping' */

/* Module declarations from 'cpython.iterator' */

/* Module declarations from 'cpython.number' */

/* Module declarations from 'cpython.int' */

/* Module declarations from '__builtin__' */

/* Module declarations from 'cpython.bool' */
static PyTypeObject *__pyx_ptype_7cpython_4bool_bool = 0;

/* Module declarations from 'cpython.long' */

/* Module declarations from 'cpython.float' */

/* Module declarations from '__builtin__' */

/* Module declarations from 'cpython.complex' */
static PyTypeObject *__pyx_ptype_7cpython_7complex_complex = 0;

/* Module declarations from 'cpython.string' */

/* Module declarations from 'cpython.unicode' */

/* Module declarations from 'cpython.dict' */

/* Module declarations from 'cpython.instance' */

/* Module declarations from 'cpython.function' */

/* Module declarations from 'cpython.method' */

/* Module declarations from 'cpython.weakref' */

/* Module declarations from 'cpython.getargs' */

/* Module declarations from 'cpython.pythread' */

/* Module declarations from 'cpython.pystate' */

/* Module declarations from 'cpython.cobject' */

/* Module declarations from 'cpython.oldbuffer' */

/* Module declarations from 'cpython.set' */

/* Module declarations from 'cpython.bytes' */

/* Module declarations from 'cpython.pycapsule' */

/* Module declarations from 'cpython' */

/* Module declarations from 'cpython.object' */

/* Module declarations from 'cpython.ref' */

/* Module declarations from 'numpy' */

/* Module declarations from 'numpy' */
static PyTypeObject *__pyx_ptype_5numpy_dtype = 0;
static PyTypeObject *__pyx_ptype_5numpy_flatiter = 0;
static PyTypeObject *__pyx_ptype_5numpy_broadcast = 0;
static PyTypeObject *__pyx_ptype_5numpy_ndarray = 0;
static PyTypeObject *__pyx_ptype_5numpy_ufunc = 0;
static CYTHON_INLINE char *__pyx_f_5numpy__util_dtypestring(PyArray_Descr *, char *, char *, int *); /*proto*/
static CYTHON_INLINE int __pyx_f_5numpy_import_array(void); /*proto*/

/* Module declarations from 'libc.stdlib' */

/* Module declarations from 'pygpu.gpuarray' */
static PyTypeObject *__pyx_ptype_5pygpu_8gpuarray_GpuContext = 0;
static PyTypeObject *__pyx_ptype_5pygpu_8gpuarray_GpuArray = 0;
static PyTypeObject *__pyx_ptype_5pygpu_8gpuarray_GpuKernel = 0;
static PyTypeObject *__pyx_ptype_5pygpu_8gpuarray_flags = 0;
static PyTypeObject *__pyx_ptype_5pygpu_8gpuarray___pyx_scope_struct__genexpr = 0;
static PyTypeObject *__pyx_ptype_5pygpu_8gpuarray___pyx_scope_struct_1___repr__ = 0;
static PyTypeObject *__pyx_ptype_5pygpu_8gpuarray___pyx_scope_struct_2_genexpr = 0;
static PyTypeObject *__pyx_ptype_5pygpu_8gpuarray___pyx_scope_struct_3___getitem__ = 0;
static PyTypeObject *__pyx_ptype_5pygpu_8gpuarray___pyx_scope_struct_4_genexpr = 0;
static PyTypeObject *__pyx_ptype_5pygpu_8gpuarray___pyx_scope_struct_5_genexpr = 0;
static PyTypeObject *__pyx_ptype_5pygpu_8gpuarray___pyx_scope_struct_6_genexpr = 0;
static PyTypeObject *__pyx_ptype_5pygpu_8gpuarray___pyx_scope_struct_7___setitem__ = 0;
static PyTypeObject *__pyx_ptype_5pygpu_8gpuarray___pyx_scope_struct_8_genexpr = 0;
static PyTypeObject *__pyx_ptype_5pygpu_8gpuarray___pyx_scope_struct_9_genexpr = 0;
static PyTypeObject *__pyx_ptype_5pygpu_8gpuarray___pyx_scope_struct_10_genexpr = 0;
static PyObject *__pyx_v_5pygpu_8gpuarray_NP_TO_TYPE = 0;
static PyObject *__pyx_v_5pygpu_8gpuarray_TYPE_TO_NP = 0;
static struct PyGpuContextObject *__pyx_v_5pygpu_8gpuarray_default_context = 0;
static void (*__pyx_v_5pygpu_8gpuarray_cuda_enter)(gpucontext *);
static void (*__pyx_v_5pygpu_8gpuarray_cuda_exit)(gpucontext *);
static int (*__pyx_v_5pygpu_8gpuarray_cuda_get_ipc_handle)(gpudata *, GpuArrayIpcMemHandle *);
static gpudata *(*__pyx_v_5pygpu_8gpuarray_cuda_open_ipc_handle)(gpucontext *, GpuArrayIpcMemHandle *, size_t);
static PyObject *__pyx_f_5pygpu_8gpuarray_PyArray_Empty(int, npy_intp *, PyArray_Descr *, int); /*proto*/
static PyTypeObject *__pyx_f_5pygpu_8gpuarray_get_exc(int); /*proto*/
static PyArray_Descr *__pyx_f_5pygpu_8gpuarray_dtype_to_npdtype(PyObject *); /*proto*/
static PyArray_Descr *__pyx_f_5pygpu_8gpuarray_typecode_to_dtype(int); /*proto*/
static int __pyx_f_5pygpu_8gpuarray_get_typecode(PyObject *); /*proto*/
static int __pyx_f_5pygpu_8gpuarray_dtype_to_typecode(PyObject *, int __pyx_skip_dispatch); /*proto*/
static ga_order __pyx_f_5pygpu_8gpuarray_to_ga_order(PyObject *); /*proto*/
static int __pyx_f_5pygpu_8gpuarray_py_CHKFLAGS(struct PyGpuArrayObject *, int); /*proto*/
static int __pyx_f_5pygpu_8gpuarray_py_ISONESEGMENT(struct PyGpuArrayObject *); /*proto*/
static int __pyx_f_5pygpu_8gpuarray_array_empty(struct PyGpuArrayObject *, gpucontext *, int, unsigned int, size_t const *, ga_order); /*proto*/
static int __pyx_f_5pygpu_8gpuarray_array_fromdata(struct PyGpuArrayObject *, gpudata *, size_t, int, unsigned int, size_t const *, Py_ssize_t const *, int); /*proto*/
static int __pyx_f_5pygpu_8gpuarray_array_view(struct PyGpuArrayObject *, struct PyGpuArrayObject *); /*proto*/
static int __pyx_f_5pygpu_8gpuarray_array_sync(struct PyGpuArrayObject *); /*proto*/
static int __pyx_f_5pygpu_8gpuarray_array_index(struct PyGpuArrayObject *, struct PyGpuArrayObject *, Py_ssize_t const *, Py_ssize_t const *, Py_ssize_t const *); /*proto*/
static int __pyx_f_5pygpu_8gpuarray_array_take1(struct PyGpuArrayObject *, struct PyGpuArrayObject *, struct PyGpuArrayObject *, int); /*proto*/
static int __pyx_f_5pygpu_8gpuarray_array_setarray(struct PyGpuArrayObject *, struct PyGpuArrayObject *); /*proto*/
static int __pyx_f_5pygpu_8gpuarray_array_reshape(struct PyGpuArrayObject *, struct PyGpuArrayObject *, unsigned int, size_t const *, ga_order, int); /*proto*/
static int __pyx_f_5pygpu_8gpuarray_array_transpose(struct PyGpuArrayObject *, struct PyGpuArrayObject *, unsigned int const *); /*proto*/
static int __pyx_f_5pygpu_8gpuarray_array_clear(struct PyGpuArrayObject *); /*proto*/
static int __pyx_f_5pygpu_8gpuarray_array_share(struct PyGpuArrayObject *, struct PyGpuArrayObject *); /*proto*/
static gpucontext *__pyx_f_5pygpu_8gpuarray_array_context(struct PyGpuArrayObject *); /*proto*/
static int __pyx_f_5pygpu_8gpuarray_array_move(struct PyGpuArrayObject *, struct PyGpuArrayObject *); /*proto*/
static int __pyx_f_5pygpu_8gpuarray_array_write(struct PyGpuArrayObject *, void *, size_t); /*proto*/
static int __pyx_f_5pygpu_8gpuarray_array_read(void *, size_t, struct PyGpuArrayObject *); /*proto*/
static int __pyx_f_5pygpu_8gpuarray_array_memset(struct PyGpuArrayObject *, int); /*proto*/
static int __pyx_f_5pygpu_8gpuarray_array_copy(struct PyGpuArrayObject *, struct PyGpuArrayObject *, ga_order); /*proto*/
static int __pyx_f_5pygpu_8gpuarray_array_transfer(struct PyGpuArrayObject *, struct PyGpuArrayObject *); /*proto*/
static char const *__pyx_f_5pygpu_8gpuarray_kernel_error(struct PyGpuKernelObject *, int); /*proto*/
static int __pyx_f_5pygpu_8gpuarray_kernel_init(struct PyGpuKernelObject *, gpucontext *, unsigned int, char const **, size_t const *, char const *, unsigned int, int const *, int); /*proto*/
static int __pyx_f_5pygpu_8gpuarray_kernel_clear(struct PyGpuKernelObject *); /*proto*/
static int __pyx_f_5pygpu_8gpuarray_kernel_sched(struct PyGpuKernelObject *, size_t, size_t *, size_t *); /*proto*/
static int __pyx_f_5pygpu_8gpuarray_kernel_call(struct PyGpuKernelObject *, unsigned int, size_t const *, size_t const *, size_t, void **); /*proto*/
static int __pyx_f_5pygpu_8gpuarray_kernel_property(struct PyGpuKernelObject *, int, void *); /*proto*/
static int __pyx_f_5pygpu_8gpuarray_ctx_property(struct PyGpuContextObject *, int, void *); /*proto*/
static struct PyGpuContextObject *__pyx_f_5pygpu_8gpuarray_ensure_context(struct PyGpuContextObject *); /*proto*/
static struct PyGpuContextObject *__pyx_f_5pygpu_8gpuarray_pygpu_default_context(void); /*proto*/
static int __pyx_f_5pygpu_8gpuarray_pygpu_GpuArray_Check(PyObject *); /*proto*/
static struct PyGpuContextObject *__pyx_f_5pygpu_8gpuarray_pygpu_init(PyObject *, gpucontext_props *); /*proto*/
static struct PyGpuArrayObject *__pyx_f_5pygpu_8gpuarray_pygpu_zeros(unsigned int, size_t const *, int, ga_order, struct PyGpuContextObject *, PyObject *); /*proto*/
static struct PyGpuArrayObject *__pyx_f_5pygpu_8gpuarray_pygpu_empty(unsigned int, size_t const *, int, ga_order, struct PyGpuContextObject *, PyObject *); /*proto*/
static struct PyGpuArrayObject *__pyx_f_5pygpu_8gpuarray_pygpu_fromgpudata(gpudata *, size_t, int, unsigned int, size_t const *, Py_ssize_t const *, struct PyGpuContextObject *, int, PyObject *, PyObject *); /*proto*/
static struct PyGpuArrayObject *__pyx_f_5pygpu_8gpuarray_pygpu_copy(struct PyGpuArrayObject *, ga_order); /*proto*/
static int __pyx_f_5pygpu_8gpuarray_pygpu_move(struct PyGpuArrayObject *, struct PyGpuArrayObject *); /*proto*/
static struct PyGpuArrayObject *__pyx_f_5pygpu_8gpuarray_pygpu_view(struct PyGpuArrayObject *, PyObject *); /*proto*/
static int __pyx_f_5pygpu_8gpuarray_pygpu_sync(struct PyGpuArrayObject *); /*proto*/
static struct PyGpuArrayObject *__pyx_f_5pygpu_8gpuarray_pygpu_empty_like(struct PyGpuArrayObject *, ga_order, int); /*proto*/
static PyArrayObject *__pyx_f_5pygpu_8gpuarray_pygpu_as_ndarray(struct PyGpuArrayObject *); /*proto*/
static PyArrayObject *__pyx_f_5pygpu_8gpuarray__pygpu_as_ndarray(struct PyGpuArrayObject *, PyArray_Descr *); /*proto*/
static struct PyGpuArrayObject *__pyx_f_5pygpu_8gpuarray_pygpu_index(struct PyGpuArrayObject *, Py_ssize_t const *, Py_ssize_t const *, Py_ssize_t const *); /*proto*/
static struct PyGpuArrayObject *__pyx_f_5pygpu_8gpuarray_pygpu_reshape(struct PyGpuArrayObject *, unsigned int, size_t const *, ga_order, int, int); /*proto*/
static struct PyGpuArrayObject *__pyx_f_5pygpu_8gpuarray_pygpu_transpose(struct PyGpuArrayObject *, unsigned int const *); /*proto*/
static int __pyx_f_5pygpu_8gpuarray_pygpu_transfer(struct PyGpuArrayObject *, struct PyGpuArrayObject *); /*proto*/
static struct PyGpuArrayObject *__pyx_f_5pygpu_8gpuarray_pygpu_concatenate(GpuArray const **, size_t, unsigned int, int, PyObject *, struct PyGpuContextObject *); /*proto*/
static struct PyGpuArrayObject *__pyx_f_5pygpu_8gpuarray_new_GpuArray(PyObject *, struct PyGpuContextObject *, PyObject *); /*proto*/
static PyObject *__pyx_f_5pygpu_8gpuarray__s(PyObject *); /*proto*/
static size_t __pyx_f_5pygpu_8gpuarray_countis(PyObject *, PyObject *); /*proto*/
static int __pyx_f_5pygpu_8gpuarray_strides_ok(struct PyGpuArrayObject *, PyObject *); /*proto*/
static void __pyx_f_5pygpu_8gpuarray_array_fix_flags(struct PyGpuArrayObject *); /*proto*/
static int __pyx_f_5pygpu_8gpuarray_array_split(GpuArray **, struct PyGpuArrayObject *, size_t, size_t *, unsigned int); /*proto*/
static int __pyx_f_5pygpu_8gpuarray_array_concatenate(struct PyGpuArrayObject *, GpuArray const **, size_t, unsigned int, int); /*proto*/
static PyObject *__pyx_f_5pygpu_8gpuarray_carray(PyObject *, PyObject *, PyObject *, PyObject *, unsigned int, struct PyGpuContextObject *, PyObject *); /*proto*/
#define __Pyx_MODULE_NAME "pygpu.gpuarray"
extern int __pyx_module_is_main_pygpu__gpuarray;
int __pyx_module_is_main_pygpu__gpuarray = 0;

/* Implementation of 'pygpu.gpuarray' */
static PyObject *__pyx_builtin_TypeError;
static PyObject *__pyx_builtin_range;
static PyObject *__pyx_builtin_RuntimeError;
static PyObject *__pyx_builtin_MemoryError;
static PyObject *__pyx_builtin_NotImplementedError;
static PyObject *__pyx_builtin_ValueError;
static PyObject *__pyx_builtin_IndexError;
static PyObject *__pyx_builtin_enumerate;
static PyObject *__pyx_builtin_KeyError;
static PyObject *__pyx_builtin_NotImplemented;
static PyObject *__pyx_builtin_Ellipsis;
static PyObject *__pyx_builtin_SystemError;
static PyObject *__pyx_builtin_id;
static PyObject *__pyx_builtin_ImportError;
static const char __pyx_k_A[] = "A";
static const char __pyx_k_C[] = "C";
static const char __pyx_k_F[] = "F";
static const char __pyx_k_a[] = "a";
static const char __pyx_k_b[] = "b";
static const char __pyx_k_c[] = "c";
static const char __pyx_k_d[] = "d";
static const char __pyx_k_f[] = "f";
static const char __pyx_k_h[] = "h";
static const char __pyx_k_i[] = "i";
static const char __pyx_k_l[] = "l";
static const char __pyx_k_m[] = "m";
static const char __pyx_k_n[] = "n";
static const char __pyx_k_p[] = "p";
static const char __pyx_k_r[] = "r";
static const char __pyx_k_s[] = "s";
static const char __pyx_k_t[] = "t";
static const char __pyx_k_v[] = "v";
static const char __pyx_k__4[] = "";
static const char __pyx_k__8[] = ":";
static const char __pyx_k_al[] = "al";
static const char __pyx_k_fl[] = "fl";
static const char __pyx_k_gs[] = "gs";
static const char __pyx_k_id[] = "id";
static const char __pyx_k_ls[] = "ls";
static const char __pyx_k_nd[] = "nd";
static const char __pyx_k_np[] = "np";
static const char __pyx_k_rs[] = "rs";
static const char __pyx_k_tb[] = "tb";
static const char __pyx_k__20[] = "\n";
static const char __pyx_k__22[] = "...";
static const char __pyx_k_als[] = "als";
static const char __pyx_k_cls[] = "cls";
static const char __pyx_k_ctx[] = "ctx";
static const char __pyx_k_dev[] = "dev";
static const char __pyx_k_doc[] = "__doc__";
static const char __pyx_k_err[] = "err";
static const char __pyx_k_fnc[] = "fnc";
static const char __pyx_k_get[] = "get";
static const char __pyx_k_hpy[] = "hpy";
static const char __pyx_k_ind[] = "ind";
static const char __pyx_k_new[] = "__new__";
static const char __pyx_k_own[] = "own";
static const char __pyx_k_ptr[] = "ptr";
static const char __pyx_k_res[] = "res";
static const char __pyx_k_s_s[] = " %s : %s";
static const char __pyx_k_sys[] = "sys";
static const char __pyx_k_tmp[] = "tmp";
static const char __pyx_k_SIZE[] = "SIZE";
static const char __pyx_k_TODO[] = "TODO";
static const char __pyx_k_args[] = "args";
static const char __pyx_k_axis[] = "axis";
static const char __pyx_k_base[] = "base";
static const char __pyx_k_bool[] = "bool";
static const char __pyx_k_copy[] = "copy";
static const char __pyx_k_cuda[] = "cuda";
static const char __pyx_k_data[] = "data";
static const char __pyx_k_forc[] = "forc";
static const char __pyx_k_init[] = "init";
static const char __pyx_k_int8[] = "int8";
static const char __pyx_k_join[] = "join";
static const char __pyx_k_kind[] = "kind";
static const char __pyx_k_main[] = "__main__";
static const char __pyx_k_name[] = "name";
static const char __pyx_k_send[] = "send";
static const char __pyx_k_size[] = "size";
static const char __pyx_k_test[] = "__test__";
static const char __pyx_k_view[] = "view";
static const char __pyx_k_SSIZE[] = "SSIZE";
static const char __pyx_k_UTF_8[] = "UTF-8";
static const char __pyx_k_array[] = "array";
static const char __pyx_k_cdims[] = "cdims";
static const char __pyx_k_class[] = "__class__";
static const char __pyx_k_close[] = "close";
static const char __pyx_k_cname[] = "cname";
static const char __pyx_k_dtype[] = "dtype";
static const char __pyx_k_empty[] = "empty";
static const char __pyx_k_flags[] = "flags";
static const char __pyx_k_index[] = "index";
static const char __pyx_k_int16[] = "int16";
static const char __pyx_k_int32[] = "int32";
static const char __pyx_k_int64[] = "int64";
static const char __pyx_k_multi[] = "multi";
static const char __pyx_k_ndmin[] = "ndmin";
static const char __pyx_k_numpy[] = "numpy";
static const char __pyx_k_order[] = "order";
static const char __pyx_k_proto[] = "proto";
static const char __pyx_k_range[] = "range";
static const char __pyx_k_sched[] = "sched";
static const char __pyx_k_shape[] = "shape";
static const char __pyx_k_split[] = "split";
static const char __pyx_k_throw[] = "throw";
static const char __pyx_k_types[] = "types";
static const char __pyx_k_uint8[] = "uint8";
static const char __pyx_k_upper[] = "upper";
static const char __pyx_k_zeros[] = "zeros";
static const char __pyx_k_calloc[] = "calloc";
static const char __pyx_k_carray[] = "carray";
static const char __pyx_k_encode[] = "encode";
static const char __pyx_k_farray[] = "farray";
static const char __pyx_k_import[] = "__import__";
static const char __pyx_k_ldtype[] = "ldtype";
static const char __pyx_k_module[] = "__module__";
static const char __pyx_k_offset[] = "offset";
static const char __pyx_k_opencl[] = "opencl";
static const char __pyx_k_shared[] = "shared";
static const char __pyx_k_single[] = "single";
static const char __pyx_k_source[] = "source";
static const char __pyx_k_uint16[] = "uint16";
static const char __pyx_k_uint32[] = "uint32";
static const char __pyx_k_uint64[] = "uint64";
static const char __pyx_k_aligned[] = "aligned";
static const char __pyx_k_asarray[] = "asarray";
static const char __pyx_k_behaved[] = "behaved";
static const char __pyx_k_context[] = "context";
static const char __pyx_k_default[] = "default";
static const char __pyx_k_float16[] = "float16";
static const char __pyx_k_float32[] = "float32";
static const char __pyx_k_float64[] = "float64";
static const char __pyx_k_fortran[] = "fortran";
static const char __pyx_k_genexpr[] = "genexpr";
static const char __pyx_k_getitem[] = "__getitem__";
static const char __pyx_k_isdigit[] = "isdigit";
static const char __pyx_k_maxsize[] = "maxsize";
static const char __pyx_k_numargs[] = "numargs";
static const char __pyx_k_owndata[] = "owndata";
static const char __pyx_k_prepare[] = "__prepare__";
static const char __pyx_k_reshape[] = "reshape";
static const char __pyx_k_restype[] = "restype";
static const char __pyx_k_setitem[] = "__setitem__";
static const char __pyx_k_split_2[] = "_split";
static const char __pyx_k_strides[] = "strides";
static const char __pyx_k_Ellipsis[] = "Ellipsis";
static const char __pyx_k_KeyError[] = "KeyError";
static const char __pyx_k_cstrides[] = "cstrides";
static const char __pyx_k_devcount[] = "devcount";
static const char __pyx_k_gpuarray[] = "gpuarray.";
static const char __pyx_k_platform[] = "platform";
static const char __pyx_k_qualname[] = "__qualname__";
static const char __pyx_k_typecode[] = "typecode";
static const char __pyx_k_writable[] = "writable";
static const char __pyx_k_TypeError[] = "TypeError";
static const char __pyx_k_complex64[] = "complex64";
static const char __pyx_k_enumerate[] = "enumerate";
static const char __pyx_k_have_half[] = "have_half";
static const char __pyx_k_iteritems[] = "iteritems";
static const char __pyx_k_metaclass[] = "__metaclass__";
static const char __pyx_k_platcount[] = "platcount";
static const char __pyx_k_writeable[] = "writeable";
static const char __pyx_k_IndexError[] = "IndexError";
static const char __pyx_k_ValueError[] = "ValueError";
static const char __pyx_k_complex128[] = "complex128";
static const char __pyx_k_have_small[] = "have_small";
static const char __pyx_k_pyx_vtable[] = "__pyx_vtable__";
static const char __pyx_k_startswith[] = "startswith";
static const char __pyx_k_ImportError[] = "ImportError";
static const char __pyx_k_MemoryError[] = "MemoryError";
static const char __pyx_k_SystemError[] = "SystemError";
static const char __pyx_k_abi_version[] = "abi_version";
static const char __pyx_k_api_version[] = "api_version";
static const char __pyx_k_cl_make_ctx[] = "cl_make_ctx";
static const char __pyx_k_cl_wrap_ctx[] = "cl_wrap_ctx";
static const char __pyx_k_concatenate[] = "_concatenate";
static const char __pyx_k_have_double[] = "have_double";
static const char __pyx_k_C_CONTIGUOUS[] = "C_CONTIGUOUS";
static const char __pyx_k_F_CONTIGUOUS[] = "F_CONTIGUOUS";
static const char __pyx_k_RuntimeError[] = "RuntimeError";
static const char __pyx_k_Unknown_flag[] = "Unknown flag";
static const char __pyx_k_c_contiguous[] = "c_contiguous";
static const char __pyx_k_f_contiguous[] = "f_contiguous";
static const char __pyx_k_from_gpudata[] = "from_gpudata";
static const char __pyx_k_have_complex[] = "have_complex";
static const char __pyx_k_updateifcopy[] = "updateifcopy";
static const char __pyx_k_count_devices[] = "count_devices";
static const char __pyx_k_cuda_make_ctx[] = "cuda_make_ctx";
static const char __pyx_k_cuda_wrap_ctx[] = "cuda_wrap_ctx";
static const char __pyx_k_empty_like_me[] = "_empty_like_me";
static const char __pyx_k_major_version[] = "major_version";
static const char __pyx_k_minor_version[] = "minor_version";
static const char __pyx_k_single_stream[] = "single_stream";
static const char __pyx_k_NotImplemented[] = "NotImplemented";
static const char __pyx_k_asfortranarray[] = "asfortranarray";
static const char __pyx_k_dtype_to_ctype[] = "dtype_to_ctype";
static const char __pyx_k_max_cache_size[] = "max_cache_size";
static const char __pyx_k_pygpu_gpuarray[] = "pygpu.gpuarray";
static const char __pyx_k_register_dtype[] = "register_dtype";
static const char __pyx_k_count_platforms[] = "count_platforms";
static const char __pyx_k_open_ipc_handle[] = "open_ipc_handle";
static const char __pyx_k_No_mapping_for_s[] = "No mapping for %s";
static const char __pyx_k_axes_don_t_match[] = "axes don't match: ";
static const char __pyx_k_may_share_memory[] = "may_share_memory";
static const char __pyx_k_too_many_indices[] = "too many indices";
static const char __pyx_k_Expected_a_string[] = "Expected a string";
static const char __pyx_k_GpuArrayException[] = "GpuArrayException";
static const char __pyx_k_ascontiguousarray[] = "ascontiguousarray";
static const char __pyx_k_kernel_cache_path[] = "kernel_cache_path";
static const char __pyx_k_unhashable_type_s[] = "unhashable type '%s'";
static const char __pyx_k_cline_in_traceback[] = "cline_in_traceback";
static const char __pyx_k_initial_cache_size[] = "initial_cache_size";
static const char __pyx_k_pygpu_gpuarray_pyx[] = "pygpu/gpuarray.pyx";
static const char __pyx_k_NotImplementedError[] = "NotImplementedError";
static const char __pyx_k_cannot_index_with_s[] = "cannot index with: %s";
static const char __pyx_k_expected_a_GpuArray[] = "expected a GpuArray";
static const char __pyx_k_get_default_context[] = "get_default_context";
static const char __pyx_k_index_out_of_bounds[] = "index out of bounds";
static const char __pyx_k_kernel_cache_path_b[] = "kernel_cache_path_b";
static const char __pyx_k_set_default_context[] = "set_default_context";
static const char __pyx_k_No_context_specified[] = "No context specified.";
static const char __pyx_k_UnsupportedException[] = "UnsupportedException";
static const char __pyx_k_Unknown_device_format[] = "Unknown device format:";
static const char __pyx_k_gs_is_not_int_or_list[] = "gs is not int or list";
static const char __pyx_k_index_d_out_of_bounds[] = "index %d out of bounds";
static const char __pyx_k_len_of_unsized_object[] = "len() of unsized object";
static const char __pyx_k_ls_is_not_int_or_list[] = "ls is not int or list";
static const char __pyx_k_repr___locals_genexpr[] = "__repr__.<locals>.genexpr";
static const char __pyx_k_nd_mismatch_for_gs_int[] = "nd mismatch for gs (int)";
static const char __pyx_k_Can_t_allocate_new_type[] = "Can't allocate new type";
static const char __pyx_k_Could_not_register_type[] = "Could not register type";
static const char __pyx_k_This_is_for_CUDA_arrays[] = "This is for CUDA arrays.";
static const char __pyx_k_cl_make_ctx_call_failed[] = "cl_make_ctx call failed";
static const char __pyx_k_cuda_exit_not_available[] = "cuda_exit not available";
static const char __pyx_k_n_is_specified_and_nd_1[] = "n is specified and nd != 1";
static const char __pyx_k_nd_mismatch_for_gs_None[] = "nd mismatch for gs (None)";
static const char __pyx_k_Expected_index_with_nd_1[] = "Expected index with nd=1";
static const char __pyx_k_This_array_has_an_offset[] = "This array has an offset.";
static const char __pyx_k_could_not_allocate_cdims[] = "could not allocate cdims";
static const char __pyx_k_cuda_enter_not_available[] = "cuda_enter not available";
static const char __pyx_k_data_type_not_understood[] = "data type not understood";
static const char __pyx_k_getitem___locals_genexpr[] = "__getitem__.<locals>.genexpr";
static const char __pyx_k_nd_mismatch_for_gs_tuple[] = "nd mismatch for gs (tuple)";
static const char __pyx_k_setitem___locals_genexpr[] = "__setitem__.<locals>.genexpr";
static const char __pyx_k_This_is_for_OpenCL_arrays[] = "This is for OpenCL arrays.";
static const char __pyx_k_cuda_make_ctx_call_failed[] = "cuda_make_ctx call failed";
static const char __pyx_k_Called_raw_GpuArray___init[] = "Called raw GpuArray.__init__";
static const char __pyx_k_Expected_d_arguments_got_d[] = "Expected %d arguments, got %d,";
static const char __pyx_k_split_on_non_existant_axis[] = "split on non-existant axis";
static const char __pyx_k_0_d_arrays_can_t_be_indexed[] = "0-d arrays can't be indexed";
static const char __pyx_k_ctx_is_None_in_new_GpuArray[] = "ctx is None in new_GpuArray";
static const char __pyx_k_ndarray_is_not_C_contiguous[] = "ndarray is not C contiguous";
static const char __pyx_k_Called_raw_GpuContext___init[] = "Called raw GpuContext.__init__";
static const char __pyx_k_Only_works_for_cuda_contexts[] = "Only works for cuda contexts";
static const char __pyx_k_fancy_indexing_not_supported[] = "fancy indexing not supported";
static const char __pyx_k_Cannot_pickle_GpuArray_object[] = "Cannot pickle GpuArray object";
static const char __pyx_k_compute_axis_is_out_of_bounds[] = "compute_axis is out of bounds";
static const char __pyx_k_gs_is_not_of_length_3_or_less[] = "gs is not of length 3 or less";
static const char __pyx_k_ls_is_not_of_length_3_or_less[] = "ls is not of length 3 or less";
static const char __pyx_k_Cannot_pickle_GpuKernel_object[] = "Cannot pickle GpuKernel object";
static const char __pyx_k_Exception_used_for_most_errors[] = "\n    Exception used for most errors related to libgpuarray.\n    ";
static const char __pyx_k_Cannot_pickle_GpuContext_object[] = "Cannot pickle GpuContext object";
static const char __pyx_k_GpuArray_and_Numpy_array_do_not[] = "GpuArray and Numpy array do not have matching data types";
static const char __pyx_k_OpenCL_name_incorrect_Should_be[] = "OpenCL name incorrect. Should be opencl<int>:<int> instead got: ";
static const char __pyx_k_cl_make_ctx_extension_is_absent[] = "cl_make_ctx extension is absent";
static const char __pyx_k_numpy_core_multiarray_failed_to[] = "numpy.core.multiarray failed to import";
static const char __pyx_k_strides_must_be_the_same_length[] = "strides must be the same length as shape";
static const char __pyx_k_unknown_dtype_code_in_numpy_pxd[] = "unknown dtype code in numpy.pxd (%d)";
static const char __pyx_k_Bad_typecode_in__setarg_d_please[] = "Bad typecode in _setarg: %d (please report this, it is a bug)";
static const char __pyx_k_Context_manager_only_works_for_c[] = "Context manager only works for cuda";
static const char __pyx_k_Could_not_get_necessary_extensio[] = "Could not get necessary extension";
static const char __pyx_k_Destination_GpuArray_is_not_cont[] = "Destination GpuArray is not contiguous";
static const char __pyx_k_Destination_GpuArray_is_not_well[] = "Destination GpuArray is not well behaved: aligned and writeable";
static const char __pyx_k_Destination_Numpy_array_is_not_w[] = "Destination Numpy array is not well behaved: aligned and writeable";
static const char __pyx_k_Format_string_allocated_too_shor[] = "Format string allocated too short, see comment in numpy.pxd";
static const char __pyx_k_Invalid_array_or_destroyed_conte[] = "Invalid array or destroyed context";
static const char __pyx_k_Invalid_kernel_or_destroyed_cont[] = "Invalid kernel or destroyed context";
static const char __pyx_k_Must_specify_size_n_or_both_gs_a[] = "Must specify size (n) or both gs and ls";
static const char __pyx_k_Non_native_byte_order_not_suppor[] = "Non-native byte order not supported";
static const char __pyx_k_The_truth_value_of_a_multi_eleme[] = "The truth value of a multi-element array is ambiguous";
static const char __pyx_k_Truth_value_of_array_with_more_t[] = "Truth value of array with more than one element is ambiguous";
static const char __pyx_k_Valid_orders_are_A_any_C_C_F_For[] = "Valid orders are: 'A' (any), 'C' (C), 'F' (Fortran)";
static const char __pyx_k_cannot_copy_an_array_to_a_differ[] = "cannot copy an array to a different context";
static const char __pyx_k_cannot_use_more_than_one_Ellipsi[] = "cannot use more than one Ellipsis";
static const char __pyx_k_cuda_make_ctx_extension_is_absen[] = "cuda_make_ctx extension is absent";
static const char __pyx_k_don_t_know_how_to_convert_to_dty[] = "don't know how to convert to dtype: %s";
static const char __pyx_k_expected_GpuArrays_to_concatenat[] = "expected GpuArrays to concatenate";
static const char __pyx_k_gpuarray_array_content_not_avail[] = "gpuarray.array(<content not available>)";
static const char __pyx_k_ndarray_is_not_Fortran_contiguou[] = "ndarray is not Fortran contiguous";
static const char __pyx_k_new_strides_are_the_wrong_length[] = "new strides are the wrong length";
static const char __pyx_k_new_strides_go_outside_of_alloca[] = "new strides go outside of allocated memory";
static const char __pyx_k_numpy_core_umath_failed_to_impor[] = "numpy.core.umath failed to import";
static const char __pyx_k_transfer_only_works_for_contigou[] = "transfer() only works for contigous source";
static const char __pyx_k_undefined_comparison_for_flag_ob[] = "undefined comparison for flag object";
static const char __pyx_k_unexpected_value_for_parameter_s[] = "unexpected value for parameter sched: %s";
static const char __pyx_k_GpuArray_and_Numpy_array_do_not_2[] = "GpuArray and Numpy array do not have the same size in bytes";
static const char __pyx_k_GpuArray_and_Numpy_array_do_not_3[] = "GpuArray and Numpy array do not match in contiguity or GpuArray is not aligned";
static const char __pyx_k_Format_string_allocated_too_shor_2[] = "Format string allocated too short.";
static PyObject *__pyx_kp_s_0_d_arrays_can_t_be_indexed;
static PyObject *__pyx_n_s_A;
static PyObject *__pyx_kp_s_Bad_typecode_in__setarg_d_please;
static PyObject *__pyx_n_s_C;
static PyObject *__pyx_n_s_C_CONTIGUOUS;
static PyObject *__pyx_kp_s_Called_raw_GpuArray___init;
static PyObject *__pyx_kp_s_Called_raw_GpuContext___init;
static PyObject *__pyx_kp_s_Can_t_allocate_new_type;
static PyObject *__pyx_kp_s_Cannot_pickle_GpuArray_object;
static PyObject *__pyx_kp_s_Cannot_pickle_GpuContext_object;
static PyObject *__pyx_kp_s_Cannot_pickle_GpuKernel_object;
static PyObject *__pyx_kp_s_Context_manager_only_works_for_c;
static PyObject *__pyx_kp_s_Could_not_get_necessary_extensio;
static PyObject *__pyx_kp_s_Could_not_register_type;
static PyObject *__pyx_kp_s_Destination_GpuArray_is_not_cont;
static PyObject *__pyx_kp_s_Destination_GpuArray_is_not_well;
static PyObject *__pyx_kp_s_Destination_Numpy_array_is_not_w;
static PyObject *__pyx_n_s_Ellipsis;
static PyObject *__pyx_kp_s_Exception_used_for_most_errors;
static PyObject *__pyx_kp_s_Expected_a_string;
static PyObject *__pyx_kp_s_Expected_d_arguments_got_d;
static PyObject *__pyx_kp_s_Expected_index_with_nd_1;
static PyObject *__pyx_n_s_F;
static PyObject *__pyx_n_s_F_CONTIGUOUS;
static PyObject *__pyx_kp_u_Format_string_allocated_too_shor;
static PyObject *__pyx_kp_u_Format_string_allocated_too_shor_2;
static PyObject *__pyx_n_s_GpuArrayException;
static PyObject *__pyx_kp_s_GpuArray_and_Numpy_array_do_not;
static PyObject *__pyx_kp_s_GpuArray_and_Numpy_array_do_not_2;
static PyObject *__pyx_kp_s_GpuArray_and_Numpy_array_do_not_3;
static PyObject *__pyx_n_s_ImportError;
static PyObject *__pyx_n_s_IndexError;
static PyObject *__pyx_kp_s_Invalid_array_or_destroyed_conte;
static PyObject *__pyx_kp_s_Invalid_kernel_or_destroyed_cont;
static PyObject *__pyx_n_s_KeyError;
static PyObject *__pyx_n_s_MemoryError;
static PyObject *__pyx_kp_s_Must_specify_size_n_or_both_gs_a;
static PyObject *__pyx_kp_s_No_context_specified;
static PyObject *__pyx_kp_s_No_mapping_for_s;
static PyObject *__pyx_kp_u_Non_native_byte_order_not_suppor;
static PyObject *__pyx_n_s_NotImplemented;
static PyObject *__pyx_n_s_NotImplementedError;
static PyObject *__pyx_kp_s_Only_works_for_cuda_contexts;
static PyObject *__pyx_kp_s_OpenCL_name_incorrect_Should_be;
static PyObject *__pyx_n_s_RuntimeError;
static PyObject *__pyx_n_s_SIZE;
static PyObject *__pyx_n_s_SSIZE;
static PyObject *__pyx_n_s_SystemError;
static PyObject *__pyx_n_s_TODO;
static PyObject *__pyx_kp_s_The_truth_value_of_a_multi_eleme;
static PyObject *__pyx_kp_s_This_array_has_an_offset;
static PyObject *__pyx_kp_s_This_is_for_CUDA_arrays;
static PyObject *__pyx_kp_s_This_is_for_OpenCL_arrays;
static PyObject *__pyx_kp_s_Truth_value_of_array_with_more_t;
static PyObject *__pyx_n_s_TypeError;
static PyObject *__pyx_kp_s_UTF_8;
static PyObject *__pyx_kp_s_Unknown_device_format;
static PyObject *__pyx_kp_s_Unknown_flag;
static PyObject *__pyx_n_s_UnsupportedException;
static PyObject *__pyx_kp_s_Valid_orders_are_A_any_C_C_F_For;
static PyObject *__pyx_n_s_ValueError;
static PyObject *__pyx_kp_s__20;
static PyObject *__pyx_kp_s__22;
static PyObject *__pyx_kp_s__4;
static PyObject *__pyx_kp_s__8;
static PyObject *__pyx_n_s_a;
static PyObject *__pyx_n_s_abi_version;
static PyObject *__pyx_n_s_al;
static PyObject *__pyx_n_s_aligned;
static PyObject *__pyx_n_s_als;
static PyObject *__pyx_n_s_api_version;
static PyObject *__pyx_n_s_args;
static PyObject *__pyx_n_s_array;
static PyObject *__pyx_n_s_asarray;
static PyObject *__pyx_n_s_ascontiguousarray;
static PyObject *__pyx_n_s_asfortranarray;
static PyObject *__pyx_kp_s_axes_don_t_match;
static PyObject *__pyx_n_s_axis;
static PyObject *__pyx_n_s_b;
static PyObject *__pyx_n_s_base;
static PyObject *__pyx_n_s_behaved;
static PyObject *__pyx_n_s_bool;
static PyObject *__pyx_n_s_c;
static PyObject *__pyx_n_s_c_contiguous;
static PyObject *__pyx_n_s_calloc;
static PyObject *__pyx_kp_s_cannot_copy_an_array_to_a_differ;
static PyObject *__pyx_kp_s_cannot_index_with_s;
static PyObject *__pyx_kp_s_cannot_use_more_than_one_Ellipsi;
static PyObject *__pyx_n_s_carray;
static PyObject *__pyx_n_s_cdims;
static PyObject *__pyx_n_s_cl_make_ctx;
static PyObject *__pyx_kp_s_cl_make_ctx_call_failed;
static PyObject *__pyx_kp_s_cl_make_ctx_extension_is_absent;
static PyObject *__pyx_n_s_cl_wrap_ctx;
static PyObject *__pyx_n_s_class;
static PyObject *__pyx_n_s_cline_in_traceback;
static PyObject *__pyx_n_s_close;
static PyObject *__pyx_n_s_cls;
static PyObject *__pyx_n_s_cname;
static PyObject *__pyx_n_s_complex128;
static PyObject *__pyx_n_s_complex64;
static PyObject *__pyx_kp_s_compute_axis_is_out_of_bounds;
static PyObject *__pyx_n_s_concatenate;
static PyObject *__pyx_n_s_context;
static PyObject *__pyx_n_s_copy;
static PyObject *__pyx_kp_s_could_not_allocate_cdims;
static PyObject *__pyx_n_s_count_devices;
static PyObject *__pyx_n_s_count_platforms;
static PyObject *__pyx_n_s_cstrides;
static PyObject *__pyx_n_s_ctx;
static PyObject *__pyx_kp_s_ctx_is_None_in_new_GpuArray;
static PyObject *__pyx_n_b_cuda;
static PyObject *__pyx_n_s_cuda;
static PyObject *__pyx_kp_s_cuda_enter_not_available;
static PyObject *__pyx_kp_s_cuda_exit_not_available;
static PyObject *__pyx_n_s_cuda_make_ctx;
static PyObject *__pyx_kp_s_cuda_make_ctx_call_failed;
static PyObject *__pyx_kp_s_cuda_make_ctx_extension_is_absen;
static PyObject *__pyx_n_s_cuda_wrap_ctx;
static PyObject *__pyx_n_s_d;
static PyObject *__pyx_n_s_data;
static PyObject *__pyx_kp_s_data_type_not_understood;
static PyObject *__pyx_n_s_default;
static PyObject *__pyx_n_s_dev;
static PyObject *__pyx_n_s_devcount;
static PyObject *__pyx_n_s_doc;
static PyObject *__pyx_kp_s_don_t_know_how_to_convert_to_dty;
static PyObject *__pyx_n_s_dtype;
static PyObject *__pyx_n_s_dtype_to_ctype;
static PyObject *__pyx_n_s_empty;
static PyObject *__pyx_n_s_empty_like_me;
static PyObject *__pyx_n_s_encode;
static PyObject *__pyx_n_s_enumerate;
static PyObject *__pyx_n_s_err;
static PyObject *__pyx_kp_s_expected_GpuArrays_to_concatenat;
static PyObject *__pyx_kp_s_expected_a_GpuArray;
static PyObject *__pyx_n_s_f;
static PyObject *__pyx_n_s_f_contiguous;
static PyObject *__pyx_kp_s_fancy_indexing_not_supported;
static PyObject *__pyx_n_s_farray;
static PyObject *__pyx_n_s_fl;
static PyObject *__pyx_n_s_flags;
static PyObject *__pyx_n_s_float16;
static PyObject *__pyx_n_s_float32;
static PyObject *__pyx_n_s_float64;
static PyObject *__pyx_n_s_fnc;
static PyObject *__pyx_n_s_forc;
static PyObject *__pyx_n_s_fortran;
static PyObject *__pyx_n_s_from_gpudata;
static PyObject *__pyx_n_s_genexpr;
static PyObject *__pyx_n_s_get;
static PyObject *__pyx_n_s_get_default_context;
static PyObject *__pyx_n_s_getitem;
static PyObject *__pyx_n_s_getitem___locals_genexpr;
static PyObject *__pyx_kp_s_gpuarray;
static PyObject *__pyx_kp_s_gpuarray_array_content_not_avail;
static PyObject *__pyx_n_s_gs;
static PyObject *__pyx_kp_s_gs_is_not_int_or_list;
static PyObject *__pyx_kp_s_gs_is_not_of_length_3_or_less;
static PyObject *__pyx_n_s_h;
static PyObject *__pyx_n_s_have_complex;
static PyObject *__pyx_n_s_have_double;
static PyObject *__pyx_n_s_have_half;
static PyObject *__pyx_n_s_have_small;
static PyObject *__pyx_n_s_hpy;
static PyObject *__pyx_n_s_i;
static PyObject *__pyx_n_s_id;
static PyObject *__pyx_n_s_import;
static PyObject *__pyx_n_s_ind;
static PyObject *__pyx_n_s_index;
static PyObject *__pyx_kp_s_index_d_out_of_bounds;
static PyObject *__pyx_kp_s_index_out_of_bounds;
static PyObject *__pyx_n_s_init;
static PyObject *__pyx_n_s_initial_cache_size;
static PyObject *__pyx_n_s_int16;
static PyObject *__pyx_n_s_int32;
static PyObject *__pyx_n_s_int64;
static PyObject *__pyx_n_s_int8;
static PyObject *__pyx_n_s_isdigit;
static PyObject *__pyx_n_s_iteritems;
static PyObject *__pyx_n_s_join;
static PyObject *__pyx_n_s_kernel_cache_path;
static PyObject *__pyx_n_s_kernel_cache_path_b;
static PyObject *__pyx_n_s_kind;
static PyObject *__pyx_n_s_l;
static PyObject *__pyx_n_s_ldtype;
static PyObject *__pyx_kp_s_len_of_unsized_object;
static PyObject *__pyx_n_s_ls;
static PyObject *__pyx_kp_s_ls_is_not_int_or_list;
static PyObject *__pyx_kp_s_ls_is_not_of_length_3_or_less;
static PyObject *__pyx_n_s_m;
static PyObject *__pyx_n_s_main;
static PyObject *__pyx_n_s_major_version;
static PyObject *__pyx_n_s_max_cache_size;
static PyObject *__pyx_n_s_maxsize;
static PyObject *__pyx_n_s_may_share_memory;
static PyObject *__pyx_n_s_metaclass;
static PyObject *__pyx_n_s_minor_version;
static PyObject *__pyx_n_s_module;
static PyObject *__pyx_n_s_multi;
static PyObject *__pyx_n_s_n;
static PyObject *__pyx_kp_s_n_is_specified_and_nd_1;
static PyObject *__pyx_n_s_name;
static PyObject *__pyx_n_s_nd;
static PyObject *__pyx_kp_s_nd_mismatch_for_gs_None;
static PyObject *__pyx_kp_s_nd_mismatch_for_gs_int;
static PyObject *__pyx_kp_s_nd_mismatch_for_gs_tuple;
static PyObject *__pyx_kp_u_ndarray_is_not_C_contiguous;
static PyObject *__pyx_kp_u_ndarray_is_not_Fortran_contiguou;
static PyObject *__pyx_n_s_ndmin;
static PyObject *__pyx_n_s_new;
static PyObject *__pyx_kp_s_new_strides_are_the_wrong_length;
static PyObject *__pyx_kp_s_new_strides_go_outside_of_alloca;
static PyObject *__pyx_n_s_np;
static PyObject *__pyx_n_s_numargs;
static PyObject *__pyx_n_s_numpy;
static PyObject *__pyx_kp_s_numpy_core_multiarray_failed_to;
static PyObject *__pyx_kp_s_numpy_core_umath_failed_to_impor;
static PyObject *__pyx_n_s_offset;
static PyObject *__pyx_n_s_open_ipc_handle;
static PyObject *__pyx_n_b_opencl;
static PyObject *__pyx_n_s_opencl;
static PyObject *__pyx_n_s_order;
static PyObject *__pyx_n_s_own;
static PyObject *__pyx_n_s_owndata;
static PyObject *__pyx_n_s_p;
static PyObject *__pyx_n_s_platcount;
static PyObject *__pyx_n_s_platform;
static PyObject *__pyx_n_s_prepare;
static PyObject *__pyx_n_s_proto;
static PyObject *__pyx_n_s_ptr;
static PyObject *__pyx_n_s_pygpu_gpuarray;
static PyObject *__pyx_kp_s_pygpu_gpuarray_pyx;
static PyObject *__pyx_n_s_pyx_vtable;
static PyObject *__pyx_n_s_qualname;
static PyObject *__pyx_n_s_r;
static PyObject *__pyx_n_s_range;
static PyObject *__pyx_n_s_register_dtype;
static PyObject *__pyx_n_s_repr___locals_genexpr;
static PyObject *__pyx_n_s_res;
static PyObject *__pyx_n_s_reshape;
static PyObject *__pyx_n_s_restype;
static PyObject *__pyx_n_s_rs;
static PyObject *__pyx_n_s_s;
static PyObject *__pyx_kp_s_s_s;
static PyObject *__pyx_n_s_sched;
static PyObject *__pyx_n_s_send;
static PyObject *__pyx_n_s_set_default_context;
static PyObject *__pyx_n_s_setitem;
static PyObject *__pyx_n_s_setitem___locals_genexpr;
static PyObject *__pyx_n_s_shape;
static PyObject *__pyx_n_s_shared;
static PyObject *__pyx_n_s_single;
static PyObject *__pyx_n_s_single_stream;
static PyObject *__pyx_n_s_size;
static PyObject *__pyx_n_s_source;
static PyObject *__pyx_n_s_split;
static PyObject *__pyx_n_s_split_2;
static PyObject *__pyx_kp_s_split_on_non_existant_axis;
static PyObject *__pyx_n_s_startswith;
static PyObject *__pyx_n_s_strides;
static PyObject *__pyx_kp_s_strides_must_be_the_same_length;
static PyObject *__pyx_n_s_sys;
static PyObject *__pyx_n_s_t;
static PyObject *__pyx_n_s_tb;
static PyObject *__pyx_n_s_test;
static PyObject *__pyx_n_s_throw;
static PyObject *__pyx_n_s_tmp;
static PyObject *__pyx_kp_s_too_many_indices;
static PyObject *__pyx_kp_s_transfer_only_works_for_contigou;
static PyObject *__pyx_n_s_typecode;
static PyObject *__pyx_n_s_types;
static PyObject *__pyx_n_s_uint16;
static PyObject *__pyx_n_s_uint32;
static PyObject *__pyx_n_s_uint64;
static PyObject *__pyx_n_s_uint8;
static PyObject *__pyx_kp_s_undefined_comparison_for_flag_ob;
static PyObject *__pyx_kp_s_unexpected_value_for_parameter_s;
static PyObject *__pyx_kp_s_unhashable_type_s;
static PyObject *__pyx_kp_u_unknown_dtype_code_in_numpy_pxd;
static PyObject *__pyx_n_s_updateifcopy;
static PyObject *__pyx_n_s_upper;
static PyObject *__pyx_n_s_v;
static PyObject *__pyx_n_s_view;
static PyObject *__pyx_n_s_writable;
static PyObject *__pyx_n_s_writeable;
static PyObject *__pyx_n_s_zeros;
static PyObject *__pyx_pf_5pygpu_8gpuarray_46genexpr(CYTHON_UNUSED PyObject *__pyx_self); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_api_version(CYTHON_UNUSED PyObject *__pyx_self); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_2abi_version(CYTHON_UNUSED PyObject *__pyx_self); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_4cl_wrap_ctx(CYTHON_UNUSED PyObject *__pyx_self, size_t __pyx_v_ptr); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_6cuda_wrap_ctx(CYTHON_UNUSED PyObject *__pyx_self, size_t __pyx_v_ptr, int __pyx_v_own); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_8register_dtype(CYTHON_UNUSED PyObject *__pyx_self, PyArray_Descr *__pyx_v_dtype, PyObject *__pyx_v_cname); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_10dtype_to_typecode(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_dtype); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_12dtype_to_ctype(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_dtype); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_14set_default_context(CYTHON_UNUSED PyObject *__pyx_self, struct PyGpuContextObject *__pyx_v_ctx); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_16get_default_context(CYTHON_UNUSED PyObject *__pyx_self); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_18count_platforms(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_kind); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_20count_devices(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_kind, unsigned int __pyx_v_platform); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_22init(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_dev, PyObject *__pyx_v_sched, PyObject *__pyx_v_single_stream, PyObject *__pyx_v_kernel_cache_path, PyObject *__pyx_v_max_cache_size, PyObject *__pyx_v_initial_cache_size); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_24zeros(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_shape, PyObject *__pyx_v_dtype, PyObject *__pyx_v_order, struct PyGpuContextObject *__pyx_v_context, PyObject *__pyx_v_cls); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_26empty(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_shape, PyObject *__pyx_v_dtype, PyObject *__pyx_v_order, struct PyGpuContextObject *__pyx_v_context, PyObject *__pyx_v_cls); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_28asarray(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_a, PyObject *__pyx_v_dtype, PyObject *__pyx_v_order, struct PyGpuContextObject *__pyx_v_context); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_30ascontiguousarray(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_a, PyObject *__pyx_v_dtype, struct PyGpuContextObject *__pyx_v_context); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_32asfortranarray(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_a, PyObject *__pyx_v_dtype, struct PyGpuArrayObject *__pyx_v_context); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_34may_share_memory(CYTHON_UNUSED PyObject *__pyx_self, struct PyGpuArrayObject *__pyx_v_a, struct PyGpuArrayObject *__pyx_v_b); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_36from_gpudata(CYTHON_UNUSED PyObject *__pyx_self, size_t __pyx_v_data, PyObject *__pyx_v_offset, PyObject *__pyx_v_dtype, PyObject *__pyx_v_shape, struct PyGpuContextObject *__pyx_v_context, PyObject *__pyx_v_strides, PyObject *__pyx_v_writable, PyObject *__pyx_v_base, PyObject *__pyx_v_cls); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_38array(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_proto, PyObject *__pyx_v_dtype, PyObject *__pyx_v_copy, PyObject *__pyx_v_order, unsigned int __pyx_v_ndmin, struct PyGpuContextObject *__pyx_v_context, PyObject *__pyx_v_cls); /* proto */
static void __pyx_pf_5pygpu_8gpuarray_10GpuContext___dealloc__(struct PyGpuContextObject *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_10GpuContext_2__reduce__(CYTHON_UNUSED struct PyGpuContextObject *__pyx_v_self); /* proto */
static int __pyx_pf_5pygpu_8gpuarray_10GpuContext_4__init__(struct PyGpuContextObject *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_10GpuContext_6__enter__(struct PyGpuContextObject *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_10GpuContext_8__exit__(struct PyGpuContextObject *__pyx_v_self, CYTHON_UNUSED PyObject *__pyx_v_t, CYTHON_UNUSED PyObject *__pyx_v_v, CYTHON_UNUSED PyObject *__pyx_v_tb); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_10GpuContext_3ptr___get__(struct PyGpuContextObject *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_10GpuContext_7devname___get__(struct PyGpuContextObject *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_10GpuContext_9unique_id___get__(struct PyGpuContextObject *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_10GpuContext_8lmemsize___get__(struct PyGpuContextObject *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_10GpuContext_8numprocs___get__(struct PyGpuContextObject *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_10GpuContext_6bin_id___get__(struct PyGpuContextObject *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_10GpuContext_10total_gmem___get__(struct PyGpuContextObject *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_10GpuContext_9free_gmem___get__(struct PyGpuContextObject *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_10GpuContext_9maxlsize0___get__(struct PyGpuContextObject *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_10GpuContext_9maxlsize1___get__(struct PyGpuContextObject *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_10GpuContext_9maxlsize2___get__(struct PyGpuContextObject *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_10GpuContext_9maxgsize0___get__(struct PyGpuContextObject *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_10GpuContext_9maxgsize1___get__(struct PyGpuContextObject *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_10GpuContext_9maxgsize2___get__(struct PyGpuContextObject *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_10GpuContext_16largest_memblock___get__(struct PyGpuContextObject *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_10GpuContext_4kind___get__(struct PyGpuContextObject *__pyx_v_self); /* proto */
static int __pyx_pf_5pygpu_8gpuarray_5flags___cinit__(struct __pyx_obj_5pygpu_8gpuarray_flags *__pyx_v_self, PyObject *__pyx_v_fl); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_5flags_2__reduce__(struct __pyx_obj_5pygpu_8gpuarray_flags *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_5flags_4__getitem__(struct __pyx_obj_5pygpu_8gpuarray_flags *__pyx_v_self, PyObject *__pyx_v_idx); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_5flags_8__repr___genexpr(PyObject *__pyx_self); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_5flags_6__repr__(struct __pyx_obj_5pygpu_8gpuarray_flags *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_5flags_8__richcmp__(PyObject *__pyx_v_self, PyObject *__pyx_v_other, int __pyx_v_op); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_5flags_12c_contiguous___get__(struct __pyx_obj_5pygpu_8gpuarray_flags *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_5flags_10contiguous___get__(struct __pyx_obj_5pygpu_8gpuarray_flags *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_5flags_12f_contiguous___get__(struct __pyx_obj_5pygpu_8gpuarray_flags *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_5flags_7fortran___get__(struct __pyx_obj_5pygpu_8gpuarray_flags *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_5flags_12updateifcopy___get__(CYTHON_UNUSED struct __pyx_obj_5pygpu_8gpuarray_flags *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_5flags_7owndata___get__(CYTHON_UNUSED struct __pyx_obj_5pygpu_8gpuarray_flags *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_5flags_7aligned___get__(struct __pyx_obj_5pygpu_8gpuarray_flags *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_5flags_9writeable___get__(struct __pyx_obj_5pygpu_8gpuarray_flags *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_5flags_7behaved___get__(struct __pyx_obj_5pygpu_8gpuarray_flags *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_5flags_6carray___get__(struct __pyx_obj_5pygpu_8gpuarray_flags *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_5flags_4forc___get__(struct __pyx_obj_5pygpu_8gpuarray_flags *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_5flags_3fnc___get__(struct __pyx_obj_5pygpu_8gpuarray_flags *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_5flags_6farray___get__(struct __pyx_obj_5pygpu_8gpuarray_flags *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_5flags_3num___get__(struct __pyx_obj_5pygpu_8gpuarray_flags *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_40_split(CYTHON_UNUSED PyObject *__pyx_self, struct PyGpuArrayObject *__pyx_v_a, PyObject *__pyx_v_ind, unsigned int __pyx_v_axis); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_42_concatenate(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_al, unsigned int __pyx_v_axis, int __pyx_v_restype, PyObject *__pyx_v_cls, struct PyGpuContextObject *__pyx_v_context); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_44open_ipc_handle(CYTHON_UNUSED PyObject *__pyx_self, struct PyGpuContextObject *__pyx_v_c, PyObject *__pyx_v_hpy, size_t __pyx_v_l); /* proto */
static void __pyx_pf_5pygpu_8gpuarray_8GpuArray___dealloc__(struct PyGpuArrayObject *__pyx_v_self); /* proto */
static int __pyx_pf_5pygpu_8gpuarray_8GpuArray_2__cinit__(struct PyGpuArrayObject *__pyx_v_self); /* proto */
static int __pyx_pf_5pygpu_8gpuarray_8GpuArray_4__init__(struct PyGpuArrayObject *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_8GpuArray_6__reduce__(CYTHON_UNUSED struct PyGpuArrayObject *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_8GpuArray_8write(struct PyGpuArrayObject *__pyx_v_self, PyArrayObject *__pyx_v_src); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_8GpuArray_10read(struct PyGpuArrayObject *__pyx_v_self, PyArrayObject *__pyx_v_dst); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_8GpuArray_12get_ipc_handle(struct PyGpuArrayObject *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_8GpuArray_14__array__(struct PyGpuArrayObject *__pyx_v_self, PyObject *__pyx_v_ldtype); /* proto */
static int __pyx_pf_5pygpu_8gpuarray_8GpuArray_16__bool__(struct PyGpuArrayObject *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_8GpuArray_18_empty_like_me(struct PyGpuArrayObject *__pyx_v_self, PyObject *__pyx_v_dtype, PyObject *__pyx_v_order); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_8GpuArray_20copy(struct PyGpuArrayObject *__pyx_v_self, PyObject *__pyx_v_order); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_8GpuArray_22transfer(struct PyGpuArrayObject *__pyx_v_self, struct PyGpuContextObject *__pyx_v_new_ctx); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_8GpuArray_24__copy__(struct PyGpuArrayObject *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_8GpuArray_26__deepcopy__(struct PyGpuArrayObject *__pyx_v_self, PyObject *__pyx_v_memo); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_8GpuArray_28sync(struct PyGpuArrayObject *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_8GpuArray_30view(struct PyGpuArrayObject *__pyx_v_self, PyObject *__pyx_v_cls); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_8GpuArray_32astype(struct PyGpuArrayObject *__pyx_v_self, PyObject *__pyx_v_dtype, PyObject *__pyx_v_order, PyObject *__pyx_v_copy); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_8GpuArray_34reshape(struct PyGpuArrayObject *__pyx_v_self, PyObject *__pyx_v_shape, PyObject *__pyx_v_order); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_8GpuArray_36transpose(struct PyGpuArrayObject *__pyx_v_self, PyObject *__pyx_v_params); /* proto */
static Py_ssize_t __pyx_pf_5pygpu_8gpuarray_8GpuArray_38__len__(struct PyGpuArrayObject *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_8GpuArray_11__getitem___genexpr(PyObject *__pyx_self); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_8GpuArray_11__getitem___3genexpr(PyObject *__pyx_self); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_8GpuArray_11__getitem___6genexpr(PyObject *__pyx_self); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_8GpuArray_40__getitem__(struct PyGpuArrayObject *__pyx_v_self, PyObject *__pyx_v_key); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_8GpuArray_11__setitem___genexpr(PyObject *__pyx_self); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_8GpuArray_11__setitem___3genexpr(PyObject *__pyx_self); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_8GpuArray_11__setitem___6genexpr(PyObject *__pyx_self); /* proto */
static int __pyx_pf_5pygpu_8gpuarray_8GpuArray_42__setitem__(struct PyGpuArrayObject *__pyx_v_self, PyObject *__pyx_v_idx, PyObject *__pyx_v_v); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_8GpuArray_44take1(struct PyGpuArrayObject *__pyx_v_self, struct PyGpuArrayObject *__pyx_v_idx); /* proto */
static Py_hash_t __pyx_pf_5pygpu_8gpuarray_8GpuArray_46__hash__(struct PyGpuArrayObject *__pyx_v_self); /* proto */
static int __pyx_pf_5pygpu_8gpuarray_8GpuArray_48__nonzero__(struct PyGpuArrayObject *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_8GpuArray_5shape___get__(struct PyGpuArrayObject *__pyx_v_self); /* proto */
static int __pyx_pf_5pygpu_8gpuarray_8GpuArray_5shape_2__set__(struct PyGpuArrayObject *__pyx_v_self, PyObject *__pyx_v_newshape); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_8GpuArray_1T___get__(struct PyGpuArrayObject *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_8GpuArray_4size___get__(struct PyGpuArrayObject *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_8GpuArray_7strides___get__(struct PyGpuArrayObject *__pyx_v_self); /* proto */
static int __pyx_pf_5pygpu_8gpuarray_8GpuArray_7strides_2__set__(struct PyGpuArrayObject *__pyx_v_self, PyObject *__pyx_v_newstrides); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_8GpuArray_4ndim___get__(struct PyGpuArrayObject *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_8GpuArray_5dtype___get__(struct PyGpuArrayObject *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_8GpuArray_8typecode___get__(struct PyGpuArrayObject *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_8GpuArray_8itemsize___get__(struct PyGpuArrayObject *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_8GpuArray_5flags___get__(struct PyGpuArrayObject *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_8GpuArray_6offset___get__(struct PyGpuArrayObject *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_8GpuArray_4data___get__(struct PyGpuArrayObject *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_8GpuArray_9base_data___get__(struct PyGpuArrayObject *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_8GpuArray_7gpudata___get__(struct PyGpuArrayObject *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_8GpuArray_50__str__(struct PyGpuArrayObject *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_8GpuArray_52__repr__(struct PyGpuArrayObject *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_8GpuArray_7context___get__(struct PyGpuArrayObject *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_8GpuArray_4base___get__(struct PyGpuArrayObject *__pyx_v_self); /* proto */
static void __pyx_pf_5pygpu_8gpuarray_9GpuKernel___dealloc__(struct PyGpuKernelObject *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_9GpuKernel_2__reduce__(CYTHON_UNUSED struct PyGpuKernelObject *__pyx_v_self); /* proto */
static int __pyx_pf_5pygpu_8gpuarray_9GpuKernel_4__cinit__(struct PyGpuKernelObject *__pyx_v_self, PyObject *__pyx_v_source, PyObject *__pyx_v_name, PyObject *__pyx_v_types, struct PyGpuContextObject *__pyx_v_context, PyObject *__pyx_v_have_double, PyObject *__pyx_v_have_small, PyObject *__pyx_v_have_complex, PyObject *__pyx_v_have_half, PyObject *__pyx_v_cuda, PyObject *__pyx_v_opencl, CYTHON_UNUSED PyObject *__pyx_v_a, CYTHON_UNUSED PyObject *__pyx_v_kwa); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_9GpuKernel_6__call__(struct PyGpuKernelObject *__pyx_v_self, PyObject *__pyx_v_n, PyObject *__pyx_v_gs, PyObject *__pyx_v_ls, PyObject *__pyx_v_shared, PyObject *__pyx_v_args); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_9GpuKernel_8maxlsize___get__(struct PyGpuKernelObject *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_9GpuKernel_9preflsize___get__(struct PyGpuKernelObject *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_9GpuKernel_7numargs___get__(struct PyGpuKernelObject *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_5pygpu_8gpuarray_9GpuKernel_7context___get__(struct PyGpuKernelObject *__pyx_v_self); /* proto */
static int __pyx_pf_5numpy_7ndarray___getbuffer__(PyArrayObject *__pyx_v_self, Py_buffer *__pyx_v_info, int __pyx_v_flags); /* proto */
static void __pyx_pf_5numpy_7ndarray_2__releasebuffer__(PyArrayObject *__pyx_v_self, Py_buffer *__pyx_v_info); /* proto */
static PyObject *__pyx_tp_new_5pygpu_8gpuarray_GpuContext(PyTypeObject *t, PyObject *a, PyObject *k); /*proto*/
static PyObject *__pyx_tp_new_5pygpu_8gpuarray_GpuArray(PyTypeObject *t, PyObject *a, PyObject *k); /*proto*/
static PyObject *__pyx_tp_new_5pygpu_8gpuarray_GpuKernel(PyTypeObject *t, PyObject *a, PyObject *k); /*proto*/
static PyObject *__pyx_tp_new_5pygpu_8gpuarray_flags(PyTypeObject *t, PyObject *a, PyObject *k); /*proto*/
static PyObject *__pyx_tp_new_5pygpu_8gpuarray___pyx_scope_struct__genexpr(PyTypeObject *t, PyObject *a, PyObject *k); /*proto*/
static PyObject *__pyx_tp_new_5pygpu_8gpuarray___pyx_scope_struct_1___repr__(PyTypeObject *t, PyObject *a, PyObject *k); /*proto*/
static PyObject *__pyx_tp_new_5pygpu_8gpuarray___pyx_scope_struct_2_genexpr(PyTypeObject *t, PyObject *a, PyObject *k); /*proto*/
static PyObject *__pyx_tp_new_5pygpu_8gpuarray___pyx_scope_struct_3___getitem__(PyTypeObject *t, PyObject *a, PyObject *k); /*proto*/
static PyObject *__pyx_tp_new_5pygpu_8gpuarray___pyx_scope_struct_4_genexpr(PyTypeObject *t, PyObject *a, PyObject *k); /*proto*/
static PyObject *__pyx_tp_new_5pygpu_8gpuarray___pyx_scope_struct_5_genexpr(PyTypeObject *t, PyObject *a, PyObject *k); /*proto*/
static PyObject *__pyx_tp_new_5pygpu_8gpuarray___pyx_scope_struct_6_genexpr(PyTypeObject *t, PyObject *a, PyObject *k); /*proto*/
static PyObject *__pyx_tp_new_5pygpu_8gpuarray___pyx_scope_struct_7___setitem__(PyTypeObject *t, PyObject *a, PyObject *k); /*proto*/
static PyObject *__pyx_tp_new_5pygpu_8gpuarray___pyx_scope_struct_8_genexpr(PyTypeObject *t, PyObject *a, PyObject *k); /*proto*/
static PyObject *__pyx_tp_new_5pygpu_8gpuarray___pyx_scope_struct_9_genexpr(PyTypeObject *t, PyObject *a, PyObject *k); /*proto*/
static PyObject *__pyx_tp_new_5pygpu_8gpuarray___pyx_scope_struct_10_genexpr(PyTypeObject *t, PyObject *a, PyObject *k); /*proto*/
static PyObject *__pyx_int_0;
static PyObject *__pyx_int_1;
static PyObject *__pyx_int_4;
static PyObject *__pyx_int_6;
static PyObject *__pyx_int_neg_1;
static PyObject *__pyx_k__10;
static PyObject *__pyx_k__11;
static PyObject *__pyx_k__12;
static PyObject *__pyx_k__25;
static PyObject *__pyx_tuple_;
static PyObject *__pyx_slice__3;
static PyObject *__pyx_slice__5;
static PyObject *__pyx_slice__7;
static PyObject *__pyx_tuple__2;
static PyObject *__pyx_tuple__6;
static PyObject *__pyx_tuple__9;
static PyObject *__pyx_slice__28;
static PyObject *__pyx_slice__30;
static PyObject *__pyx_tuple__13;
static PyObject *__pyx_tuple__14;
static PyObject *__pyx_tuple__15;
static PyObject *__pyx_tuple__16;
static PyObject *__pyx_tuple__17;
static PyObject *__pyx_tuple__18;
static PyObject *__pyx_tuple__19;
static PyObject *__pyx_tuple__21;
static PyObject *__pyx_tuple__23;
static PyObject *__pyx_tuple__24;
static PyObject *__pyx_tuple__26;
static PyObject *__pyx_tuple__27;
static PyObject *__pyx_tuple__29;
static PyObject *__pyx_tuple__31;
static PyObject *__pyx_tuple__32;
static PyObject *__pyx_tuple__33;
static PyObject *__pyx_tuple__34;
static PyObject *__pyx_tuple__35;
static PyObject *__pyx_tuple__36;
static PyObject *__pyx_tuple__37;
static PyObject *__pyx_tuple__38;
static PyObject *__pyx_tuple__39;
static PyObject *__pyx_tuple__40;
static PyObject *__pyx_tuple__41;
static PyObject *__pyx_tuple__42;
static PyObject *__pyx_tuple__43;
static PyObject *__pyx_tuple__44;
static PyObject *__pyx_tuple__45;
static PyObject *__pyx_tuple__46;
static PyObject *__pyx_tuple__47;
static PyObject *__pyx_tuple__48;
static PyObject *__pyx_tuple__50;
static PyObject *__pyx_tuple__52;
static PyObject *__pyx_tuple__54;
static PyObject *__pyx_tuple__56;
static PyObject *__pyx_tuple__57;
static PyObject *__pyx_tuple__58;
static PyObject *__pyx_tuple__59;
static PyObject *__pyx_tuple__60;
static PyObject *__pyx_tuple__61;
static PyObject *__pyx_tuple__62;
static PyObject *__pyx_tuple__63;
static PyObject *__pyx_tuple__64;
static PyObject *__pyx_tuple__65;
static PyObject *__pyx_tuple__66;
static PyObject *__pyx_tuple__67;
static PyObject *__pyx_tuple__68;
static PyObject *__pyx_tuple__69;
static PyObject *__pyx_tuple__70;
static PyObject *__pyx_tuple__72;
static PyObject *__pyx_tuple__74;
static PyObject *__pyx_tuple__77;
static PyObject *__pyx_tuple__79;
static PyObject *__pyx_tuple__81;
static PyObject *__pyx_tuple__83;
static PyObject *__pyx_tuple__85;
static PyObject *__pyx_tuple__87;
static PyObject *__pyx_tuple__89;
static PyObject *__pyx_tuple__91;
static PyObject *__pyx_tuple__93;
static PyObject *__pyx_tuple__95;
static PyObject *__pyx_tuple__97;
static PyObject *__pyx_tuple__99;
static PyObject *__pyx_tuple__101;
static PyObject *__pyx_tuple__103;
static PyObject *__pyx_codeobj__49;
static PyObject *__pyx_codeobj__51;
static PyObject *__pyx_codeobj__53;
static PyObject *__pyx_codeobj__55;
static PyObject *__pyx_codeobj__71;
static PyObject *__pyx_codeobj__73;
static PyObject *__pyx_codeobj__75;
static PyObject *__pyx_codeobj__76;
static PyObject *__pyx_codeobj__78;
static PyObject *__pyx_codeobj__80;
static PyObject *__pyx_codeobj__82;
static PyObject *__pyx_codeobj__84;
static PyObject *__pyx_codeobj__86;
static PyObject *__pyx_codeobj__88;
static PyObject *__pyx_codeobj__90;
static PyObject *__pyx_codeobj__92;
static PyObject *__pyx_codeobj__94;
static PyObject *__pyx_codeobj__96;
static PyObject *__pyx_codeobj__98;
static PyObject *__pyx_codeobj__100;
static PyObject *__pyx_codeobj__102;
static PyObject *__pyx_codeobj__104;
static PyObject *__pyx_gb_5pygpu_8gpuarray_48generator(__pyx_CoroutineObject *__pyx_generator, CYTHON_UNUSED PyThreadState *__pyx_tstate, PyObject *__pyx_sent_value); /* proto */

/* "pygpu/gpuarray.pyx":118
 * }
 * 
 * cdef dict TYPE_TO_NP = dict((v, k) for k, v in NP_TO_TYPE.iteritems())             # <<<<<<<<<<<<<<
 * 
 * def register_dtype(np.dtype dtype, cname):
 */

static PyObject *__pyx_pf_5pygpu_8gpuarray_46genexpr(CYTHON_UNUSED PyObject *__pyx_self) {
  struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct__genexpr *__pyx_cur_scope;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("genexpr", 0);
  __pyx_cur_scope = (struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct__genexpr *)__pyx_tp_new_5pygpu_8gpuarray___pyx_scope_struct__genexpr(__pyx_ptype_5pygpu_8gpuarray___pyx_scope_struct__genexpr, __pyx_empty_tuple, NULL);
  if (unlikely(!__pyx_cur_scope)) {
    __pyx_cur_scope = ((struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct__genexpr *)Py_None);
    __Pyx_INCREF(Py_None);
    __PYX_ERR(0, 118, __pyx_L1_error)
  } else {
    __Pyx_GOTREF(__pyx_cur_scope);
  }
  {
    __pyx_CoroutineObject *gen = __Pyx_Generator_New((__pyx_coroutine_body_t) __pyx_gb_5pygpu_8gpuarray_48generator, (PyObject *) __pyx_cur_scope, __pyx_n_s_genexpr, __pyx_n_s_genexpr, __pyx_n_s_pygpu_gpuarray); if (unlikely(!gen)) __PYX_ERR(0, 118, __pyx_L1_error)
    __Pyx_DECREF(__pyx_cur_scope);
    __Pyx_RefNannyFinishContext();
    return (PyObject *) gen;
  }

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_AddTraceback("pygpu.gpuarray.genexpr", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __Pyx_DECREF(((PyObject *)__pyx_cur_scope));
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_gb_5pygpu_8gpuarray_48generator(__pyx_CoroutineObject *__pyx_generator, CYTHON_UNUSED PyThreadState *__pyx_tstate, PyObject *__pyx_sent_value) /* generator body */
{
  struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct__genexpr *__pyx_cur_scope = ((struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct__genexpr *)__pyx_generator->closure);
  PyObject *__pyx_r = NULL;
  PyObject *__pyx_t_1 = NULL;
  Py_ssize_t __pyx_t_2;
  Py_ssize_t __pyx_t_3;
  int __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  int __pyx_t_7;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("genexpr", 0);
  switch (__pyx_generator->resume_label) {
    case 0: goto __pyx_L3_first_run;
    default: /* CPython raises the right error here */
    __Pyx_RefNannyFinishContext();
    return NULL;
  }
  __pyx_L3_first_run:;
  if (unlikely(!__pyx_sent_value)) __PYX_ERR(0, 118, __pyx_L1_error)
  __pyx_r = PyDict_New(); if (unlikely(!__pyx_r)) __PYX_ERR(0, 118, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_r);
  __pyx_t_2 = 0;
  if (unlikely(__pyx_v_5pygpu_8gpuarray_NP_TO_TYPE == Py_None)) {
    PyErr_Format(PyExc_AttributeError, "'NoneType' object has no attribute '%.30s'", "iteritems");
    __PYX_ERR(0, 118, __pyx_L1_error)
  }
  __pyx_t_5 = __Pyx_dict_iterator(__pyx_v_5pygpu_8gpuarray_NP_TO_TYPE, 1, __pyx_n_s_iteritems, (&__pyx_t_3), (&__pyx_t_4)); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 118, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_1);
  __pyx_t_1 = __pyx_t_5;
  __pyx_t_5 = 0;
  while (1) {
    __pyx_t_7 = __Pyx_dict_iter_next(__pyx_t_1, __pyx_t_3, &__pyx_t_2, &__pyx_t_5, &__pyx_t_6, NULL, __pyx_t_4);
    if (unlikely(__pyx_t_7 == 0)) break;
    if (unlikely(__pyx_t_7 == -1)) __PYX_ERR(0, 118, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_XGOTREF(__pyx_cur_scope->__pyx_v_k);
    __Pyx_XDECREF_SET(__pyx_cur_scope->__pyx_v_k, __pyx_t_5);
    __Pyx_GIVEREF(__pyx_t_5);
    __pyx_t_5 = 0;
    __Pyx_XGOTREF(__pyx_cur_scope->__pyx_v_v);
    __Pyx_XDECREF_SET(__pyx_cur_scope->__pyx_v_v, __pyx_t_6);
    __Pyx_GIVEREF(__pyx_t_6);
    __pyx_t_6 = 0;
    if (unlikely(PyDict_SetItem(__pyx_r, (PyObject*)__pyx_cur_scope->__pyx_v_v, (PyObject*)__pyx_cur_scope->__pyx_v_k))) __PYX_ERR(0, 118, __pyx_L1_error)
  }
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  CYTHON_MAYBE_UNUSED_VAR(__pyx_cur_scope);

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_r); __pyx_r = 0;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_AddTraceback("genexpr", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_Coroutine_ResetAndClearException(__pyx_generator);
  __pyx_generator->resume_label = -1;
  __Pyx_Coroutine_clear((PyObject*)__pyx_generator);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":14
 * from cpython.object cimport Py_EQ, Py_NE
 * 
 * def api_version():             # <<<<<<<<<<<<<<
 *     """api_version()
 *     """
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_1api_version(PyObject *__pyx_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static char __pyx_doc_5pygpu_8gpuarray_api_version[] = "api_version()\n    ";
static PyMethodDef __pyx_mdef_5pygpu_8gpuarray_1api_version = {"api_version", (PyCFunction)__pyx_pw_5pygpu_8gpuarray_1api_version, METH_NOARGS, __pyx_doc_5pygpu_8gpuarray_api_version};
static PyObject *__pyx_pw_5pygpu_8gpuarray_1api_version(PyObject *__pyx_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("api_version (wrapper)", 0);
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_api_version(__pyx_self);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_api_version(CYTHON_UNUSED PyObject *__pyx_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  __Pyx_RefNannySetupContext("api_version", 0);

  /* "pygpu/gpuarray.pyx":18
 *     """
 *     # (library version, module version)
 *     return (GPUARRAY_API_VERSION, 0)             # <<<<<<<<<<<<<<
 * 
 * def abi_version():
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyInt_From_int(GPUARRAY_API_VERSION); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 18, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = PyTuple_New(2); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 18, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_GIVEREF(__pyx_t_1);
  PyTuple_SET_ITEM(__pyx_t_2, 0, __pyx_t_1);
  __Pyx_INCREF(__pyx_int_0);
  __Pyx_GIVEREF(__pyx_int_0);
  PyTuple_SET_ITEM(__pyx_t_2, 1, __pyx_int_0);
  __pyx_t_1 = 0;
  __pyx_r = __pyx_t_2;
  __pyx_t_2 = 0;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":14
 * from cpython.object cimport Py_EQ, Py_NE
 * 
 * def api_version():             # <<<<<<<<<<<<<<
 *     """api_version()
 *     """
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("pygpu.gpuarray.api_version", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":20
 *     return (GPUARRAY_API_VERSION, 0)
 * 
 * def abi_version():             # <<<<<<<<<<<<<<
 *     """abi_version()
 *     """
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_3abi_version(PyObject *__pyx_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static char __pyx_doc_5pygpu_8gpuarray_2abi_version[] = "abi_version()\n    ";
static PyMethodDef __pyx_mdef_5pygpu_8gpuarray_3abi_version = {"abi_version", (PyCFunction)__pyx_pw_5pygpu_8gpuarray_3abi_version, METH_NOARGS, __pyx_doc_5pygpu_8gpuarray_2abi_version};
static PyObject *__pyx_pw_5pygpu_8gpuarray_3abi_version(PyObject *__pyx_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("abi_version (wrapper)", 0);
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_2abi_version(__pyx_self);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_2abi_version(CYTHON_UNUSED PyObject *__pyx_self) {
  long __pyx_v_major_version;
  long __pyx_v_minor_version;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  __Pyx_RefNannySetupContext("abi_version", 0);

  /* "pygpu/gpuarray.pyx":23
 *     """abi_version()
 *     """
 *     major_version = GPUARRAY_ABI_VERSION / 1000             # <<<<<<<<<<<<<<
 *     minor_version = GPUARRAY_ABI_VERSION % 1000
 *     return (major_version, minor_version)
 */
  __pyx_v_major_version = __Pyx_div_long(GPUARRAY_ABI_VERSION, 0x3E8);

  /* "pygpu/gpuarray.pyx":24
 *     """
 *     major_version = GPUARRAY_ABI_VERSION / 1000
 *     minor_version = GPUARRAY_ABI_VERSION % 1000             # <<<<<<<<<<<<<<
 *     return (major_version, minor_version)
 * 
 */
  __pyx_v_minor_version = __Pyx_mod_long(GPUARRAY_ABI_VERSION, 0x3E8);

  /* "pygpu/gpuarray.pyx":25
 *     major_version = GPUARRAY_ABI_VERSION / 1000
 *     minor_version = GPUARRAY_ABI_VERSION % 1000
 *     return (major_version, minor_version)             # <<<<<<<<<<<<<<
 * 
 * np.import_array()
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyInt_From_long(__pyx_v_major_version); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 25, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyInt_From_long(__pyx_v_minor_version); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 25, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = PyTuple_New(2); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 25, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_GIVEREF(__pyx_t_1);
  PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_1);
  __Pyx_GIVEREF(__pyx_t_2);
  PyTuple_SET_ITEM(__pyx_t_3, 1, __pyx_t_2);
  __pyx_t_1 = 0;
  __pyx_t_2 = 0;
  __pyx_r = __pyx_t_3;
  __pyx_t_3 = 0;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":20
 *     return (GPUARRAY_API_VERSION, 0)
 * 
 * def abi_version():             # <<<<<<<<<<<<<<
 *     """abi_version()
 *     """
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("pygpu.gpuarray.abi_version", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":34
 * 
 * # Numpy API steals dtype references and this breaks cython
 * cdef object PyArray_Empty(int a, np.npy_intp *b, np.dtype c, int d):             # <<<<<<<<<<<<<<
 *     Py_INCREF(c)
 *     return _PyArray_Empty(a, b, c, d)
 */

static PyObject *__pyx_f_5pygpu_8gpuarray_PyArray_Empty(int __pyx_v_a, npy_intp *__pyx_v_b, PyArray_Descr *__pyx_v_c, int __pyx_v_d) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("PyArray_Empty", 0);

  /* "pygpu/gpuarray.pyx":35
 * # Numpy API steals dtype references and this breaks cython
 * cdef object PyArray_Empty(int a, np.npy_intp *b, np.dtype c, int d):
 *     Py_INCREF(c)             # <<<<<<<<<<<<<<
 *     return _PyArray_Empty(a, b, c, d)
 * 
 */
  Py_INCREF(((PyObject *)__pyx_v_c));

  /* "pygpu/gpuarray.pyx":36
 * cdef object PyArray_Empty(int a, np.npy_intp *b, np.dtype c, int d):
 *     Py_INCREF(c)
 *     return _PyArray_Empty(a, b, c, d)             # <<<<<<<<<<<<<<
 * 
 * cdef bytes _s(s):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = PyArray_Empty(__pyx_v_a, __pyx_v_b, __pyx_v_c, __pyx_v_d); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 36, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":34
 * 
 * # Numpy API steals dtype references and this breaks cython
 * cdef object PyArray_Empty(int a, np.npy_intp *b, np.dtype c, int d):             # <<<<<<<<<<<<<<
 *     Py_INCREF(c)
 *     return _PyArray_Empty(a, b, c, d)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("pygpu.gpuarray.PyArray_Empty", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":38
 *     return _PyArray_Empty(a, b, c, d)
 * 
 * cdef bytes _s(s):             # <<<<<<<<<<<<<<
 *     if isinstance(s, unicode):
 *         return (<unicode>s).encode('ascii')
 */

static PyObject *__pyx_f_5pygpu_8gpuarray__s(PyObject *__pyx_v_s) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_t_2;
  PyObject *__pyx_t_3 = NULL;
  __Pyx_RefNannySetupContext("_s", 0);

  /* "pygpu/gpuarray.pyx":39
 * 
 * cdef bytes _s(s):
 *     if isinstance(s, unicode):             # <<<<<<<<<<<<<<
 *         return (<unicode>s).encode('ascii')
 *     if isinstance(s, bytes):
 */
  __pyx_t_1 = PyUnicode_Check(__pyx_v_s); 
  __pyx_t_2 = (__pyx_t_1 != 0);
  if (__pyx_t_2) {

    /* "pygpu/gpuarray.pyx":40
 * cdef bytes _s(s):
 *     if isinstance(s, unicode):
 *         return (<unicode>s).encode('ascii')             # <<<<<<<<<<<<<<
 *     if isinstance(s, bytes):
 *         return s
 */
    __Pyx_XDECREF(__pyx_r);
    if (unlikely(__pyx_v_s == Py_None)) {
      PyErr_Format(PyExc_AttributeError, "'NoneType' object has no attribute '%.30s'", "encode");
      __PYX_ERR(0, 40, __pyx_L1_error)
    }
    __pyx_t_3 = PyUnicode_AsASCIIString(((PyObject*)__pyx_v_s)); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 40, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    if (!(likely(PyBytes_CheckExact(__pyx_t_3))||(PyErr_Format(PyExc_TypeError, "Expected %.16s, got %.200s", "bytes", Py_TYPE(__pyx_t_3)->tp_name), 0))) __PYX_ERR(0, 40, __pyx_L1_error)
    __pyx_r = ((PyObject*)__pyx_t_3);
    __pyx_t_3 = 0;
    goto __pyx_L0;

    /* "pygpu/gpuarray.pyx":39
 * 
 * cdef bytes _s(s):
 *     if isinstance(s, unicode):             # <<<<<<<<<<<<<<
 *         return (<unicode>s).encode('ascii')
 *     if isinstance(s, bytes):
 */
  }

  /* "pygpu/gpuarray.pyx":41
 *     if isinstance(s, unicode):
 *         return (<unicode>s).encode('ascii')
 *     if isinstance(s, bytes):             # <<<<<<<<<<<<<<
 *         return s
 *     raise TypeError("Expected a string")
 */
  __pyx_t_2 = PyBytes_Check(__pyx_v_s); 
  __pyx_t_1 = (__pyx_t_2 != 0);
  if (__pyx_t_1) {

    /* "pygpu/gpuarray.pyx":42
 *         return (<unicode>s).encode('ascii')
 *     if isinstance(s, bytes):
 *         return s             # <<<<<<<<<<<<<<
 *     raise TypeError("Expected a string")
 * 
 */
    __Pyx_XDECREF(__pyx_r);
    if (!(likely(PyBytes_CheckExact(__pyx_v_s))||((__pyx_v_s) == Py_None)||(PyErr_Format(PyExc_TypeError, "Expected %.16s, got %.200s", "bytes", Py_TYPE(__pyx_v_s)->tp_name), 0))) __PYX_ERR(0, 42, __pyx_L1_error)
    __Pyx_INCREF(__pyx_v_s);
    __pyx_r = ((PyObject*)__pyx_v_s);
    goto __pyx_L0;

    /* "pygpu/gpuarray.pyx":41
 *     if isinstance(s, unicode):
 *         return (<unicode>s).encode('ascii')
 *     if isinstance(s, bytes):             # <<<<<<<<<<<<<<
 *         return s
 *     raise TypeError("Expected a string")
 */
  }

  /* "pygpu/gpuarray.pyx":43
 *     if isinstance(s, bytes):
 *         return s
 *     raise TypeError("Expected a string")             # <<<<<<<<<<<<<<
 * 
 * cdef size_t countis(l, object val):
 */
  __pyx_t_3 = __Pyx_PyObject_Call(__pyx_builtin_TypeError, __pyx_tuple_, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 43, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_Raise(__pyx_t_3, 0, 0, 0);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __PYX_ERR(0, 43, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":38
 *     return _PyArray_Empty(a, b, c, d)
 * 
 * cdef bytes _s(s):             # <<<<<<<<<<<<<<
 *     if isinstance(s, unicode):
 *         return (<unicode>s).encode('ascii')
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("pygpu.gpuarray._s", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":45
 *     raise TypeError("Expected a string")
 * 
 * cdef size_t countis(l, object val):             # <<<<<<<<<<<<<<
 *     cdef size_t count
 *     cdef size_t i
 */

static size_t __pyx_f_5pygpu_8gpuarray_countis(PyObject *__pyx_v_l, PyObject *__pyx_v_val) {
  size_t __pyx_v_count;
  size_t __pyx_v_i;
  size_t __pyx_r;
  __Pyx_RefNannyDeclarations
  Py_ssize_t __pyx_t_1;
  size_t __pyx_t_2;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  int __pyx_t_5;
  __Pyx_RefNannySetupContext("countis", 0);

  /* "pygpu/gpuarray.pyx":48
 *     cdef size_t count
 *     cdef size_t i
 *     count = 0             # <<<<<<<<<<<<<<
 *     for i in range(len(l)):
 *         if l[i] is val:
 */
  __pyx_v_count = 0;

  /* "pygpu/gpuarray.pyx":49
 *     cdef size_t i
 *     count = 0
 *     for i in range(len(l)):             # <<<<<<<<<<<<<<
 *         if l[i] is val:
 *             count += 1
 */
  __pyx_t_1 = PyObject_Length(__pyx_v_l); if (unlikely(__pyx_t_1 == ((Py_ssize_t)-1))) __PYX_ERR(0, 49, __pyx_L1_error)
  for (__pyx_t_2 = 0; __pyx_t_2 < __pyx_t_1; __pyx_t_2+=1) {
    __pyx_v_i = __pyx_t_2;

    /* "pygpu/gpuarray.pyx":50
 *     count = 0
 *     for i in range(len(l)):
 *         if l[i] is val:             # <<<<<<<<<<<<<<
 *             count += 1
 *     return count
 */
    __pyx_t_3 = __Pyx_GetItemInt(__pyx_v_l, __pyx_v_i, size_t, 0, __Pyx_PyInt_FromSize_t, 0, 0, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 50, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_4 = (__pyx_t_3 == __pyx_v_val);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_5 = (__pyx_t_4 != 0);
    if (__pyx_t_5) {

      /* "pygpu/gpuarray.pyx":51
 *     for i in range(len(l)):
 *         if l[i] is val:
 *             count += 1             # <<<<<<<<<<<<<<
 *     return count
 * 
 */
      __pyx_v_count = (__pyx_v_count + 1);

      /* "pygpu/gpuarray.pyx":50
 *     count = 0
 *     for i in range(len(l)):
 *         if l[i] is val:             # <<<<<<<<<<<<<<
 *             count += 1
 *     return count
 */
    }
  }

  /* "pygpu/gpuarray.pyx":52
 *         if l[i] is val:
 *             count += 1
 *     return count             # <<<<<<<<<<<<<<
 * 
 * def cl_wrap_ctx(size_t ptr):
 */
  __pyx_r = __pyx_v_count;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":45
 *     raise TypeError("Expected a string")
 * 
 * cdef size_t countis(l, object val):             # <<<<<<<<<<<<<<
 *     cdef size_t count
 *     cdef size_t i
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_WriteUnraisable("pygpu.gpuarray.countis", __pyx_clineno, __pyx_lineno, __pyx_filename, 1, 0);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":54
 *     return count
 * 
 * def cl_wrap_ctx(size_t ptr):             # <<<<<<<<<<<<<<
 *     """
 *     cl_wrap_ctx(ptr)
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_5cl_wrap_ctx(PyObject *__pyx_self, PyObject *__pyx_arg_ptr); /*proto*/
static char __pyx_doc_5pygpu_8gpuarray_4cl_wrap_ctx[] = "\n    cl_wrap_ctx(ptr)\n\n    Wrap an existing OpenCL context (the cl_context struct) into a\n    GpuContext class.\n    ";
static PyMethodDef __pyx_mdef_5pygpu_8gpuarray_5cl_wrap_ctx = {"cl_wrap_ctx", (PyCFunction)__pyx_pw_5pygpu_8gpuarray_5cl_wrap_ctx, METH_O, __pyx_doc_5pygpu_8gpuarray_4cl_wrap_ctx};
static PyObject *__pyx_pw_5pygpu_8gpuarray_5cl_wrap_ctx(PyObject *__pyx_self, PyObject *__pyx_arg_ptr) {
  size_t __pyx_v_ptr;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cl_wrap_ctx (wrapper)", 0);
  assert(__pyx_arg_ptr); {
    __pyx_v_ptr = __Pyx_PyInt_As_size_t(__pyx_arg_ptr); if (unlikely((__pyx_v_ptr == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 54, __pyx_L3_error)
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  __Pyx_AddTraceback("pygpu.gpuarray.cl_wrap_ctx", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_4cl_wrap_ctx(__pyx_self, ((size_t)__pyx_v_ptr));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_4cl_wrap_ctx(CYTHON_UNUSED PyObject *__pyx_self, size_t __pyx_v_ptr) {
  gpucontext *(*__pyx_v_cl_make_ctx)(void *, int);
  struct PyGpuContextObject *__pyx_v_res = 0;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  __Pyx_RefNannySetupContext("cl_wrap_ctx", 0);

  /* "pygpu/gpuarray.pyx":63
 *     cdef gpucontext *(*cl_make_ctx)(void *, int)
 *     cdef GpuContext res
 *     cl_make_ctx = <gpucontext *(*)(void *, int)>gpuarray_get_extension("cl_make_ctx")             # <<<<<<<<<<<<<<
 *     if cl_make_ctx == NULL:
 *         raise RuntimeError, "cl_make_ctx extension is absent"
 */
  __pyx_v_cl_make_ctx = ((gpucontext *(*)(void *, int))gpuarray_get_extension(((char const *)"cl_make_ctx")));

  /* "pygpu/gpuarray.pyx":64
 *     cdef GpuContext res
 *     cl_make_ctx = <gpucontext *(*)(void *, int)>gpuarray_get_extension("cl_make_ctx")
 *     if cl_make_ctx == NULL:             # <<<<<<<<<<<<<<
 *         raise RuntimeError, "cl_make_ctx extension is absent"
 *     res = GpuContext.__new__(GpuContext)
 */
  __pyx_t_1 = ((__pyx_v_cl_make_ctx == NULL) != 0);
  if (__pyx_t_1) {

    /* "pygpu/gpuarray.pyx":65
 *     cl_make_ctx = <gpucontext *(*)(void *, int)>gpuarray_get_extension("cl_make_ctx")
 *     if cl_make_ctx == NULL:
 *         raise RuntimeError, "cl_make_ctx extension is absent"             # <<<<<<<<<<<<<<
 *     res = GpuContext.__new__(GpuContext)
 *     res.ctx = cl_make_ctx(<void *>ptr, 0)
 */
    __Pyx_Raise(__pyx_builtin_RuntimeError, __pyx_kp_s_cl_make_ctx_extension_is_absent, 0, 0);
    __PYX_ERR(0, 65, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":64
 *     cdef GpuContext res
 *     cl_make_ctx = <gpucontext *(*)(void *, int)>gpuarray_get_extension("cl_make_ctx")
 *     if cl_make_ctx == NULL:             # <<<<<<<<<<<<<<
 *         raise RuntimeError, "cl_make_ctx extension is absent"
 *     res = GpuContext.__new__(GpuContext)
 */
  }

  /* "pygpu/gpuarray.pyx":66
 *     if cl_make_ctx == NULL:
 *         raise RuntimeError, "cl_make_ctx extension is absent"
 *     res = GpuContext.__new__(GpuContext)             # <<<<<<<<<<<<<<
 *     res.ctx = cl_make_ctx(<void *>ptr, 0)
 *     if res.ctx == NULL:
 */
  __pyx_t_2 = __pyx_tp_new_5pygpu_8gpuarray_GpuContext(((PyTypeObject *)__pyx_ptype_5pygpu_8gpuarray_GpuContext), __pyx_empty_tuple, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 66, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (!(likely(__Pyx_TypeTest(__pyx_t_2, __pyx_ptype_5pygpu_8gpuarray_GpuContext)))) __PYX_ERR(0, 66, __pyx_L1_error)
  __pyx_v_res = ((struct PyGpuContextObject *)__pyx_t_2);
  __pyx_t_2 = 0;

  /* "pygpu/gpuarray.pyx":67
 *         raise RuntimeError, "cl_make_ctx extension is absent"
 *     res = GpuContext.__new__(GpuContext)
 *     res.ctx = cl_make_ctx(<void *>ptr, 0)             # <<<<<<<<<<<<<<
 *     if res.ctx == NULL:
 *         raise RuntimeError, "cl_make_ctx call failed"
 */
  __pyx_v_res->ctx = __pyx_v_cl_make_ctx(((void *)__pyx_v_ptr), 0);

  /* "pygpu/gpuarray.pyx":68
 *     res = GpuContext.__new__(GpuContext)
 *     res.ctx = cl_make_ctx(<void *>ptr, 0)
 *     if res.ctx == NULL:             # <<<<<<<<<<<<<<
 *         raise RuntimeError, "cl_make_ctx call failed"
 *     return res
 */
  __pyx_t_1 = ((__pyx_v_res->ctx == NULL) != 0);
  if (__pyx_t_1) {

    /* "pygpu/gpuarray.pyx":69
 *     res.ctx = cl_make_ctx(<void *>ptr, 0)
 *     if res.ctx == NULL:
 *         raise RuntimeError, "cl_make_ctx call failed"             # <<<<<<<<<<<<<<
 *     return res
 * 
 */
    __Pyx_Raise(__pyx_builtin_RuntimeError, __pyx_kp_s_cl_make_ctx_call_failed, 0, 0);
    __PYX_ERR(0, 69, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":68
 *     res = GpuContext.__new__(GpuContext)
 *     res.ctx = cl_make_ctx(<void *>ptr, 0)
 *     if res.ctx == NULL:             # <<<<<<<<<<<<<<
 *         raise RuntimeError, "cl_make_ctx call failed"
 *     return res
 */
  }

  /* "pygpu/gpuarray.pyx":70
 *     if res.ctx == NULL:
 *         raise RuntimeError, "cl_make_ctx call failed"
 *     return res             # <<<<<<<<<<<<<<
 * 
 * def cuda_wrap_ctx(size_t ptr, bint own):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_res));
  __pyx_r = ((PyObject *)__pyx_v_res);
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":54
 *     return count
 * 
 * def cl_wrap_ctx(size_t ptr):             # <<<<<<<<<<<<<<
 *     """
 *     cl_wrap_ctx(ptr)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("pygpu.gpuarray.cl_wrap_ctx", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_res);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":72
 *     return res
 * 
 * def cuda_wrap_ctx(size_t ptr, bint own):             # <<<<<<<<<<<<<<
 *     """
 *     cuda_wrap_ctx(ptr)
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_7cuda_wrap_ctx(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static char __pyx_doc_5pygpu_8gpuarray_6cuda_wrap_ctx[] = "\n    cuda_wrap_ctx(ptr)\n\n    Wrap an existing CUDA driver context (CUcontext) into a GpuContext\n    class.\n\n    If `own` is true, libgpuarray is now reponsible for the context and\n    it will be destroyed once there are no references to it.\n    Otherwise, the context will not be destroyed and it is the calling\n    code's reponsability.\n    ";
static PyMethodDef __pyx_mdef_5pygpu_8gpuarray_7cuda_wrap_ctx = {"cuda_wrap_ctx", (PyCFunction)__pyx_pw_5pygpu_8gpuarray_7cuda_wrap_ctx, METH_VARARGS|METH_KEYWORDS, __pyx_doc_5pygpu_8gpuarray_6cuda_wrap_ctx};
static PyObject *__pyx_pw_5pygpu_8gpuarray_7cuda_wrap_ctx(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  size_t __pyx_v_ptr;
  int __pyx_v_own;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cuda_wrap_ctx (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_ptr,&__pyx_n_s_own,0};
    PyObject* values[2] = {0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_ptr)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_own)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cuda_wrap_ctx", 1, 2, 2, 1); __PYX_ERR(0, 72, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cuda_wrap_ctx") < 0)) __PYX_ERR(0, 72, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 2) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
    }
    __pyx_v_ptr = __Pyx_PyInt_As_size_t(values[0]); if (unlikely((__pyx_v_ptr == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 72, __pyx_L3_error)
    __pyx_v_own = __Pyx_PyObject_IsTrue(values[1]); if (unlikely((__pyx_v_own == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 72, __pyx_L3_error)
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cuda_wrap_ctx", 1, 2, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 72, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("pygpu.gpuarray.cuda_wrap_ctx", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_6cuda_wrap_ctx(__pyx_self, __pyx_v_ptr, __pyx_v_own);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_6cuda_wrap_ctx(CYTHON_UNUSED PyObject *__pyx_self, size_t __pyx_v_ptr, int __pyx_v_own) {
  gpucontext *(*__pyx_v_cuda_make_ctx)(void *, int);
  int __pyx_v_flags;
  struct PyGpuContextObject *__pyx_v_res = 0;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  __Pyx_RefNannySetupContext("cuda_wrap_ctx", 0);

  /* "pygpu/gpuarray.pyx":87
 *     cdef int flags
 *     cdef GpuContext res
 *     cuda_make_ctx = <gpucontext *(*)(void *, int)>gpuarray_get_extension("cuda_make_ctx")             # <<<<<<<<<<<<<<
 *     if cuda_make_ctx == NULL:
 *         raise RuntimeError, "cuda_make_ctx extension is absent"
 */
  __pyx_v_cuda_make_ctx = ((gpucontext *(*)(void *, int))gpuarray_get_extension(((char const *)"cuda_make_ctx")));

  /* "pygpu/gpuarray.pyx":88
 *     cdef GpuContext res
 *     cuda_make_ctx = <gpucontext *(*)(void *, int)>gpuarray_get_extension("cuda_make_ctx")
 *     if cuda_make_ctx == NULL:             # <<<<<<<<<<<<<<
 *         raise RuntimeError, "cuda_make_ctx extension is absent"
 *     res = GpuContext.__new__(GpuContext)
 */
  __pyx_t_1 = ((__pyx_v_cuda_make_ctx == NULL) != 0);
  if (__pyx_t_1) {

    /* "pygpu/gpuarray.pyx":89
 *     cuda_make_ctx = <gpucontext *(*)(void *, int)>gpuarray_get_extension("cuda_make_ctx")
 *     if cuda_make_ctx == NULL:
 *         raise RuntimeError, "cuda_make_ctx extension is absent"             # <<<<<<<<<<<<<<
 *     res = GpuContext.__new__(GpuContext)
 *     flags = 0
 */
    __Pyx_Raise(__pyx_builtin_RuntimeError, __pyx_kp_s_cuda_make_ctx_extension_is_absen, 0, 0);
    __PYX_ERR(0, 89, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":88
 *     cdef GpuContext res
 *     cuda_make_ctx = <gpucontext *(*)(void *, int)>gpuarray_get_extension("cuda_make_ctx")
 *     if cuda_make_ctx == NULL:             # <<<<<<<<<<<<<<
 *         raise RuntimeError, "cuda_make_ctx extension is absent"
 *     res = GpuContext.__new__(GpuContext)
 */
  }

  /* "pygpu/gpuarray.pyx":90
 *     if cuda_make_ctx == NULL:
 *         raise RuntimeError, "cuda_make_ctx extension is absent"
 *     res = GpuContext.__new__(GpuContext)             # <<<<<<<<<<<<<<
 *     flags = 0
 *     if not own:
 */
  __pyx_t_2 = __pyx_tp_new_5pygpu_8gpuarray_GpuContext(((PyTypeObject *)__pyx_ptype_5pygpu_8gpuarray_GpuContext), __pyx_empty_tuple, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 90, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (!(likely(__Pyx_TypeTest(__pyx_t_2, __pyx_ptype_5pygpu_8gpuarray_GpuContext)))) __PYX_ERR(0, 90, __pyx_L1_error)
  __pyx_v_res = ((struct PyGpuContextObject *)__pyx_t_2);
  __pyx_t_2 = 0;

  /* "pygpu/gpuarray.pyx":91
 *         raise RuntimeError, "cuda_make_ctx extension is absent"
 *     res = GpuContext.__new__(GpuContext)
 *     flags = 0             # <<<<<<<<<<<<<<
 *     if not own:
 *         flags |= GPUARRAY_CUDA_CTX_NOFREE
 */
  __pyx_v_flags = 0;

  /* "pygpu/gpuarray.pyx":92
 *     res = GpuContext.__new__(GpuContext)
 *     flags = 0
 *     if not own:             # <<<<<<<<<<<<<<
 *         flags |= GPUARRAY_CUDA_CTX_NOFREE
 *     res.ctx = cuda_make_ctx(<void *>ptr, flags)
 */
  __pyx_t_1 = ((!(__pyx_v_own != 0)) != 0);
  if (__pyx_t_1) {

    /* "pygpu/gpuarray.pyx":93
 *     flags = 0
 *     if not own:
 *         flags |= GPUARRAY_CUDA_CTX_NOFREE             # <<<<<<<<<<<<<<
 *     res.ctx = cuda_make_ctx(<void *>ptr, flags)
 *     if res.ctx == NULL:
 */
    __pyx_v_flags = (__pyx_v_flags | GPUARRAY_CUDA_CTX_NOFREE);

    /* "pygpu/gpuarray.pyx":92
 *     res = GpuContext.__new__(GpuContext)
 *     flags = 0
 *     if not own:             # <<<<<<<<<<<<<<
 *         flags |= GPUARRAY_CUDA_CTX_NOFREE
 *     res.ctx = cuda_make_ctx(<void *>ptr, flags)
 */
  }

  /* "pygpu/gpuarray.pyx":94
 *     if not own:
 *         flags |= GPUARRAY_CUDA_CTX_NOFREE
 *     res.ctx = cuda_make_ctx(<void *>ptr, flags)             # <<<<<<<<<<<<<<
 *     if res.ctx == NULL:
 *         raise RuntimeError, "cuda_make_ctx call failed"
 */
  __pyx_v_res->ctx = __pyx_v_cuda_make_ctx(((void *)__pyx_v_ptr), __pyx_v_flags);

  /* "pygpu/gpuarray.pyx":95
 *         flags |= GPUARRAY_CUDA_CTX_NOFREE
 *     res.ctx = cuda_make_ctx(<void *>ptr, flags)
 *     if res.ctx == NULL:             # <<<<<<<<<<<<<<
 *         raise RuntimeError, "cuda_make_ctx call failed"
 *     return res
 */
  __pyx_t_1 = ((__pyx_v_res->ctx == NULL) != 0);
  if (__pyx_t_1) {

    /* "pygpu/gpuarray.pyx":96
 *     res.ctx = cuda_make_ctx(<void *>ptr, flags)
 *     if res.ctx == NULL:
 *         raise RuntimeError, "cuda_make_ctx call failed"             # <<<<<<<<<<<<<<
 *     return res
 * 
 */
    __Pyx_Raise(__pyx_builtin_RuntimeError, __pyx_kp_s_cuda_make_ctx_call_failed, 0, 0);
    __PYX_ERR(0, 96, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":95
 *         flags |= GPUARRAY_CUDA_CTX_NOFREE
 *     res.ctx = cuda_make_ctx(<void *>ptr, flags)
 *     if res.ctx == NULL:             # <<<<<<<<<<<<<<
 *         raise RuntimeError, "cuda_make_ctx call failed"
 *     return res
 */
  }

  /* "pygpu/gpuarray.pyx":97
 *     if res.ctx == NULL:
 *         raise RuntimeError, "cuda_make_ctx call failed"
 *     return res             # <<<<<<<<<<<<<<
 * 
 * import numpy
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_res));
  __pyx_r = ((PyObject *)__pyx_v_res);
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":72
 *     return res
 * 
 * def cuda_wrap_ctx(size_t ptr, bint own):             # <<<<<<<<<<<<<<
 *     """
 *     cuda_wrap_ctx(ptr)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("pygpu.gpuarray.cuda_wrap_ctx", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_res);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":120
 * cdef dict TYPE_TO_NP = dict((v, k) for k, v in NP_TO_TYPE.iteritems())
 * 
 * def register_dtype(np.dtype dtype, cname):             # <<<<<<<<<<<<<<
 *     """
 *     register_dtype(dtype, cname)
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_9register_dtype(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static char __pyx_doc_5pygpu_8gpuarray_8register_dtype[] = "\n    register_dtype(dtype, cname)\n\n    Make a new type known to the cluda machinery.\n\n    This function return the associted internal typecode for the new\n    type.\n\n    Parameters\n    ----------\n    dtype: numpy.dtype\n        new type\n    cname: str\n        C name for the type declarations\n\n    ";
static PyMethodDef __pyx_mdef_5pygpu_8gpuarray_9register_dtype = {"register_dtype", (PyCFunction)__pyx_pw_5pygpu_8gpuarray_9register_dtype, METH_VARARGS|METH_KEYWORDS, __pyx_doc_5pygpu_8gpuarray_8register_dtype};
static PyObject *__pyx_pw_5pygpu_8gpuarray_9register_dtype(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyArray_Descr *__pyx_v_dtype = 0;
  PyObject *__pyx_v_cname = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("register_dtype (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_dtype,&__pyx_n_s_cname,0};
    PyObject* values[2] = {0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_dtype)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_cname)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("register_dtype", 1, 2, 2, 1); __PYX_ERR(0, 120, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "register_dtype") < 0)) __PYX_ERR(0, 120, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 2) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
    }
    __pyx_v_dtype = ((PyArray_Descr *)values[0]);
    __pyx_v_cname = values[1];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("register_dtype", 1, 2, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 120, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("pygpu.gpuarray.register_dtype", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_dtype), __pyx_ptype_5numpy_dtype, 1, "dtype", 0))) __PYX_ERR(0, 120, __pyx_L1_error)
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_8register_dtype(__pyx_self, __pyx_v_dtype, __pyx_v_cname);

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_8register_dtype(CYTHON_UNUSED PyObject *__pyx_self, PyArray_Descr *__pyx_v_dtype, PyObject *__pyx_v_cname) {
  gpuarray_type *__pyx_v_t;
  int __pyx_v_typecode;
  char *__pyx_v_tmp;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  Py_ssize_t __pyx_t_2;
  char *__pyx_t_3;
  int __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  __Pyx_RefNannySetupContext("register_dtype", 0);

  /* "pygpu/gpuarray.pyx":141
 *     cdef char *tmp
 * 
 *     t = <gpuarray_type *>malloc(sizeof(gpuarray_type))             # <<<<<<<<<<<<<<
 *     if t == NULL:
 *         raise MemoryError, "Can't allocate new type"
 */
  __pyx_v_t = ((gpuarray_type *)malloc((sizeof(gpuarray_type))));

  /* "pygpu/gpuarray.pyx":142
 * 
 *     t = <gpuarray_type *>malloc(sizeof(gpuarray_type))
 *     if t == NULL:             # <<<<<<<<<<<<<<
 *         raise MemoryError, "Can't allocate new type"
 *     tmp = <char *>malloc(len(cname)+1)
 */
  __pyx_t_1 = ((__pyx_v_t == NULL) != 0);
  if (__pyx_t_1) {

    /* "pygpu/gpuarray.pyx":143
 *     t = <gpuarray_type *>malloc(sizeof(gpuarray_type))
 *     if t == NULL:
 *         raise MemoryError, "Can't allocate new type"             # <<<<<<<<<<<<<<
 *     tmp = <char *>malloc(len(cname)+1)
 *     if tmp == NULL:
 */
    __Pyx_Raise(__pyx_builtin_MemoryError, __pyx_kp_s_Can_t_allocate_new_type, 0, 0);
    __PYX_ERR(0, 143, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":142
 * 
 *     t = <gpuarray_type *>malloc(sizeof(gpuarray_type))
 *     if t == NULL:             # <<<<<<<<<<<<<<
 *         raise MemoryError, "Can't allocate new type"
 *     tmp = <char *>malloc(len(cname)+1)
 */
  }

  /* "pygpu/gpuarray.pyx":144
 *     if t == NULL:
 *         raise MemoryError, "Can't allocate new type"
 *     tmp = <char *>malloc(len(cname)+1)             # <<<<<<<<<<<<<<
 *     if tmp == NULL:
 *         free(t)
 */
  __pyx_t_2 = PyObject_Length(__pyx_v_cname); if (unlikely(__pyx_t_2 == ((Py_ssize_t)-1))) __PYX_ERR(0, 144, __pyx_L1_error)
  __pyx_v_tmp = ((char *)malloc((__pyx_t_2 + 1)));

  /* "pygpu/gpuarray.pyx":145
 *         raise MemoryError, "Can't allocate new type"
 *     tmp = <char *>malloc(len(cname)+1)
 *     if tmp == NULL:             # <<<<<<<<<<<<<<
 *         free(t)
 *         raise MemoryError
 */
  __pyx_t_1 = ((__pyx_v_tmp == NULL) != 0);
  if (__pyx_t_1) {

    /* "pygpu/gpuarray.pyx":146
 *     tmp = <char *>malloc(len(cname)+1)
 *     if tmp == NULL:
 *         free(t)             # <<<<<<<<<<<<<<
 *         raise MemoryError
 *     memcpy(tmp, <char *>cname, len(cname)+1)
 */
    free(__pyx_v_t);

    /* "pygpu/gpuarray.pyx":147
 *     if tmp == NULL:
 *         free(t)
 *         raise MemoryError             # <<<<<<<<<<<<<<
 *     memcpy(tmp, <char *>cname, len(cname)+1)
 *     t.size = dtype.itemsize
 */
    PyErr_NoMemory(); __PYX_ERR(0, 147, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":145
 *         raise MemoryError, "Can't allocate new type"
 *     tmp = <char *>malloc(len(cname)+1)
 *     if tmp == NULL:             # <<<<<<<<<<<<<<
 *         free(t)
 *         raise MemoryError
 */
  }

  /* "pygpu/gpuarray.pyx":148
 *         free(t)
 *         raise MemoryError
 *     memcpy(tmp, <char *>cname, len(cname)+1)             # <<<<<<<<<<<<<<
 *     t.size = dtype.itemsize
 *     t.align = dtype.alignment
 */
  __pyx_t_3 = __Pyx_PyObject_AsWritableString(__pyx_v_cname); if (unlikely((!__pyx_t_3) && PyErr_Occurred())) __PYX_ERR(0, 148, __pyx_L1_error)
  __pyx_t_2 = PyObject_Length(__pyx_v_cname); if (unlikely(__pyx_t_2 == ((Py_ssize_t)-1))) __PYX_ERR(0, 148, __pyx_L1_error)
  memcpy(__pyx_v_tmp, ((char *)__pyx_t_3), (__pyx_t_2 + 1));

  /* "pygpu/gpuarray.pyx":149
 *         raise MemoryError
 *     memcpy(tmp, <char *>cname, len(cname)+1)
 *     t.size = dtype.itemsize             # <<<<<<<<<<<<<<
 *     t.align = dtype.alignment
 *     t.cluda_name = tmp
 */
  __pyx_t_4 = __pyx_v_dtype->elsize;
  __pyx_v_t->size = __pyx_t_4;

  /* "pygpu/gpuarray.pyx":150
 *     memcpy(tmp, <char *>cname, len(cname)+1)
 *     t.size = dtype.itemsize
 *     t.align = dtype.alignment             # <<<<<<<<<<<<<<
 *     t.cluda_name = tmp
 *     typecode = gpuarray_register_type(t, NULL)
 */
  __pyx_t_4 = __pyx_v_dtype->alignment;
  __pyx_v_t->align = __pyx_t_4;

  /* "pygpu/gpuarray.pyx":151
 *     t.size = dtype.itemsize
 *     t.align = dtype.alignment
 *     t.cluda_name = tmp             # <<<<<<<<<<<<<<
 *     typecode = gpuarray_register_type(t, NULL)
 *     if typecode == -1:
 */
  __pyx_v_t->cluda_name = __pyx_v_tmp;

  /* "pygpu/gpuarray.pyx":152
 *     t.align = dtype.alignment
 *     t.cluda_name = tmp
 *     typecode = gpuarray_register_type(t, NULL)             # <<<<<<<<<<<<<<
 *     if typecode == -1:
 *         free(tmp)
 */
  __pyx_v_typecode = gpuarray_register_type(__pyx_v_t, NULL);

  /* "pygpu/gpuarray.pyx":153
 *     t.cluda_name = tmp
 *     typecode = gpuarray_register_type(t, NULL)
 *     if typecode == -1:             # <<<<<<<<<<<<<<
 *         free(tmp)
 *         free(t)
 */
  __pyx_t_1 = ((__pyx_v_typecode == -1L) != 0);
  if (__pyx_t_1) {

    /* "pygpu/gpuarray.pyx":154
 *     typecode = gpuarray_register_type(t, NULL)
 *     if typecode == -1:
 *         free(tmp)             # <<<<<<<<<<<<<<
 *         free(t)
 *         raise RuntimeError, "Could not register type"
 */
    free(__pyx_v_tmp);

    /* "pygpu/gpuarray.pyx":155
 *     if typecode == -1:
 *         free(tmp)
 *         free(t)             # <<<<<<<<<<<<<<
 *         raise RuntimeError, "Could not register type"
 *     NP_TO_TYPE[dtype] = typecode
 */
    free(__pyx_v_t);

    /* "pygpu/gpuarray.pyx":156
 *         free(tmp)
 *         free(t)
 *         raise RuntimeError, "Could not register type"             # <<<<<<<<<<<<<<
 *     NP_TO_TYPE[dtype] = typecode
 *     TYPE_TO_NP[typecode] = dtype
 */
    __Pyx_Raise(__pyx_builtin_RuntimeError, __pyx_kp_s_Could_not_register_type, 0, 0);
    __PYX_ERR(0, 156, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":153
 *     t.cluda_name = tmp
 *     typecode = gpuarray_register_type(t, NULL)
 *     if typecode == -1:             # <<<<<<<<<<<<<<
 *         free(tmp)
 *         free(t)
 */
  }

  /* "pygpu/gpuarray.pyx":157
 *         free(t)
 *         raise RuntimeError, "Could not register type"
 *     NP_TO_TYPE[dtype] = typecode             # <<<<<<<<<<<<<<
 *     TYPE_TO_NP[typecode] = dtype
 * 
 */
  __pyx_t_5 = __Pyx_PyInt_From_int(__pyx_v_typecode); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 157, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  if (unlikely(__pyx_v_5pygpu_8gpuarray_NP_TO_TYPE == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
    __PYX_ERR(0, 157, __pyx_L1_error)
  }
  if (unlikely(PyDict_SetItem(__pyx_v_5pygpu_8gpuarray_NP_TO_TYPE, ((PyObject *)__pyx_v_dtype), __pyx_t_5) < 0)) __PYX_ERR(0, 157, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;

  /* "pygpu/gpuarray.pyx":158
 *         raise RuntimeError, "Could not register type"
 *     NP_TO_TYPE[dtype] = typecode
 *     TYPE_TO_NP[typecode] = dtype             # <<<<<<<<<<<<<<
 * 
 * cdef np.dtype typecode_to_dtype(int typecode):
 */
  if (unlikely(__pyx_v_5pygpu_8gpuarray_TYPE_TO_NP == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
    __PYX_ERR(0, 158, __pyx_L1_error)
  }
  __pyx_t_5 = __Pyx_PyInt_From_int(__pyx_v_typecode); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 158, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  if (unlikely(PyDict_SetItem(__pyx_v_5pygpu_8gpuarray_TYPE_TO_NP, __pyx_t_5, ((PyObject *)__pyx_v_dtype)) < 0)) __PYX_ERR(0, 158, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;

  /* "pygpu/gpuarray.pyx":120
 * cdef dict TYPE_TO_NP = dict((v, k) for k, v in NP_TO_TYPE.iteritems())
 * 
 * def register_dtype(np.dtype dtype, cname):             # <<<<<<<<<<<<<<
 *     """
 *     register_dtype(dtype, cname)
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("pygpu.gpuarray.register_dtype", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":160
 *     TYPE_TO_NP[typecode] = dtype
 * 
 * cdef np.dtype typecode_to_dtype(int typecode):             # <<<<<<<<<<<<<<
 *     res = TYPE_TO_NP.get(typecode, None)
 *     if res is not None:
 */

static PyArray_Descr *__pyx_f_5pygpu_8gpuarray_typecode_to_dtype(int __pyx_v_typecode) {
  PyObject *__pyx_v_res = NULL;
  PyArray_Descr *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  int __pyx_t_3;
  int __pyx_t_4;
  __Pyx_RefNannySetupContext("typecode_to_dtype", 0);

  /* "pygpu/gpuarray.pyx":161
 * 
 * cdef np.dtype typecode_to_dtype(int typecode):
 *     res = TYPE_TO_NP.get(typecode, None)             # <<<<<<<<<<<<<<
 *     if res is not None:
 *         return res
 */
  if (unlikely(__pyx_v_5pygpu_8gpuarray_TYPE_TO_NP == Py_None)) {
    PyErr_Format(PyExc_AttributeError, "'NoneType' object has no attribute '%.30s'", "get");
    __PYX_ERR(0, 161, __pyx_L1_error)
  }
  __pyx_t_1 = __Pyx_PyInt_From_int(__pyx_v_typecode); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 161, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyDict_GetItemDefault(__pyx_v_5pygpu_8gpuarray_TYPE_TO_NP, __pyx_t_1, Py_None); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 161, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_res = __pyx_t_2;
  __pyx_t_2 = 0;

  /* "pygpu/gpuarray.pyx":162
 * cdef np.dtype typecode_to_dtype(int typecode):
 *     res = TYPE_TO_NP.get(typecode, None)
 *     if res is not None:             # <<<<<<<<<<<<<<
 *         return res
 *     else:
 */
  __pyx_t_3 = (__pyx_v_res != Py_None);
  __pyx_t_4 = (__pyx_t_3 != 0);
  if (__pyx_t_4) {

    /* "pygpu/gpuarray.pyx":163
 *     res = TYPE_TO_NP.get(typecode, None)
 *     if res is not None:
 *         return res             # <<<<<<<<<<<<<<
 *     else:
 *         raise NotImplementedError, "TODO"
 */
    __Pyx_XDECREF(((PyObject *)__pyx_r));
    if (!(likely(((__pyx_v_res) == Py_None) || likely(__Pyx_TypeTest(__pyx_v_res, __pyx_ptype_5numpy_dtype))))) __PYX_ERR(0, 163, __pyx_L1_error)
    __Pyx_INCREF(__pyx_v_res);
    __pyx_r = ((PyArray_Descr *)__pyx_v_res);
    goto __pyx_L0;

    /* "pygpu/gpuarray.pyx":162
 * cdef np.dtype typecode_to_dtype(int typecode):
 *     res = TYPE_TO_NP.get(typecode, None)
 *     if res is not None:             # <<<<<<<<<<<<<<
 *         return res
 *     else:
 */
  }

  /* "pygpu/gpuarray.pyx":165
 *         return res
 *     else:
 *         raise NotImplementedError, "TODO"             # <<<<<<<<<<<<<<
 * 
 * # This function takes a flexible dtype as accepted by the functions of
 */
  /*else*/ {
    __Pyx_Raise(__pyx_builtin_NotImplementedError, __pyx_n_s_TODO, 0, 0);
    __PYX_ERR(0, 165, __pyx_L1_error)
  }

  /* "pygpu/gpuarray.pyx":160
 *     TYPE_TO_NP[typecode] = dtype
 * 
 * cdef np.dtype typecode_to_dtype(int typecode):             # <<<<<<<<<<<<<<
 *     res = TYPE_TO_NP.get(typecode, None)
 *     if res is not None:
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("pygpu.gpuarray.typecode_to_dtype", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_res);
  __Pyx_XGIVEREF((PyObject *)__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":169
 * # This function takes a flexible dtype as accepted by the functions of
 * # this module and ensures it becomes a numpy dtype.
 * cdef np.dtype dtype_to_npdtype(dtype):             # <<<<<<<<<<<<<<
 *     if dtype is None:
 *         return None
 */

static PyArray_Descr *__pyx_f_5pygpu_8gpuarray_dtype_to_npdtype(PyObject *__pyx_v_dtype) {
  PyArray_Descr *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_t_2;
  int __pyx_t_3;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  PyObject *__pyx_t_8 = NULL;
  __Pyx_RefNannySetupContext("dtype_to_npdtype", 0);

  /* "pygpu/gpuarray.pyx":170
 * # this module and ensures it becomes a numpy dtype.
 * cdef np.dtype dtype_to_npdtype(dtype):
 *     if dtype is None:             # <<<<<<<<<<<<<<
 *         return None
 *     if isinstance(dtype, int):
 */
  __pyx_t_1 = (__pyx_v_dtype == Py_None);
  __pyx_t_2 = (__pyx_t_1 != 0);
  if (__pyx_t_2) {

    /* "pygpu/gpuarray.pyx":171
 * cdef np.dtype dtype_to_npdtype(dtype):
 *     if dtype is None:
 *         return None             # <<<<<<<<<<<<<<
 *     if isinstance(dtype, int):
 *         return typecode_to_dtype(dtype)
 */
    __Pyx_XDECREF(((PyObject *)__pyx_r));
    __Pyx_INCREF(Py_None);
    __pyx_r = ((PyArray_Descr *)Py_None);
    goto __pyx_L0;

    /* "pygpu/gpuarray.pyx":170
 * # this module and ensures it becomes a numpy dtype.
 * cdef np.dtype dtype_to_npdtype(dtype):
 *     if dtype is None:             # <<<<<<<<<<<<<<
 *         return None
 *     if isinstance(dtype, int):
 */
  }

  /* "pygpu/gpuarray.pyx":172
 *     if dtype is None:
 *         return None
 *     if isinstance(dtype, int):             # <<<<<<<<<<<<<<
 *         return typecode_to_dtype(dtype)
 *     try:
 */
  __pyx_t_2 = PyInt_Check(__pyx_v_dtype); 
  __pyx_t_1 = (__pyx_t_2 != 0);
  if (__pyx_t_1) {

    /* "pygpu/gpuarray.pyx":173
 *         return None
 *     if isinstance(dtype, int):
 *         return typecode_to_dtype(dtype)             # <<<<<<<<<<<<<<
 *     try:
 *         return np.dtype(dtype)
 */
    __Pyx_XDECREF(((PyObject *)__pyx_r));
    __pyx_t_3 = __Pyx_PyInt_As_int(__pyx_v_dtype); if (unlikely((__pyx_t_3 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 173, __pyx_L1_error)
    __pyx_t_4 = ((PyObject *)__pyx_f_5pygpu_8gpuarray_typecode_to_dtype(__pyx_t_3)); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 173, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_r = ((PyArray_Descr *)__pyx_t_4);
    __pyx_t_4 = 0;
    goto __pyx_L0;

    /* "pygpu/gpuarray.pyx":172
 *     if dtype is None:
 *         return None
 *     if isinstance(dtype, int):             # <<<<<<<<<<<<<<
 *         return typecode_to_dtype(dtype)
 *     try:
 */
  }

  /* "pygpu/gpuarray.pyx":174
 *     if isinstance(dtype, int):
 *         return typecode_to_dtype(dtype)
 *     try:             # <<<<<<<<<<<<<<
 *         return np.dtype(dtype)
 *     except TypeError:
 */
  {
    __Pyx_PyThreadState_declare
    __Pyx_PyThreadState_assign
    __Pyx_ExceptionSave(&__pyx_t_5, &__pyx_t_6, &__pyx_t_7);
    __Pyx_XGOTREF(__pyx_t_5);
    __Pyx_XGOTREF(__pyx_t_6);
    __Pyx_XGOTREF(__pyx_t_7);
    /*try:*/ {

      /* "pygpu/gpuarray.pyx":175
 *         return typecode_to_dtype(dtype)
 *     try:
 *         return np.dtype(dtype)             # <<<<<<<<<<<<<<
 *     except TypeError:
 *         pass
 */
      __Pyx_XDECREF(((PyObject *)__pyx_r));
      __pyx_t_4 = PyTuple_New(1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 175, __pyx_L5_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_INCREF(__pyx_v_dtype);
      __Pyx_GIVEREF(__pyx_v_dtype);
      PyTuple_SET_ITEM(__pyx_t_4, 0, __pyx_v_dtype);
      __pyx_t_8 = __Pyx_PyObject_Call(((PyObject *)__pyx_ptype_5numpy_dtype), __pyx_t_4, NULL); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 175, __pyx_L5_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __pyx_r = ((PyArray_Descr *)__pyx_t_8);
      __pyx_t_8 = 0;
      goto __pyx_L9_try_return;

      /* "pygpu/gpuarray.pyx":174
 *     if isinstance(dtype, int):
 *         return typecode_to_dtype(dtype)
 *     try:             # <<<<<<<<<<<<<<
 *         return np.dtype(dtype)
 *     except TypeError:
 */
    }
    __pyx_L5_error:;
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;

    /* "pygpu/gpuarray.pyx":176
 *     try:
 *         return np.dtype(dtype)
 *     except TypeError:             # <<<<<<<<<<<<<<
 *         pass
 *     if isinstance(dtype, np.dtype):
 */
    __pyx_t_3 = __Pyx_PyErr_ExceptionMatches(__pyx_builtin_TypeError);
    if (__pyx_t_3) {
      __Pyx_ErrRestore(0,0,0);
      goto __pyx_L6_exception_handled;
    }
    goto __pyx_L7_except_error;
    __pyx_L7_except_error:;

    /* "pygpu/gpuarray.pyx":174
 *     if isinstance(dtype, int):
 *         return typecode_to_dtype(dtype)
 *     try:             # <<<<<<<<<<<<<<
 *         return np.dtype(dtype)
 *     except TypeError:
 */
    __Pyx_XGIVEREF(__pyx_t_5);
    __Pyx_XGIVEREF(__pyx_t_6);
    __Pyx_XGIVEREF(__pyx_t_7);
    __Pyx_ExceptionReset(__pyx_t_5, __pyx_t_6, __pyx_t_7);
    goto __pyx_L1_error;
    __pyx_L9_try_return:;
    __Pyx_XGIVEREF(__pyx_t_5);
    __Pyx_XGIVEREF(__pyx_t_6);
    __Pyx_XGIVEREF(__pyx_t_7);
    __Pyx_ExceptionReset(__pyx_t_5, __pyx_t_6, __pyx_t_7);
    goto __pyx_L0;
    __pyx_L6_exception_handled:;
    __Pyx_XGIVEREF(__pyx_t_5);
    __Pyx_XGIVEREF(__pyx_t_6);
    __Pyx_XGIVEREF(__pyx_t_7);
    __Pyx_ExceptionReset(__pyx_t_5, __pyx_t_6, __pyx_t_7);
  }

  /* "pygpu/gpuarray.pyx":178
 *     except TypeError:
 *         pass
 *     if isinstance(dtype, np.dtype):             # <<<<<<<<<<<<<<
 *         return dtype
 *     raise ValueError("data type not understood", dtype)
 */
  __pyx_t_1 = __Pyx_TypeCheck(__pyx_v_dtype, __pyx_ptype_5numpy_dtype); 
  __pyx_t_2 = (__pyx_t_1 != 0);
  if (__pyx_t_2) {

    /* "pygpu/gpuarray.pyx":179
 *         pass
 *     if isinstance(dtype, np.dtype):
 *         return dtype             # <<<<<<<<<<<<<<
 *     raise ValueError("data type not understood", dtype)
 * 
 */
    __Pyx_XDECREF(((PyObject *)__pyx_r));
    if (!(likely(((__pyx_v_dtype) == Py_None) || likely(__Pyx_TypeTest(__pyx_v_dtype, __pyx_ptype_5numpy_dtype))))) __PYX_ERR(0, 179, __pyx_L1_error)
    __Pyx_INCREF(__pyx_v_dtype);
    __pyx_r = ((PyArray_Descr *)__pyx_v_dtype);
    goto __pyx_L0;

    /* "pygpu/gpuarray.pyx":178
 *     except TypeError:
 *         pass
 *     if isinstance(dtype, np.dtype):             # <<<<<<<<<<<<<<
 *         return dtype
 *     raise ValueError("data type not understood", dtype)
 */
  }

  /* "pygpu/gpuarray.pyx":180
 *     if isinstance(dtype, np.dtype):
 *         return dtype
 *     raise ValueError("data type not understood", dtype)             # <<<<<<<<<<<<<<
 * 
 * # This is a stupid wrapper to avoid the extra argument introduced by having
 */
  __pyx_t_8 = PyTuple_New(2); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 180, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __Pyx_INCREF(__pyx_kp_s_data_type_not_understood);
  __Pyx_GIVEREF(__pyx_kp_s_data_type_not_understood);
  PyTuple_SET_ITEM(__pyx_t_8, 0, __pyx_kp_s_data_type_not_understood);
  __Pyx_INCREF(__pyx_v_dtype);
  __Pyx_GIVEREF(__pyx_v_dtype);
  PyTuple_SET_ITEM(__pyx_t_8, 1, __pyx_v_dtype);
  __pyx_t_4 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_t_8, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 180, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  __Pyx_Raise(__pyx_t_4, 0, 0, 0);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __PYX_ERR(0, 180, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":169
 * # This function takes a flexible dtype as accepted by the functions of
 * # this module and ensures it becomes a numpy dtype.
 * cdef np.dtype dtype_to_npdtype(dtype):             # <<<<<<<<<<<<<<
 *     if dtype is None:
 *         return None
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_AddTraceback("pygpu.gpuarray.dtype_to_npdtype", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XGIVEREF((PyObject *)__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":184
 * # This is a stupid wrapper to avoid the extra argument introduced by having
 * # dtype_to_typecode declared 'cpdef'.
 * cdef int get_typecode(dtype) except -1:             # <<<<<<<<<<<<<<
 *     return dtype_to_typecode(dtype)
 * 
 */

static int __pyx_f_5pygpu_8gpuarray_get_typecode(PyObject *__pyx_v_dtype) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  __Pyx_RefNannySetupContext("get_typecode", 0);

  /* "pygpu/gpuarray.pyx":185
 * # dtype_to_typecode declared 'cpdef'.
 * cdef int get_typecode(dtype) except -1:
 *     return dtype_to_typecode(dtype)             # <<<<<<<<<<<<<<
 * 
 * cpdef int dtype_to_typecode(dtype) except -1:
 */
  __pyx_t_1 = __pyx_f_5pygpu_8gpuarray_dtype_to_typecode(__pyx_v_dtype, 0); if (unlikely(__pyx_t_1 == ((int)-1))) __PYX_ERR(0, 185, __pyx_L1_error)
  __pyx_r = __pyx_t_1;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":184
 * # This is a stupid wrapper to avoid the extra argument introduced by having
 * # dtype_to_typecode declared 'cpdef'.
 * cdef int get_typecode(dtype) except -1:             # <<<<<<<<<<<<<<
 *     return dtype_to_typecode(dtype)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_AddTraceback("pygpu.gpuarray.get_typecode", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":187
 *     return dtype_to_typecode(dtype)
 * 
 * cpdef int dtype_to_typecode(dtype) except -1:             # <<<<<<<<<<<<<<
 *     """
 *     dtype_to_typecode(dtype)
 */

static PyObject *__pyx_pw_5pygpu_8gpuarray_11dtype_to_typecode(PyObject *__pyx_self, PyObject *__pyx_v_dtype); /*proto*/
static int __pyx_f_5pygpu_8gpuarray_dtype_to_typecode(PyObject *__pyx_v_dtype, CYTHON_UNUSED int __pyx_skip_dispatch) {
  PyObject *__pyx_v_res = NULL;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_t_2;
  int __pyx_t_3;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  PyObject *__pyx_t_8 = NULL;
  __Pyx_RefNannySetupContext("dtype_to_typecode", 0);
  __Pyx_INCREF(__pyx_v_dtype);

  /* "pygpu/gpuarray.pyx":199
 * 
 *     """
 *     if isinstance(dtype, int):             # <<<<<<<<<<<<<<
 *         return dtype
 *     try:
 */
  __pyx_t_1 = PyInt_Check(__pyx_v_dtype); 
  __pyx_t_2 = (__pyx_t_1 != 0);
  if (__pyx_t_2) {

    /* "pygpu/gpuarray.pyx":200
 *     """
 *     if isinstance(dtype, int):
 *         return dtype             # <<<<<<<<<<<<<<
 *     try:
 *         dtype = np.dtype(dtype)
 */
    __pyx_t_3 = __Pyx_PyInt_As_int(__pyx_v_dtype); if (unlikely((__pyx_t_3 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 200, __pyx_L1_error)
    __pyx_r = __pyx_t_3;
    goto __pyx_L0;

    /* "pygpu/gpuarray.pyx":199
 * 
 *     """
 *     if isinstance(dtype, int):             # <<<<<<<<<<<<<<
 *         return dtype
 *     try:
 */
  }

  /* "pygpu/gpuarray.pyx":201
 *     if isinstance(dtype, int):
 *         return dtype
 *     try:             # <<<<<<<<<<<<<<
 *         dtype = np.dtype(dtype)
 *     except TypeError:
 */
  {
    __Pyx_PyThreadState_declare
    __Pyx_PyThreadState_assign
    __Pyx_ExceptionSave(&__pyx_t_4, &__pyx_t_5, &__pyx_t_6);
    __Pyx_XGOTREF(__pyx_t_4);
    __Pyx_XGOTREF(__pyx_t_5);
    __Pyx_XGOTREF(__pyx_t_6);
    /*try:*/ {

      /* "pygpu/gpuarray.pyx":202
 *         return dtype
 *     try:
 *         dtype = np.dtype(dtype)             # <<<<<<<<<<<<<<
 *     except TypeError:
 *         pass
 */
      __pyx_t_7 = PyTuple_New(1); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 202, __pyx_L4_error)
      __Pyx_GOTREF(__pyx_t_7);
      __Pyx_INCREF(__pyx_v_dtype);
      __Pyx_GIVEREF(__pyx_v_dtype);
      PyTuple_SET_ITEM(__pyx_t_7, 0, __pyx_v_dtype);
      __pyx_t_8 = __Pyx_PyObject_Call(((PyObject *)__pyx_ptype_5numpy_dtype), __pyx_t_7, NULL); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 202, __pyx_L4_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      __Pyx_DECREF_SET(__pyx_v_dtype, __pyx_t_8);
      __pyx_t_8 = 0;

      /* "pygpu/gpuarray.pyx":201
 *     if isinstance(dtype, int):
 *         return dtype
 *     try:             # <<<<<<<<<<<<<<
 *         dtype = np.dtype(dtype)
 *     except TypeError:
 */
    }
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
    goto __pyx_L9_try_end;
    __pyx_L4_error:;
    __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
    __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;

    /* "pygpu/gpuarray.pyx":203
 *     try:
 *         dtype = np.dtype(dtype)
 *     except TypeError:             # <<<<<<<<<<<<<<
 *         pass
 *     if isinstance(dtype, np.dtype):
 */
    __pyx_t_3 = __Pyx_PyErr_ExceptionMatches(__pyx_builtin_TypeError);
    if (__pyx_t_3) {
      __Pyx_ErrRestore(0,0,0);
      goto __pyx_L5_exception_handled;
    }
    goto __pyx_L6_except_error;
    __pyx_L6_except_error:;

    /* "pygpu/gpuarray.pyx":201
 *     if isinstance(dtype, int):
 *         return dtype
 *     try:             # <<<<<<<<<<<<<<
 *         dtype = np.dtype(dtype)
 *     except TypeError:
 */
    __Pyx_XGIVEREF(__pyx_t_4);
    __Pyx_XGIVEREF(__pyx_t_5);
    __Pyx_XGIVEREF(__pyx_t_6);
    __Pyx_ExceptionReset(__pyx_t_4, __pyx_t_5, __pyx_t_6);
    goto __pyx_L1_error;
    __pyx_L5_exception_handled:;
    __Pyx_XGIVEREF(__pyx_t_4);
    __Pyx_XGIVEREF(__pyx_t_5);
    __Pyx_XGIVEREF(__pyx_t_6);
    __Pyx_ExceptionReset(__pyx_t_4, __pyx_t_5, __pyx_t_6);
    __pyx_L9_try_end:;
  }

  /* "pygpu/gpuarray.pyx":205
 *     except TypeError:
 *         pass
 *     if isinstance(dtype, np.dtype):             # <<<<<<<<<<<<<<
 *         res = NP_TO_TYPE.get(dtype, None)
 *         if res is not None:
 */
  __pyx_t_2 = __Pyx_TypeCheck(__pyx_v_dtype, __pyx_ptype_5numpy_dtype); 
  __pyx_t_1 = (__pyx_t_2 != 0);
  if (__pyx_t_1) {

    /* "pygpu/gpuarray.pyx":206
 *         pass
 *     if isinstance(dtype, np.dtype):
 *         res = NP_TO_TYPE.get(dtype, None)             # <<<<<<<<<<<<<<
 *         if res is not None:
 *             return res
 */
    if (unlikely(__pyx_v_5pygpu_8gpuarray_NP_TO_TYPE == Py_None)) {
      PyErr_Format(PyExc_AttributeError, "'NoneType' object has no attribute '%.30s'", "get");
      __PYX_ERR(0, 206, __pyx_L1_error)
    }
    __pyx_t_8 = __Pyx_PyDict_GetItemDefault(__pyx_v_5pygpu_8gpuarray_NP_TO_TYPE, __pyx_v_dtype, Py_None); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 206, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __pyx_v_res = __pyx_t_8;
    __pyx_t_8 = 0;

    /* "pygpu/gpuarray.pyx":207
 *     if isinstance(dtype, np.dtype):
 *         res = NP_TO_TYPE.get(dtype, None)
 *         if res is not None:             # <<<<<<<<<<<<<<
 *             return res
 *     raise ValueError, "don't know how to convert to dtype: %s"%(dtype,)
 */
    __pyx_t_1 = (__pyx_v_res != Py_None);
    __pyx_t_2 = (__pyx_t_1 != 0);
    if (__pyx_t_2) {

      /* "pygpu/gpuarray.pyx":208
 *         res = NP_TO_TYPE.get(dtype, None)
 *         if res is not None:
 *             return res             # <<<<<<<<<<<<<<
 *     raise ValueError, "don't know how to convert to dtype: %s"%(dtype,)
 * 
 */
      __pyx_t_3 = __Pyx_PyInt_As_int(__pyx_v_res); if (unlikely((__pyx_t_3 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 208, __pyx_L1_error)
      __pyx_r = __pyx_t_3;
      goto __pyx_L0;

      /* "pygpu/gpuarray.pyx":207
 *     if isinstance(dtype, np.dtype):
 *         res = NP_TO_TYPE.get(dtype, None)
 *         if res is not None:             # <<<<<<<<<<<<<<
 *             return res
 *     raise ValueError, "don't know how to convert to dtype: %s"%(dtype,)
 */
    }

    /* "pygpu/gpuarray.pyx":205
 *     except TypeError:
 *         pass
 *     if isinstance(dtype, np.dtype):             # <<<<<<<<<<<<<<
 *         res = NP_TO_TYPE.get(dtype, None)
 *         if res is not None:
 */
  }

  /* "pygpu/gpuarray.pyx":209
 *         if res is not None:
 *             return res
 *     raise ValueError, "don't know how to convert to dtype: %s"%(dtype,)             # <<<<<<<<<<<<<<
 * 
 * def dtype_to_ctype(dtype):
 */
  __pyx_t_8 = PyTuple_New(1); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 209, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __Pyx_INCREF(__pyx_v_dtype);
  __Pyx_GIVEREF(__pyx_v_dtype);
  PyTuple_SET_ITEM(__pyx_t_8, 0, __pyx_v_dtype);
  __pyx_t_7 = __Pyx_PyString_Format(__pyx_kp_s_don_t_know_how_to_convert_to_dty, __pyx_t_8); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 209, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  __Pyx_Raise(__pyx_builtin_ValueError, __pyx_t_7, 0, 0);
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __PYX_ERR(0, 209, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":187
 *     return dtype_to_typecode(dtype)
 * 
 * cpdef int dtype_to_typecode(dtype) except -1:             # <<<<<<<<<<<<<<
 *     """
 *     dtype_to_typecode(dtype)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_AddTraceback("pygpu.gpuarray.dtype_to_typecode", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_res);
  __Pyx_XDECREF(__pyx_v_dtype);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_11dtype_to_typecode(PyObject *__pyx_self, PyObject *__pyx_v_dtype); /*proto*/
static char __pyx_doc_5pygpu_8gpuarray_10dtype_to_typecode[] = "\n    dtype_to_typecode(dtype)\n\n    Get the internal typecode for a type.\n\n    Parameters\n    ----------\n    dtype: numpy.dtype\n        type to get the code for\n\n    ";
static PyObject *__pyx_pw_5pygpu_8gpuarray_11dtype_to_typecode(PyObject *__pyx_self, PyObject *__pyx_v_dtype) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("dtype_to_typecode (wrapper)", 0);
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_10dtype_to_typecode(__pyx_self, ((PyObject *)__pyx_v_dtype));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_10dtype_to_typecode(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_dtype) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  __Pyx_RefNannySetupContext("dtype_to_typecode", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __pyx_f_5pygpu_8gpuarray_dtype_to_typecode(__pyx_v_dtype, 0); if (unlikely(__pyx_t_1 == ((int)-1))) __PYX_ERR(0, 187, __pyx_L1_error)
  __pyx_t_2 = __Pyx_PyInt_From_int(__pyx_t_1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 187, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_r = __pyx_t_2;
  __pyx_t_2 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("pygpu.gpuarray.dtype_to_typecode", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":211
 *     raise ValueError, "don't know how to convert to dtype: %s"%(dtype,)
 * 
 * def dtype_to_ctype(dtype):             # <<<<<<<<<<<<<<
 *     """
 *     dtype_to_ctype(dtype)
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_13dtype_to_ctype(PyObject *__pyx_self, PyObject *__pyx_v_dtype); /*proto*/
static char __pyx_doc_5pygpu_8gpuarray_12dtype_to_ctype[] = "\n    dtype_to_ctype(dtype)\n\n    Return the C name for a type.\n\n    Parameters\n    ----------\n    dtype: numpy.dtype\n        type to get the name for\n\n    ";
static PyMethodDef __pyx_mdef_5pygpu_8gpuarray_13dtype_to_ctype = {"dtype_to_ctype", (PyCFunction)__pyx_pw_5pygpu_8gpuarray_13dtype_to_ctype, METH_O, __pyx_doc_5pygpu_8gpuarray_12dtype_to_ctype};
static PyObject *__pyx_pw_5pygpu_8gpuarray_13dtype_to_ctype(PyObject *__pyx_self, PyObject *__pyx_v_dtype) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("dtype_to_ctype (wrapper)", 0);
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_12dtype_to_ctype(__pyx_self, ((PyObject *)__pyx_v_dtype));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_12dtype_to_ctype(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_dtype) {
  int __pyx_v_typecode;
  gpuarray_type const *__pyx_v_t;
  PyObject *__pyx_v_res = 0;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_t_2;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  __Pyx_RefNannySetupContext("dtype_to_ctype", 0);

  /* "pygpu/gpuarray.pyx":223
 * 
 *     """
 *     cdef int typecode = dtype_to_typecode(dtype)             # <<<<<<<<<<<<<<
 *     cdef const gpuarray_type *t = gpuarray_get_type(typecode)
 *     cdef bytes res
 */
  __pyx_t_1 = __pyx_f_5pygpu_8gpuarray_dtype_to_typecode(__pyx_v_dtype, 0); if (unlikely(__pyx_t_1 == ((int)-1))) __PYX_ERR(0, 223, __pyx_L1_error)
  __pyx_v_typecode = __pyx_t_1;

  /* "pygpu/gpuarray.pyx":224
 *     """
 *     cdef int typecode = dtype_to_typecode(dtype)
 *     cdef const gpuarray_type *t = gpuarray_get_type(typecode)             # <<<<<<<<<<<<<<
 *     cdef bytes res
 *     if t.cluda_name == NULL:
 */
  __pyx_v_t = gpuarray_get_type(__pyx_v_typecode);

  /* "pygpu/gpuarray.pyx":226
 *     cdef const gpuarray_type *t = gpuarray_get_type(typecode)
 *     cdef bytes res
 *     if t.cluda_name == NULL:             # <<<<<<<<<<<<<<
 *         raise ValueError, "No mapping for %s"%(dtype,)
 *     res = t.cluda_name
 */
  __pyx_t_2 = ((__pyx_v_t->cluda_name == NULL) != 0);
  if (__pyx_t_2) {

    /* "pygpu/gpuarray.pyx":227
 *     cdef bytes res
 *     if t.cluda_name == NULL:
 *         raise ValueError, "No mapping for %s"%(dtype,)             # <<<<<<<<<<<<<<
 *     res = t.cluda_name
 *     return res.decode('ascii')
 */
    __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 227, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_INCREF(__pyx_v_dtype);
    __Pyx_GIVEREF(__pyx_v_dtype);
    PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_v_dtype);
    __pyx_t_4 = __Pyx_PyString_Format(__pyx_kp_s_No_mapping_for_s, __pyx_t_3); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 227, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_Raise(__pyx_builtin_ValueError, __pyx_t_4, 0, 0);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __PYX_ERR(0, 227, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":226
 *     cdef const gpuarray_type *t = gpuarray_get_type(typecode)
 *     cdef bytes res
 *     if t.cluda_name == NULL:             # <<<<<<<<<<<<<<
 *         raise ValueError, "No mapping for %s"%(dtype,)
 *     res = t.cluda_name
 */
  }

  /* "pygpu/gpuarray.pyx":228
 *     if t.cluda_name == NULL:
 *         raise ValueError, "No mapping for %s"%(dtype,)
 *     res = t.cluda_name             # <<<<<<<<<<<<<<
 *     return res.decode('ascii')
 * 
 */
  __pyx_t_4 = __Pyx_PyBytes_FromString(__pyx_v_t->cluda_name); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 228, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_v_res = ((PyObject*)__pyx_t_4);
  __pyx_t_4 = 0;

  /* "pygpu/gpuarray.pyx":229
 *         raise ValueError, "No mapping for %s"%(dtype,)
 *     res = t.cluda_name
 *     return res.decode('ascii')             # <<<<<<<<<<<<<<
 * 
 * cdef ga_order to_ga_order(ord) except <ga_order>-2:
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_4 = __Pyx_decode_bytes(__pyx_v_res, 0, PY_SSIZE_T_MAX, NULL, NULL, PyUnicode_DecodeASCII); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 229, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_r = __pyx_t_4;
  __pyx_t_4 = 0;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":211
 *     raise ValueError, "don't know how to convert to dtype: %s"%(dtype,)
 * 
 * def dtype_to_ctype(dtype):             # <<<<<<<<<<<<<<
 *     """
 *     dtype_to_ctype(dtype)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_AddTraceback("pygpu.gpuarray.dtype_to_ctype", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_res);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":231
 *     return res.decode('ascii')
 * 
 * cdef ga_order to_ga_order(ord) except <ga_order>-2:             # <<<<<<<<<<<<<<
 *     if ord == "C" or ord == "c":
 *         return GA_C_ORDER
 */

static ga_order __pyx_f_5pygpu_8gpuarray_to_ga_order(PyObject *__pyx_v_ord) {
  ga_order __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_t_2;
  int __pyx_t_3;
  __Pyx_RefNannySetupContext("to_ga_order", 0);

  /* "pygpu/gpuarray.pyx":232
 * 
 * cdef ga_order to_ga_order(ord) except <ga_order>-2:
 *     if ord == "C" or ord == "c":             # <<<<<<<<<<<<<<
 *         return GA_C_ORDER
 *     elif ord == "A" or ord == "a" or ord is None:
 */
  __pyx_t_2 = (__Pyx_PyString_Equals(__pyx_v_ord, __pyx_n_s_C, Py_EQ)); if (unlikely(__pyx_t_2 < 0)) __PYX_ERR(0, 232, __pyx_L1_error)
  if (!__pyx_t_2) {
  } else {
    __pyx_t_1 = __pyx_t_2;
    goto __pyx_L4_bool_binop_done;
  }
  __pyx_t_2 = (__Pyx_PyString_Equals(__pyx_v_ord, __pyx_n_s_c, Py_EQ)); if (unlikely(__pyx_t_2 < 0)) __PYX_ERR(0, 232, __pyx_L1_error)
  __pyx_t_1 = __pyx_t_2;
  __pyx_L4_bool_binop_done:;
  if (__pyx_t_1) {

    /* "pygpu/gpuarray.pyx":233
 * cdef ga_order to_ga_order(ord) except <ga_order>-2:
 *     if ord == "C" or ord == "c":
 *         return GA_C_ORDER             # <<<<<<<<<<<<<<
 *     elif ord == "A" or ord == "a" or ord is None:
 *         return GA_ANY_ORDER
 */
    __pyx_r = GA_C_ORDER;
    goto __pyx_L0;

    /* "pygpu/gpuarray.pyx":232
 * 
 * cdef ga_order to_ga_order(ord) except <ga_order>-2:
 *     if ord == "C" or ord == "c":             # <<<<<<<<<<<<<<
 *         return GA_C_ORDER
 *     elif ord == "A" or ord == "a" or ord is None:
 */
  }

  /* "pygpu/gpuarray.pyx":234
 *     if ord == "C" or ord == "c":
 *         return GA_C_ORDER
 *     elif ord == "A" or ord == "a" or ord is None:             # <<<<<<<<<<<<<<
 *         return GA_ANY_ORDER
 *     elif ord == "F" or ord == "f":
 */
  __pyx_t_2 = (__Pyx_PyString_Equals(__pyx_v_ord, __pyx_n_s_A, Py_EQ)); if (unlikely(__pyx_t_2 < 0)) __PYX_ERR(0, 234, __pyx_L1_error)
  if (!__pyx_t_2) {
  } else {
    __pyx_t_1 = __pyx_t_2;
    goto __pyx_L6_bool_binop_done;
  }
  __pyx_t_2 = (__Pyx_PyString_Equals(__pyx_v_ord, __pyx_n_s_a, Py_EQ)); if (unlikely(__pyx_t_2 < 0)) __PYX_ERR(0, 234, __pyx_L1_error)
  if (!__pyx_t_2) {
  } else {
    __pyx_t_1 = __pyx_t_2;
    goto __pyx_L6_bool_binop_done;
  }
  __pyx_t_2 = (__pyx_v_ord == Py_None);
  __pyx_t_3 = (__pyx_t_2 != 0);
  __pyx_t_1 = __pyx_t_3;
  __pyx_L6_bool_binop_done:;
  if (__pyx_t_1) {

    /* "pygpu/gpuarray.pyx":235
 *         return GA_C_ORDER
 *     elif ord == "A" or ord == "a" or ord is None:
 *         return GA_ANY_ORDER             # <<<<<<<<<<<<<<
 *     elif ord == "F" or ord == "f":
 *         return GA_F_ORDER
 */
    __pyx_r = GA_ANY_ORDER;
    goto __pyx_L0;

    /* "pygpu/gpuarray.pyx":234
 *     if ord == "C" or ord == "c":
 *         return GA_C_ORDER
 *     elif ord == "A" or ord == "a" or ord is None:             # <<<<<<<<<<<<<<
 *         return GA_ANY_ORDER
 *     elif ord == "F" or ord == "f":
 */
  }

  /* "pygpu/gpuarray.pyx":236
 *     elif ord == "A" or ord == "a" or ord is None:
 *         return GA_ANY_ORDER
 *     elif ord == "F" or ord == "f":             # <<<<<<<<<<<<<<
 *         return GA_F_ORDER
 *     else:
 */
  __pyx_t_3 = (__Pyx_PyString_Equals(__pyx_v_ord, __pyx_n_s_F, Py_EQ)); if (unlikely(__pyx_t_3 < 0)) __PYX_ERR(0, 236, __pyx_L1_error)
  if (!__pyx_t_3) {
  } else {
    __pyx_t_1 = __pyx_t_3;
    goto __pyx_L9_bool_binop_done;
  }
  __pyx_t_3 = (__Pyx_PyString_Equals(__pyx_v_ord, __pyx_n_s_f, Py_EQ)); if (unlikely(__pyx_t_3 < 0)) __PYX_ERR(0, 236, __pyx_L1_error)
  __pyx_t_1 = __pyx_t_3;
  __pyx_L9_bool_binop_done:;
  if (__pyx_t_1) {

    /* "pygpu/gpuarray.pyx":237
 *         return GA_ANY_ORDER
 *     elif ord == "F" or ord == "f":
 *         return GA_F_ORDER             # <<<<<<<<<<<<<<
 *     else:
 *         raise ValueError, "Valid orders are: 'A' (any), 'C' (C), 'F' (Fortran)"
 */
    __pyx_r = GA_F_ORDER;
    goto __pyx_L0;

    /* "pygpu/gpuarray.pyx":236
 *     elif ord == "A" or ord == "a" or ord is None:
 *         return GA_ANY_ORDER
 *     elif ord == "F" or ord == "f":             # <<<<<<<<<<<<<<
 *         return GA_F_ORDER
 *     else:
 */
  }

  /* "pygpu/gpuarray.pyx":239
 *         return GA_F_ORDER
 *     else:
 *         raise ValueError, "Valid orders are: 'A' (any), 'C' (C), 'F' (Fortran)"             # <<<<<<<<<<<<<<
 * 
 * cdef int strides_ok(GpuArray a, strides):
 */
  /*else*/ {
    __Pyx_Raise(__pyx_builtin_ValueError, __pyx_kp_s_Valid_orders_are_A_any_C_C_F_For, 0, 0);
    __PYX_ERR(0, 239, __pyx_L1_error)
  }

  /* "pygpu/gpuarray.pyx":231
 *     return res.decode('ascii')
 * 
 * cdef ga_order to_ga_order(ord) except <ga_order>-2:             # <<<<<<<<<<<<<<
 *     if ord == "C" or ord == "c":
 *         return GA_C_ORDER
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_AddTraceback("pygpu.gpuarray.to_ga_order", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = ((ga_order)-2L);
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":241
 *         raise ValueError, "Valid orders are: 'A' (any), 'C' (C), 'F' (Fortran)"
 * 
 * cdef int strides_ok(GpuArray a, strides):             # <<<<<<<<<<<<<<
 *     # Check that the passed in strides will not go outside of the
 *     # memory of the array.  It is assumed that the strides are of the
 */

static int __pyx_f_5pygpu_8gpuarray_strides_ok(struct PyGpuArrayObject *__pyx_v_a, PyObject *__pyx_v_strides) {
  Py_ssize_t __pyx_v_max_axis_offset;
  size_t __pyx_v_lower;
  size_t __pyx_v_upper;
  size_t __pyx_v_itemsize;
  size_t __pyx_v_size;
  unsigned int __pyx_v_i;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  size_t __pyx_t_1;
  unsigned int __pyx_t_2;
  unsigned int __pyx_t_3;
  int __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  Py_ssize_t __pyx_t_6;
  __Pyx_RefNannySetupContext("strides_ok", 0);

  /* "pygpu/gpuarray.pyx":246
 *     # proper length.
 *     cdef ssize_t max_axis_offset
 *     cdef size_t lower = a.ga.offset             # <<<<<<<<<<<<<<
 *     cdef size_t upper = a.ga.offset
 *     cdef size_t itemsize = gpuarray_get_elsize(a.ga.typecode)
 */
  __pyx_t_1 = __pyx_v_a->ga.offset;
  __pyx_v_lower = __pyx_t_1;

  /* "pygpu/gpuarray.pyx":247
 *     cdef ssize_t max_axis_offset
 *     cdef size_t lower = a.ga.offset
 *     cdef size_t upper = a.ga.offset             # <<<<<<<<<<<<<<
 *     cdef size_t itemsize = gpuarray_get_elsize(a.ga.typecode)
 *     cdef size_t size
 */
  __pyx_t_1 = __pyx_v_a->ga.offset;
  __pyx_v_upper = __pyx_t_1;

  /* "pygpu/gpuarray.pyx":248
 *     cdef size_t lower = a.ga.offset
 *     cdef size_t upper = a.ga.offset
 *     cdef size_t itemsize = gpuarray_get_elsize(a.ga.typecode)             # <<<<<<<<<<<<<<
 *     cdef size_t size
 *     cdef unsigned int i
 */
  __pyx_v_itemsize = gpuarray_get_elsize(__pyx_v_a->ga.typecode);

  /* "pygpu/gpuarray.pyx":252
 *     cdef unsigned int i
 * 
 *     gpudata_property(a.ga.data, GA_BUFFER_PROP_SIZE, &size)             # <<<<<<<<<<<<<<
 * 
 *     for i in range(a.ga.nd):
 */
  gpudata_property(__pyx_v_a->ga.data, GA_BUFFER_PROP_SIZE, (&__pyx_v_size));

  /* "pygpu/gpuarray.pyx":254
 *     gpudata_property(a.ga.data, GA_BUFFER_PROP_SIZE, &size)
 * 
 *     for i in range(a.ga.nd):             # <<<<<<<<<<<<<<
 *         if a.ga.dimensions[i] == 0:
 *             return 1
 */
  __pyx_t_2 = __pyx_v_a->ga.nd;
  for (__pyx_t_3 = 0; __pyx_t_3 < __pyx_t_2; __pyx_t_3+=1) {
    __pyx_v_i = __pyx_t_3;

    /* "pygpu/gpuarray.pyx":255
 * 
 *     for i in range(a.ga.nd):
 *         if a.ga.dimensions[i] == 0:             # <<<<<<<<<<<<<<
 *             return 1
 * 
 */
    __pyx_t_4 = (((__pyx_v_a->ga.dimensions[__pyx_v_i]) == 0) != 0);
    if (__pyx_t_4) {

      /* "pygpu/gpuarray.pyx":256
 *     for i in range(a.ga.nd):
 *         if a.ga.dimensions[i] == 0:
 *             return 1             # <<<<<<<<<<<<<<
 * 
 *         max_axis_offset = <ssize_t>(strides[i]) * <ssize_t>(a.ga.dimensions[i] - 1)
 */
      __pyx_r = 1;
      goto __pyx_L0;

      /* "pygpu/gpuarray.pyx":255
 * 
 *     for i in range(a.ga.nd):
 *         if a.ga.dimensions[i] == 0:             # <<<<<<<<<<<<<<
 *             return 1
 * 
 */
    }

    /* "pygpu/gpuarray.pyx":258
 *             return 1
 * 
 *         max_axis_offset = <ssize_t>(strides[i]) * <ssize_t>(a.ga.dimensions[i] - 1)             # <<<<<<<<<<<<<<
 *         if max_axis_offset > 0:
 *             if upper + max_axis_offset > size:
 */
    __pyx_t_5 = __Pyx_GetItemInt(__pyx_v_strides, __pyx_v_i, unsigned int, 0, __Pyx_PyInt_From_unsigned_int, 0, 0, 1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 258, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_6 = PyInt_AsSsize_t(__pyx_t_5); if (unlikely((__pyx_t_6 == (Py_ssize_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 258, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_v_max_axis_offset = (((Py_ssize_t)__pyx_t_6) * ((Py_ssize_t)((__pyx_v_a->ga.dimensions[__pyx_v_i]) - 1)));

    /* "pygpu/gpuarray.pyx":259
 * 
 *         max_axis_offset = <ssize_t>(strides[i]) * <ssize_t>(a.ga.dimensions[i] - 1)
 *         if max_axis_offset > 0:             # <<<<<<<<<<<<<<
 *             if upper + max_axis_offset > size:
 *                 return 0
 */
    __pyx_t_4 = ((__pyx_v_max_axis_offset > 0) != 0);
    if (__pyx_t_4) {

      /* "pygpu/gpuarray.pyx":260
 *         max_axis_offset = <ssize_t>(strides[i]) * <ssize_t>(a.ga.dimensions[i] - 1)
 *         if max_axis_offset > 0:
 *             if upper + max_axis_offset > size:             # <<<<<<<<<<<<<<
 *                 return 0
 *             upper += max_axis_offset
 */
      __pyx_t_4 = (((__pyx_v_upper + __pyx_v_max_axis_offset) > __pyx_v_size) != 0);
      if (__pyx_t_4) {

        /* "pygpu/gpuarray.pyx":261
 *         if max_axis_offset > 0:
 *             if upper + max_axis_offset > size:
 *                 return 0             # <<<<<<<<<<<<<<
 *             upper += max_axis_offset
 *         else:
 */
        __pyx_r = 0;
        goto __pyx_L0;

        /* "pygpu/gpuarray.pyx":260
 *         max_axis_offset = <ssize_t>(strides[i]) * <ssize_t>(a.ga.dimensions[i] - 1)
 *         if max_axis_offset > 0:
 *             if upper + max_axis_offset > size:             # <<<<<<<<<<<<<<
 *                 return 0
 *             upper += max_axis_offset
 */
      }

      /* "pygpu/gpuarray.pyx":262
 *             if upper + max_axis_offset > size:
 *                 return 0
 *             upper += max_axis_offset             # <<<<<<<<<<<<<<
 *         else:
 *             if lower < <size_t>(-max_axis_offset):
 */
      __pyx_v_upper = (__pyx_v_upper + __pyx_v_max_axis_offset);

      /* "pygpu/gpuarray.pyx":259
 * 
 *         max_axis_offset = <ssize_t>(strides[i]) * <ssize_t>(a.ga.dimensions[i] - 1)
 *         if max_axis_offset > 0:             # <<<<<<<<<<<<<<
 *             if upper + max_axis_offset > size:
 *                 return 0
 */
      goto __pyx_L6;
    }

    /* "pygpu/gpuarray.pyx":264
 *             upper += max_axis_offset
 *         else:
 *             if lower < <size_t>(-max_axis_offset):             # <<<<<<<<<<<<<<
 *                 return 0
 *             lower += max_axis_offset
 */
    /*else*/ {
      __pyx_t_4 = ((__pyx_v_lower < ((size_t)(-__pyx_v_max_axis_offset))) != 0);
      if (__pyx_t_4) {

        /* "pygpu/gpuarray.pyx":265
 *         else:
 *             if lower < <size_t>(-max_axis_offset):
 *                 return 0             # <<<<<<<<<<<<<<
 *             lower += max_axis_offset
 *     return (upper + itemsize) <= size
 */
        __pyx_r = 0;
        goto __pyx_L0;

        /* "pygpu/gpuarray.pyx":264
 *             upper += max_axis_offset
 *         else:
 *             if lower < <size_t>(-max_axis_offset):             # <<<<<<<<<<<<<<
 *                 return 0
 *             lower += max_axis_offset
 */
      }

      /* "pygpu/gpuarray.pyx":266
 *             if lower < <size_t>(-max_axis_offset):
 *                 return 0
 *             lower += max_axis_offset             # <<<<<<<<<<<<<<
 *     return (upper + itemsize) <= size
 * 
 */
      __pyx_v_lower = (__pyx_v_lower + __pyx_v_max_axis_offset);
    }
    __pyx_L6:;
  }

  /* "pygpu/gpuarray.pyx":267
 *                 return 0
 *             lower += max_axis_offset
 *     return (upper + itemsize) <= size             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_r = ((__pyx_v_upper + __pyx_v_itemsize) <= __pyx_v_size);
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":241
 *         raise ValueError, "Valid orders are: 'A' (any), 'C' (C), 'F' (Fortran)"
 * 
 * cdef int strides_ok(GpuArray a, strides):             # <<<<<<<<<<<<<<
 *     # Check that the passed in strides will not go outside of the
 *     # memory of the array.  It is assumed that the strides are of the
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_WriteUnraisable("pygpu.gpuarray.strides_ok", __pyx_clineno, __pyx_lineno, __pyx_filename, 1, 0);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":278
 *     pass
 * 
 * cdef type get_exc(int errcode):             # <<<<<<<<<<<<<<
 *     if errcode == GA_VALUE_ERROR:
 *         return ValueError
 */

static PyTypeObject *__pyx_f_5pygpu_8gpuarray_get_exc(int __pyx_v_errcode) {
  PyTypeObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  __Pyx_RefNannySetupContext("get_exc", 0);

  /* "pygpu/gpuarray.pyx":279
 * 
 * cdef type get_exc(int errcode):
 *     if errcode == GA_VALUE_ERROR:             # <<<<<<<<<<<<<<
 *         return ValueError
 *     if errcode == GA_DEVSUP_ERROR:
 */
  __pyx_t_1 = ((__pyx_v_errcode == GA_VALUE_ERROR) != 0);
  if (__pyx_t_1) {

    /* "pygpu/gpuarray.pyx":280
 * cdef type get_exc(int errcode):
 *     if errcode == GA_VALUE_ERROR:
 *         return ValueError             # <<<<<<<<<<<<<<
 *     if errcode == GA_DEVSUP_ERROR:
 *         return UnsupportedException
 */
    __Pyx_XDECREF(((PyObject *)__pyx_r));
    if (!(likely(PyType_CheckExact(__pyx_builtin_ValueError))||((__pyx_builtin_ValueError) == Py_None)||(PyErr_Format(PyExc_TypeError, "Expected %.16s, got %.200s", "type", Py_TYPE(__pyx_builtin_ValueError)->tp_name), 0))) __PYX_ERR(0, 280, __pyx_L1_error)
    __Pyx_INCREF(__pyx_builtin_ValueError);
    __pyx_r = ((PyTypeObject*)__pyx_builtin_ValueError);
    goto __pyx_L0;

    /* "pygpu/gpuarray.pyx":279
 * 
 * cdef type get_exc(int errcode):
 *     if errcode == GA_VALUE_ERROR:             # <<<<<<<<<<<<<<
 *         return ValueError
 *     if errcode == GA_DEVSUP_ERROR:
 */
  }

  /* "pygpu/gpuarray.pyx":281
 *     if errcode == GA_VALUE_ERROR:
 *         return ValueError
 *     if errcode == GA_DEVSUP_ERROR:             # <<<<<<<<<<<<<<
 *         return UnsupportedException
 *     else:
 */
  __pyx_t_1 = ((__pyx_v_errcode == GA_DEVSUP_ERROR) != 0);
  if (__pyx_t_1) {

    /* "pygpu/gpuarray.pyx":282
 *         return ValueError
 *     if errcode == GA_DEVSUP_ERROR:
 *         return UnsupportedException             # <<<<<<<<<<<<<<
 *     else:
 *         return GpuArrayException
 */
    __Pyx_XDECREF(((PyObject *)__pyx_r));
    __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_UnsupportedException); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 282, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    if (!(likely(PyType_CheckExact(__pyx_t_2))||((__pyx_t_2) == Py_None)||(PyErr_Format(PyExc_TypeError, "Expected %.16s, got %.200s", "type", Py_TYPE(__pyx_t_2)->tp_name), 0))) __PYX_ERR(0, 282, __pyx_L1_error)
    __pyx_r = ((PyTypeObject*)__pyx_t_2);
    __pyx_t_2 = 0;
    goto __pyx_L0;

    /* "pygpu/gpuarray.pyx":281
 *     if errcode == GA_VALUE_ERROR:
 *         return ValueError
 *     if errcode == GA_DEVSUP_ERROR:             # <<<<<<<<<<<<<<
 *         return UnsupportedException
 *     else:
 */
  }

  /* "pygpu/gpuarray.pyx":284
 *         return UnsupportedException
 *     else:
 *         return GpuArrayException             # <<<<<<<<<<<<<<
 * 
 * cdef bint py_CHKFLAGS(GpuArray a, int flags):
 */
  /*else*/ {
    __Pyx_XDECREF(((PyObject *)__pyx_r));
    __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_GpuArrayException); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 284, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    if (!(likely(PyType_CheckExact(__pyx_t_2))||((__pyx_t_2) == Py_None)||(PyErr_Format(PyExc_TypeError, "Expected %.16s, got %.200s", "type", Py_TYPE(__pyx_t_2)->tp_name), 0))) __PYX_ERR(0, 284, __pyx_L1_error)
    __pyx_r = ((PyTypeObject*)__pyx_t_2);
    __pyx_t_2 = 0;
    goto __pyx_L0;
  }

  /* "pygpu/gpuarray.pyx":278
 *     pass
 * 
 * cdef type get_exc(int errcode):             # <<<<<<<<<<<<<<
 *     if errcode == GA_VALUE_ERROR:
 *         return ValueError
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("pygpu.gpuarray.get_exc", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XGIVEREF((PyObject *)__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":286
 *         return GpuArrayException
 * 
 * cdef bint py_CHKFLAGS(GpuArray a, int flags):             # <<<<<<<<<<<<<<
 *     return GpuArray_CHKFLAGS(&a.ga, flags)
 * 
 */

static int __pyx_f_5pygpu_8gpuarray_py_CHKFLAGS(struct PyGpuArrayObject *__pyx_v_a, int __pyx_v_flags) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("py_CHKFLAGS", 0);

  /* "pygpu/gpuarray.pyx":287
 * 
 * cdef bint py_CHKFLAGS(GpuArray a, int flags):
 *     return GpuArray_CHKFLAGS(&a.ga, flags)             # <<<<<<<<<<<<<<
 * 
 * cdef bint py_ISONESEGMENT(GpuArray a):
 */
  __pyx_r = GpuArray_CHKFLAGS((&__pyx_v_a->ga), __pyx_v_flags);
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":286
 *         return GpuArrayException
 * 
 * cdef bint py_CHKFLAGS(GpuArray a, int flags):             # <<<<<<<<<<<<<<
 *     return GpuArray_CHKFLAGS(&a.ga, flags)
 * 
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":289
 *     return GpuArray_CHKFLAGS(&a.ga, flags)
 * 
 * cdef bint py_ISONESEGMENT(GpuArray a):             # <<<<<<<<<<<<<<
 *     return GpuArray_ISONESEGMENT(&a.ga)
 * 
 */

static int __pyx_f_5pygpu_8gpuarray_py_ISONESEGMENT(struct PyGpuArrayObject *__pyx_v_a) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("py_ISONESEGMENT", 0);

  /* "pygpu/gpuarray.pyx":290
 * 
 * cdef bint py_ISONESEGMENT(GpuArray a):
 *     return GpuArray_ISONESEGMENT(&a.ga)             # <<<<<<<<<<<<<<
 * 
 * cdef void array_fix_flags(GpuArray a):
 */
  __pyx_r = GpuArray_ISONESEGMENT((&__pyx_v_a->ga));
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":289
 *     return GpuArray_CHKFLAGS(&a.ga, flags)
 * 
 * cdef bint py_ISONESEGMENT(GpuArray a):             # <<<<<<<<<<<<<<
 *     return GpuArray_ISONESEGMENT(&a.ga)
 * 
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":292
 *     return GpuArray_ISONESEGMENT(&a.ga)
 * 
 * cdef void array_fix_flags(GpuArray a):             # <<<<<<<<<<<<<<
 *     GpuArray_fix_flags(&a.ga)
 * 
 */

static void __pyx_f_5pygpu_8gpuarray_array_fix_flags(struct PyGpuArrayObject *__pyx_v_a) {
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("array_fix_flags", 0);

  /* "pygpu/gpuarray.pyx":293
 * 
 * cdef void array_fix_flags(GpuArray a):
 *     GpuArray_fix_flags(&a.ga)             # <<<<<<<<<<<<<<
 * 
 * cdef int array_empty(GpuArray a, gpucontext *ctx,
 */
  GpuArray_fix_flags((&__pyx_v_a->ga));

  /* "pygpu/gpuarray.pyx":292
 *     return GpuArray_ISONESEGMENT(&a.ga)
 * 
 * cdef void array_fix_flags(GpuArray a):             # <<<<<<<<<<<<<<
 *     GpuArray_fix_flags(&a.ga)
 * 
 */

  /* function exit code */
  __Pyx_RefNannyFinishContext();
}

/* "pygpu/gpuarray.pyx":295
 *     GpuArray_fix_flags(&a.ga)
 * 
 * cdef int array_empty(GpuArray a, gpucontext *ctx,             # <<<<<<<<<<<<<<
 *                      int typecode, unsigned int nd, const size_t *dims,
 *                      ga_order ord) except -1:
 */

static int __pyx_f_5pygpu_8gpuarray_array_empty(struct PyGpuArrayObject *__pyx_v_a, gpucontext *__pyx_v_ctx, int __pyx_v_typecode, unsigned int __pyx_v_nd, size_t const *__pyx_v_dims, ga_order __pyx_v_ord) {
  int __pyx_v_err;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  __Pyx_RefNannySetupContext("array_empty", 0);

  /* "pygpu/gpuarray.pyx":299
 *                      ga_order ord) except -1:
 *     cdef int err
 *     err = GpuArray_empty(&a.ga, ctx, typecode, nd, dims, ord)             # <<<<<<<<<<<<<<
 *     if err != GA_NO_ERROR:
 *         raise get_exc(err), gpucontext_error(ctx, err)
 */
  __pyx_v_err = GpuArray_empty((&__pyx_v_a->ga), __pyx_v_ctx, __pyx_v_typecode, __pyx_v_nd, __pyx_v_dims, __pyx_v_ord);

  /* "pygpu/gpuarray.pyx":300
 *     cdef int err
 *     err = GpuArray_empty(&a.ga, ctx, typecode, nd, dims, ord)
 *     if err != GA_NO_ERROR:             # <<<<<<<<<<<<<<
 *         raise get_exc(err), gpucontext_error(ctx, err)
 * 
 */
  __pyx_t_1 = ((__pyx_v_err != GA_NO_ERROR) != 0);
  if (__pyx_t_1) {

    /* "pygpu/gpuarray.pyx":301
 *     err = GpuArray_empty(&a.ga, ctx, typecode, nd, dims, ord)
 *     if err != GA_NO_ERROR:
 *         raise get_exc(err), gpucontext_error(ctx, err)             # <<<<<<<<<<<<<<
 * 
 * cdef int array_fromdata(GpuArray a,
 */
    __pyx_t_2 = ((PyObject *)__pyx_f_5pygpu_8gpuarray_get_exc(__pyx_v_err)); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 301, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_3 = __Pyx_PyBytes_FromString(gpucontext_error(__pyx_v_ctx, __pyx_v_err)); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 301, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_Raise(__pyx_t_2, __pyx_t_3, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __PYX_ERR(0, 301, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":300
 *     cdef int err
 *     err = GpuArray_empty(&a.ga, ctx, typecode, nd, dims, ord)
 *     if err != GA_NO_ERROR:             # <<<<<<<<<<<<<<
 *         raise get_exc(err), gpucontext_error(ctx, err)
 * 
 */
  }

  /* "pygpu/gpuarray.pyx":295
 *     GpuArray_fix_flags(&a.ga)
 * 
 * cdef int array_empty(GpuArray a, gpucontext *ctx,             # <<<<<<<<<<<<<<
 *                      int typecode, unsigned int nd, const size_t *dims,
 *                      ga_order ord) except -1:
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("pygpu.gpuarray.array_empty", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":303
 *         raise get_exc(err), gpucontext_error(ctx, err)
 * 
 * cdef int array_fromdata(GpuArray a,             # <<<<<<<<<<<<<<
 *                         gpudata *data, size_t offset, int typecode,
 *                         unsigned int nd, const size_t *dims,
 */

static int __pyx_f_5pygpu_8gpuarray_array_fromdata(struct PyGpuArrayObject *__pyx_v_a, gpudata *__pyx_v_data, size_t __pyx_v_offset, int __pyx_v_typecode, unsigned int __pyx_v_nd, size_t const *__pyx_v_dims, Py_ssize_t const *__pyx_v_strides, int __pyx_v_writeable) {
  int __pyx_v_err;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  __Pyx_RefNannySetupContext("array_fromdata", 0);

  /* "pygpu/gpuarray.pyx":308
 *                         const ssize_t *strides, int writeable) except -1:
 *     cdef int err
 *     err = GpuArray_fromdata(&a.ga, data, offset, typecode, nd, dims,             # <<<<<<<<<<<<<<
 *                             strides, writeable)
 *     if err != GA_NO_ERROR:
 */
  __pyx_v_err = GpuArray_fromdata((&__pyx_v_a->ga), __pyx_v_data, __pyx_v_offset, __pyx_v_typecode, __pyx_v_nd, __pyx_v_dims, __pyx_v_strides, __pyx_v_writeable);

  /* "pygpu/gpuarray.pyx":310
 *     err = GpuArray_fromdata(&a.ga, data, offset, typecode, nd, dims,
 *                             strides, writeable)
 *     if err != GA_NO_ERROR:             # <<<<<<<<<<<<<<
 *         raise get_exc(err), gpucontext_error(gpudata_context(data), err)
 * 
 */
  __pyx_t_1 = ((__pyx_v_err != GA_NO_ERROR) != 0);
  if (__pyx_t_1) {

    /* "pygpu/gpuarray.pyx":311
 *                             strides, writeable)
 *     if err != GA_NO_ERROR:
 *         raise get_exc(err), gpucontext_error(gpudata_context(data), err)             # <<<<<<<<<<<<<<
 * 
 * cdef int array_view(GpuArray v, GpuArray a) except -1:
 */
    __pyx_t_2 = ((PyObject *)__pyx_f_5pygpu_8gpuarray_get_exc(__pyx_v_err)); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 311, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_3 = __Pyx_PyBytes_FromString(gpucontext_error(gpudata_context(__pyx_v_data), __pyx_v_err)); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 311, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_Raise(__pyx_t_2, __pyx_t_3, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __PYX_ERR(0, 311, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":310
 *     err = GpuArray_fromdata(&a.ga, data, offset, typecode, nd, dims,
 *                             strides, writeable)
 *     if err != GA_NO_ERROR:             # <<<<<<<<<<<<<<
 *         raise get_exc(err), gpucontext_error(gpudata_context(data), err)
 * 
 */
  }

  /* "pygpu/gpuarray.pyx":303
 *         raise get_exc(err), gpucontext_error(ctx, err)
 * 
 * cdef int array_fromdata(GpuArray a,             # <<<<<<<<<<<<<<
 *                         gpudata *data, size_t offset, int typecode,
 *                         unsigned int nd, const size_t *dims,
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("pygpu.gpuarray.array_fromdata", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":313
 *         raise get_exc(err), gpucontext_error(gpudata_context(data), err)
 * 
 * cdef int array_view(GpuArray v, GpuArray a) except -1:             # <<<<<<<<<<<<<<
 *     cdef int err
 *     err = GpuArray_view(&v.ga, &a.ga)
 */

static int __pyx_f_5pygpu_8gpuarray_array_view(struct PyGpuArrayObject *__pyx_v_v, struct PyGpuArrayObject *__pyx_v_a) {
  int __pyx_v_err;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  __Pyx_RefNannySetupContext("array_view", 0);

  /* "pygpu/gpuarray.pyx":315
 * cdef int array_view(GpuArray v, GpuArray a) except -1:
 *     cdef int err
 *     err = GpuArray_view(&v.ga, &a.ga)             # <<<<<<<<<<<<<<
 *     if err != GA_NO_ERROR:
 *         raise get_exc(err), GpuArray_error(&a.ga, err)
 */
  __pyx_v_err = GpuArray_view((&__pyx_v_v->ga), (&__pyx_v_a->ga));

  /* "pygpu/gpuarray.pyx":316
 *     cdef int err
 *     err = GpuArray_view(&v.ga, &a.ga)
 *     if err != GA_NO_ERROR:             # <<<<<<<<<<<<<<
 *         raise get_exc(err), GpuArray_error(&a.ga, err)
 * 
 */
  __pyx_t_1 = ((__pyx_v_err != GA_NO_ERROR) != 0);
  if (__pyx_t_1) {

    /* "pygpu/gpuarray.pyx":317
 *     err = GpuArray_view(&v.ga, &a.ga)
 *     if err != GA_NO_ERROR:
 *         raise get_exc(err), GpuArray_error(&a.ga, err)             # <<<<<<<<<<<<<<
 * 
 * cdef int array_sync(GpuArray a) except -1:
 */
    __pyx_t_2 = ((PyObject *)__pyx_f_5pygpu_8gpuarray_get_exc(__pyx_v_err)); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 317, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_3 = __Pyx_PyBytes_FromString(GpuArray_error((&__pyx_v_a->ga), __pyx_v_err)); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 317, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_Raise(__pyx_t_2, __pyx_t_3, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __PYX_ERR(0, 317, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":316
 *     cdef int err
 *     err = GpuArray_view(&v.ga, &a.ga)
 *     if err != GA_NO_ERROR:             # <<<<<<<<<<<<<<
 *         raise get_exc(err), GpuArray_error(&a.ga, err)
 * 
 */
  }

  /* "pygpu/gpuarray.pyx":313
 *         raise get_exc(err), gpucontext_error(gpudata_context(data), err)
 * 
 * cdef int array_view(GpuArray v, GpuArray a) except -1:             # <<<<<<<<<<<<<<
 *     cdef int err
 *     err = GpuArray_view(&v.ga, &a.ga)
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("pygpu.gpuarray.array_view", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":319
 *         raise get_exc(err), GpuArray_error(&a.ga, err)
 * 
 * cdef int array_sync(GpuArray a) except -1:             # <<<<<<<<<<<<<<
 *     cdef int err
 *     with nogil:
 */

static int __pyx_f_5pygpu_8gpuarray_array_sync(struct PyGpuArrayObject *__pyx_v_a) {
  int __pyx_v_err;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  __Pyx_RefNannySetupContext("array_sync", 0);

  /* "pygpu/gpuarray.pyx":321
 * cdef int array_sync(GpuArray a) except -1:
 *     cdef int err
 *     with nogil:             # <<<<<<<<<<<<<<
 *         err = GpuArray_sync(&a.ga)
 *     if err != GA_NO_ERROR:
 */
  {
      #ifdef WITH_THREAD
      PyThreadState *_save;
      Py_UNBLOCK_THREADS
      __Pyx_FastGIL_Remember();
      #endif
      /*try:*/ {

        /* "pygpu/gpuarray.pyx":322
 *     cdef int err
 *     with nogil:
 *         err = GpuArray_sync(&a.ga)             # <<<<<<<<<<<<<<
 *     if err != GA_NO_ERROR:
 *         raise get_exc(err), GpuArray_error(&a.ga, err)
 */
        __pyx_v_err = GpuArray_sync((&__pyx_v_a->ga));
      }

      /* "pygpu/gpuarray.pyx":321
 * cdef int array_sync(GpuArray a) except -1:
 *     cdef int err
 *     with nogil:             # <<<<<<<<<<<<<<
 *         err = GpuArray_sync(&a.ga)
 *     if err != GA_NO_ERROR:
 */
      /*finally:*/ {
        /*normal exit:*/{
          #ifdef WITH_THREAD
          __Pyx_FastGIL_Forget();
          Py_BLOCK_THREADS
          #endif
          goto __pyx_L5;
        }
        __pyx_L5:;
      }
  }

  /* "pygpu/gpuarray.pyx":323
 *     with nogil:
 *         err = GpuArray_sync(&a.ga)
 *     if err != GA_NO_ERROR:             # <<<<<<<<<<<<<<
 *         raise get_exc(err), GpuArray_error(&a.ga, err)
 * 
 */
  __pyx_t_1 = ((__pyx_v_err != GA_NO_ERROR) != 0);
  if (__pyx_t_1) {

    /* "pygpu/gpuarray.pyx":324
 *         err = GpuArray_sync(&a.ga)
 *     if err != GA_NO_ERROR:
 *         raise get_exc(err), GpuArray_error(&a.ga, err)             # <<<<<<<<<<<<<<
 * 
 * cdef int array_index(GpuArray r, GpuArray a, const ssize_t *starts,
 */
    __pyx_t_2 = ((PyObject *)__pyx_f_5pygpu_8gpuarray_get_exc(__pyx_v_err)); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 324, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_3 = __Pyx_PyBytes_FromString(GpuArray_error((&__pyx_v_a->ga), __pyx_v_err)); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 324, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_Raise(__pyx_t_2, __pyx_t_3, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __PYX_ERR(0, 324, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":323
 *     with nogil:
 *         err = GpuArray_sync(&a.ga)
 *     if err != GA_NO_ERROR:             # <<<<<<<<<<<<<<
 *         raise get_exc(err), GpuArray_error(&a.ga, err)
 * 
 */
  }

  /* "pygpu/gpuarray.pyx":319
 *         raise get_exc(err), GpuArray_error(&a.ga, err)
 * 
 * cdef int array_sync(GpuArray a) except -1:             # <<<<<<<<<<<<<<
 *     cdef int err
 *     with nogil:
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("pygpu.gpuarray.array_sync", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":326
 *         raise get_exc(err), GpuArray_error(&a.ga, err)
 * 
 * cdef int array_index(GpuArray r, GpuArray a, const ssize_t *starts,             # <<<<<<<<<<<<<<
 *                      const ssize_t *stops, const ssize_t *steps) except -1:
 *     cdef int err
 */

static int __pyx_f_5pygpu_8gpuarray_array_index(struct PyGpuArrayObject *__pyx_v_r, struct PyGpuArrayObject *__pyx_v_a, Py_ssize_t const *__pyx_v_starts, Py_ssize_t const *__pyx_v_stops, Py_ssize_t const *__pyx_v_steps) {
  int __pyx_v_err;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  __Pyx_RefNannySetupContext("array_index", 0);

  /* "pygpu/gpuarray.pyx":329
 *                      const ssize_t *stops, const ssize_t *steps) except -1:
 *     cdef int err
 *     err = GpuArray_index(&r.ga, &a.ga, starts, stops, steps)             # <<<<<<<<<<<<<<
 *     if err != GA_NO_ERROR:
 *         raise get_exc(err), GpuArray_error(&a.ga, err)
 */
  __pyx_v_err = GpuArray_index((&__pyx_v_r->ga), (&__pyx_v_a->ga), __pyx_v_starts, __pyx_v_stops, __pyx_v_steps);

  /* "pygpu/gpuarray.pyx":330
 *     cdef int err
 *     err = GpuArray_index(&r.ga, &a.ga, starts, stops, steps)
 *     if err != GA_NO_ERROR:             # <<<<<<<<<<<<<<
 *         raise get_exc(err), GpuArray_error(&a.ga, err)
 * 
 */
  __pyx_t_1 = ((__pyx_v_err != GA_NO_ERROR) != 0);
  if (__pyx_t_1) {

    /* "pygpu/gpuarray.pyx":331
 *     err = GpuArray_index(&r.ga, &a.ga, starts, stops, steps)
 *     if err != GA_NO_ERROR:
 *         raise get_exc(err), GpuArray_error(&a.ga, err)             # <<<<<<<<<<<<<<
 * 
 * cdef int array_take1(GpuArray r, GpuArray a, GpuArray i,
 */
    __pyx_t_2 = ((PyObject *)__pyx_f_5pygpu_8gpuarray_get_exc(__pyx_v_err)); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 331, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_3 = __Pyx_PyBytes_FromString(GpuArray_error((&__pyx_v_a->ga), __pyx_v_err)); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 331, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_Raise(__pyx_t_2, __pyx_t_3, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __PYX_ERR(0, 331, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":330
 *     cdef int err
 *     err = GpuArray_index(&r.ga, &a.ga, starts, stops, steps)
 *     if err != GA_NO_ERROR:             # <<<<<<<<<<<<<<
 *         raise get_exc(err), GpuArray_error(&a.ga, err)
 * 
 */
  }

  /* "pygpu/gpuarray.pyx":326
 *         raise get_exc(err), GpuArray_error(&a.ga, err)
 * 
 * cdef int array_index(GpuArray r, GpuArray a, const ssize_t *starts,             # <<<<<<<<<<<<<<
 *                      const ssize_t *stops, const ssize_t *steps) except -1:
 *     cdef int err
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("pygpu.gpuarray.array_index", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":333
 *         raise get_exc(err), GpuArray_error(&a.ga, err)
 * 
 * cdef int array_take1(GpuArray r, GpuArray a, GpuArray i,             # <<<<<<<<<<<<<<
 *                      int check_err) except -1:
 *     cdef int err
 */

static int __pyx_f_5pygpu_8gpuarray_array_take1(struct PyGpuArrayObject *__pyx_v_r, struct PyGpuArrayObject *__pyx_v_a, struct PyGpuArrayObject *__pyx_v_i, int __pyx_v_check_err) {
  int __pyx_v_err;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  __Pyx_RefNannySetupContext("array_take1", 0);

  /* "pygpu/gpuarray.pyx":336
 *                      int check_err) except -1:
 *     cdef int err
 *     err = GpuArray_take1(&r.ga, &a.ga, &i.ga, check_err)             # <<<<<<<<<<<<<<
 *     if err != GA_NO_ERROR:
 *         if err == GA_VALUE_ERROR:
 */
  __pyx_v_err = GpuArray_take1((&__pyx_v_r->ga), (&__pyx_v_a->ga), (&__pyx_v_i->ga), __pyx_v_check_err);

  /* "pygpu/gpuarray.pyx":337
 *     cdef int err
 *     err = GpuArray_take1(&r.ga, &a.ga, &i.ga, check_err)
 *     if err != GA_NO_ERROR:             # <<<<<<<<<<<<<<
 *         if err == GA_VALUE_ERROR:
 *             raise IndexError, GpuArray_error(&r.ga, err)
 */
  __pyx_t_1 = ((__pyx_v_err != GA_NO_ERROR) != 0);
  if (__pyx_t_1) {

    /* "pygpu/gpuarray.pyx":338
 *     err = GpuArray_take1(&r.ga, &a.ga, &i.ga, check_err)
 *     if err != GA_NO_ERROR:
 *         if err == GA_VALUE_ERROR:             # <<<<<<<<<<<<<<
 *             raise IndexError, GpuArray_error(&r.ga, err)
 *         raise get_exc(err), GpuArray_error(&r.ga, err)
 */
    __pyx_t_1 = ((__pyx_v_err == GA_VALUE_ERROR) != 0);
    if (__pyx_t_1) {

      /* "pygpu/gpuarray.pyx":339
 *     if err != GA_NO_ERROR:
 *         if err == GA_VALUE_ERROR:
 *             raise IndexError, GpuArray_error(&r.ga, err)             # <<<<<<<<<<<<<<
 *         raise get_exc(err), GpuArray_error(&r.ga, err)
 * 
 */
      __pyx_t_2 = __Pyx_PyBytes_FromString(GpuArray_error((&__pyx_v_r->ga), __pyx_v_err)); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 339, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_Raise(__pyx_builtin_IndexError, __pyx_t_2, 0, 0);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __PYX_ERR(0, 339, __pyx_L1_error)

      /* "pygpu/gpuarray.pyx":338
 *     err = GpuArray_take1(&r.ga, &a.ga, &i.ga, check_err)
 *     if err != GA_NO_ERROR:
 *         if err == GA_VALUE_ERROR:             # <<<<<<<<<<<<<<
 *             raise IndexError, GpuArray_error(&r.ga, err)
 *         raise get_exc(err), GpuArray_error(&r.ga, err)
 */
    }

    /* "pygpu/gpuarray.pyx":340
 *         if err == GA_VALUE_ERROR:
 *             raise IndexError, GpuArray_error(&r.ga, err)
 *         raise get_exc(err), GpuArray_error(&r.ga, err)             # <<<<<<<<<<<<<<
 * 
 * cdef int array_setarray(GpuArray v, GpuArray a) except -1:
 */
    __pyx_t_2 = ((PyObject *)__pyx_f_5pygpu_8gpuarray_get_exc(__pyx_v_err)); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 340, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_3 = __Pyx_PyBytes_FromString(GpuArray_error((&__pyx_v_r->ga), __pyx_v_err)); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 340, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_Raise(__pyx_t_2, __pyx_t_3, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __PYX_ERR(0, 340, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":337
 *     cdef int err
 *     err = GpuArray_take1(&r.ga, &a.ga, &i.ga, check_err)
 *     if err != GA_NO_ERROR:             # <<<<<<<<<<<<<<
 *         if err == GA_VALUE_ERROR:
 *             raise IndexError, GpuArray_error(&r.ga, err)
 */
  }

  /* "pygpu/gpuarray.pyx":333
 *         raise get_exc(err), GpuArray_error(&a.ga, err)
 * 
 * cdef int array_take1(GpuArray r, GpuArray a, GpuArray i,             # <<<<<<<<<<<<<<
 *                      int check_err) except -1:
 *     cdef int err
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("pygpu.gpuarray.array_take1", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":342
 *         raise get_exc(err), GpuArray_error(&r.ga, err)
 * 
 * cdef int array_setarray(GpuArray v, GpuArray a) except -1:             # <<<<<<<<<<<<<<
 *     cdef int err
 *     err = GpuArray_setarray(&v.ga, &a.ga)
 */

static int __pyx_f_5pygpu_8gpuarray_array_setarray(struct PyGpuArrayObject *__pyx_v_v, struct PyGpuArrayObject *__pyx_v_a) {
  int __pyx_v_err;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  __Pyx_RefNannySetupContext("array_setarray", 0);

  /* "pygpu/gpuarray.pyx":344
 * cdef int array_setarray(GpuArray v, GpuArray a) except -1:
 *     cdef int err
 *     err = GpuArray_setarray(&v.ga, &a.ga)             # <<<<<<<<<<<<<<
 *     if err != GA_NO_ERROR:
 *         raise get_exc(err), GpuArray_error(&v.ga, err)
 */
  __pyx_v_err = GpuArray_setarray((&__pyx_v_v->ga), (&__pyx_v_a->ga));

  /* "pygpu/gpuarray.pyx":345
 *     cdef int err
 *     err = GpuArray_setarray(&v.ga, &a.ga)
 *     if err != GA_NO_ERROR:             # <<<<<<<<<<<<<<
 *         raise get_exc(err), GpuArray_error(&v.ga, err)
 * 
 */
  __pyx_t_1 = ((__pyx_v_err != GA_NO_ERROR) != 0);
  if (__pyx_t_1) {

    /* "pygpu/gpuarray.pyx":346
 *     err = GpuArray_setarray(&v.ga, &a.ga)
 *     if err != GA_NO_ERROR:
 *         raise get_exc(err), GpuArray_error(&v.ga, err)             # <<<<<<<<<<<<<<
 * 
 * cdef int array_reshape(GpuArray res, GpuArray a, unsigned int nd,
 */
    __pyx_t_2 = ((PyObject *)__pyx_f_5pygpu_8gpuarray_get_exc(__pyx_v_err)); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 346, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_3 = __Pyx_PyBytes_FromString(GpuArray_error((&__pyx_v_v->ga), __pyx_v_err)); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 346, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_Raise(__pyx_t_2, __pyx_t_3, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __PYX_ERR(0, 346, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":345
 *     cdef int err
 *     err = GpuArray_setarray(&v.ga, &a.ga)
 *     if err != GA_NO_ERROR:             # <<<<<<<<<<<<<<
 *         raise get_exc(err), GpuArray_error(&v.ga, err)
 * 
 */
  }

  /* "pygpu/gpuarray.pyx":342
 *         raise get_exc(err), GpuArray_error(&r.ga, err)
 * 
 * cdef int array_setarray(GpuArray v, GpuArray a) except -1:             # <<<<<<<<<<<<<<
 *     cdef int err
 *     err = GpuArray_setarray(&v.ga, &a.ga)
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("pygpu.gpuarray.array_setarray", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":348
 *         raise get_exc(err), GpuArray_error(&v.ga, err)
 * 
 * cdef int array_reshape(GpuArray res, GpuArray a, unsigned int nd,             # <<<<<<<<<<<<<<
 *                        const size_t *newdims, ga_order ord,
 *                        bint nocopy) except -1:
 */

static int __pyx_f_5pygpu_8gpuarray_array_reshape(struct PyGpuArrayObject *__pyx_v_res, struct PyGpuArrayObject *__pyx_v_a, unsigned int __pyx_v_nd, size_t const *__pyx_v_newdims, ga_order __pyx_v_ord, int __pyx_v_nocopy) {
  int __pyx_v_err;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  __Pyx_RefNannySetupContext("array_reshape", 0);

  /* "pygpu/gpuarray.pyx":352
 *                        bint nocopy) except -1:
 *     cdef int err
 *     err = GpuArray_reshape(&res.ga, &a.ga, nd, newdims, ord, nocopy)             # <<<<<<<<<<<<<<
 *     if err != GA_NO_ERROR:
 *         raise get_exc(err), GpuArray_error(&a.ga, err)
 */
  __pyx_v_err = GpuArray_reshape((&__pyx_v_res->ga), (&__pyx_v_a->ga), __pyx_v_nd, __pyx_v_newdims, __pyx_v_ord, __pyx_v_nocopy);

  /* "pygpu/gpuarray.pyx":353
 *     cdef int err
 *     err = GpuArray_reshape(&res.ga, &a.ga, nd, newdims, ord, nocopy)
 *     if err != GA_NO_ERROR:             # <<<<<<<<<<<<<<
 *         raise get_exc(err), GpuArray_error(&a.ga, err)
 * 
 */
  __pyx_t_1 = ((__pyx_v_err != GA_NO_ERROR) != 0);
  if (__pyx_t_1) {

    /* "pygpu/gpuarray.pyx":354
 *     err = GpuArray_reshape(&res.ga, &a.ga, nd, newdims, ord, nocopy)
 *     if err != GA_NO_ERROR:
 *         raise get_exc(err), GpuArray_error(&a.ga, err)             # <<<<<<<<<<<<<<
 * 
 * cdef int array_transpose(GpuArray res, GpuArray a,
 */
    __pyx_t_2 = ((PyObject *)__pyx_f_5pygpu_8gpuarray_get_exc(__pyx_v_err)); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 354, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_3 = __Pyx_PyBytes_FromString(GpuArray_error((&__pyx_v_a->ga), __pyx_v_err)); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 354, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_Raise(__pyx_t_2, __pyx_t_3, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __PYX_ERR(0, 354, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":353
 *     cdef int err
 *     err = GpuArray_reshape(&res.ga, &a.ga, nd, newdims, ord, nocopy)
 *     if err != GA_NO_ERROR:             # <<<<<<<<<<<<<<
 *         raise get_exc(err), GpuArray_error(&a.ga, err)
 * 
 */
  }

  /* "pygpu/gpuarray.pyx":348
 *         raise get_exc(err), GpuArray_error(&v.ga, err)
 * 
 * cdef int array_reshape(GpuArray res, GpuArray a, unsigned int nd,             # <<<<<<<<<<<<<<
 *                        const size_t *newdims, ga_order ord,
 *                        bint nocopy) except -1:
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("pygpu.gpuarray.array_reshape", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":356
 *         raise get_exc(err), GpuArray_error(&a.ga, err)
 * 
 * cdef int array_transpose(GpuArray res, GpuArray a,             # <<<<<<<<<<<<<<
 *                          const unsigned int *new_axes) except -1:
 *     cdef int err
 */

static int __pyx_f_5pygpu_8gpuarray_array_transpose(struct PyGpuArrayObject *__pyx_v_res, struct PyGpuArrayObject *__pyx_v_a, unsigned int const *__pyx_v_new_axes) {
  int __pyx_v_err;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  __Pyx_RefNannySetupContext("array_transpose", 0);

  /* "pygpu/gpuarray.pyx":359
 *                          const unsigned int *new_axes) except -1:
 *     cdef int err
 *     err = GpuArray_transpose(&res.ga, &a.ga, new_axes)             # <<<<<<<<<<<<<<
 *     if err != GA_NO_ERROR:
 *         raise get_exc(err), GpuArray_error(&a.ga, err)
 */
  __pyx_v_err = GpuArray_transpose((&__pyx_v_res->ga), (&__pyx_v_a->ga), __pyx_v_new_axes);

  /* "pygpu/gpuarray.pyx":360
 *     cdef int err
 *     err = GpuArray_transpose(&res.ga, &a.ga, new_axes)
 *     if err != GA_NO_ERROR:             # <<<<<<<<<<<<<<
 *         raise get_exc(err), GpuArray_error(&a.ga, err)
 * 
 */
  __pyx_t_1 = ((__pyx_v_err != GA_NO_ERROR) != 0);
  if (__pyx_t_1) {

    /* "pygpu/gpuarray.pyx":361
 *     err = GpuArray_transpose(&res.ga, &a.ga, new_axes)
 *     if err != GA_NO_ERROR:
 *         raise get_exc(err), GpuArray_error(&a.ga, err)             # <<<<<<<<<<<<<<
 * 
 * cdef int array_clear(GpuArray a) except -1:
 */
    __pyx_t_2 = ((PyObject *)__pyx_f_5pygpu_8gpuarray_get_exc(__pyx_v_err)); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 361, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_3 = __Pyx_PyBytes_FromString(GpuArray_error((&__pyx_v_a->ga), __pyx_v_err)); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 361, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_Raise(__pyx_t_2, __pyx_t_3, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __PYX_ERR(0, 361, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":360
 *     cdef int err
 *     err = GpuArray_transpose(&res.ga, &a.ga, new_axes)
 *     if err != GA_NO_ERROR:             # <<<<<<<<<<<<<<
 *         raise get_exc(err), GpuArray_error(&a.ga, err)
 * 
 */
  }

  /* "pygpu/gpuarray.pyx":356
 *         raise get_exc(err), GpuArray_error(&a.ga, err)
 * 
 * cdef int array_transpose(GpuArray res, GpuArray a,             # <<<<<<<<<<<<<<
 *                          const unsigned int *new_axes) except -1:
 *     cdef int err
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("pygpu.gpuarray.array_transpose", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":363
 *         raise get_exc(err), GpuArray_error(&a.ga, err)
 * 
 * cdef int array_clear(GpuArray a) except -1:             # <<<<<<<<<<<<<<
 *     GpuArray_clear(&a.ga)
 * 
 */

static int __pyx_f_5pygpu_8gpuarray_array_clear(struct PyGpuArrayObject *__pyx_v_a) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("array_clear", 0);

  /* "pygpu/gpuarray.pyx":364
 * 
 * cdef int array_clear(GpuArray a) except -1:
 *     GpuArray_clear(&a.ga)             # <<<<<<<<<<<<<<
 * 
 * cdef bint array_share(GpuArray a, GpuArray b):
 */
  GpuArray_clear((&__pyx_v_a->ga));

  /* "pygpu/gpuarray.pyx":363
 *         raise get_exc(err), GpuArray_error(&a.ga, err)
 * 
 * cdef int array_clear(GpuArray a) except -1:             # <<<<<<<<<<<<<<
 *     GpuArray_clear(&a.ga)
 * 
 */

  /* function exit code */
  __pyx_r = 0;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":366
 *     GpuArray_clear(&a.ga)
 * 
 * cdef bint array_share(GpuArray a, GpuArray b):             # <<<<<<<<<<<<<<
 *     return GpuArray_share(&a.ga, &b.ga)
 * 
 */

static int __pyx_f_5pygpu_8gpuarray_array_share(struct PyGpuArrayObject *__pyx_v_a, struct PyGpuArrayObject *__pyx_v_b) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("array_share", 0);

  /* "pygpu/gpuarray.pyx":367
 * 
 * cdef bint array_share(GpuArray a, GpuArray b):
 *     return GpuArray_share(&a.ga, &b.ga)             # <<<<<<<<<<<<<<
 * 
 * cdef gpucontext *array_context(GpuArray a) except NULL:
 */
  __pyx_r = GpuArray_share((&__pyx_v_a->ga), (&__pyx_v_b->ga));
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":366
 *     GpuArray_clear(&a.ga)
 * 
 * cdef bint array_share(GpuArray a, GpuArray b):             # <<<<<<<<<<<<<<
 *     return GpuArray_share(&a.ga, &b.ga)
 * 
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":369
 *     return GpuArray_share(&a.ga, &b.ga)
 * 
 * cdef gpucontext *array_context(GpuArray a) except NULL:             # <<<<<<<<<<<<<<
 *     cdef gpucontext *res
 *     res = GpuArray_context(&a.ga)
 */

static gpucontext *__pyx_f_5pygpu_8gpuarray_array_context(struct PyGpuArrayObject *__pyx_v_a) {
  gpucontext *__pyx_v_res;
  gpucontext *__pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  __Pyx_RefNannySetupContext("array_context", 0);

  /* "pygpu/gpuarray.pyx":371
 * cdef gpucontext *array_context(GpuArray a) except NULL:
 *     cdef gpucontext *res
 *     res = GpuArray_context(&a.ga)             # <<<<<<<<<<<<<<
 *     if res is NULL:
 *         raise GpuArrayException, "Invalid array or destroyed context"
 */
  __pyx_v_res = GpuArray_context((&__pyx_v_a->ga));

  /* "pygpu/gpuarray.pyx":372
 *     cdef gpucontext *res
 *     res = GpuArray_context(&a.ga)
 *     if res is NULL:             # <<<<<<<<<<<<<<
 *         raise GpuArrayException, "Invalid array or destroyed context"
 *     return res
 */
  __pyx_t_1 = ((__pyx_v_res == NULL) != 0);
  if (__pyx_t_1) {

    /* "pygpu/gpuarray.pyx":373
 *     res = GpuArray_context(&a.ga)
 *     if res is NULL:
 *         raise GpuArrayException, "Invalid array or destroyed context"             # <<<<<<<<<<<<<<
 *     return res
 * 
 */
    __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_GpuArrayException); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 373, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_Raise(__pyx_t_2, __pyx_kp_s_Invalid_array_or_destroyed_conte, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(0, 373, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":372
 *     cdef gpucontext *res
 *     res = GpuArray_context(&a.ga)
 *     if res is NULL:             # <<<<<<<<<<<<<<
 *         raise GpuArrayException, "Invalid array or destroyed context"
 *     return res
 */
  }

  /* "pygpu/gpuarray.pyx":374
 *     if res is NULL:
 *         raise GpuArrayException, "Invalid array or destroyed context"
 *     return res             # <<<<<<<<<<<<<<
 * 
 * cdef int array_move(GpuArray a, GpuArray src) except -1:
 */
  __pyx_r = __pyx_v_res;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":369
 *     return GpuArray_share(&a.ga, &b.ga)
 * 
 * cdef gpucontext *array_context(GpuArray a) except NULL:             # <<<<<<<<<<<<<<
 *     cdef gpucontext *res
 *     res = GpuArray_context(&a.ga)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("pygpu.gpuarray.array_context", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":376
 *     return res
 * 
 * cdef int array_move(GpuArray a, GpuArray src) except -1:             # <<<<<<<<<<<<<<
 *     cdef int err
 *     err = GpuArray_move(&a.ga, &src.ga)
 */

static int __pyx_f_5pygpu_8gpuarray_array_move(struct PyGpuArrayObject *__pyx_v_a, struct PyGpuArrayObject *__pyx_v_src) {
  int __pyx_v_err;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  __Pyx_RefNannySetupContext("array_move", 0);

  /* "pygpu/gpuarray.pyx":378
 * cdef int array_move(GpuArray a, GpuArray src) except -1:
 *     cdef int err
 *     err = GpuArray_move(&a.ga, &src.ga)             # <<<<<<<<<<<<<<
 *     if err != GA_NO_ERROR:
 *         raise get_exc(err), GpuArray_error(&a.ga, err)
 */
  __pyx_v_err = GpuArray_move((&__pyx_v_a->ga), (&__pyx_v_src->ga));

  /* "pygpu/gpuarray.pyx":379
 *     cdef int err
 *     err = GpuArray_move(&a.ga, &src.ga)
 *     if err != GA_NO_ERROR:             # <<<<<<<<<<<<<<
 *         raise get_exc(err), GpuArray_error(&a.ga, err)
 * 
 */
  __pyx_t_1 = ((__pyx_v_err != GA_NO_ERROR) != 0);
  if (__pyx_t_1) {

    /* "pygpu/gpuarray.pyx":380
 *     err = GpuArray_move(&a.ga, &src.ga)
 *     if err != GA_NO_ERROR:
 *         raise get_exc(err), GpuArray_error(&a.ga, err)             # <<<<<<<<<<<<<<
 * 
 * cdef int array_write(GpuArray a, void *src, size_t sz) except -1:
 */
    __pyx_t_2 = ((PyObject *)__pyx_f_5pygpu_8gpuarray_get_exc(__pyx_v_err)); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 380, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_3 = __Pyx_PyBytes_FromString(GpuArray_error((&__pyx_v_a->ga), __pyx_v_err)); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 380, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_Raise(__pyx_t_2, __pyx_t_3, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __PYX_ERR(0, 380, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":379
 *     cdef int err
 *     err = GpuArray_move(&a.ga, &src.ga)
 *     if err != GA_NO_ERROR:             # <<<<<<<<<<<<<<
 *         raise get_exc(err), GpuArray_error(&a.ga, err)
 * 
 */
  }

  /* "pygpu/gpuarray.pyx":376
 *     return res
 * 
 * cdef int array_move(GpuArray a, GpuArray src) except -1:             # <<<<<<<<<<<<<<
 *     cdef int err
 *     err = GpuArray_move(&a.ga, &src.ga)
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("pygpu.gpuarray.array_move", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":382
 *         raise get_exc(err), GpuArray_error(&a.ga, err)
 * 
 * cdef int array_write(GpuArray a, void *src, size_t sz) except -1:             # <<<<<<<<<<<<<<
 *     cdef int err
 *     with nogil:
 */

static int __pyx_f_5pygpu_8gpuarray_array_write(struct PyGpuArrayObject *__pyx_v_a, void *__pyx_v_src, size_t __pyx_v_sz) {
  int __pyx_v_err;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  __Pyx_RefNannySetupContext("array_write", 0);

  /* "pygpu/gpuarray.pyx":384
 * cdef int array_write(GpuArray a, void *src, size_t sz) except -1:
 *     cdef int err
 *     with nogil:             # <<<<<<<<<<<<<<
 *         err = GpuArray_write(&a.ga, src, sz)
 *     if err != GA_NO_ERROR:
 */
  {
      #ifdef WITH_THREAD
      PyThreadState *_save;
      Py_UNBLOCK_THREADS
      __Pyx_FastGIL_Remember();
      #endif
      /*try:*/ {

        /* "pygpu/gpuarray.pyx":385
 *     cdef int err
 *     with nogil:
 *         err = GpuArray_write(&a.ga, src, sz)             # <<<<<<<<<<<<<<
 *     if err != GA_NO_ERROR:
 *         raise get_exc(err), GpuArray_error(&a.ga, err)
 */
        __pyx_v_err = GpuArray_write((&__pyx_v_a->ga), __pyx_v_src, __pyx_v_sz);
      }

      /* "pygpu/gpuarray.pyx":384
 * cdef int array_write(GpuArray a, void *src, size_t sz) except -1:
 *     cdef int err
 *     with nogil:             # <<<<<<<<<<<<<<
 *         err = GpuArray_write(&a.ga, src, sz)
 *     if err != GA_NO_ERROR:
 */
      /*finally:*/ {
        /*normal exit:*/{
          #ifdef WITH_THREAD
          __Pyx_FastGIL_Forget();
          Py_BLOCK_THREADS
          #endif
          goto __pyx_L5;
        }
        __pyx_L5:;
      }
  }

  /* "pygpu/gpuarray.pyx":386
 *     with nogil:
 *         err = GpuArray_write(&a.ga, src, sz)
 *     if err != GA_NO_ERROR:             # <<<<<<<<<<<<<<
 *         raise get_exc(err), GpuArray_error(&a.ga, err)
 * 
 */
  __pyx_t_1 = ((__pyx_v_err != GA_NO_ERROR) != 0);
  if (__pyx_t_1) {

    /* "pygpu/gpuarray.pyx":387
 *         err = GpuArray_write(&a.ga, src, sz)
 *     if err != GA_NO_ERROR:
 *         raise get_exc(err), GpuArray_error(&a.ga, err)             # <<<<<<<<<<<<<<
 * 
 * cdef int array_read(void *dst, size_t sz, GpuArray src) except -1:
 */
    __pyx_t_2 = ((PyObject *)__pyx_f_5pygpu_8gpuarray_get_exc(__pyx_v_err)); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 387, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_3 = __Pyx_PyBytes_FromString(GpuArray_error((&__pyx_v_a->ga), __pyx_v_err)); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 387, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_Raise(__pyx_t_2, __pyx_t_3, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __PYX_ERR(0, 387, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":386
 *     with nogil:
 *         err = GpuArray_write(&a.ga, src, sz)
 *     if err != GA_NO_ERROR:             # <<<<<<<<<<<<<<
 *         raise get_exc(err), GpuArray_error(&a.ga, err)
 * 
 */
  }

  /* "pygpu/gpuarray.pyx":382
 *         raise get_exc(err), GpuArray_error(&a.ga, err)
 * 
 * cdef int array_write(GpuArray a, void *src, size_t sz) except -1:             # <<<<<<<<<<<<<<
 *     cdef int err
 *     with nogil:
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("pygpu.gpuarray.array_write", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":389
 *         raise get_exc(err), GpuArray_error(&a.ga, err)
 * 
 * cdef int array_read(void *dst, size_t sz, GpuArray src) except -1:             # <<<<<<<<<<<<<<
 *     cdef int err
 *     with nogil:
 */

static int __pyx_f_5pygpu_8gpuarray_array_read(void *__pyx_v_dst, size_t __pyx_v_sz, struct PyGpuArrayObject *__pyx_v_src) {
  int __pyx_v_err;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  __Pyx_RefNannySetupContext("array_read", 0);

  /* "pygpu/gpuarray.pyx":391
 * cdef int array_read(void *dst, size_t sz, GpuArray src) except -1:
 *     cdef int err
 *     with nogil:             # <<<<<<<<<<<<<<
 *         err = GpuArray_read(dst, sz, &src.ga)
 *     if err != GA_NO_ERROR:
 */
  {
      #ifdef WITH_THREAD
      PyThreadState *_save;
      Py_UNBLOCK_THREADS
      __Pyx_FastGIL_Remember();
      #endif
      /*try:*/ {

        /* "pygpu/gpuarray.pyx":392
 *     cdef int err
 *     with nogil:
 *         err = GpuArray_read(dst, sz, &src.ga)             # <<<<<<<<<<<<<<
 *     if err != GA_NO_ERROR:
 *         raise get_exc(err), GpuArray_error(&src.ga, err)
 */
        __pyx_v_err = GpuArray_read(__pyx_v_dst, __pyx_v_sz, (&__pyx_v_src->ga));
      }

      /* "pygpu/gpuarray.pyx":391
 * cdef int array_read(void *dst, size_t sz, GpuArray src) except -1:
 *     cdef int err
 *     with nogil:             # <<<<<<<<<<<<<<
 *         err = GpuArray_read(dst, sz, &src.ga)
 *     if err != GA_NO_ERROR:
 */
      /*finally:*/ {
        /*normal exit:*/{
          #ifdef WITH_THREAD
          __Pyx_FastGIL_Forget();
          Py_BLOCK_THREADS
          #endif
          goto __pyx_L5;
        }
        __pyx_L5:;
      }
  }

  /* "pygpu/gpuarray.pyx":393
 *     with nogil:
 *         err = GpuArray_read(dst, sz, &src.ga)
 *     if err != GA_NO_ERROR:             # <<<<<<<<<<<<<<
 *         raise get_exc(err), GpuArray_error(&src.ga, err)
 * 
 */
  __pyx_t_1 = ((__pyx_v_err != GA_NO_ERROR) != 0);
  if (__pyx_t_1) {

    /* "pygpu/gpuarray.pyx":394
 *         err = GpuArray_read(dst, sz, &src.ga)
 *     if err != GA_NO_ERROR:
 *         raise get_exc(err), GpuArray_error(&src.ga, err)             # <<<<<<<<<<<<<<
 * 
 * cdef int array_memset(GpuArray a, int data) except -1:
 */
    __pyx_t_2 = ((PyObject *)__pyx_f_5pygpu_8gpuarray_get_exc(__pyx_v_err)); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 394, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_3 = __Pyx_PyBytes_FromString(GpuArray_error((&__pyx_v_src->ga), __pyx_v_err)); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 394, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_Raise(__pyx_t_2, __pyx_t_3, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __PYX_ERR(0, 394, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":393
 *     with nogil:
 *         err = GpuArray_read(dst, sz, &src.ga)
 *     if err != GA_NO_ERROR:             # <<<<<<<<<<<<<<
 *         raise get_exc(err), GpuArray_error(&src.ga, err)
 * 
 */
  }

  /* "pygpu/gpuarray.pyx":389
 *         raise get_exc(err), GpuArray_error(&a.ga, err)
 * 
 * cdef int array_read(void *dst, size_t sz, GpuArray src) except -1:             # <<<<<<<<<<<<<<
 *     cdef int err
 *     with nogil:
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("pygpu.gpuarray.array_read", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":396
 *         raise get_exc(err), GpuArray_error(&src.ga, err)
 * 
 * cdef int array_memset(GpuArray a, int data) except -1:             # <<<<<<<<<<<<<<
 *     cdef int err
 *     err = GpuArray_memset(&a.ga, data)
 */

static int __pyx_f_5pygpu_8gpuarray_array_memset(struct PyGpuArrayObject *__pyx_v_a, int __pyx_v_data) {
  int __pyx_v_err;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  __Pyx_RefNannySetupContext("array_memset", 0);

  /* "pygpu/gpuarray.pyx":398
 * cdef int array_memset(GpuArray a, int data) except -1:
 *     cdef int err
 *     err = GpuArray_memset(&a.ga, data)             # <<<<<<<<<<<<<<
 *     if err != GA_NO_ERROR:
 *         raise get_exc(err), GpuArray_error(&a.ga, err)
 */
  __pyx_v_err = GpuArray_memset((&__pyx_v_a->ga), __pyx_v_data);

  /* "pygpu/gpuarray.pyx":399
 *     cdef int err
 *     err = GpuArray_memset(&a.ga, data)
 *     if err != GA_NO_ERROR:             # <<<<<<<<<<<<<<
 *         raise get_exc(err), GpuArray_error(&a.ga, err)
 * 
 */
  __pyx_t_1 = ((__pyx_v_err != GA_NO_ERROR) != 0);
  if (__pyx_t_1) {

    /* "pygpu/gpuarray.pyx":400
 *     err = GpuArray_memset(&a.ga, data)
 *     if err != GA_NO_ERROR:
 *         raise get_exc(err), GpuArray_error(&a.ga, err)             # <<<<<<<<<<<<<<
 * 
 * cdef int array_copy(GpuArray res, GpuArray a, ga_order order) except -1:
 */
    __pyx_t_2 = ((PyObject *)__pyx_f_5pygpu_8gpuarray_get_exc(__pyx_v_err)); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 400, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_3 = __Pyx_PyBytes_FromString(GpuArray_error((&__pyx_v_a->ga), __pyx_v_err)); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 400, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_Raise(__pyx_t_2, __pyx_t_3, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __PYX_ERR(0, 400, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":399
 *     cdef int err
 *     err = GpuArray_memset(&a.ga, data)
 *     if err != GA_NO_ERROR:             # <<<<<<<<<<<<<<
 *         raise get_exc(err), GpuArray_error(&a.ga, err)
 * 
 */
  }

  /* "pygpu/gpuarray.pyx":396
 *         raise get_exc(err), GpuArray_error(&src.ga, err)
 * 
 * cdef int array_memset(GpuArray a, int data) except -1:             # <<<<<<<<<<<<<<
 *     cdef int err
 *     err = GpuArray_memset(&a.ga, data)
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("pygpu.gpuarray.array_memset", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":402
 *         raise get_exc(err), GpuArray_error(&a.ga, err)
 * 
 * cdef int array_copy(GpuArray res, GpuArray a, ga_order order) except -1:             # <<<<<<<<<<<<<<
 *     cdef int err
 *     err = GpuArray_copy(&res.ga, &a.ga, order)
 */

static int __pyx_f_5pygpu_8gpuarray_array_copy(struct PyGpuArrayObject *__pyx_v_res, struct PyGpuArrayObject *__pyx_v_a, ga_order __pyx_v_order) {
  int __pyx_v_err;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  __Pyx_RefNannySetupContext("array_copy", 0);

  /* "pygpu/gpuarray.pyx":404
 * cdef int array_copy(GpuArray res, GpuArray a, ga_order order) except -1:
 *     cdef int err
 *     err = GpuArray_copy(&res.ga, &a.ga, order)             # <<<<<<<<<<<<<<
 *     if err != GA_NO_ERROR:
 *         raise get_exc(err), GpuArray_error(&a.ga, err)
 */
  __pyx_v_err = GpuArray_copy((&__pyx_v_res->ga), (&__pyx_v_a->ga), __pyx_v_order);

  /* "pygpu/gpuarray.pyx":405
 *     cdef int err
 *     err = GpuArray_copy(&res.ga, &a.ga, order)
 *     if err != GA_NO_ERROR:             # <<<<<<<<<<<<<<
 *         raise get_exc(err), GpuArray_error(&a.ga, err)
 * 
 */
  __pyx_t_1 = ((__pyx_v_err != GA_NO_ERROR) != 0);
  if (__pyx_t_1) {

    /* "pygpu/gpuarray.pyx":406
 *     err = GpuArray_copy(&res.ga, &a.ga, order)
 *     if err != GA_NO_ERROR:
 *         raise get_exc(err), GpuArray_error(&a.ga, err)             # <<<<<<<<<<<<<<
 * 
 * cdef int array_transfer(GpuArray res, GpuArray a) except -1:
 */
    __pyx_t_2 = ((PyObject *)__pyx_f_5pygpu_8gpuarray_get_exc(__pyx_v_err)); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 406, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_3 = __Pyx_PyBytes_FromString(GpuArray_error((&__pyx_v_a->ga), __pyx_v_err)); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 406, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_Raise(__pyx_t_2, __pyx_t_3, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __PYX_ERR(0, 406, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":405
 *     cdef int err
 *     err = GpuArray_copy(&res.ga, &a.ga, order)
 *     if err != GA_NO_ERROR:             # <<<<<<<<<<<<<<
 *         raise get_exc(err), GpuArray_error(&a.ga, err)
 * 
 */
  }

  /* "pygpu/gpuarray.pyx":402
 *         raise get_exc(err), GpuArray_error(&a.ga, err)
 * 
 * cdef int array_copy(GpuArray res, GpuArray a, ga_order order) except -1:             # <<<<<<<<<<<<<<
 *     cdef int err
 *     err = GpuArray_copy(&res.ga, &a.ga, order)
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("pygpu.gpuarray.array_copy", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":408
 *         raise get_exc(err), GpuArray_error(&a.ga, err)
 * 
 * cdef int array_transfer(GpuArray res, GpuArray a) except -1:             # <<<<<<<<<<<<<<
 *     cdef int err
 *     with nogil:
 */

static int __pyx_f_5pygpu_8gpuarray_array_transfer(struct PyGpuArrayObject *__pyx_v_res, struct PyGpuArrayObject *__pyx_v_a) {
  int __pyx_v_err;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  __Pyx_RefNannySetupContext("array_transfer", 0);

  /* "pygpu/gpuarray.pyx":410
 * cdef int array_transfer(GpuArray res, GpuArray a) except -1:
 *     cdef int err
 *     with nogil:             # <<<<<<<<<<<<<<
 *         err = GpuArray_transfer(&res.ga, &a.ga)
 *     if err != GA_NO_ERROR:
 */
  {
      #ifdef WITH_THREAD
      PyThreadState *_save;
      Py_UNBLOCK_THREADS
      __Pyx_FastGIL_Remember();
      #endif
      /*try:*/ {

        /* "pygpu/gpuarray.pyx":411
 *     cdef int err
 *     with nogil:
 *         err = GpuArray_transfer(&res.ga, &a.ga)             # <<<<<<<<<<<<<<
 *     if err != GA_NO_ERROR:
 *         raise get_exc(err), GpuArray_error(&a.ga, err)
 */
        __pyx_v_err = GpuArray_transfer((&__pyx_v_res->ga), (&__pyx_v_a->ga));
      }

      /* "pygpu/gpuarray.pyx":410
 * cdef int array_transfer(GpuArray res, GpuArray a) except -1:
 *     cdef int err
 *     with nogil:             # <<<<<<<<<<<<<<
 *         err = GpuArray_transfer(&res.ga, &a.ga)
 *     if err != GA_NO_ERROR:
 */
      /*finally:*/ {
        /*normal exit:*/{
          #ifdef WITH_THREAD
          __Pyx_FastGIL_Forget();
          Py_BLOCK_THREADS
          #endif
          goto __pyx_L5;
        }
        __pyx_L5:;
      }
  }

  /* "pygpu/gpuarray.pyx":412
 *     with nogil:
 *         err = GpuArray_transfer(&res.ga, &a.ga)
 *     if err != GA_NO_ERROR:             # <<<<<<<<<<<<<<
 *         raise get_exc(err), GpuArray_error(&a.ga, err)
 * 
 */
  __pyx_t_1 = ((__pyx_v_err != GA_NO_ERROR) != 0);
  if (__pyx_t_1) {

    /* "pygpu/gpuarray.pyx":413
 *         err = GpuArray_transfer(&res.ga, &a.ga)
 *     if err != GA_NO_ERROR:
 *         raise get_exc(err), GpuArray_error(&a.ga, err)             # <<<<<<<<<<<<<<
 * 
 * cdef int array_split(_GpuArray **res, GpuArray a, size_t n, size_t *p,
 */
    __pyx_t_2 = ((PyObject *)__pyx_f_5pygpu_8gpuarray_get_exc(__pyx_v_err)); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 413, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_3 = __Pyx_PyBytes_FromString(GpuArray_error((&__pyx_v_a->ga), __pyx_v_err)); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 413, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_Raise(__pyx_t_2, __pyx_t_3, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __PYX_ERR(0, 413, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":412
 *     with nogil:
 *         err = GpuArray_transfer(&res.ga, &a.ga)
 *     if err != GA_NO_ERROR:             # <<<<<<<<<<<<<<
 *         raise get_exc(err), GpuArray_error(&a.ga, err)
 * 
 */
  }

  /* "pygpu/gpuarray.pyx":408
 *         raise get_exc(err), GpuArray_error(&a.ga, err)
 * 
 * cdef int array_transfer(GpuArray res, GpuArray a) except -1:             # <<<<<<<<<<<<<<
 *     cdef int err
 *     with nogil:
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("pygpu.gpuarray.array_transfer", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":415
 *         raise get_exc(err), GpuArray_error(&a.ga, err)
 * 
 * cdef int array_split(_GpuArray **res, GpuArray a, size_t n, size_t *p,             # <<<<<<<<<<<<<<
 *                      unsigned int axis) except -1:
 *     cdef int err
 */

static int __pyx_f_5pygpu_8gpuarray_array_split(GpuArray **__pyx_v_res, struct PyGpuArrayObject *__pyx_v_a, size_t __pyx_v_n, size_t *__pyx_v_p, unsigned int __pyx_v_axis) {
  int __pyx_v_err;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  __Pyx_RefNannySetupContext("array_split", 0);

  /* "pygpu/gpuarray.pyx":418
 *                      unsigned int axis) except -1:
 *     cdef int err
 *     err = GpuArray_split(res, &a.ga, n, p, axis)             # <<<<<<<<<<<<<<
 *     if err != GA_NO_ERROR:
 *         raise get_exc(err), GpuArray_error(&a.ga, err)
 */
  __pyx_v_err = GpuArray_split(__pyx_v_res, (&__pyx_v_a->ga), __pyx_v_n, __pyx_v_p, __pyx_v_axis);

  /* "pygpu/gpuarray.pyx":419
 *     cdef int err
 *     err = GpuArray_split(res, &a.ga, n, p, axis)
 *     if err != GA_NO_ERROR:             # <<<<<<<<<<<<<<
 *         raise get_exc(err), GpuArray_error(&a.ga, err)
 * 
 */
  __pyx_t_1 = ((__pyx_v_err != GA_NO_ERROR) != 0);
  if (__pyx_t_1) {

    /* "pygpu/gpuarray.pyx":420
 *     err = GpuArray_split(res, &a.ga, n, p, axis)
 *     if err != GA_NO_ERROR:
 *         raise get_exc(err), GpuArray_error(&a.ga, err)             # <<<<<<<<<<<<<<
 * 
 * cdef int array_concatenate(GpuArray r, const _GpuArray **a, size_t n,
 */
    __pyx_t_2 = ((PyObject *)__pyx_f_5pygpu_8gpuarray_get_exc(__pyx_v_err)); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 420, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_3 = __Pyx_PyBytes_FromString(GpuArray_error((&__pyx_v_a->ga), __pyx_v_err)); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 420, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_Raise(__pyx_t_2, __pyx_t_3, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __PYX_ERR(0, 420, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":419
 *     cdef int err
 *     err = GpuArray_split(res, &a.ga, n, p, axis)
 *     if err != GA_NO_ERROR:             # <<<<<<<<<<<<<<
 *         raise get_exc(err), GpuArray_error(&a.ga, err)
 * 
 */
  }

  /* "pygpu/gpuarray.pyx":415
 *         raise get_exc(err), GpuArray_error(&a.ga, err)
 * 
 * cdef int array_split(_GpuArray **res, GpuArray a, size_t n, size_t *p,             # <<<<<<<<<<<<<<
 *                      unsigned int axis) except -1:
 *     cdef int err
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("pygpu.gpuarray.array_split", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":422
 *         raise get_exc(err), GpuArray_error(&a.ga, err)
 * 
 * cdef int array_concatenate(GpuArray r, const _GpuArray **a, size_t n,             # <<<<<<<<<<<<<<
 *                            unsigned int axis, int restype) except -1:
 *     cdef int err
 */

static int __pyx_f_5pygpu_8gpuarray_array_concatenate(struct PyGpuArrayObject *__pyx_v_r, GpuArray const **__pyx_v_a, size_t __pyx_v_n, unsigned int __pyx_v_axis, int __pyx_v_restype) {
  int __pyx_v_err;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  __Pyx_RefNannySetupContext("array_concatenate", 0);

  /* "pygpu/gpuarray.pyx":425
 *                            unsigned int axis, int restype) except -1:
 *     cdef int err
 *     err = GpuArray_concatenate(&r.ga, a, n, axis, restype)             # <<<<<<<<<<<<<<
 *     if err != GA_NO_ERROR:
 *         raise get_exc(err), GpuArray_error(a[0], err)
 */
  __pyx_v_err = GpuArray_concatenate((&__pyx_v_r->ga), __pyx_v_a, __pyx_v_n, __pyx_v_axis, __pyx_v_restype);

  /* "pygpu/gpuarray.pyx":426
 *     cdef int err
 *     err = GpuArray_concatenate(&r.ga, a, n, axis, restype)
 *     if err != GA_NO_ERROR:             # <<<<<<<<<<<<<<
 *         raise get_exc(err), GpuArray_error(a[0], err)
 * 
 */
  __pyx_t_1 = ((__pyx_v_err != GA_NO_ERROR) != 0);
  if (__pyx_t_1) {

    /* "pygpu/gpuarray.pyx":427
 *     err = GpuArray_concatenate(&r.ga, a, n, axis, restype)
 *     if err != GA_NO_ERROR:
 *         raise get_exc(err), GpuArray_error(a[0], err)             # <<<<<<<<<<<<<<
 * 
 * cdef const char *kernel_error(GpuKernel k, int err) except NULL:
 */
    __pyx_t_2 = ((PyObject *)__pyx_f_5pygpu_8gpuarray_get_exc(__pyx_v_err)); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 427, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_3 = __Pyx_PyBytes_FromString(GpuArray_error((__pyx_v_a[0]), __pyx_v_err)); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 427, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_Raise(__pyx_t_2, __pyx_t_3, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __PYX_ERR(0, 427, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":426
 *     cdef int err
 *     err = GpuArray_concatenate(&r.ga, a, n, axis, restype)
 *     if err != GA_NO_ERROR:             # <<<<<<<<<<<<<<
 *         raise get_exc(err), GpuArray_error(a[0], err)
 * 
 */
  }

  /* "pygpu/gpuarray.pyx":422
 *         raise get_exc(err), GpuArray_error(&a.ga, err)
 * 
 * cdef int array_concatenate(GpuArray r, const _GpuArray **a, size_t n,             # <<<<<<<<<<<<<<
 *                            unsigned int axis, int restype) except -1:
 *     cdef int err
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("pygpu.gpuarray.array_concatenate", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":429
 *         raise get_exc(err), GpuArray_error(a[0], err)
 * 
 * cdef const char *kernel_error(GpuKernel k, int err) except NULL:             # <<<<<<<<<<<<<<
 *     return gpucontext_error(gpukernel_context(k.k.k), err)
 * 
 */

static char const *__pyx_f_5pygpu_8gpuarray_kernel_error(struct PyGpuKernelObject *__pyx_v_k, int __pyx_v_err) {
  char const *__pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("kernel_error", 0);

  /* "pygpu/gpuarray.pyx":430
 * 
 * cdef const char *kernel_error(GpuKernel k, int err) except NULL:
 *     return gpucontext_error(gpukernel_context(k.k.k), err)             # <<<<<<<<<<<<<<
 * 
 * cdef int kernel_init(GpuKernel k, gpucontext *ctx,
 */
  __pyx_r = gpucontext_error(gpukernel_context(__pyx_v_k->k.k), __pyx_v_err);
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":429
 *         raise get_exc(err), GpuArray_error(a[0], err)
 * 
 * cdef const char *kernel_error(GpuKernel k, int err) except NULL:             # <<<<<<<<<<<<<<
 *     return gpucontext_error(gpukernel_context(k.k.k), err)
 * 
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":432
 *     return gpucontext_error(gpukernel_context(k.k.k), err)
 * 
 * cdef int kernel_init(GpuKernel k, gpucontext *ctx,             # <<<<<<<<<<<<<<
 *                      unsigned int count, const char **strs, const size_t *len,
 *                      const char *name, unsigned int argcount, const int *types,
 */

static int __pyx_f_5pygpu_8gpuarray_kernel_init(struct PyGpuKernelObject *__pyx_v_k, gpucontext *__pyx_v_ctx, unsigned int __pyx_v_count, char const **__pyx_v_strs, size_t const *__pyx_v_len, char const *__pyx_v_name, unsigned int __pyx_v_argcount, int const *__pyx_v_types, int __pyx_v_flags) {
  int __pyx_v_err;
  char *__pyx_v_err_str;
  PyObject *__pyx_v_py_err_str = NULL;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  int __pyx_t_3;
  int __pyx_t_4;
  char const *__pyx_t_5;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  PyObject *__pyx_t_8 = NULL;
  PyObject *__pyx_t_9 = NULL;
  PyObject *__pyx_t_10 = NULL;
  PyObject *__pyx_t_11 = NULL;
  PyObject *__pyx_t_12 = NULL;
  __Pyx_RefNannySetupContext("kernel_init", 0);

  /* "pygpu/gpuarray.pyx":437
 *                      int flags) except -1:
 *     cdef int err
 *     cdef char *err_str = NULL             # <<<<<<<<<<<<<<
 *     err = GpuKernel_init(&k.k, ctx, count, strs, len, name, argcount,
 *                           types, flags, &err_str)
 */
  __pyx_v_err_str = NULL;

  /* "pygpu/gpuarray.pyx":438
 *     cdef int err
 *     cdef char *err_str = NULL
 *     err = GpuKernel_init(&k.k, ctx, count, strs, len, name, argcount,             # <<<<<<<<<<<<<<
 *                           types, flags, &err_str)
 *     if err != GA_NO_ERROR:
 */
  __pyx_v_err = GpuKernel_init((&__pyx_v_k->k), __pyx_v_ctx, __pyx_v_count, __pyx_v_strs, __pyx_v_len, __pyx_v_name, __pyx_v_argcount, __pyx_v_types, __pyx_v_flags, (&__pyx_v_err_str));

  /* "pygpu/gpuarray.pyx":440
 *     err = GpuKernel_init(&k.k, ctx, count, strs, len, name, argcount,
 *                           types, flags, &err_str)
 *     if err != GA_NO_ERROR:             # <<<<<<<<<<<<<<
 *         if err_str != NULL:
 *             try:
 */
  __pyx_t_1 = ((__pyx_v_err != GA_NO_ERROR) != 0);
  if (__pyx_t_1) {

    /* "pygpu/gpuarray.pyx":441
 *                           types, flags, &err_str)
 *     if err != GA_NO_ERROR:
 *         if err_str != NULL:             # <<<<<<<<<<<<<<
 *             try:
 *                 py_err_str = err_str.decode('UTF-8')
 */
    __pyx_t_1 = ((__pyx_v_err_str != NULL) != 0);
    if (__pyx_t_1) {

      /* "pygpu/gpuarray.pyx":442
 *     if err != GA_NO_ERROR:
 *         if err_str != NULL:
 *             try:             # <<<<<<<<<<<<<<
 *                 py_err_str = err_str.decode('UTF-8')
 *             finally:
 */
      /*try:*/ {

        /* "pygpu/gpuarray.pyx":443
 *         if err_str != NULL:
 *             try:
 *                 py_err_str = err_str.decode('UTF-8')             # <<<<<<<<<<<<<<
 *             finally:
 *                 free(err_str)
 */
        __pyx_t_2 = __Pyx_decode_c_string(__pyx_v_err_str, 0, strlen(__pyx_v_err_str), NULL, NULL, PyUnicode_DecodeUTF8); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 443, __pyx_L6_error)
        __Pyx_GOTREF(__pyx_t_2);
        __pyx_v_py_err_str = __pyx_t_2;
        __pyx_t_2 = 0;
      }

      /* "pygpu/gpuarray.pyx":445
 *                 py_err_str = err_str.decode('UTF-8')
 *             finally:
 *                 free(err_str)             # <<<<<<<<<<<<<<
 *             raise get_exc(err), py_err_str
 *         raise get_exc(err), gpucontext_error(ctx, err)
 */
      /*finally:*/ {
        /*normal exit:*/{
          free(__pyx_v_err_str);
          goto __pyx_L7;
        }
        __pyx_L6_error:;
        /*exception exit:*/{
          __Pyx_PyThreadState_declare
          __Pyx_PyThreadState_assign
          __pyx_t_6 = 0; __pyx_t_7 = 0; __pyx_t_8 = 0; __pyx_t_9 = 0; __pyx_t_10 = 0; __pyx_t_11 = 0;
          __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
          if (PY_MAJOR_VERSION >= 3) __Pyx_ExceptionSwap(&__pyx_t_9, &__pyx_t_10, &__pyx_t_11);
          if ((PY_MAJOR_VERSION < 3) || unlikely(__Pyx_GetException(&__pyx_t_6, &__pyx_t_7, &__pyx_t_8) < 0)) __Pyx_ErrFetch(&__pyx_t_6, &__pyx_t_7, &__pyx_t_8);
          __Pyx_XGOTREF(__pyx_t_6);
          __Pyx_XGOTREF(__pyx_t_7);
          __Pyx_XGOTREF(__pyx_t_8);
          __Pyx_XGOTREF(__pyx_t_9);
          __Pyx_XGOTREF(__pyx_t_10);
          __Pyx_XGOTREF(__pyx_t_11);
          __pyx_t_3 = __pyx_lineno; __pyx_t_4 = __pyx_clineno; __pyx_t_5 = __pyx_filename;
          {
            free(__pyx_v_err_str);
          }
          if (PY_MAJOR_VERSION >= 3) {
            __Pyx_XGIVEREF(__pyx_t_9);
            __Pyx_XGIVEREF(__pyx_t_10);
            __Pyx_XGIVEREF(__pyx_t_11);
            __Pyx_ExceptionReset(__pyx_t_9, __pyx_t_10, __pyx_t_11);
          }
          __Pyx_XGIVEREF(__pyx_t_6);
          __Pyx_XGIVEREF(__pyx_t_7);
          __Pyx_XGIVEREF(__pyx_t_8);
          __Pyx_ErrRestore(__pyx_t_6, __pyx_t_7, __pyx_t_8);
          __pyx_t_6 = 0; __pyx_t_7 = 0; __pyx_t_8 = 0; __pyx_t_9 = 0; __pyx_t_10 = 0; __pyx_t_11 = 0;
          __pyx_lineno = __pyx_t_3; __pyx_clineno = __pyx_t_4; __pyx_filename = __pyx_t_5;
          goto __pyx_L1_error;
        }
        __pyx_L7:;
      }

      /* "pygpu/gpuarray.pyx":446
 *             finally:
 *                 free(err_str)
 *             raise get_exc(err), py_err_str             # <<<<<<<<<<<<<<
 *         raise get_exc(err), gpucontext_error(ctx, err)
 * 
 */
      __pyx_t_2 = ((PyObject *)__pyx_f_5pygpu_8gpuarray_get_exc(__pyx_v_err)); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 446, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_Raise(__pyx_t_2, __pyx_v_py_err_str, 0, 0);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __PYX_ERR(0, 446, __pyx_L1_error)

      /* "pygpu/gpuarray.pyx":441
 *                           types, flags, &err_str)
 *     if err != GA_NO_ERROR:
 *         if err_str != NULL:             # <<<<<<<<<<<<<<
 *             try:
 *                 py_err_str = err_str.decode('UTF-8')
 */
    }

    /* "pygpu/gpuarray.pyx":447
 *                 free(err_str)
 *             raise get_exc(err), py_err_str
 *         raise get_exc(err), gpucontext_error(ctx, err)             # <<<<<<<<<<<<<<
 * 
 * cdef int kernel_clear(GpuKernel k) except -1:
 */
    __pyx_t_2 = ((PyObject *)__pyx_f_5pygpu_8gpuarray_get_exc(__pyx_v_err)); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 447, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_12 = __Pyx_PyBytes_FromString(gpucontext_error(__pyx_v_ctx, __pyx_v_err)); if (unlikely(!__pyx_t_12)) __PYX_ERR(0, 447, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_12);
    __Pyx_Raise(__pyx_t_2, __pyx_t_12, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_12); __pyx_t_12 = 0;
    __PYX_ERR(0, 447, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":440
 *     err = GpuKernel_init(&k.k, ctx, count, strs, len, name, argcount,
 *                           types, flags, &err_str)
 *     if err != GA_NO_ERROR:             # <<<<<<<<<<<<<<
 *         if err_str != NULL:
 *             try:
 */
  }

  /* "pygpu/gpuarray.pyx":432
 *     return gpucontext_error(gpukernel_context(k.k.k), err)
 * 
 * cdef int kernel_init(GpuKernel k, gpucontext *ctx,             # <<<<<<<<<<<<<<
 *                      unsigned int count, const char **strs, const size_t *len,
 *                      const char *name, unsigned int argcount, const int *types,
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_12);
  __Pyx_AddTraceback("pygpu.gpuarray.kernel_init", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_py_err_str);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":449
 *         raise get_exc(err), gpucontext_error(ctx, err)
 * 
 * cdef int kernel_clear(GpuKernel k) except -1:             # <<<<<<<<<<<<<<
 *     GpuKernel_clear(&k.k)
 * 
 */

static int __pyx_f_5pygpu_8gpuarray_kernel_clear(struct PyGpuKernelObject *__pyx_v_k) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("kernel_clear", 0);

  /* "pygpu/gpuarray.pyx":450
 * 
 * cdef int kernel_clear(GpuKernel k) except -1:
 *     GpuKernel_clear(&k.k)             # <<<<<<<<<<<<<<
 * 
 * cdef gpucontext *kernel_context(GpuKernel k) except NULL:
 */
  GpuKernel_clear((&__pyx_v_k->k));

  /* "pygpu/gpuarray.pyx":449
 *         raise get_exc(err), gpucontext_error(ctx, err)
 * 
 * cdef int kernel_clear(GpuKernel k) except -1:             # <<<<<<<<<<<<<<
 *     GpuKernel_clear(&k.k)
 * 
 */

  /* function exit code */
  __pyx_r = 0;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":452
 *     GpuKernel_clear(&k.k)
 * 
 * cdef gpucontext *kernel_context(GpuKernel k) except NULL:             # <<<<<<<<<<<<<<
 *     cdef gpucontext *res
 *     res = GpuKernel_context(&k.k)
 */

static gpucontext *__pyx_f_5pygpu_8gpuarray_kernel_context(struct PyGpuKernelObject *__pyx_v_k) {
  gpucontext *__pyx_v_res;
  gpucontext *__pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  __Pyx_RefNannySetupContext("kernel_context", 0);

  /* "pygpu/gpuarray.pyx":454
 * cdef gpucontext *kernel_context(GpuKernel k) except NULL:
 *     cdef gpucontext *res
 *     res = GpuKernel_context(&k.k)             # <<<<<<<<<<<<<<
 *     if res is NULL:
 *         raise GpuArrayException, "Invalid kernel or destroyed context"
 */
  __pyx_v_res = GpuKernel_context((&__pyx_v_k->k));

  /* "pygpu/gpuarray.pyx":455
 *     cdef gpucontext *res
 *     res = GpuKernel_context(&k.k)
 *     if res is NULL:             # <<<<<<<<<<<<<<
 *         raise GpuArrayException, "Invalid kernel or destroyed context"
 *     return res
 */
  __pyx_t_1 = ((__pyx_v_res == NULL) != 0);
  if (__pyx_t_1) {

    /* "pygpu/gpuarray.pyx":456
 *     res = GpuKernel_context(&k.k)
 *     if res is NULL:
 *         raise GpuArrayException, "Invalid kernel or destroyed context"             # <<<<<<<<<<<<<<
 *     return res
 * 
 */
    __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_GpuArrayException); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 456, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_Raise(__pyx_t_2, __pyx_kp_s_Invalid_kernel_or_destroyed_cont, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(0, 456, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":455
 *     cdef gpucontext *res
 *     res = GpuKernel_context(&k.k)
 *     if res is NULL:             # <<<<<<<<<<<<<<
 *         raise GpuArrayException, "Invalid kernel or destroyed context"
 *     return res
 */
  }

  /* "pygpu/gpuarray.pyx":457
 *     if res is NULL:
 *         raise GpuArrayException, "Invalid kernel or destroyed context"
 *     return res             # <<<<<<<<<<<<<<
 * 
 * cdef int kernel_sched(GpuKernel k, size_t n, size_t *gs, size_t *ls) except -1:
 */
  __pyx_r = __pyx_v_res;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":452
 *     GpuKernel_clear(&k.k)
 * 
 * cdef gpucontext *kernel_context(GpuKernel k) except NULL:             # <<<<<<<<<<<<<<
 *     cdef gpucontext *res
 *     res = GpuKernel_context(&k.k)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("pygpu.gpuarray.kernel_context", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":459
 *     return res
 * 
 * cdef int kernel_sched(GpuKernel k, size_t n, size_t *gs, size_t *ls) except -1:             # <<<<<<<<<<<<<<
 *     cdef int err
 *     err = GpuKernel_sched(&k.k, n, gs, ls)
 */

static int __pyx_f_5pygpu_8gpuarray_kernel_sched(struct PyGpuKernelObject *__pyx_v_k, size_t __pyx_v_n, size_t *__pyx_v_gs, size_t *__pyx_v_ls) {
  int __pyx_v_err;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  char const *__pyx_t_3;
  PyObject *__pyx_t_4 = NULL;
  __Pyx_RefNannySetupContext("kernel_sched", 0);

  /* "pygpu/gpuarray.pyx":461
 * cdef int kernel_sched(GpuKernel k, size_t n, size_t *gs, size_t *ls) except -1:
 *     cdef int err
 *     err = GpuKernel_sched(&k.k, n, gs, ls)             # <<<<<<<<<<<<<<
 *     if err != GA_NO_ERROR:
 *         raise get_exc(err), kernel_error(k, err)
 */
  __pyx_v_err = GpuKernel_sched((&__pyx_v_k->k), __pyx_v_n, __pyx_v_gs, __pyx_v_ls);

  /* "pygpu/gpuarray.pyx":462
 *     cdef int err
 *     err = GpuKernel_sched(&k.k, n, gs, ls)
 *     if err != GA_NO_ERROR:             # <<<<<<<<<<<<<<
 *         raise get_exc(err), kernel_error(k, err)
 * 
 */
  __pyx_t_1 = ((__pyx_v_err != GA_NO_ERROR) != 0);
  if (__pyx_t_1) {

    /* "pygpu/gpuarray.pyx":463
 *     err = GpuKernel_sched(&k.k, n, gs, ls)
 *     if err != GA_NO_ERROR:
 *         raise get_exc(err), kernel_error(k, err)             # <<<<<<<<<<<<<<
 * 
 * cdef int kernel_call(GpuKernel k, unsigned int n, const size_t *gs,
 */
    __pyx_t_2 = ((PyObject *)__pyx_f_5pygpu_8gpuarray_get_exc(__pyx_v_err)); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 463, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_3 = __pyx_f_5pygpu_8gpuarray_kernel_error(__pyx_v_k, __pyx_v_err); if (unlikely(__pyx_t_3 == ((char const *)NULL))) __PYX_ERR(0, 463, __pyx_L1_error)
    __pyx_t_4 = __Pyx_PyBytes_FromString(__pyx_t_3); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 463, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_Raise(__pyx_t_2, __pyx_t_4, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __PYX_ERR(0, 463, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":462
 *     cdef int err
 *     err = GpuKernel_sched(&k.k, n, gs, ls)
 *     if err != GA_NO_ERROR:             # <<<<<<<<<<<<<<
 *         raise get_exc(err), kernel_error(k, err)
 * 
 */
  }

  /* "pygpu/gpuarray.pyx":459
 *     return res
 * 
 * cdef int kernel_sched(GpuKernel k, size_t n, size_t *gs, size_t *ls) except -1:             # <<<<<<<<<<<<<<
 *     cdef int err
 *     err = GpuKernel_sched(&k.k, n, gs, ls)
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_AddTraceback("pygpu.gpuarray.kernel_sched", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":465
 *         raise get_exc(err), kernel_error(k, err)
 * 
 * cdef int kernel_call(GpuKernel k, unsigned int n, const size_t *gs,             # <<<<<<<<<<<<<<
 *                      const size_t *ls, size_t shared, void **args) except -1:
 *     cdef int err
 */

static int __pyx_f_5pygpu_8gpuarray_kernel_call(struct PyGpuKernelObject *__pyx_v_k, unsigned int __pyx_v_n, size_t const *__pyx_v_gs, size_t const *__pyx_v_ls, size_t __pyx_v_shared, void **__pyx_v_args) {
  int __pyx_v_err;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  char const *__pyx_t_3;
  PyObject *__pyx_t_4 = NULL;
  __Pyx_RefNannySetupContext("kernel_call", 0);

  /* "pygpu/gpuarray.pyx":468
 *                      const size_t *ls, size_t shared, void **args) except -1:
 *     cdef int err
 *     err = GpuKernel_call(&k.k, n, gs, ls, shared, args)             # <<<<<<<<<<<<<<
 *     if err != GA_NO_ERROR:
 *         raise get_exc(err), kernel_error(k, err)
 */
  __pyx_v_err = GpuKernel_call((&__pyx_v_k->k), __pyx_v_n, __pyx_v_gs, __pyx_v_ls, __pyx_v_shared, __pyx_v_args);

  /* "pygpu/gpuarray.pyx":469
 *     cdef int err
 *     err = GpuKernel_call(&k.k, n, gs, ls, shared, args)
 *     if err != GA_NO_ERROR:             # <<<<<<<<<<<<<<
 *         raise get_exc(err), kernel_error(k, err)
 * 
 */
  __pyx_t_1 = ((__pyx_v_err != GA_NO_ERROR) != 0);
  if (__pyx_t_1) {

    /* "pygpu/gpuarray.pyx":470
 *     err = GpuKernel_call(&k.k, n, gs, ls, shared, args)
 *     if err != GA_NO_ERROR:
 *         raise get_exc(err), kernel_error(k, err)             # <<<<<<<<<<<<<<
 * 
 * cdef int kernel_property(GpuKernel k, int prop_id, void *res) except -1:
 */
    __pyx_t_2 = ((PyObject *)__pyx_f_5pygpu_8gpuarray_get_exc(__pyx_v_err)); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 470, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_3 = __pyx_f_5pygpu_8gpuarray_kernel_error(__pyx_v_k, __pyx_v_err); if (unlikely(__pyx_t_3 == ((char const *)NULL))) __PYX_ERR(0, 470, __pyx_L1_error)
    __pyx_t_4 = __Pyx_PyBytes_FromString(__pyx_t_3); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 470, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_Raise(__pyx_t_2, __pyx_t_4, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __PYX_ERR(0, 470, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":469
 *     cdef int err
 *     err = GpuKernel_call(&k.k, n, gs, ls, shared, args)
 *     if err != GA_NO_ERROR:             # <<<<<<<<<<<<<<
 *         raise get_exc(err), kernel_error(k, err)
 * 
 */
  }

  /* "pygpu/gpuarray.pyx":465
 *         raise get_exc(err), kernel_error(k, err)
 * 
 * cdef int kernel_call(GpuKernel k, unsigned int n, const size_t *gs,             # <<<<<<<<<<<<<<
 *                      const size_t *ls, size_t shared, void **args) except -1:
 *     cdef int err
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_AddTraceback("pygpu.gpuarray.kernel_call", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":472
 *         raise get_exc(err), kernel_error(k, err)
 * 
 * cdef int kernel_property(GpuKernel k, int prop_id, void *res) except -1:             # <<<<<<<<<<<<<<
 *     cdef int err
 *     err = gpukernel_property(k.k.k, prop_id, res)
 */

static int __pyx_f_5pygpu_8gpuarray_kernel_property(struct PyGpuKernelObject *__pyx_v_k, int __pyx_v_prop_id, void *__pyx_v_res) {
  int __pyx_v_err;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  char const *__pyx_t_3;
  PyObject *__pyx_t_4 = NULL;
  __Pyx_RefNannySetupContext("kernel_property", 0);

  /* "pygpu/gpuarray.pyx":474
 * cdef int kernel_property(GpuKernel k, int prop_id, void *res) except -1:
 *     cdef int err
 *     err = gpukernel_property(k.k.k, prop_id, res)             # <<<<<<<<<<<<<<
 *     if err != GA_NO_ERROR:
 *         raise get_exc(err), kernel_error(k, err)
 */
  __pyx_v_err = gpukernel_property(__pyx_v_k->k.k, __pyx_v_prop_id, __pyx_v_res);

  /* "pygpu/gpuarray.pyx":475
 *     cdef int err
 *     err = gpukernel_property(k.k.k, prop_id, res)
 *     if err != GA_NO_ERROR:             # <<<<<<<<<<<<<<
 *         raise get_exc(err), kernel_error(k, err)
 * 
 */
  __pyx_t_1 = ((__pyx_v_err != GA_NO_ERROR) != 0);
  if (__pyx_t_1) {

    /* "pygpu/gpuarray.pyx":476
 *     err = gpukernel_property(k.k.k, prop_id, res)
 *     if err != GA_NO_ERROR:
 *         raise get_exc(err), kernel_error(k, err)             # <<<<<<<<<<<<<<
 * 
 * cdef GpuContext pygpu_default_context():
 */
    __pyx_t_2 = ((PyObject *)__pyx_f_5pygpu_8gpuarray_get_exc(__pyx_v_err)); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 476, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_3 = __pyx_f_5pygpu_8gpuarray_kernel_error(__pyx_v_k, __pyx_v_err); if (unlikely(__pyx_t_3 == ((char const *)NULL))) __PYX_ERR(0, 476, __pyx_L1_error)
    __pyx_t_4 = __Pyx_PyBytes_FromString(__pyx_t_3); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 476, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_Raise(__pyx_t_2, __pyx_t_4, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __PYX_ERR(0, 476, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":475
 *     cdef int err
 *     err = gpukernel_property(k.k.k, prop_id, res)
 *     if err != GA_NO_ERROR:             # <<<<<<<<<<<<<<
 *         raise get_exc(err), kernel_error(k, err)
 * 
 */
  }

  /* "pygpu/gpuarray.pyx":472
 *         raise get_exc(err), kernel_error(k, err)
 * 
 * cdef int kernel_property(GpuKernel k, int prop_id, void *res) except -1:             # <<<<<<<<<<<<<<
 *     cdef int err
 *     err = gpukernel_property(k.k.k, prop_id, res)
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_AddTraceback("pygpu.gpuarray.kernel_property", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":478
 *         raise get_exc(err), kernel_error(k, err)
 * 
 * cdef GpuContext pygpu_default_context():             # <<<<<<<<<<<<<<
 *     return default_context
 * 
 */

static struct PyGpuContextObject *__pyx_f_5pygpu_8gpuarray_pygpu_default_context(void) {
  struct PyGpuContextObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("pygpu_default_context", 0);

  /* "pygpu/gpuarray.pyx":479
 * 
 * cdef GpuContext pygpu_default_context():
 *     return default_context             # <<<<<<<<<<<<<<
 * 
 * cdef GpuContext default_context = None
 */
  __Pyx_XDECREF(((PyObject *)__pyx_r));
  __Pyx_INCREF(((PyObject *)__pyx_v_5pygpu_8gpuarray_default_context));
  __pyx_r = __pyx_v_5pygpu_8gpuarray_default_context;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":478
 *         raise get_exc(err), kernel_error(k, err)
 * 
 * cdef GpuContext pygpu_default_context():             # <<<<<<<<<<<<<<
 *     return default_context
 * 
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF((PyObject *)__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":483
 * cdef GpuContext default_context = None
 * 
 * cdef int ctx_property(GpuContext c, int prop_id, void *res) except -1:             # <<<<<<<<<<<<<<
 *     cdef int err
 *     err = gpucontext_property(c.ctx, prop_id, res)
 */

static int __pyx_f_5pygpu_8gpuarray_ctx_property(struct PyGpuContextObject *__pyx_v_c, int __pyx_v_prop_id, void *__pyx_v_res) {
  int __pyx_v_err;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  __Pyx_RefNannySetupContext("ctx_property", 0);

  /* "pygpu/gpuarray.pyx":485
 * cdef int ctx_property(GpuContext c, int prop_id, void *res) except -1:
 *     cdef int err
 *     err = gpucontext_property(c.ctx, prop_id, res)             # <<<<<<<<<<<<<<
 *     if err != GA_NO_ERROR:
 *         raise get_exc(err), gpucontext_error(c.ctx, err)
 */
  __pyx_v_err = gpucontext_property(__pyx_v_c->ctx, __pyx_v_prop_id, __pyx_v_res);

  /* "pygpu/gpuarray.pyx":486
 *     cdef int err
 *     err = gpucontext_property(c.ctx, prop_id, res)
 *     if err != GA_NO_ERROR:             # <<<<<<<<<<<<<<
 *         raise get_exc(err), gpucontext_error(c.ctx, err)
 * 
 */
  __pyx_t_1 = ((__pyx_v_err != GA_NO_ERROR) != 0);
  if (__pyx_t_1) {

    /* "pygpu/gpuarray.pyx":487
 *     err = gpucontext_property(c.ctx, prop_id, res)
 *     if err != GA_NO_ERROR:
 *         raise get_exc(err), gpucontext_error(c.ctx, err)             # <<<<<<<<<<<<<<
 * 
 * def set_default_context(GpuContext ctx):
 */
    __pyx_t_2 = ((PyObject *)__pyx_f_5pygpu_8gpuarray_get_exc(__pyx_v_err)); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 487, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_3 = __Pyx_PyBytes_FromString(gpucontext_error(__pyx_v_c->ctx, __pyx_v_err)); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 487, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_Raise(__pyx_t_2, __pyx_t_3, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __PYX_ERR(0, 487, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":486
 *     cdef int err
 *     err = gpucontext_property(c.ctx, prop_id, res)
 *     if err != GA_NO_ERROR:             # <<<<<<<<<<<<<<
 *         raise get_exc(err), gpucontext_error(c.ctx, err)
 * 
 */
  }

  /* "pygpu/gpuarray.pyx":483
 * cdef GpuContext default_context = None
 * 
 * cdef int ctx_property(GpuContext c, int prop_id, void *res) except -1:             # <<<<<<<<<<<<<<
 *     cdef int err
 *     err = gpucontext_property(c.ctx, prop_id, res)
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("pygpu.gpuarray.ctx_property", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":489
 *         raise get_exc(err), gpucontext_error(c.ctx, err)
 * 
 * def set_default_context(GpuContext ctx):             # <<<<<<<<<<<<<<
 *     """
 *     set_default_context(ctx)
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_15set_default_context(PyObject *__pyx_self, PyObject *__pyx_v_ctx); /*proto*/
static char __pyx_doc_5pygpu_8gpuarray_14set_default_context[] = "\n    set_default_context(ctx)\n\n    Set the default context for the module.\n\n    The provided context will be used as a default value for all the\n    other functions in this module which take a context as parameter.\n    Call with `None` to clear the default value.\n\n    If you don't call this function the context of all other functions\n    is a mandatory argument.\n\n    This can be helpful to reduce clutter when working with only one\n    context. It is strongly discouraged to use this function when\n    working with multiple contexts at once.\n\n    Parameters\n    ----------\n    ctx: GpuContext\n        default context\n\n    ";
static PyMethodDef __pyx_mdef_5pygpu_8gpuarray_15set_default_context = {"set_default_context", (PyCFunction)__pyx_pw_5pygpu_8gpuarray_15set_default_context, METH_O, __pyx_doc_5pygpu_8gpuarray_14set_default_context};
static PyObject *__pyx_pw_5pygpu_8gpuarray_15set_default_context(PyObject *__pyx_self, PyObject *__pyx_v_ctx) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("set_default_context (wrapper)", 0);
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_ctx), __pyx_ptype_5pygpu_8gpuarray_GpuContext, 1, "ctx", 0))) __PYX_ERR(0, 489, __pyx_L1_error)
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_14set_default_context(__pyx_self, ((struct PyGpuContextObject *)__pyx_v_ctx));

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_14set_default_context(CYTHON_UNUSED PyObject *__pyx_self, struct PyGpuContextObject *__pyx_v_ctx) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("set_default_context", 0);

  /* "pygpu/gpuarray.pyx":513
 *     """
 *     global default_context
 *     default_context = ctx             # <<<<<<<<<<<<<<
 * 
 * def get_default_context():
 */
  __Pyx_INCREF(((PyObject *)__pyx_v_ctx));
  __Pyx_XGOTREF(((PyObject *)__pyx_v_5pygpu_8gpuarray_default_context));
  __Pyx_DECREF_SET(__pyx_v_5pygpu_8gpuarray_default_context, __pyx_v_ctx);
  __Pyx_GIVEREF(((PyObject *)__pyx_v_ctx));

  /* "pygpu/gpuarray.pyx":489
 *         raise get_exc(err), gpucontext_error(c.ctx, err)
 * 
 * def set_default_context(GpuContext ctx):             # <<<<<<<<<<<<<<
 *     """
 *     set_default_context(ctx)
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":515
 *     default_context = ctx
 * 
 * def get_default_context():             # <<<<<<<<<<<<<<
 *     """
 *     get_default_context()
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_17get_default_context(PyObject *__pyx_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static char __pyx_doc_5pygpu_8gpuarray_16get_default_context[] = "\n    get_default_context()\n\n    Return the currently defined default context (or `None`).\n    ";
static PyMethodDef __pyx_mdef_5pygpu_8gpuarray_17get_default_context = {"get_default_context", (PyCFunction)__pyx_pw_5pygpu_8gpuarray_17get_default_context, METH_NOARGS, __pyx_doc_5pygpu_8gpuarray_16get_default_context};
static PyObject *__pyx_pw_5pygpu_8gpuarray_17get_default_context(PyObject *__pyx_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("get_default_context (wrapper)", 0);
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_16get_default_context(__pyx_self);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_16get_default_context(CYTHON_UNUSED PyObject *__pyx_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("get_default_context", 0);

  /* "pygpu/gpuarray.pyx":521
 *     Return the currently defined default context (or `None`).
 *     """
 *     return default_context             # <<<<<<<<<<<<<<
 * 
 * cdef GpuContext ensure_context(GpuContext c):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_5pygpu_8gpuarray_default_context));
  __pyx_r = ((PyObject *)__pyx_v_5pygpu_8gpuarray_default_context);
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":515
 *     default_context = ctx
 * 
 * def get_default_context():             # <<<<<<<<<<<<<<
 *     """
 *     get_default_context()
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":523
 *     return default_context
 * 
 * cdef GpuContext ensure_context(GpuContext c):             # <<<<<<<<<<<<<<
 *     global default_context
 *     if c is None:
 */

static struct PyGpuContextObject *__pyx_f_5pygpu_8gpuarray_ensure_context(struct PyGpuContextObject *__pyx_v_c) {
  struct PyGpuContextObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_t_2;
  __Pyx_RefNannySetupContext("ensure_context", 0);

  /* "pygpu/gpuarray.pyx":525
 * cdef GpuContext ensure_context(GpuContext c):
 *     global default_context
 *     if c is None:             # <<<<<<<<<<<<<<
 *         if default_context is None:
 *             raise TypeError, "No context specified."
 */
  __pyx_t_1 = (((PyObject *)__pyx_v_c) == Py_None);
  __pyx_t_2 = (__pyx_t_1 != 0);
  if (__pyx_t_2) {

    /* "pygpu/gpuarray.pyx":526
 *     global default_context
 *     if c is None:
 *         if default_context is None:             # <<<<<<<<<<<<<<
 *             raise TypeError, "No context specified."
 *         return default_context
 */
    __pyx_t_2 = (((PyObject *)__pyx_v_5pygpu_8gpuarray_default_context) == Py_None);
    __pyx_t_1 = (__pyx_t_2 != 0);
    if (__pyx_t_1) {

      /* "pygpu/gpuarray.pyx":527
 *     if c is None:
 *         if default_context is None:
 *             raise TypeError, "No context specified."             # <<<<<<<<<<<<<<
 *         return default_context
 *     return c
 */
      __Pyx_Raise(__pyx_builtin_TypeError, __pyx_kp_s_No_context_specified, 0, 0);
      __PYX_ERR(0, 527, __pyx_L1_error)

      /* "pygpu/gpuarray.pyx":526
 *     global default_context
 *     if c is None:
 *         if default_context is None:             # <<<<<<<<<<<<<<
 *             raise TypeError, "No context specified."
 *         return default_context
 */
    }

    /* "pygpu/gpuarray.pyx":528
 *         if default_context is None:
 *             raise TypeError, "No context specified."
 *         return default_context             # <<<<<<<<<<<<<<
 *     return c
 * 
 */
    __Pyx_XDECREF(((PyObject *)__pyx_r));
    __Pyx_INCREF(((PyObject *)__pyx_v_5pygpu_8gpuarray_default_context));
    __pyx_r = __pyx_v_5pygpu_8gpuarray_default_context;
    goto __pyx_L0;

    /* "pygpu/gpuarray.pyx":525
 * cdef GpuContext ensure_context(GpuContext c):
 *     global default_context
 *     if c is None:             # <<<<<<<<<<<<<<
 *         if default_context is None:
 *             raise TypeError, "No context specified."
 */
  }

  /* "pygpu/gpuarray.pyx":529
 *             raise TypeError, "No context specified."
 *         return default_context
 *     return c             # <<<<<<<<<<<<<<
 * 
 * cdef bint pygpu_GpuArray_Check(object o):
 */
  __Pyx_XDECREF(((PyObject *)__pyx_r));
  __Pyx_INCREF(((PyObject *)__pyx_v_c));
  __pyx_r = __pyx_v_c;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":523
 *     return default_context
 * 
 * cdef GpuContext ensure_context(GpuContext c):             # <<<<<<<<<<<<<<
 *     global default_context
 *     if c is None:
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_AddTraceback("pygpu.gpuarray.ensure_context", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XGIVEREF((PyObject *)__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":531
 *     return c
 * 
 * cdef bint pygpu_GpuArray_Check(object o):             # <<<<<<<<<<<<<<
 *     return isinstance(o, GpuArray)
 * 
 */

static int __pyx_f_5pygpu_8gpuarray_pygpu_GpuArray_Check(PyObject *__pyx_v_o) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  __Pyx_RefNannySetupContext("pygpu_GpuArray_Check", 0);

  /* "pygpu/gpuarray.pyx":532
 * 
 * cdef bint pygpu_GpuArray_Check(object o):
 *     return isinstance(o, GpuArray)             # <<<<<<<<<<<<<<
 * 
 * def count_platforms(kind):
 */
  __pyx_t_1 = __Pyx_TypeCheck(__pyx_v_o, __pyx_ptype_5pygpu_8gpuarray_GpuArray); 
  __pyx_r = __pyx_t_1;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":531
 *     return c
 * 
 * cdef bint pygpu_GpuArray_Check(object o):             # <<<<<<<<<<<<<<
 *     return isinstance(o, GpuArray)
 * 
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":534
 *     return isinstance(o, GpuArray)
 * 
 * def count_platforms(kind):             # <<<<<<<<<<<<<<
 *     """
 *     count_platforms(kind)
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_19count_platforms(PyObject *__pyx_self, PyObject *__pyx_v_kind); /*proto*/
static char __pyx_doc_5pygpu_8gpuarray_18count_platforms[] = "\n    count_platforms(kind)\n\n    Return number of host's platforms compatible with `kind`.\n    ";
static PyMethodDef __pyx_mdef_5pygpu_8gpuarray_19count_platforms = {"count_platforms", (PyCFunction)__pyx_pw_5pygpu_8gpuarray_19count_platforms, METH_O, __pyx_doc_5pygpu_8gpuarray_18count_platforms};
static PyObject *__pyx_pw_5pygpu_8gpuarray_19count_platforms(PyObject *__pyx_self, PyObject *__pyx_v_kind) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("count_platforms (wrapper)", 0);
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_18count_platforms(__pyx_self, ((PyObject *)__pyx_v_kind));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_18count_platforms(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_kind) {
  unsigned int __pyx_v_platcount;
  int __pyx_v_err;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  char const *__pyx_t_2;
  int __pyx_t_3;
  PyObject *__pyx_t_4 = NULL;
  __Pyx_RefNannySetupContext("count_platforms", 0);

  /* "pygpu/gpuarray.pyx":542
 *     cdef unsigned int platcount
 *     cdef int err
 *     err = gpu_get_platform_count(_s(kind), &platcount)             # <<<<<<<<<<<<<<
 *     if err != GA_NO_ERROR:
 *         raise get_exc(err), gpucontext_error(NULL, err)
 */
  __pyx_t_1 = __pyx_f_5pygpu_8gpuarray__s(__pyx_v_kind); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 542, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (unlikely(__pyx_t_1 == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "expected bytes, NoneType found");
    __PYX_ERR(0, 542, __pyx_L1_error)
  }
  __pyx_t_2 = __Pyx_PyBytes_AsString(__pyx_t_1); if (unlikely((!__pyx_t_2) && PyErr_Occurred())) __PYX_ERR(0, 542, __pyx_L1_error)
  __pyx_v_err = gpu_get_platform_count(__pyx_t_2, (&__pyx_v_platcount));
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "pygpu/gpuarray.pyx":543
 *     cdef int err
 *     err = gpu_get_platform_count(_s(kind), &platcount)
 *     if err != GA_NO_ERROR:             # <<<<<<<<<<<<<<
 *         raise get_exc(err), gpucontext_error(NULL, err)
 *     return platcount
 */
  __pyx_t_3 = ((__pyx_v_err != GA_NO_ERROR) != 0);
  if (__pyx_t_3) {

    /* "pygpu/gpuarray.pyx":544
 *     err = gpu_get_platform_count(_s(kind), &platcount)
 *     if err != GA_NO_ERROR:
 *         raise get_exc(err), gpucontext_error(NULL, err)             # <<<<<<<<<<<<<<
 *     return platcount
 * 
 */
    __pyx_t_1 = ((PyObject *)__pyx_f_5pygpu_8gpuarray_get_exc(__pyx_v_err)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 544, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_4 = __Pyx_PyBytes_FromString(gpucontext_error(NULL, __pyx_v_err)); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 544, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_Raise(__pyx_t_1, __pyx_t_4, 0, 0);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __PYX_ERR(0, 544, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":543
 *     cdef int err
 *     err = gpu_get_platform_count(_s(kind), &platcount)
 *     if err != GA_NO_ERROR:             # <<<<<<<<<<<<<<
 *         raise get_exc(err), gpucontext_error(NULL, err)
 *     return platcount
 */
  }

  /* "pygpu/gpuarray.pyx":545
 *     if err != GA_NO_ERROR:
 *         raise get_exc(err), gpucontext_error(NULL, err)
 *     return platcount             # <<<<<<<<<<<<<<
 * 
 * def count_devices(kind, unsigned int platform):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_4 = __Pyx_PyInt_From_unsigned_int(__pyx_v_platcount); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 545, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_r = __pyx_t_4;
  __pyx_t_4 = 0;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":534
 *     return isinstance(o, GpuArray)
 * 
 * def count_platforms(kind):             # <<<<<<<<<<<<<<
 *     """
 *     count_platforms(kind)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_AddTraceback("pygpu.gpuarray.count_platforms", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":547
 *     return platcount
 * 
 * def count_devices(kind, unsigned int platform):             # <<<<<<<<<<<<<<
 *     """
 *     count_devices(kind, platform)
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_21count_devices(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static char __pyx_doc_5pygpu_8gpuarray_20count_devices[] = "\n    count_devices(kind, platform)\n\n    Returns number of devices in host's `platform` compatible with `kind`.\n    ";
static PyMethodDef __pyx_mdef_5pygpu_8gpuarray_21count_devices = {"count_devices", (PyCFunction)__pyx_pw_5pygpu_8gpuarray_21count_devices, METH_VARARGS|METH_KEYWORDS, __pyx_doc_5pygpu_8gpuarray_20count_devices};
static PyObject *__pyx_pw_5pygpu_8gpuarray_21count_devices(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_kind = 0;
  unsigned int __pyx_v_platform;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("count_devices (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_kind,&__pyx_n_s_platform,0};
    PyObject* values[2] = {0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_kind)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_platform)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("count_devices", 1, 2, 2, 1); __PYX_ERR(0, 547, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "count_devices") < 0)) __PYX_ERR(0, 547, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 2) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
    }
    __pyx_v_kind = values[0];
    __pyx_v_platform = __Pyx_PyInt_As_unsigned_int(values[1]); if (unlikely((__pyx_v_platform == (unsigned int)-1) && PyErr_Occurred())) __PYX_ERR(0, 547, __pyx_L3_error)
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("count_devices", 1, 2, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 547, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("pygpu.gpuarray.count_devices", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_20count_devices(__pyx_self, __pyx_v_kind, __pyx_v_platform);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_20count_devices(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_kind, unsigned int __pyx_v_platform) {
  unsigned int __pyx_v_devcount;
  int __pyx_v_err;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  char const *__pyx_t_2;
  int __pyx_t_3;
  PyObject *__pyx_t_4 = NULL;
  __Pyx_RefNannySetupContext("count_devices", 0);

  /* "pygpu/gpuarray.pyx":555
 *     cdef unsigned int devcount
 *     cdef int err
 *     err = gpu_get_device_count(_s(kind), platform, &devcount)             # <<<<<<<<<<<<<<
 *     if err != GA_NO_ERROR:
 *         raise get_exc(err), gpucontext_error(NULL, err)
 */
  __pyx_t_1 = __pyx_f_5pygpu_8gpuarray__s(__pyx_v_kind); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 555, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (unlikely(__pyx_t_1 == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "expected bytes, NoneType found");
    __PYX_ERR(0, 555, __pyx_L1_error)
  }
  __pyx_t_2 = __Pyx_PyBytes_AsString(__pyx_t_1); if (unlikely((!__pyx_t_2) && PyErr_Occurred())) __PYX_ERR(0, 555, __pyx_L1_error)
  __pyx_v_err = gpu_get_device_count(__pyx_t_2, __pyx_v_platform, (&__pyx_v_devcount));
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "pygpu/gpuarray.pyx":556
 *     cdef int err
 *     err = gpu_get_device_count(_s(kind), platform, &devcount)
 *     if err != GA_NO_ERROR:             # <<<<<<<<<<<<<<
 *         raise get_exc(err), gpucontext_error(NULL, err)
 *     return devcount
 */
  __pyx_t_3 = ((__pyx_v_err != GA_NO_ERROR) != 0);
  if (__pyx_t_3) {

    /* "pygpu/gpuarray.pyx":557
 *     err = gpu_get_device_count(_s(kind), platform, &devcount)
 *     if err != GA_NO_ERROR:
 *         raise get_exc(err), gpucontext_error(NULL, err)             # <<<<<<<<<<<<<<
 *     return devcount
 * 
 */
    __pyx_t_1 = ((PyObject *)__pyx_f_5pygpu_8gpuarray_get_exc(__pyx_v_err)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 557, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_4 = __Pyx_PyBytes_FromString(gpucontext_error(NULL, __pyx_v_err)); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 557, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_Raise(__pyx_t_1, __pyx_t_4, 0, 0);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __PYX_ERR(0, 557, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":556
 *     cdef int err
 *     err = gpu_get_device_count(_s(kind), platform, &devcount)
 *     if err != GA_NO_ERROR:             # <<<<<<<<<<<<<<
 *         raise get_exc(err), gpucontext_error(NULL, err)
 *     return devcount
 */
  }

  /* "pygpu/gpuarray.pyx":558
 *     if err != GA_NO_ERROR:
 *         raise get_exc(err), gpucontext_error(NULL, err)
 *     return devcount             # <<<<<<<<<<<<<<
 * 
 * cdef GpuContext pygpu_init(dev, gpucontext_props *p):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_4 = __Pyx_PyInt_From_unsigned_int(__pyx_v_devcount); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 558, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_r = __pyx_t_4;
  __pyx_t_4 = 0;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":547
 *     return platcount
 * 
 * def count_devices(kind, unsigned int platform):             # <<<<<<<<<<<<<<
 *     """
 *     count_devices(kind, platform)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_AddTraceback("pygpu.gpuarray.count_devices", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":560
 *     return devcount
 * 
 * cdef GpuContext pygpu_init(dev, gpucontext_props *p):             # <<<<<<<<<<<<<<
 *     cdef int err
 *     cdef GpuContext res
 */

static struct PyGpuContextObject *__pyx_f_5pygpu_8gpuarray_pygpu_init(PyObject *__pyx_v_dev, gpucontext_props *__pyx_v_p) {
  int __pyx_v_err;
  struct PyGpuContextObject *__pyx_v_res = 0;
  PyObject *__pyx_v_kind = NULL;
  PyObject *__pyx_v_devnum = NULL;
  PyObject *__pyx_v_devspec = NULL;
  struct PyGpuContextObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  int __pyx_t_3;
  int __pyx_t_4;
  Py_ssize_t __pyx_t_5;
  PyObject *__pyx_t_6 = NULL;
  int __pyx_t_7;
  int __pyx_t_8;
  int __pyx_t_9;
  char *__pyx_t_10;
  __Pyx_RefNannySetupContext("pygpu_init", 0);

  /* "pygpu/gpuarray.pyx":564
 *     cdef GpuContext res
 * 
 *     if dev.startswith('cuda'):             # <<<<<<<<<<<<<<
 *         kind = b"cuda"
 *         if dev[4:] == '':
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_dev, __pyx_n_s_startswith); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 564, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_1, __pyx_tuple__2, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 564, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_3 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely(__pyx_t_3 < 0)) __PYX_ERR(0, 564, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (__pyx_t_3) {

    /* "pygpu/gpuarray.pyx":565
 * 
 *     if dev.startswith('cuda'):
 *         kind = b"cuda"             # <<<<<<<<<<<<<<
 *         if dev[4:] == '':
 *             devnum = -1
 */
    __Pyx_INCREF(__pyx_n_b_cuda);
    __pyx_v_kind = __pyx_n_b_cuda;

    /* "pygpu/gpuarray.pyx":566
 *     if dev.startswith('cuda'):
 *         kind = b"cuda"
 *         if dev[4:] == '':             # <<<<<<<<<<<<<<
 *             devnum = -1
 *         else:
 */
    __pyx_t_2 = __Pyx_PyObject_GetSlice(__pyx_v_dev, 4, 0, NULL, NULL, &__pyx_slice__3, 1, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 566, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_3 = (__Pyx_PyString_Equals(__pyx_t_2, __pyx_kp_s__4, Py_EQ)); if (unlikely(__pyx_t_3 < 0)) __PYX_ERR(0, 566, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    if (__pyx_t_3) {

      /* "pygpu/gpuarray.pyx":567
 *         kind = b"cuda"
 *         if dev[4:] == '':
 *             devnum = -1             # <<<<<<<<<<<<<<
 *         else:
 *             devnum = int(dev[4:])
 */
      __Pyx_INCREF(__pyx_int_neg_1);
      __pyx_v_devnum = __pyx_int_neg_1;

      /* "pygpu/gpuarray.pyx":566
 *     if dev.startswith('cuda'):
 *         kind = b"cuda"
 *         if dev[4:] == '':             # <<<<<<<<<<<<<<
 *             devnum = -1
 *         else:
 */
      goto __pyx_L4;
    }

    /* "pygpu/gpuarray.pyx":569
 *             devnum = -1
 *         else:
 *             devnum = int(dev[4:])             # <<<<<<<<<<<<<<
 *         gpucontext_props_cuda_dev(p, devnum)
 *     elif dev.startswith('opencl'):
 */
    /*else*/ {
      __pyx_t_2 = __Pyx_PyObject_GetSlice(__pyx_v_dev, 4, 0, NULL, NULL, &__pyx_slice__5, 1, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 569, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_1 = __Pyx_PyNumber_Int(__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 569, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_v_devnum = __pyx_t_1;
      __pyx_t_1 = 0;
    }
    __pyx_L4:;

    /* "pygpu/gpuarray.pyx":570
 *         else:
 *             devnum = int(dev[4:])
 *         gpucontext_props_cuda_dev(p, devnum)             # <<<<<<<<<<<<<<
 *     elif dev.startswith('opencl'):
 *         kind = b"opencl"
 */
    __pyx_t_4 = __Pyx_PyInt_As_int(__pyx_v_devnum); if (unlikely((__pyx_t_4 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 570, __pyx_L1_error)
    gpucontext_props_cuda_dev(__pyx_v_p, __pyx_t_4);

    /* "pygpu/gpuarray.pyx":564
 *     cdef GpuContext res
 * 
 *     if dev.startswith('cuda'):             # <<<<<<<<<<<<<<
 *         kind = b"cuda"
 *         if dev[4:] == '':
 */
    goto __pyx_L3;
  }

  /* "pygpu/gpuarray.pyx":571
 *             devnum = int(dev[4:])
 *         gpucontext_props_cuda_dev(p, devnum)
 *     elif dev.startswith('opencl'):             # <<<<<<<<<<<<<<
 *         kind = b"opencl"
 *         devspec = dev[6:].split(':')
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_dev, __pyx_n_s_startswith); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 571, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_1, __pyx_tuple__6, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 571, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_3 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely(__pyx_t_3 < 0)) __PYX_ERR(0, 571, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (__pyx_t_3) {

    /* "pygpu/gpuarray.pyx":572
 *         gpucontext_props_cuda_dev(p, devnum)
 *     elif dev.startswith('opencl'):
 *         kind = b"opencl"             # <<<<<<<<<<<<<<
 *         devspec = dev[6:].split(':')
 *         if len(devspec) < 2:
 */
    __Pyx_INCREF(__pyx_n_b_opencl);
    __pyx_v_kind = __pyx_n_b_opencl;

    /* "pygpu/gpuarray.pyx":573
 *     elif dev.startswith('opencl'):
 *         kind = b"opencl"
 *         devspec = dev[6:].split(':')             # <<<<<<<<<<<<<<
 *         if len(devspec) < 2:
 *             raise ValueError, "OpenCL name incorrect. Should be opencl<int>:<int> instead got: " + dev
 */
    __pyx_t_2 = __Pyx_PyObject_GetSlice(__pyx_v_dev, 6, 0, NULL, NULL, &__pyx_slice__7, 1, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 573, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_split); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 573, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_1, __pyx_tuple__9, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 573, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_v_devspec = __pyx_t_2;
    __pyx_t_2 = 0;

    /* "pygpu/gpuarray.pyx":574
 *         kind = b"opencl"
 *         devspec = dev[6:].split(':')
 *         if len(devspec) < 2:             # <<<<<<<<<<<<<<
 *             raise ValueError, "OpenCL name incorrect. Should be opencl<int>:<int> instead got: " + dev
 *         if not devspec[0].isdigit() or not devspec[1].isdigit():
 */
    __pyx_t_5 = PyObject_Length(__pyx_v_devspec); if (unlikely(__pyx_t_5 == ((Py_ssize_t)-1))) __PYX_ERR(0, 574, __pyx_L1_error)
    __pyx_t_3 = ((__pyx_t_5 < 2) != 0);
    if (__pyx_t_3) {

      /* "pygpu/gpuarray.pyx":575
 *         devspec = dev[6:].split(':')
 *         if len(devspec) < 2:
 *             raise ValueError, "OpenCL name incorrect. Should be opencl<int>:<int> instead got: " + dev             # <<<<<<<<<<<<<<
 *         if not devspec[0].isdigit() or not devspec[1].isdigit():
 *             raise ValueError, "OpenCL name incorrect. Should be opencl<int>:<int> instead got: " + dev
 */
      __pyx_t_2 = PyNumber_Add(__pyx_kp_s_OpenCL_name_incorrect_Should_be, __pyx_v_dev); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 575, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_Raise(__pyx_builtin_ValueError, __pyx_t_2, 0, 0);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __PYX_ERR(0, 575, __pyx_L1_error)

      /* "pygpu/gpuarray.pyx":574
 *         kind = b"opencl"
 *         devspec = dev[6:].split(':')
 *         if len(devspec) < 2:             # <<<<<<<<<<<<<<
 *             raise ValueError, "OpenCL name incorrect. Should be opencl<int>:<int> instead got: " + dev
 *         if not devspec[0].isdigit() or not devspec[1].isdigit():
 */
    }

    /* "pygpu/gpuarray.pyx":576
 *         if len(devspec) < 2:
 *             raise ValueError, "OpenCL name incorrect. Should be opencl<int>:<int> instead got: " + dev
 *         if not devspec[0].isdigit() or not devspec[1].isdigit():             # <<<<<<<<<<<<<<
 *             raise ValueError, "OpenCL name incorrect. Should be opencl<int>:<int> instead got: " + dev
 *         else:
 */
    __pyx_t_1 = __Pyx_GetItemInt(__pyx_v_devspec, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 576, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_isdigit); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 576, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_1 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_6))) {
      __pyx_t_1 = PyMethod_GET_SELF(__pyx_t_6);
      if (likely(__pyx_t_1)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_6);
        __Pyx_INCREF(__pyx_t_1);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_6, function);
      }
    }
    if (__pyx_t_1) {
      __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_t_6, __pyx_t_1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 576, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    } else {
      __pyx_t_2 = __Pyx_PyObject_CallNoArg(__pyx_t_6); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 576, __pyx_L1_error)
    }
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __pyx_t_7 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely(__pyx_t_7 < 0)) __PYX_ERR(0, 576, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_8 = ((!__pyx_t_7) != 0);
    if (!__pyx_t_8) {
    } else {
      __pyx_t_3 = __pyx_t_8;
      goto __pyx_L7_bool_binop_done;
    }
    __pyx_t_6 = __Pyx_GetItemInt(__pyx_v_devspec, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 576, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_6, __pyx_n_s_isdigit); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 576, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __pyx_t_6 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_1))) {
      __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_1);
      if (likely(__pyx_t_6)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_1);
        __Pyx_INCREF(__pyx_t_6);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_1, function);
      }
    }
    if (__pyx_t_6) {
      __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_t_1, __pyx_t_6); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 576, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    } else {
      __pyx_t_2 = __Pyx_PyObject_CallNoArg(__pyx_t_1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 576, __pyx_L1_error)
    }
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_8 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely(__pyx_t_8 < 0)) __PYX_ERR(0, 576, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_7 = ((!__pyx_t_8) != 0);
    __pyx_t_3 = __pyx_t_7;
    __pyx_L7_bool_binop_done:;
    if (__pyx_t_3) {

      /* "pygpu/gpuarray.pyx":577
 *             raise ValueError, "OpenCL name incorrect. Should be opencl<int>:<int> instead got: " + dev
 *         if not devspec[0].isdigit() or not devspec[1].isdigit():
 *             raise ValueError, "OpenCL name incorrect. Should be opencl<int>:<int> instead got: " + dev             # <<<<<<<<<<<<<<
 *         else:
 *             gpucontext_props_opencl_dev(p, int(devspec[0]), int(devspec[1]))
 */
      __pyx_t_2 = PyNumber_Add(__pyx_kp_s_OpenCL_name_incorrect_Should_be, __pyx_v_dev); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 577, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_Raise(__pyx_builtin_ValueError, __pyx_t_2, 0, 0);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __PYX_ERR(0, 577, __pyx_L1_error)

      /* "pygpu/gpuarray.pyx":576
 *         if len(devspec) < 2:
 *             raise ValueError, "OpenCL name incorrect. Should be opencl<int>:<int> instead got: " + dev
 *         if not devspec[0].isdigit() or not devspec[1].isdigit():             # <<<<<<<<<<<<<<
 *             raise ValueError, "OpenCL name incorrect. Should be opencl<int>:<int> instead got: " + dev
 *         else:
 */
    }

    /* "pygpu/gpuarray.pyx":579
 *             raise ValueError, "OpenCL name incorrect. Should be opencl<int>:<int> instead got: " + dev
 *         else:
 *             gpucontext_props_opencl_dev(p, int(devspec[0]), int(devspec[1]))             # <<<<<<<<<<<<<<
 *     else:
 *         raise ValueError, "Unknown device format:" + dev
 */
    /*else*/ {
      __pyx_t_2 = __Pyx_GetItemInt(__pyx_v_devspec, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 579, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_1 = __Pyx_PyNumber_Int(__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 579, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_4 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_4 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 579, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __pyx_t_1 = __Pyx_GetItemInt(__pyx_v_devspec, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 579, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __pyx_t_2 = __Pyx_PyNumber_Int(__pyx_t_1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 579, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __pyx_t_9 = __Pyx_PyInt_As_int(__pyx_t_2); if (unlikely((__pyx_t_9 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 579, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      gpucontext_props_opencl_dev(__pyx_v_p, __pyx_t_4, __pyx_t_9);
    }

    /* "pygpu/gpuarray.pyx":571
 *             devnum = int(dev[4:])
 *         gpucontext_props_cuda_dev(p, devnum)
 *     elif dev.startswith('opencl'):             # <<<<<<<<<<<<<<
 *         kind = b"opencl"
 *         devspec = dev[6:].split(':')
 */
    goto __pyx_L3;
  }

  /* "pygpu/gpuarray.pyx":581
 *             gpucontext_props_opencl_dev(p, int(devspec[0]), int(devspec[1]))
 *     else:
 *         raise ValueError, "Unknown device format:" + dev             # <<<<<<<<<<<<<<
 * 
 *     res = GpuContext.__new__(GpuContext)
 */
  /*else*/ {
    __pyx_t_2 = PyNumber_Add(__pyx_kp_s_Unknown_device_format, __pyx_v_dev); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 581, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_Raise(__pyx_builtin_ValueError, __pyx_t_2, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(0, 581, __pyx_L1_error)
  }
  __pyx_L3:;

  /* "pygpu/gpuarray.pyx":583
 *         raise ValueError, "Unknown device format:" + dev
 * 
 *     res = GpuContext.__new__(GpuContext)             # <<<<<<<<<<<<<<
 *     res.kind = kind
 *     err = gpucontext_init(&res.ctx, <char *>res.kind, p)
 */
  __pyx_t_2 = __pyx_tp_new_5pygpu_8gpuarray_GpuContext(((PyTypeObject *)__pyx_ptype_5pygpu_8gpuarray_GpuContext), __pyx_empty_tuple, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 583, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (!(likely(__Pyx_TypeTest(__pyx_t_2, __pyx_ptype_5pygpu_8gpuarray_GpuContext)))) __PYX_ERR(0, 583, __pyx_L1_error)
  __pyx_v_res = ((struct PyGpuContextObject *)__pyx_t_2);
  __pyx_t_2 = 0;

  /* "pygpu/gpuarray.pyx":584
 * 
 *     res = GpuContext.__new__(GpuContext)
 *     res.kind = kind             # <<<<<<<<<<<<<<
 *     err = gpucontext_init(&res.ctx, <char *>res.kind, p)
 *     if err != GA_NO_ERROR:
 */
  __Pyx_INCREF(__pyx_v_kind);
  __Pyx_GIVEREF(__pyx_v_kind);
  __Pyx_GOTREF(__pyx_v_res->kind);
  __Pyx_DECREF(__pyx_v_res->kind);
  __pyx_v_res->kind = __pyx_v_kind;

  /* "pygpu/gpuarray.pyx":585
 *     res = GpuContext.__new__(GpuContext)
 *     res.kind = kind
 *     err = gpucontext_init(&res.ctx, <char *>res.kind, p)             # <<<<<<<<<<<<<<
 *     if err != GA_NO_ERROR:
 *         raise get_exc(err), gpucontext_error(NULL, err)
 */
  if (unlikely(__pyx_v_res->kind == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "expected bytes, NoneType found");
    __PYX_ERR(0, 585, __pyx_L1_error)
  }
  __pyx_t_10 = __Pyx_PyBytes_AsWritableString(__pyx_v_res->kind); if (unlikely((!__pyx_t_10) && PyErr_Occurred())) __PYX_ERR(0, 585, __pyx_L1_error)
  __pyx_v_err = gpucontext_init((&__pyx_v_res->ctx), ((char *)__pyx_t_10), __pyx_v_p);

  /* "pygpu/gpuarray.pyx":586
 *     res.kind = kind
 *     err = gpucontext_init(&res.ctx, <char *>res.kind, p)
 *     if err != GA_NO_ERROR:             # <<<<<<<<<<<<<<
 *         raise get_exc(err), gpucontext_error(NULL, err)
 *     return res
 */
  __pyx_t_3 = ((__pyx_v_err != GA_NO_ERROR) != 0);
  if (__pyx_t_3) {

    /* "pygpu/gpuarray.pyx":587
 *     err = gpucontext_init(&res.ctx, <char *>res.kind, p)
 *     if err != GA_NO_ERROR:
 *         raise get_exc(err), gpucontext_error(NULL, err)             # <<<<<<<<<<<<<<
 *     return res
 * 
 */
    __pyx_t_2 = ((PyObject *)__pyx_f_5pygpu_8gpuarray_get_exc(__pyx_v_err)); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 587, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_1 = __Pyx_PyBytes_FromString(gpucontext_error(NULL, __pyx_v_err)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 587, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_Raise(__pyx_t_2, __pyx_t_1, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __PYX_ERR(0, 587, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":586
 *     res.kind = kind
 *     err = gpucontext_init(&res.ctx, <char *>res.kind, p)
 *     if err != GA_NO_ERROR:             # <<<<<<<<<<<<<<
 *         raise get_exc(err), gpucontext_error(NULL, err)
 *     return res
 */
  }

  /* "pygpu/gpuarray.pyx":588
 *     if err != GA_NO_ERROR:
 *         raise get_exc(err), gpucontext_error(NULL, err)
 *     return res             # <<<<<<<<<<<<<<
 * 
 * def init(dev, sched='default', single_stream=False, kernel_cache_path=None,
 */
  __Pyx_XDECREF(((PyObject *)__pyx_r));
  __Pyx_INCREF(((PyObject *)__pyx_v_res));
  __pyx_r = __pyx_v_res;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":560
 *     return devcount
 * 
 * cdef GpuContext pygpu_init(dev, gpucontext_props *p):             # <<<<<<<<<<<<<<
 *     cdef int err
 *     cdef GpuContext res
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_AddTraceback("pygpu.gpuarray.pygpu_init", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_res);
  __Pyx_XDECREF(__pyx_v_kind);
  __Pyx_XDECREF(__pyx_v_devnum);
  __Pyx_XDECREF(__pyx_v_devspec);
  __Pyx_XGIVEREF((PyObject *)__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":590
 *     return res
 * 
 * def init(dev, sched='default', single_stream=False, kernel_cache_path=None,             # <<<<<<<<<<<<<<
 *          max_cache_size=sys.maxsize, initial_cache_size=0):
 *     """
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_23init(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static char __pyx_doc_5pygpu_8gpuarray_22init[] = "\n    init(dev, sched='default', single_stream=False, kernel_cache_path=None,\n         max_cache_size=sys.maxsize, initial_cache_size=0)\n\n    Creates a context from a device specifier.\n\n    Device specifiers are composed of the type string and the device\n    id like so::\n\n        \"cuda0\"\n        \"opencl0:1\"\n\n    For cuda the device id is the numeric identifier.  You can see\n    what devices are available by running nvidia-smi on the machine.\n    Be aware that the ordering in nvidia-smi might not correspond to\n    the ordering in this library.  This is due to how cuda enumerates\n    devices.  If you don't specify a number (e.g. 'cuda') the first\n    available device will be selected according to the backend order.\n\n    For opencl the device id is the platform number, a colon (:) and\n    the device number.  There are no widespread and/or easy way to\n    list available platforms and devices.  You can experiement with\n    the values, unavaiable ones will just raise an error, and there\n    are no gaps in the valid numbers.\n\n    Parameters\n    ----------\n    dev: str\n        device specifier\n    sched: {'default', 'single', 'multi'}\n        optimize scheduling for which type of operation\n    disable_alloc_cache: bool\n        disable allocation cache (if any)\n    single_stream: bool\n        enable single stream mode\n\n    ";
static PyMethodDef __pyx_mdef_5pygpu_8gpuarray_23init = {"init", (PyCFunction)__pyx_pw_5pygpu_8gpuarray_23init, METH_VARARGS|METH_KEYWORDS, __pyx_doc_5pygpu_8gpuarray_22init};
static PyObject *__pyx_pw_5pygpu_8gpuarray_23init(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_dev = 0;
  PyObject *__pyx_v_sched = 0;
  PyObject *__pyx_v_single_stream = 0;
  PyObject *__pyx_v_kernel_cache_path = 0;
  PyObject *__pyx_v_max_cache_size = 0;
  PyObject *__pyx_v_initial_cache_size = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("init (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_dev,&__pyx_n_s_sched,&__pyx_n_s_single_stream,&__pyx_n_s_kernel_cache_path,&__pyx_n_s_max_cache_size,&__pyx_n_s_initial_cache_size,0};
    PyObject* values[6] = {0,0,0,0,0,0};
    values[1] = ((PyObject *)__pyx_n_s_default);
    values[2] = ((PyObject *)Py_False);
    values[3] = ((PyObject *)Py_None);
    values[4] = __pyx_k__10;
    values[5] = ((PyObject *)__pyx_int_0);
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  6: values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
        CYTHON_FALLTHROUGH;
        case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
        CYTHON_FALLTHROUGH;
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_dev)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_sched);
          if (value) { values[1] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_single_stream);
          if (value) { values[2] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  3:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_kernel_cache_path);
          if (value) { values[3] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  4:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_max_cache_size);
          if (value) { values[4] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  5:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_initial_cache_size);
          if (value) { values[5] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "init") < 0)) __PYX_ERR(0, 590, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  6: values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
        CYTHON_FALLTHROUGH;
        case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
        CYTHON_FALLTHROUGH;
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    __pyx_v_dev = values[0];
    __pyx_v_sched = values[1];
    __pyx_v_single_stream = values[2];
    __pyx_v_kernel_cache_path = values[3];
    __pyx_v_max_cache_size = values[4];
    __pyx_v_initial_cache_size = values[5];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("init", 0, 1, 6, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 590, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("pygpu.gpuarray.init", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_22init(__pyx_self, __pyx_v_dev, __pyx_v_sched, __pyx_v_single_stream, __pyx_v_kernel_cache_path, __pyx_v_max_cache_size, __pyx_v_initial_cache_size);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_22init(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_dev, PyObject *__pyx_v_sched, PyObject *__pyx_v_single_stream, PyObject *__pyx_v_kernel_cache_path, PyObject *__pyx_v_max_cache_size, PyObject *__pyx_v_initial_cache_size) {
  gpucontext_props *__pyx_v_p;
  int __pyx_v_err;
  PyObject *__pyx_v_kernel_cache_path_b = 0;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  char const *__pyx_t_7;
  size_t __pyx_t_8;
  size_t __pyx_t_9;
  PyObject *__pyx_t_10 = NULL;
  __Pyx_RefNannySetupContext("init", 0);

  /* "pygpu/gpuarray.pyx":629
 * 
 *     """
 *     cdef gpucontext_props *p = NULL             # <<<<<<<<<<<<<<
 *     cdef int err
 *     cdef bytes kernel_cache_path_b
 */
  __pyx_v_p = NULL;

  /* "pygpu/gpuarray.pyx":632
 *     cdef int err
 *     cdef bytes kernel_cache_path_b
 *     err = gpucontext_props_new(&p)             # <<<<<<<<<<<<<<
 *     if err != GA_NO_ERROR:
 *         raise MemoryError
 */
  __pyx_v_err = gpucontext_props_new((&__pyx_v_p));

  /* "pygpu/gpuarray.pyx":633
 *     cdef bytes kernel_cache_path_b
 *     err = gpucontext_props_new(&p)
 *     if err != GA_NO_ERROR:             # <<<<<<<<<<<<<<
 *         raise MemoryError
 *     try:
 */
  __pyx_t_1 = ((__pyx_v_err != GA_NO_ERROR) != 0);
  if (__pyx_t_1) {

    /* "pygpu/gpuarray.pyx":634
 *     err = gpucontext_props_new(&p)
 *     if err != GA_NO_ERROR:
 *         raise MemoryError             # <<<<<<<<<<<<<<
 *     try:
 *         if sched == 'single':
 */
    PyErr_NoMemory(); __PYX_ERR(0, 634, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":633
 *     cdef bytes kernel_cache_path_b
 *     err = gpucontext_props_new(&p)
 *     if err != GA_NO_ERROR:             # <<<<<<<<<<<<<<
 *         raise MemoryError
 *     try:
 */
  }

  /* "pygpu/gpuarray.pyx":635
 *     if err != GA_NO_ERROR:
 *         raise MemoryError
 *     try:             # <<<<<<<<<<<<<<
 *         if sched == 'single':
 *             err = gpucontext_props_sched(p, GA_CTX_SCHED_SINGLE)
 */
  {
    __Pyx_PyThreadState_declare
    __Pyx_PyThreadState_assign
    __Pyx_ExceptionSave(&__pyx_t_2, &__pyx_t_3, &__pyx_t_4);
    __Pyx_XGOTREF(__pyx_t_2);
    __Pyx_XGOTREF(__pyx_t_3);
    __Pyx_XGOTREF(__pyx_t_4);
    /*try:*/ {

      /* "pygpu/gpuarray.pyx":636
 *         raise MemoryError
 *     try:
 *         if sched == 'single':             # <<<<<<<<<<<<<<
 *             err = gpucontext_props_sched(p, GA_CTX_SCHED_SINGLE)
 *         elif sched == 'multi':
 */
      __pyx_t_1 = (__Pyx_PyString_Equals(__pyx_v_sched, __pyx_n_s_single, Py_EQ)); if (unlikely(__pyx_t_1 < 0)) __PYX_ERR(0, 636, __pyx_L4_error)
      if (__pyx_t_1) {

        /* "pygpu/gpuarray.pyx":637
 *     try:
 *         if sched == 'single':
 *             err = gpucontext_props_sched(p, GA_CTX_SCHED_SINGLE)             # <<<<<<<<<<<<<<
 *         elif sched == 'multi':
 *             err = gpucontext_props_sched(p, GA_CTX_SCHED_MULTI)
 */
        __pyx_v_err = gpucontext_props_sched(__pyx_v_p, GA_CTX_SCHED_SINGLE);

        /* "pygpu/gpuarray.pyx":636
 *         raise MemoryError
 *     try:
 *         if sched == 'single':             # <<<<<<<<<<<<<<
 *             err = gpucontext_props_sched(p, GA_CTX_SCHED_SINGLE)
 *         elif sched == 'multi':
 */
        goto __pyx_L10;
      }

      /* "pygpu/gpuarray.pyx":638
 *         if sched == 'single':
 *             err = gpucontext_props_sched(p, GA_CTX_SCHED_SINGLE)
 *         elif sched == 'multi':             # <<<<<<<<<<<<<<
 *             err = gpucontext_props_sched(p, GA_CTX_SCHED_MULTI)
 *         elif sched != 'default':
 */
      __pyx_t_1 = (__Pyx_PyString_Equals(__pyx_v_sched, __pyx_n_s_multi, Py_EQ)); if (unlikely(__pyx_t_1 < 0)) __PYX_ERR(0, 638, __pyx_L4_error)
      if (__pyx_t_1) {

        /* "pygpu/gpuarray.pyx":639
 *             err = gpucontext_props_sched(p, GA_CTX_SCHED_SINGLE)
 *         elif sched == 'multi':
 *             err = gpucontext_props_sched(p, GA_CTX_SCHED_MULTI)             # <<<<<<<<<<<<<<
 *         elif sched != 'default':
 *             raise TypeError('unexpected value for parameter sched: %s' % (sched,))
 */
        __pyx_v_err = gpucontext_props_sched(__pyx_v_p, GA_CTX_SCHED_MULTI);

        /* "pygpu/gpuarray.pyx":638
 *         if sched == 'single':
 *             err = gpucontext_props_sched(p, GA_CTX_SCHED_SINGLE)
 *         elif sched == 'multi':             # <<<<<<<<<<<<<<
 *             err = gpucontext_props_sched(p, GA_CTX_SCHED_MULTI)
 *         elif sched != 'default':
 */
        goto __pyx_L10;
      }

      /* "pygpu/gpuarray.pyx":640
 *         elif sched == 'multi':
 *             err = gpucontext_props_sched(p, GA_CTX_SCHED_MULTI)
 *         elif sched != 'default':             # <<<<<<<<<<<<<<
 *             raise TypeError('unexpected value for parameter sched: %s' % (sched,))
 *         if err != GA_NO_ERROR:
 */
      __pyx_t_1 = (__Pyx_PyString_Equals(__pyx_v_sched, __pyx_n_s_default, Py_NE)); if (unlikely(__pyx_t_1 < 0)) __PYX_ERR(0, 640, __pyx_L4_error)
      if (__pyx_t_1) {

        /* "pygpu/gpuarray.pyx":641
 *             err = gpucontext_props_sched(p, GA_CTX_SCHED_MULTI)
 *         elif sched != 'default':
 *             raise TypeError('unexpected value for parameter sched: %s' % (sched,))             # <<<<<<<<<<<<<<
 *         if err != GA_NO_ERROR:
 *             raise get_exc(err), gpucontext_error(NULL, err)
 */
        __pyx_t_5 = PyTuple_New(1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 641, __pyx_L4_error)
        __Pyx_GOTREF(__pyx_t_5);
        __Pyx_INCREF(__pyx_v_sched);
        __Pyx_GIVEREF(__pyx_v_sched);
        PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_v_sched);
        __pyx_t_6 = __Pyx_PyString_Format(__pyx_kp_s_unexpected_value_for_parameter_s, __pyx_t_5); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 641, __pyx_L4_error)
        __Pyx_GOTREF(__pyx_t_6);
        __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
        __pyx_t_5 = PyTuple_New(1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 641, __pyx_L4_error)
        __Pyx_GOTREF(__pyx_t_5);
        __Pyx_GIVEREF(__pyx_t_6);
        PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_6);
        __pyx_t_6 = 0;
        __pyx_t_6 = __Pyx_PyObject_Call(__pyx_builtin_TypeError, __pyx_t_5, NULL); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 641, __pyx_L4_error)
        __Pyx_GOTREF(__pyx_t_6);
        __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
        __Pyx_Raise(__pyx_t_6, 0, 0, 0);
        __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
        __PYX_ERR(0, 641, __pyx_L4_error)

        /* "pygpu/gpuarray.pyx":640
 *         elif sched == 'multi':
 *             err = gpucontext_props_sched(p, GA_CTX_SCHED_MULTI)
 *         elif sched != 'default':             # <<<<<<<<<<<<<<
 *             raise TypeError('unexpected value for parameter sched: %s' % (sched,))
 *         if err != GA_NO_ERROR:
 */
      }
      __pyx_L10:;

      /* "pygpu/gpuarray.pyx":642
 *         elif sched != 'default':
 *             raise TypeError('unexpected value for parameter sched: %s' % (sched,))
 *         if err != GA_NO_ERROR:             # <<<<<<<<<<<<<<
 *             raise get_exc(err), gpucontext_error(NULL, err)
 * 
 */
      __pyx_t_1 = ((__pyx_v_err != GA_NO_ERROR) != 0);
      if (__pyx_t_1) {

        /* "pygpu/gpuarray.pyx":643
 *             raise TypeError('unexpected value for parameter sched: %s' % (sched,))
 *         if err != GA_NO_ERROR:
 *             raise get_exc(err), gpucontext_error(NULL, err)             # <<<<<<<<<<<<<<
 * 
 *         if kernel_cache_path:
 */
        __pyx_t_6 = ((PyObject *)__pyx_f_5pygpu_8gpuarray_get_exc(__pyx_v_err)); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 643, __pyx_L4_error)
        __Pyx_GOTREF(__pyx_t_6);
        __pyx_t_5 = __Pyx_PyBytes_FromString(gpucontext_error(NULL, __pyx_v_err)); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 643, __pyx_L4_error)
        __Pyx_GOTREF(__pyx_t_5);
        __Pyx_Raise(__pyx_t_6, __pyx_t_5, 0, 0);
        __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
        __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
        __PYX_ERR(0, 643, __pyx_L4_error)

        /* "pygpu/gpuarray.pyx":642
 *         elif sched != 'default':
 *             raise TypeError('unexpected value for parameter sched: %s' % (sched,))
 *         if err != GA_NO_ERROR:             # <<<<<<<<<<<<<<
 *             raise get_exc(err), gpucontext_error(NULL, err)
 * 
 */
      }

      /* "pygpu/gpuarray.pyx":645
 *             raise get_exc(err), gpucontext_error(NULL, err)
 * 
 *         if kernel_cache_path:             # <<<<<<<<<<<<<<
 *             kernel_cache_path_b = _s(kernel_cache_path)
 *             gpucontext_props_kernel_cache(p, <const char *>kernel_cache_path_b)
 */
      __pyx_t_1 = __Pyx_PyObject_IsTrue(__pyx_v_kernel_cache_path); if (unlikely(__pyx_t_1 < 0)) __PYX_ERR(0, 645, __pyx_L4_error)
      if (__pyx_t_1) {

        /* "pygpu/gpuarray.pyx":646
 * 
 *         if kernel_cache_path:
 *             kernel_cache_path_b = _s(kernel_cache_path)             # <<<<<<<<<<<<<<
 *             gpucontext_props_kernel_cache(p, <const char *>kernel_cache_path_b)
 * 
 */
        __pyx_t_5 = __pyx_f_5pygpu_8gpuarray__s(__pyx_v_kernel_cache_path); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 646, __pyx_L4_error)
        __Pyx_GOTREF(__pyx_t_5);
        __pyx_v_kernel_cache_path_b = ((PyObject*)__pyx_t_5);
        __pyx_t_5 = 0;

        /* "pygpu/gpuarray.pyx":647
 *         if kernel_cache_path:
 *             kernel_cache_path_b = _s(kernel_cache_path)
 *             gpucontext_props_kernel_cache(p, <const char *>kernel_cache_path_b)             # <<<<<<<<<<<<<<
 * 
 *         err = gpucontext_props_alloc_cache(p, initial_cache_size,
 */
        if (unlikely(__pyx_v_kernel_cache_path_b == Py_None)) {
          PyErr_SetString(PyExc_TypeError, "expected bytes, NoneType found");
          __PYX_ERR(0, 647, __pyx_L4_error)
        }
        __pyx_t_7 = __Pyx_PyBytes_AsString(__pyx_v_kernel_cache_path_b); if (unlikely((!__pyx_t_7) && PyErr_Occurred())) __PYX_ERR(0, 647, __pyx_L4_error)
        gpucontext_props_kernel_cache(__pyx_v_p, ((char const *)__pyx_t_7));

        /* "pygpu/gpuarray.pyx":645
 *             raise get_exc(err), gpucontext_error(NULL, err)
 * 
 *         if kernel_cache_path:             # <<<<<<<<<<<<<<
 *             kernel_cache_path_b = _s(kernel_cache_path)
 *             gpucontext_props_kernel_cache(p, <const char *>kernel_cache_path_b)
 */
      }

      /* "pygpu/gpuarray.pyx":649
 *             gpucontext_props_kernel_cache(p, <const char *>kernel_cache_path_b)
 * 
 *         err = gpucontext_props_alloc_cache(p, initial_cache_size,             # <<<<<<<<<<<<<<
 *                                            max_cache_size)
 *         if err != GA_NO_ERROR:
 */
      __pyx_t_8 = __Pyx_PyInt_As_size_t(__pyx_v_initial_cache_size); if (unlikely((__pyx_t_8 == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 649, __pyx_L4_error)

      /* "pygpu/gpuarray.pyx":650
 * 
 *         err = gpucontext_props_alloc_cache(p, initial_cache_size,
 *                                            max_cache_size)             # <<<<<<<<<<<<<<
 *         if err != GA_NO_ERROR:
 *             raise get_exc(err), gpucontext_error(NULL, err)
 */
      __pyx_t_9 = __Pyx_PyInt_As_size_t(__pyx_v_max_cache_size); if (unlikely((__pyx_t_9 == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 650, __pyx_L4_error)

      /* "pygpu/gpuarray.pyx":649
 *             gpucontext_props_kernel_cache(p, <const char *>kernel_cache_path_b)
 * 
 *         err = gpucontext_props_alloc_cache(p, initial_cache_size,             # <<<<<<<<<<<<<<
 *                                            max_cache_size)
 *         if err != GA_NO_ERROR:
 */
      __pyx_v_err = gpucontext_props_alloc_cache(__pyx_v_p, __pyx_t_8, __pyx_t_9);

      /* "pygpu/gpuarray.pyx":651
 *         err = gpucontext_props_alloc_cache(p, initial_cache_size,
 *                                            max_cache_size)
 *         if err != GA_NO_ERROR:             # <<<<<<<<<<<<<<
 *             raise get_exc(err), gpucontext_error(NULL, err)
 *         if single_stream:
 */
      __pyx_t_1 = ((__pyx_v_err != GA_NO_ERROR) != 0);
      if (__pyx_t_1) {

        /* "pygpu/gpuarray.pyx":652
 *                                            max_cache_size)
 *         if err != GA_NO_ERROR:
 *             raise get_exc(err), gpucontext_error(NULL, err)             # <<<<<<<<<<<<<<
 *         if single_stream:
 *             gpucontext_props_set_single_stream(p);
 */
        __pyx_t_5 = ((PyObject *)__pyx_f_5pygpu_8gpuarray_get_exc(__pyx_v_err)); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 652, __pyx_L4_error)
        __Pyx_GOTREF(__pyx_t_5);
        __pyx_t_6 = __Pyx_PyBytes_FromString(gpucontext_error(NULL, __pyx_v_err)); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 652, __pyx_L4_error)
        __Pyx_GOTREF(__pyx_t_6);
        __Pyx_Raise(__pyx_t_5, __pyx_t_6, 0, 0);
        __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
        __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
        __PYX_ERR(0, 652, __pyx_L4_error)

        /* "pygpu/gpuarray.pyx":651
 *         err = gpucontext_props_alloc_cache(p, initial_cache_size,
 *                                            max_cache_size)
 *         if err != GA_NO_ERROR:             # <<<<<<<<<<<<<<
 *             raise get_exc(err), gpucontext_error(NULL, err)
 *         if single_stream:
 */
      }

      /* "pygpu/gpuarray.pyx":653
 *         if err != GA_NO_ERROR:
 *             raise get_exc(err), gpucontext_error(NULL, err)
 *         if single_stream:             # <<<<<<<<<<<<<<
 *             gpucontext_props_set_single_stream(p);
 *     except:
 */
      __pyx_t_1 = __Pyx_PyObject_IsTrue(__pyx_v_single_stream); if (unlikely(__pyx_t_1 < 0)) __PYX_ERR(0, 653, __pyx_L4_error)
      if (__pyx_t_1) {

        /* "pygpu/gpuarray.pyx":654
 *             raise get_exc(err), gpucontext_error(NULL, err)
 *         if single_stream:
 *             gpucontext_props_set_single_stream(p);             # <<<<<<<<<<<<<<
 *     except:
 *         gpucontext_props_del(p)
 */
        gpucontext_props_set_single_stream(__pyx_v_p);

        /* "pygpu/gpuarray.pyx":653
 *         if err != GA_NO_ERROR:
 *             raise get_exc(err), gpucontext_error(NULL, err)
 *         if single_stream:             # <<<<<<<<<<<<<<
 *             gpucontext_props_set_single_stream(p);
 *     except:
 */
      }

      /* "pygpu/gpuarray.pyx":635
 *     if err != GA_NO_ERROR:
 *         raise MemoryError
 *     try:             # <<<<<<<<<<<<<<
 *         if sched == 'single':
 *             err = gpucontext_props_sched(p, GA_CTX_SCHED_SINGLE)
 */
    }
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
    goto __pyx_L9_try_end;
    __pyx_L4_error:;
    __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;

    /* "pygpu/gpuarray.pyx":655
 *         if single_stream:
 *             gpucontext_props_set_single_stream(p);
 *     except:             # <<<<<<<<<<<<<<
 *         gpucontext_props_del(p)
 *         raise
 */
    /*except:*/ {
      __Pyx_AddTraceback("pygpu.gpuarray.init", __pyx_clineno, __pyx_lineno, __pyx_filename);
      if (__Pyx_GetException(&__pyx_t_6, &__pyx_t_5, &__pyx_t_10) < 0) __PYX_ERR(0, 655, __pyx_L6_except_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_GOTREF(__pyx_t_5);
      __Pyx_GOTREF(__pyx_t_10);

      /* "pygpu/gpuarray.pyx":656
 *             gpucontext_props_set_single_stream(p);
 *     except:
 *         gpucontext_props_del(p)             # <<<<<<<<<<<<<<
 *         raise
 *     return pygpu_init(dev, p)
 */
      gpucontext_props_del(__pyx_v_p);

      /* "pygpu/gpuarray.pyx":657
 *     except:
 *         gpucontext_props_del(p)
 *         raise             # <<<<<<<<<<<<<<
 *     return pygpu_init(dev, p)
 * 
 */
      __Pyx_GIVEREF(__pyx_t_6);
      __Pyx_GIVEREF(__pyx_t_5);
      __Pyx_XGIVEREF(__pyx_t_10);
      __Pyx_ErrRestoreWithState(__pyx_t_6, __pyx_t_5, __pyx_t_10);
      __pyx_t_6 = 0; __pyx_t_5 = 0; __pyx_t_10 = 0; 
      __PYX_ERR(0, 657, __pyx_L6_except_error)
    }
    __pyx_L6_except_error:;

    /* "pygpu/gpuarray.pyx":635
 *     if err != GA_NO_ERROR:
 *         raise MemoryError
 *     try:             # <<<<<<<<<<<<<<
 *         if sched == 'single':
 *             err = gpucontext_props_sched(p, GA_CTX_SCHED_SINGLE)
 */
    __Pyx_XGIVEREF(__pyx_t_2);
    __Pyx_XGIVEREF(__pyx_t_3);
    __Pyx_XGIVEREF(__pyx_t_4);
    __Pyx_ExceptionReset(__pyx_t_2, __pyx_t_3, __pyx_t_4);
    goto __pyx_L1_error;
    __pyx_L9_try_end:;
  }

  /* "pygpu/gpuarray.pyx":658
 *         gpucontext_props_del(p)
 *         raise
 *     return pygpu_init(dev, p)             # <<<<<<<<<<<<<<
 * 
 * def zeros(shape, dtype=GA_DOUBLE, order='C', GpuContext context=None,
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_10 = ((PyObject *)__pyx_f_5pygpu_8gpuarray_pygpu_init(__pyx_v_dev, __pyx_v_p)); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 658, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_10);
  __pyx_r = __pyx_t_10;
  __pyx_t_10 = 0;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":590
 *     return res
 * 
 * def init(dev, sched='default', single_stream=False, kernel_cache_path=None,             # <<<<<<<<<<<<<<
 *          max_cache_size=sys.maxsize, initial_cache_size=0):
 *     """
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_10);
  __Pyx_AddTraceback("pygpu.gpuarray.init", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_kernel_cache_path_b);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":660
 *     return pygpu_init(dev, p)
 * 
 * def zeros(shape, dtype=GA_DOUBLE, order='C', GpuContext context=None,             # <<<<<<<<<<<<<<
 *           cls=None):
 *     """
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_25zeros(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static char __pyx_doc_5pygpu_8gpuarray_24zeros[] = "\n    zeros(shape, dtype='float64', order='C', context=None, cls=None)\n\n    Returns an array of zero-initialized values of the requested\n    shape, type and order.\n\n    Parameters\n    ----------\n    shape: iterable of ints\n        number of elements in each dimension\n    dtype: str, numpy.dtype or int\n        type of the elements\n    order: {'A', 'C', 'F'}\n        layout of the data in memory, one of 'A'ny, 'C' or 'F'ortran\n    context: GpuContext\n        context in which to do the allocation\n    cls: type\n        class of the returned array (must inherit from GpuArray)\n\n    ";
static PyMethodDef __pyx_mdef_5pygpu_8gpuarray_25zeros = {"zeros", (PyCFunction)__pyx_pw_5pygpu_8gpuarray_25zeros, METH_VARARGS|METH_KEYWORDS, __pyx_doc_5pygpu_8gpuarray_24zeros};
static PyObject *__pyx_pw_5pygpu_8gpuarray_25zeros(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_shape = 0;
  PyObject *__pyx_v_dtype = 0;
  PyObject *__pyx_v_order = 0;
  struct PyGpuContextObject *__pyx_v_context = 0;
  PyObject *__pyx_v_cls = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("zeros (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_shape,&__pyx_n_s_dtype,&__pyx_n_s_order,&__pyx_n_s_context,&__pyx_n_s_cls,0};
    PyObject* values[5] = {0,0,0,0,0};
    values[1] = __pyx_k__11;
    values[2] = ((PyObject *)__pyx_n_s_C);
    values[3] = (PyObject *)((struct PyGpuContextObject *)Py_None);

    /* "pygpu/gpuarray.pyx":661
 * 
 * def zeros(shape, dtype=GA_DOUBLE, order='C', GpuContext context=None,
 *           cls=None):             # <<<<<<<<<<<<<<
 *     """
 *     zeros(shape, dtype='float64', order='C', context=None, cls=None)
 */
    values[4] = ((PyObject *)Py_None);
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
        CYTHON_FALLTHROUGH;
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_shape)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_dtype);
          if (value) { values[1] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_order);
          if (value) { values[2] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  3:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_context);
          if (value) { values[3] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  4:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_cls);
          if (value) { values[4] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "zeros") < 0)) __PYX_ERR(0, 660, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
        CYTHON_FALLTHROUGH;
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    __pyx_v_shape = values[0];
    __pyx_v_dtype = values[1];
    __pyx_v_order = values[2];
    __pyx_v_context = ((struct PyGpuContextObject *)values[3]);
    __pyx_v_cls = values[4];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("zeros", 0, 1, 5, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 660, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("pygpu.gpuarray.zeros", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_context), __pyx_ptype_5pygpu_8gpuarray_GpuContext, 1, "context", 0))) __PYX_ERR(0, 660, __pyx_L1_error)
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_24zeros(__pyx_self, __pyx_v_shape, __pyx_v_dtype, __pyx_v_order, __pyx_v_context, __pyx_v_cls);

  /* "pygpu/gpuarray.pyx":660
 *     return pygpu_init(dev, p)
 * 
 * def zeros(shape, dtype=GA_DOUBLE, order='C', GpuContext context=None,             # <<<<<<<<<<<<<<
 *           cls=None):
 *     """
 */

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_24zeros(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_shape, PyObject *__pyx_v_dtype, PyObject *__pyx_v_order, struct PyGpuContextObject *__pyx_v_context, PyObject *__pyx_v_cls) {
  PyObject *__pyx_v_res = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  int __pyx_t_5;
  __Pyx_RefNannySetupContext("zeros", 0);

  /* "pygpu/gpuarray.pyx":682
 * 
 *     """
 *     res = empty(shape, dtype=dtype, order=order, context=context, cls=cls)             # <<<<<<<<<<<<<<
 *     array_memset(res, 0)
 *     return res
 */
  __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_empty); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 682, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = PyTuple_New(1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 682, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_INCREF(__pyx_v_shape);
  __Pyx_GIVEREF(__pyx_v_shape);
  PyTuple_SET_ITEM(__pyx_t_2, 0, __pyx_v_shape);
  __pyx_t_3 = __Pyx_PyDict_NewPresized(4); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 682, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  if (PyDict_SetItem(__pyx_t_3, __pyx_n_s_dtype, __pyx_v_dtype) < 0) __PYX_ERR(0, 682, __pyx_L1_error)
  if (PyDict_SetItem(__pyx_t_3, __pyx_n_s_order, __pyx_v_order) < 0) __PYX_ERR(0, 682, __pyx_L1_error)
  if (PyDict_SetItem(__pyx_t_3, __pyx_n_s_context, ((PyObject *)__pyx_v_context)) < 0) __PYX_ERR(0, 682, __pyx_L1_error)
  if (PyDict_SetItem(__pyx_t_3, __pyx_n_s_cls, __pyx_v_cls) < 0) __PYX_ERR(0, 682, __pyx_L1_error)
  __pyx_t_4 = __Pyx_PyObject_Call(__pyx_t_1, __pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 682, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_v_res = __pyx_t_4;
  __pyx_t_4 = 0;

  /* "pygpu/gpuarray.pyx":683
 *     """
 *     res = empty(shape, dtype=dtype, order=order, context=context, cls=cls)
 *     array_memset(res, 0)             # <<<<<<<<<<<<<<
 *     return res
 * 
 */
  if (!(likely(((__pyx_v_res) == Py_None) || likely(__Pyx_TypeTest(__pyx_v_res, __pyx_ptype_5pygpu_8gpuarray_GpuArray))))) __PYX_ERR(0, 683, __pyx_L1_error)
  __pyx_t_5 = __pyx_f_5pygpu_8gpuarray_array_memset(((struct PyGpuArrayObject *)__pyx_v_res), 0); if (unlikely(__pyx_t_5 == ((int)-1))) __PYX_ERR(0, 683, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":684
 *     res = empty(shape, dtype=dtype, order=order, context=context, cls=cls)
 *     array_memset(res, 0)
 *     return res             # <<<<<<<<<<<<<<
 * 
 * cdef GpuArray pygpu_zeros(unsigned int nd, const size_t *dims, int typecode,
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_res);
  __pyx_r = __pyx_v_res;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":660
 *     return pygpu_init(dev, p)
 * 
 * def zeros(shape, dtype=GA_DOUBLE, order='C', GpuContext context=None,             # <<<<<<<<<<<<<<
 *           cls=None):
 *     """
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_AddTraceback("pygpu.gpuarray.zeros", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_res);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":686
 *     return res
 * 
 * cdef GpuArray pygpu_zeros(unsigned int nd, const size_t *dims, int typecode,             # <<<<<<<<<<<<<<
 *                           ga_order order, GpuContext context, object cls):
 *     cdef GpuArray res
 */

static struct PyGpuArrayObject *__pyx_f_5pygpu_8gpuarray_pygpu_zeros(unsigned int __pyx_v_nd, size_t const *__pyx_v_dims, int __pyx_v_typecode, ga_order __pyx_v_order, struct PyGpuContextObject *__pyx_v_context, PyObject *__pyx_v_cls) {
  struct PyGpuArrayObject *__pyx_v_res = 0;
  struct PyGpuArrayObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_t_2;
  __Pyx_RefNannySetupContext("pygpu_zeros", 0);

  /* "pygpu/gpuarray.pyx":689
 *                           ga_order order, GpuContext context, object cls):
 *     cdef GpuArray res
 *     res = pygpu_empty(nd, dims, typecode, order, context, cls)             # <<<<<<<<<<<<<<
 *     array_memset(res, 0)
 *     return res
 */
  __pyx_t_1 = ((PyObject *)__pyx_f_5pygpu_8gpuarray_pygpu_empty(__pyx_v_nd, __pyx_v_dims, __pyx_v_typecode, __pyx_v_order, __pyx_v_context, __pyx_v_cls)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 689, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_v_res = ((struct PyGpuArrayObject *)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "pygpu/gpuarray.pyx":690
 *     cdef GpuArray res
 *     res = pygpu_empty(nd, dims, typecode, order, context, cls)
 *     array_memset(res, 0)             # <<<<<<<<<<<<<<
 *     return res
 * 
 */
  __pyx_t_2 = __pyx_f_5pygpu_8gpuarray_array_memset(__pyx_v_res, 0); if (unlikely(__pyx_t_2 == ((int)-1))) __PYX_ERR(0, 690, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":691
 *     res = pygpu_empty(nd, dims, typecode, order, context, cls)
 *     array_memset(res, 0)
 *     return res             # <<<<<<<<<<<<<<
 * 
 * cdef GpuArray pygpu_empty(unsigned int nd, const size_t *dims, int typecode,
 */
  __Pyx_XDECREF(((PyObject *)__pyx_r));
  __Pyx_INCREF(((PyObject *)__pyx_v_res));
  __pyx_r = __pyx_v_res;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":686
 *     return res
 * 
 * cdef GpuArray pygpu_zeros(unsigned int nd, const size_t *dims, int typecode,             # <<<<<<<<<<<<<<
 *                           ga_order order, GpuContext context, object cls):
 *     cdef GpuArray res
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("pygpu.gpuarray.pygpu_zeros", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_res);
  __Pyx_XGIVEREF((PyObject *)__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":693
 *     return res
 * 
 * cdef GpuArray pygpu_empty(unsigned int nd, const size_t *dims, int typecode,             # <<<<<<<<<<<<<<
 *                           ga_order order, GpuContext context, object cls):
 *     cdef GpuArray res
 */

static struct PyGpuArrayObject *__pyx_f_5pygpu_8gpuarray_pygpu_empty(unsigned int __pyx_v_nd, size_t const *__pyx_v_dims, int __pyx_v_typecode, ga_order __pyx_v_order, struct PyGpuContextObject *__pyx_v_context, PyObject *__pyx_v_cls) {
  struct PyGpuArrayObject *__pyx_v_res = 0;
  struct PyGpuArrayObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_t_2;
  __Pyx_RefNannySetupContext("pygpu_empty", 0);
  __Pyx_INCREF((PyObject *)__pyx_v_context);

  /* "pygpu/gpuarray.pyx":697
 *     cdef GpuArray res
 * 
 *     context = ensure_context(context)             # <<<<<<<<<<<<<<
 * 
 *     res = new_GpuArray(cls, context, None)
 */
  __pyx_t_1 = ((PyObject *)__pyx_f_5pygpu_8gpuarray_ensure_context(__pyx_v_context)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 697, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF_SET(__pyx_v_context, ((struct PyGpuContextObject *)__pyx_t_1));
  __pyx_t_1 = 0;

  /* "pygpu/gpuarray.pyx":699
 *     context = ensure_context(context)
 * 
 *     res = new_GpuArray(cls, context, None)             # <<<<<<<<<<<<<<
 *     array_empty(res, context.ctx, typecode, nd, dims, order)
 *     return res
 */
  __pyx_t_1 = ((PyObject *)__pyx_f_5pygpu_8gpuarray_new_GpuArray(__pyx_v_cls, __pyx_v_context, Py_None)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 699, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_v_res = ((struct PyGpuArrayObject *)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "pygpu/gpuarray.pyx":700
 * 
 *     res = new_GpuArray(cls, context, None)
 *     array_empty(res, context.ctx, typecode, nd, dims, order)             # <<<<<<<<<<<<<<
 *     return res
 * 
 */
  __pyx_t_2 = __pyx_f_5pygpu_8gpuarray_array_empty(__pyx_v_res, __pyx_v_context->ctx, __pyx_v_typecode, __pyx_v_nd, __pyx_v_dims, __pyx_v_order); if (unlikely(__pyx_t_2 == ((int)-1))) __PYX_ERR(0, 700, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":701
 *     res = new_GpuArray(cls, context, None)
 *     array_empty(res, context.ctx, typecode, nd, dims, order)
 *     return res             # <<<<<<<<<<<<<<
 * 
 * cdef GpuArray pygpu_fromgpudata(gpudata *buf, size_t offset, int typecode,
 */
  __Pyx_XDECREF(((PyObject *)__pyx_r));
  __Pyx_INCREF(((PyObject *)__pyx_v_res));
  __pyx_r = __pyx_v_res;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":693
 *     return res
 * 
 * cdef GpuArray pygpu_empty(unsigned int nd, const size_t *dims, int typecode,             # <<<<<<<<<<<<<<
 *                           ga_order order, GpuContext context, object cls):
 *     cdef GpuArray res
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("pygpu.gpuarray.pygpu_empty", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_res);
  __Pyx_XDECREF((PyObject *)__pyx_v_context);
  __Pyx_XGIVEREF((PyObject *)__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":703
 *     return res
 * 
 * cdef GpuArray pygpu_fromgpudata(gpudata *buf, size_t offset, int typecode,             # <<<<<<<<<<<<<<
 *                                 unsigned int nd, const size_t *dims,
 *                                 const ssize_t *strides, GpuContext context,
 */

static struct PyGpuArrayObject *__pyx_f_5pygpu_8gpuarray_pygpu_fromgpudata(gpudata *__pyx_v_buf, size_t __pyx_v_offset, int __pyx_v_typecode, unsigned int __pyx_v_nd, size_t const *__pyx_v_dims, Py_ssize_t const *__pyx_v_strides, struct PyGpuContextObject *__pyx_v_context, int __pyx_v_writable, PyObject *__pyx_v_base, PyObject *__pyx_v_cls) {
  struct PyGpuArrayObject *__pyx_v_res = 0;
  struct PyGpuArrayObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_t_2;
  __Pyx_RefNannySetupContext("pygpu_fromgpudata", 0);

  /* "pygpu/gpuarray.pyx":709
 *     cdef GpuArray res
 * 
 *     res = new_GpuArray(cls, context, base)             # <<<<<<<<<<<<<<
 *     array_fromdata(res, buf, offset, typecode, nd, dims,
 *                    strides, writable)
 */
  __pyx_t_1 = ((PyObject *)__pyx_f_5pygpu_8gpuarray_new_GpuArray(__pyx_v_cls, __pyx_v_context, __pyx_v_base)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 709, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_v_res = ((struct PyGpuArrayObject *)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "pygpu/gpuarray.pyx":710
 * 
 *     res = new_GpuArray(cls, context, base)
 *     array_fromdata(res, buf, offset, typecode, nd, dims,             # <<<<<<<<<<<<<<
 *                    strides, writable)
 *     return res
 */
  __pyx_t_2 = __pyx_f_5pygpu_8gpuarray_array_fromdata(__pyx_v_res, __pyx_v_buf, __pyx_v_offset, __pyx_v_typecode, __pyx_v_nd, __pyx_v_dims, __pyx_v_strides, __pyx_v_writable); if (unlikely(__pyx_t_2 == ((int)-1))) __PYX_ERR(0, 710, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":712
 *     array_fromdata(res, buf, offset, typecode, nd, dims,
 *                    strides, writable)
 *     return res             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __Pyx_XDECREF(((PyObject *)__pyx_r));
  __Pyx_INCREF(((PyObject *)__pyx_v_res));
  __pyx_r = __pyx_v_res;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":703
 *     return res
 * 
 * cdef GpuArray pygpu_fromgpudata(gpudata *buf, size_t offset, int typecode,             # <<<<<<<<<<<<<<
 *                                 unsigned int nd, const size_t *dims,
 *                                 const ssize_t *strides, GpuContext context,
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("pygpu.gpuarray.pygpu_fromgpudata", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_res);
  __Pyx_XGIVEREF((PyObject *)__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":715
 * 
 * 
 * cdef GpuArray pygpu_copy(GpuArray a, ga_order ord):             # <<<<<<<<<<<<<<
 *     cdef GpuArray res
 *     res = new_GpuArray(type(a), a.context, None)
 */

static struct PyGpuArrayObject *__pyx_f_5pygpu_8gpuarray_pygpu_copy(struct PyGpuArrayObject *__pyx_v_a, ga_order __pyx_v_ord) {
  struct PyGpuArrayObject *__pyx_v_res = 0;
  struct PyGpuArrayObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  int __pyx_t_3;
  __Pyx_RefNannySetupContext("pygpu_copy", 0);

  /* "pygpu/gpuarray.pyx":717
 * cdef GpuArray pygpu_copy(GpuArray a, ga_order ord):
 *     cdef GpuArray res
 *     res = new_GpuArray(type(a), a.context, None)             # <<<<<<<<<<<<<<
 *     array_copy(res, a, ord)
 *     return res
 */
  __pyx_t_1 = ((PyObject *)__pyx_v_a->context);
  __Pyx_INCREF(__pyx_t_1);
  __pyx_t_2 = ((PyObject *)__pyx_f_5pygpu_8gpuarray_new_GpuArray(((PyObject *)Py_TYPE(((PyObject *)__pyx_v_a))), ((struct PyGpuContextObject *)__pyx_t_1), Py_None)); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 717, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_res = ((struct PyGpuArrayObject *)__pyx_t_2);
  __pyx_t_2 = 0;

  /* "pygpu/gpuarray.pyx":718
 *     cdef GpuArray res
 *     res = new_GpuArray(type(a), a.context, None)
 *     array_copy(res, a, ord)             # <<<<<<<<<<<<<<
 *     return res
 * 
 */
  __pyx_t_3 = __pyx_f_5pygpu_8gpuarray_array_copy(__pyx_v_res, __pyx_v_a, __pyx_v_ord); if (unlikely(__pyx_t_3 == ((int)-1))) __PYX_ERR(0, 718, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":719
 *     res = new_GpuArray(type(a), a.context, None)
 *     array_copy(res, a, ord)
 *     return res             # <<<<<<<<<<<<<<
 * 
 * cdef int pygpu_move(GpuArray a, GpuArray src) except -1:
 */
  __Pyx_XDECREF(((PyObject *)__pyx_r));
  __Pyx_INCREF(((PyObject *)__pyx_v_res));
  __pyx_r = __pyx_v_res;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":715
 * 
 * 
 * cdef GpuArray pygpu_copy(GpuArray a, ga_order ord):             # <<<<<<<<<<<<<<
 *     cdef GpuArray res
 *     res = new_GpuArray(type(a), a.context, None)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("pygpu.gpuarray.pygpu_copy", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_res);
  __Pyx_XGIVEREF((PyObject *)__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":721
 *     return res
 * 
 * cdef int pygpu_move(GpuArray a, GpuArray src) except -1:             # <<<<<<<<<<<<<<
 *     array_move(a, src)
 *     return 0
 */

static int __pyx_f_5pygpu_8gpuarray_pygpu_move(struct PyGpuArrayObject *__pyx_v_a, struct PyGpuArrayObject *__pyx_v_src) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  __Pyx_RefNannySetupContext("pygpu_move", 0);

  /* "pygpu/gpuarray.pyx":722
 * 
 * cdef int pygpu_move(GpuArray a, GpuArray src) except -1:
 *     array_move(a, src)             # <<<<<<<<<<<<<<
 *     return 0
 * 
 */
  __pyx_t_1 = __pyx_f_5pygpu_8gpuarray_array_move(__pyx_v_a, __pyx_v_src); if (unlikely(__pyx_t_1 == ((int)-1))) __PYX_ERR(0, 722, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":723
 * cdef int pygpu_move(GpuArray a, GpuArray src) except -1:
 *     array_move(a, src)
 *     return 0             # <<<<<<<<<<<<<<
 * 
 * def empty(shape, dtype=GA_DOUBLE, order='C', GpuContext context=None,
 */
  __pyx_r = 0;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":721
 *     return res
 * 
 * cdef int pygpu_move(GpuArray a, GpuArray src) except -1:             # <<<<<<<<<<<<<<
 *     array_move(a, src)
 *     return 0
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_AddTraceback("pygpu.gpuarray.pygpu_move", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":725
 *     return 0
 * 
 * def empty(shape, dtype=GA_DOUBLE, order='C', GpuContext context=None,             # <<<<<<<<<<<<<<
 *           cls=None):
 *     """
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_27empty(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static char __pyx_doc_5pygpu_8gpuarray_26empty[] = "\n    empty(shape, dtype='float64', order='C', context=None, cls=None)\n\n    Returns an empty (uninitialized) array of the requested shape,\n    type and order.\n\n    Parameters\n    ----------\n    shape: iterable of ints\n        number of elements in each dimension\n    dtype: str, numpy.dtype or int\n        type of the elements\n    order: {'A', 'C', 'F'}\n        layout of the data in memory, one of 'A'ny, 'C' or 'F'ortran\n    context: GpuContext\n        context in which to do the allocation\n    cls: type\n        class of the returned array (must inherit from GpuArray)\n\n    ";
static PyMethodDef __pyx_mdef_5pygpu_8gpuarray_27empty = {"empty", (PyCFunction)__pyx_pw_5pygpu_8gpuarray_27empty, METH_VARARGS|METH_KEYWORDS, __pyx_doc_5pygpu_8gpuarray_26empty};
static PyObject *__pyx_pw_5pygpu_8gpuarray_27empty(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_shape = 0;
  PyObject *__pyx_v_dtype = 0;
  PyObject *__pyx_v_order = 0;
  struct PyGpuContextObject *__pyx_v_context = 0;
  PyObject *__pyx_v_cls = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("empty (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_shape,&__pyx_n_s_dtype,&__pyx_n_s_order,&__pyx_n_s_context,&__pyx_n_s_cls,0};
    PyObject* values[5] = {0,0,0,0,0};
    values[1] = __pyx_k__12;
    values[2] = ((PyObject *)__pyx_n_s_C);
    values[3] = (PyObject *)((struct PyGpuContextObject *)Py_None);

    /* "pygpu/gpuarray.pyx":726
 * 
 * def empty(shape, dtype=GA_DOUBLE, order='C', GpuContext context=None,
 *           cls=None):             # <<<<<<<<<<<<<<
 *     """
 *     empty(shape, dtype='float64', order='C', context=None, cls=None)
 */
    values[4] = ((PyObject *)Py_None);
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
        CYTHON_FALLTHROUGH;
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_shape)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_dtype);
          if (value) { values[1] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_order);
          if (value) { values[2] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  3:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_context);
          if (value) { values[3] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  4:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_cls);
          if (value) { values[4] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "empty") < 0)) __PYX_ERR(0, 725, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
        CYTHON_FALLTHROUGH;
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    __pyx_v_shape = values[0];
    __pyx_v_dtype = values[1];
    __pyx_v_order = values[2];
    __pyx_v_context = ((struct PyGpuContextObject *)values[3]);
    __pyx_v_cls = values[4];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("empty", 0, 1, 5, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 725, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("pygpu.gpuarray.empty", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_context), __pyx_ptype_5pygpu_8gpuarray_GpuContext, 1, "context", 0))) __PYX_ERR(0, 725, __pyx_L1_error)
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_26empty(__pyx_self, __pyx_v_shape, __pyx_v_dtype, __pyx_v_order, __pyx_v_context, __pyx_v_cls);

  /* "pygpu/gpuarray.pyx":725
 *     return 0
 * 
 * def empty(shape, dtype=GA_DOUBLE, order='C', GpuContext context=None,             # <<<<<<<<<<<<<<
 *           cls=None):
 *     """
 */

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_26empty(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_shape, PyObject *__pyx_v_dtype, PyObject *__pyx_v_order, struct PyGpuContextObject *__pyx_v_context, PyObject *__pyx_v_cls) {
  size_t *__pyx_v_cdims;
  unsigned int __pyx_v_nd;
  PyObject *__pyx_v_i = NULL;
  PyObject *__pyx_v_d = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  Py_ssize_t __pyx_t_4;
  int __pyx_t_5;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  PyObject *__pyx_t_8 = NULL;
  PyObject *__pyx_t_9 = NULL;
  int __pyx_t_10;
  PyObject *(*__pyx_t_11)(PyObject *);
  size_t __pyx_t_12;
  Py_ssize_t __pyx_t_13;
  ga_order __pyx_t_14;
  int __pyx_t_15;
  char const *__pyx_t_16;
  PyObject *__pyx_t_17 = NULL;
  PyObject *__pyx_t_18 = NULL;
  PyObject *__pyx_t_19 = NULL;
  __Pyx_RefNannySetupContext("empty", 0);
  __Pyx_INCREF(__pyx_v_shape);

  /* "pygpu/gpuarray.pyx":750
 *     cdef unsigned int nd
 * 
 *     try:             # <<<<<<<<<<<<<<
 *         nd = <unsigned int>len(shape)
 *     except TypeError:
 */
  {
    __Pyx_PyThreadState_declare
    __Pyx_PyThreadState_assign
    __Pyx_ExceptionSave(&__pyx_t_1, &__pyx_t_2, &__pyx_t_3);
    __Pyx_XGOTREF(__pyx_t_1);
    __Pyx_XGOTREF(__pyx_t_2);
    __Pyx_XGOTREF(__pyx_t_3);
    /*try:*/ {

      /* "pygpu/gpuarray.pyx":751
 * 
 *     try:
 *         nd = <unsigned int>len(shape)             # <<<<<<<<<<<<<<
 *     except TypeError:
 *         nd = 1
 */
      __pyx_t_4 = PyObject_Length(__pyx_v_shape); if (unlikely(__pyx_t_4 == ((Py_ssize_t)-1))) __PYX_ERR(0, 751, __pyx_L3_error)
      __pyx_v_nd = ((unsigned int)__pyx_t_4);

      /* "pygpu/gpuarray.pyx":750
 *     cdef unsigned int nd
 * 
 *     try:             # <<<<<<<<<<<<<<
 *         nd = <unsigned int>len(shape)
 *     except TypeError:
 */
    }
    __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
    goto __pyx_L8_try_end;
    __pyx_L3_error:;

    /* "pygpu/gpuarray.pyx":752
 *     try:
 *         nd = <unsigned int>len(shape)
 *     except TypeError:             # <<<<<<<<<<<<<<
 *         nd = 1
 *         shape = [shape]
 */
    __pyx_t_5 = __Pyx_PyErr_ExceptionMatches(__pyx_builtin_TypeError);
    if (__pyx_t_5) {
      __Pyx_AddTraceback("pygpu.gpuarray.empty", __pyx_clineno, __pyx_lineno, __pyx_filename);
      if (__Pyx_GetException(&__pyx_t_6, &__pyx_t_7, &__pyx_t_8) < 0) __PYX_ERR(0, 752, __pyx_L5_except_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_GOTREF(__pyx_t_7);
      __Pyx_GOTREF(__pyx_t_8);

      /* "pygpu/gpuarray.pyx":753
 *         nd = <unsigned int>len(shape)
 *     except TypeError:
 *         nd = 1             # <<<<<<<<<<<<<<
 *         shape = [shape]
 * 
 */
      __pyx_v_nd = 1;

      /* "pygpu/gpuarray.pyx":754
 *     except TypeError:
 *         nd = 1
 *         shape = [shape]             # <<<<<<<<<<<<<<
 * 
 *     cdims = <size_t *>calloc(nd, sizeof(size_t))
 */
      __pyx_t_9 = PyList_New(1); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 754, __pyx_L5_except_error)
      __Pyx_GOTREF(__pyx_t_9);
      __Pyx_INCREF(__pyx_v_shape);
      __Pyx_GIVEREF(__pyx_v_shape);
      PyList_SET_ITEM(__pyx_t_9, 0, __pyx_v_shape);
      __Pyx_DECREF_SET(__pyx_v_shape, __pyx_t_9);
      __pyx_t_9 = 0;
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      goto __pyx_L4_exception_handled;
    }
    goto __pyx_L5_except_error;
    __pyx_L5_except_error:;

    /* "pygpu/gpuarray.pyx":750
 *     cdef unsigned int nd
 * 
 *     try:             # <<<<<<<<<<<<<<
 *         nd = <unsigned int>len(shape)
 *     except TypeError:
 */
    __Pyx_XGIVEREF(__pyx_t_1);
    __Pyx_XGIVEREF(__pyx_t_2);
    __Pyx_XGIVEREF(__pyx_t_3);
    __Pyx_ExceptionReset(__pyx_t_1, __pyx_t_2, __pyx_t_3);
    goto __pyx_L1_error;
    __pyx_L4_exception_handled:;
    __Pyx_XGIVEREF(__pyx_t_1);
    __Pyx_XGIVEREF(__pyx_t_2);
    __Pyx_XGIVEREF(__pyx_t_3);
    __Pyx_ExceptionReset(__pyx_t_1, __pyx_t_2, __pyx_t_3);
    __pyx_L8_try_end:;
  }

  /* "pygpu/gpuarray.pyx":756
 *         shape = [shape]
 * 
 *     cdims = <size_t *>calloc(nd, sizeof(size_t))             # <<<<<<<<<<<<<<
 *     if cdims == NULL:
 *         raise MemoryError, "could not allocate cdims"
 */
  __pyx_v_cdims = ((size_t *)calloc(__pyx_v_nd, (sizeof(size_t))));

  /* "pygpu/gpuarray.pyx":757
 * 
 *     cdims = <size_t *>calloc(nd, sizeof(size_t))
 *     if cdims == NULL:             # <<<<<<<<<<<<<<
 *         raise MemoryError, "could not allocate cdims"
 *     try:
 */
  __pyx_t_10 = ((__pyx_v_cdims == NULL) != 0);
  if (__pyx_t_10) {

    /* "pygpu/gpuarray.pyx":758
 *     cdims = <size_t *>calloc(nd, sizeof(size_t))
 *     if cdims == NULL:
 *         raise MemoryError, "could not allocate cdims"             # <<<<<<<<<<<<<<
 *     try:
 *         for i, d in enumerate(shape):
 */
    __Pyx_Raise(__pyx_builtin_MemoryError, __pyx_kp_s_could_not_allocate_cdims, 0, 0);
    __PYX_ERR(0, 758, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":757
 * 
 *     cdims = <size_t *>calloc(nd, sizeof(size_t))
 *     if cdims == NULL:             # <<<<<<<<<<<<<<
 *         raise MemoryError, "could not allocate cdims"
 *     try:
 */
  }

  /* "pygpu/gpuarray.pyx":759
 *     if cdims == NULL:
 *         raise MemoryError, "could not allocate cdims"
 *     try:             # <<<<<<<<<<<<<<
 *         for i, d in enumerate(shape):
 *             cdims[i] = d
 */
  /*try:*/ {

    /* "pygpu/gpuarray.pyx":760
 *         raise MemoryError, "could not allocate cdims"
 *     try:
 *         for i, d in enumerate(shape):             # <<<<<<<<<<<<<<
 *             cdims[i] = d
 *         return pygpu_empty(nd, cdims,
 */
    __Pyx_INCREF(__pyx_int_0);
    __pyx_t_8 = __pyx_int_0;
    if (likely(PyList_CheckExact(__pyx_v_shape)) || PyTuple_CheckExact(__pyx_v_shape)) {
      __pyx_t_7 = __pyx_v_shape; __Pyx_INCREF(__pyx_t_7); __pyx_t_4 = 0;
      __pyx_t_11 = NULL;
    } else {
      __pyx_t_4 = -1; __pyx_t_7 = PyObject_GetIter(__pyx_v_shape); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 760, __pyx_L13_error)
      __Pyx_GOTREF(__pyx_t_7);
      __pyx_t_11 = Py_TYPE(__pyx_t_7)->tp_iternext; if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 760, __pyx_L13_error)
    }
    for (;;) {
      if (likely(!__pyx_t_11)) {
        if (likely(PyList_CheckExact(__pyx_t_7))) {
          if (__pyx_t_4 >= PyList_GET_SIZE(__pyx_t_7)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_6 = PyList_GET_ITEM(__pyx_t_7, __pyx_t_4); __Pyx_INCREF(__pyx_t_6); __pyx_t_4++; if (unlikely(0 < 0)) __PYX_ERR(0, 760, __pyx_L13_error)
          #else
          __pyx_t_6 = PySequence_ITEM(__pyx_t_7, __pyx_t_4); __pyx_t_4++; if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 760, __pyx_L13_error)
          __Pyx_GOTREF(__pyx_t_6);
          #endif
        } else {
          if (__pyx_t_4 >= PyTuple_GET_SIZE(__pyx_t_7)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_6 = PyTuple_GET_ITEM(__pyx_t_7, __pyx_t_4); __Pyx_INCREF(__pyx_t_6); __pyx_t_4++; if (unlikely(0 < 0)) __PYX_ERR(0, 760, __pyx_L13_error)
          #else
          __pyx_t_6 = PySequence_ITEM(__pyx_t_7, __pyx_t_4); __pyx_t_4++; if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 760, __pyx_L13_error)
          __Pyx_GOTREF(__pyx_t_6);
          #endif
        }
      } else {
        __pyx_t_6 = __pyx_t_11(__pyx_t_7);
        if (unlikely(!__pyx_t_6)) {
          PyObject* exc_type = PyErr_Occurred();
          if (exc_type) {
            if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
            else __PYX_ERR(0, 760, __pyx_L13_error)
          }
          break;
        }
        __Pyx_GOTREF(__pyx_t_6);
      }
      __Pyx_XDECREF_SET(__pyx_v_d, __pyx_t_6);
      __pyx_t_6 = 0;
      __Pyx_INCREF(__pyx_t_8);
      __Pyx_XDECREF_SET(__pyx_v_i, __pyx_t_8);
      __pyx_t_6 = __Pyx_PyInt_AddObjC(__pyx_t_8, __pyx_int_1, 1, 0); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 760, __pyx_L13_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_8);
      __pyx_t_8 = __pyx_t_6;
      __pyx_t_6 = 0;

      /* "pygpu/gpuarray.pyx":761
 *     try:
 *         for i, d in enumerate(shape):
 *             cdims[i] = d             # <<<<<<<<<<<<<<
 *         return pygpu_empty(nd, cdims,
 *                            dtype_to_typecode(dtype), to_ga_order(order),
 */
      __pyx_t_12 = __Pyx_PyInt_As_size_t(__pyx_v_d); if (unlikely((__pyx_t_12 == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 761, __pyx_L13_error)
      __pyx_t_13 = __Pyx_PyIndex_AsSsize_t(__pyx_v_i); if (unlikely((__pyx_t_13 == (Py_ssize_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 761, __pyx_L13_error)
      (__pyx_v_cdims[__pyx_t_13]) = __pyx_t_12;

      /* "pygpu/gpuarray.pyx":760
 *         raise MemoryError, "could not allocate cdims"
 *     try:
 *         for i, d in enumerate(shape):             # <<<<<<<<<<<<<<
 *             cdims[i] = d
 *         return pygpu_empty(nd, cdims,
 */
    }
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;

    /* "pygpu/gpuarray.pyx":762
 *         for i, d in enumerate(shape):
 *             cdims[i] = d
 *         return pygpu_empty(nd, cdims,             # <<<<<<<<<<<<<<
 *                            dtype_to_typecode(dtype), to_ga_order(order),
 *                            context, cls)
 */
    __Pyx_XDECREF(__pyx_r);

    /* "pygpu/gpuarray.pyx":763
 *             cdims[i] = d
 *         return pygpu_empty(nd, cdims,
 *                            dtype_to_typecode(dtype), to_ga_order(order),             # <<<<<<<<<<<<<<
 *                            context, cls)
 *     finally:
 */
    __pyx_t_5 = __pyx_f_5pygpu_8gpuarray_dtype_to_typecode(__pyx_v_dtype, 0); if (unlikely(__pyx_t_5 == ((int)-1))) __PYX_ERR(0, 763, __pyx_L13_error)
    __pyx_t_14 = __pyx_f_5pygpu_8gpuarray_to_ga_order(__pyx_v_order); if (unlikely(__pyx_t_14 == ((ga_order)((ga_order)-2L)))) __PYX_ERR(0, 763, __pyx_L13_error)

    /* "pygpu/gpuarray.pyx":762
 *         for i, d in enumerate(shape):
 *             cdims[i] = d
 *         return pygpu_empty(nd, cdims,             # <<<<<<<<<<<<<<
 *                            dtype_to_typecode(dtype), to_ga_order(order),
 *                            context, cls)
 */
    __pyx_t_8 = ((PyObject *)__pyx_f_5pygpu_8gpuarray_pygpu_empty(__pyx_v_nd, __pyx_v_cdims, __pyx_t_5, __pyx_t_14, __pyx_v_context, __pyx_v_cls)); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 762, __pyx_L13_error)
    __Pyx_GOTREF(__pyx_t_8);
    __pyx_r = __pyx_t_8;
    __pyx_t_8 = 0;
    goto __pyx_L12_return;
  }

  /* "pygpu/gpuarray.pyx":766
 *                            context, cls)
 *     finally:
 *         free(cdims)             # <<<<<<<<<<<<<<
 * 
 * def asarray(a, dtype=None, order='A', GpuContext context=None):
 */
  /*finally:*/ {
    __pyx_L13_error:;
    /*exception exit:*/{
      __Pyx_PyThreadState_declare
      __Pyx_PyThreadState_assign
      __pyx_t_3 = 0; __pyx_t_2 = 0; __pyx_t_1 = 0; __pyx_t_17 = 0; __pyx_t_18 = 0; __pyx_t_19 = 0;
      __Pyx_XDECREF(__pyx_t_9); __pyx_t_9 = 0;
      __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
      __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
      __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
      if (PY_MAJOR_VERSION >= 3) __Pyx_ExceptionSwap(&__pyx_t_17, &__pyx_t_18, &__pyx_t_19);
      if ((PY_MAJOR_VERSION < 3) || unlikely(__Pyx_GetException(&__pyx_t_3, &__pyx_t_2, &__pyx_t_1) < 0)) __Pyx_ErrFetch(&__pyx_t_3, &__pyx_t_2, &__pyx_t_1);
      __Pyx_XGOTREF(__pyx_t_3);
      __Pyx_XGOTREF(__pyx_t_2);
      __Pyx_XGOTREF(__pyx_t_1);
      __Pyx_XGOTREF(__pyx_t_17);
      __Pyx_XGOTREF(__pyx_t_18);
      __Pyx_XGOTREF(__pyx_t_19);
      __pyx_t_5 = __pyx_lineno; __pyx_t_15 = __pyx_clineno; __pyx_t_16 = __pyx_filename;
      {
        free(__pyx_v_cdims);
      }
      if (PY_MAJOR_VERSION >= 3) {
        __Pyx_XGIVEREF(__pyx_t_17);
        __Pyx_XGIVEREF(__pyx_t_18);
        __Pyx_XGIVEREF(__pyx_t_19);
        __Pyx_ExceptionReset(__pyx_t_17, __pyx_t_18, __pyx_t_19);
      }
      __Pyx_XGIVEREF(__pyx_t_3);
      __Pyx_XGIVEREF(__pyx_t_2);
      __Pyx_XGIVEREF(__pyx_t_1);
      __Pyx_ErrRestore(__pyx_t_3, __pyx_t_2, __pyx_t_1);
      __pyx_t_3 = 0; __pyx_t_2 = 0; __pyx_t_1 = 0; __pyx_t_17 = 0; __pyx_t_18 = 0; __pyx_t_19 = 0;
      __pyx_lineno = __pyx_t_5; __pyx_clineno = __pyx_t_15; __pyx_filename = __pyx_t_16;
      goto __pyx_L1_error;
    }
    __pyx_L12_return: {
      __pyx_t_19 = __pyx_r;
      __pyx_r = 0;
      free(__pyx_v_cdims);
      __pyx_r = __pyx_t_19;
      __pyx_t_19 = 0;
      goto __pyx_L0;
    }
  }

  /* "pygpu/gpuarray.pyx":725
 *     return 0
 * 
 * def empty(shape, dtype=GA_DOUBLE, order='C', GpuContext context=None,             # <<<<<<<<<<<<<<
 *           cls=None):
 *     """
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_XDECREF(__pyx_t_9);
  __Pyx_AddTraceback("pygpu.gpuarray.empty", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_i);
  __Pyx_XDECREF(__pyx_v_d);
  __Pyx_XDECREF(__pyx_v_shape);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":768
 *         free(cdims)
 * 
 * def asarray(a, dtype=None, order='A', GpuContext context=None):             # <<<<<<<<<<<<<<
 *     """
 *     asarray(a, dtype=None, order='A', context=None)
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_29asarray(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static char __pyx_doc_5pygpu_8gpuarray_28asarray[] = "\n    asarray(a, dtype=None, order='A', context=None)\n\n    Returns a GpuArray from the data in `a`\n\n    If `a` is already a GpuArray and all other parameters match, then\n    the object itself returned.  If `a` is an instance of a subclass\n    of GpuArray then a view of the base class will be returned.\n    Otherwise a new object is create and the data is copied into it.\n\n    `context` is optional if `a` is a GpuArray (but must match exactly\n    the context of `a` if specified) and is mandatory otherwise.\n\n    Parameters\n    ----------\n    a: array-like\n        data\n    dtype: str, numpy.dtype or int\n        type of the elements\n    order: {'A', 'C', 'F'}\n        layout of the data in memory, one of 'A'ny, 'C' or 'F'ortran\n    context: GpuContext\n        context in which to do the allocation\n\n    ";
static PyMethodDef __pyx_mdef_5pygpu_8gpuarray_29asarray = {"asarray", (PyCFunction)__pyx_pw_5pygpu_8gpuarray_29asarray, METH_VARARGS|METH_KEYWORDS, __pyx_doc_5pygpu_8gpuarray_28asarray};
static PyObject *__pyx_pw_5pygpu_8gpuarray_29asarray(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_a = 0;
  PyObject *__pyx_v_dtype = 0;
  PyObject *__pyx_v_order = 0;
  struct PyGpuContextObject *__pyx_v_context = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("asarray (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_a,&__pyx_n_s_dtype,&__pyx_n_s_order,&__pyx_n_s_context,0};
    PyObject* values[4] = {0,0,0,0};
    values[1] = ((PyObject *)Py_None);
    values[2] = ((PyObject *)__pyx_n_s_A);
    values[3] = (PyObject *)((struct PyGpuContextObject *)Py_None);
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_a)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_dtype);
          if (value) { values[1] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_order);
          if (value) { values[2] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  3:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_context);
          if (value) { values[3] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "asarray") < 0)) __PYX_ERR(0, 768, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    __pyx_v_a = values[0];
    __pyx_v_dtype = values[1];
    __pyx_v_order = values[2];
    __pyx_v_context = ((struct PyGpuContextObject *)values[3]);
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("asarray", 0, 1, 4, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 768, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("pygpu.gpuarray.asarray", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_context), __pyx_ptype_5pygpu_8gpuarray_GpuContext, 1, "context", 0))) __PYX_ERR(0, 768, __pyx_L1_error)
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_28asarray(__pyx_self, __pyx_v_a, __pyx_v_dtype, __pyx_v_order, __pyx_v_context);

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_28asarray(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_a, PyObject *__pyx_v_dtype, PyObject *__pyx_v_order, struct PyGpuContextObject *__pyx_v_context) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  __Pyx_RefNannySetupContext("asarray", 0);

  /* "pygpu/gpuarray.pyx":794
 * 
 *     """
 *     return array(a, dtype=dtype, order=order, copy=False, context=context,             # <<<<<<<<<<<<<<
 *                  cls=GpuArray)
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_array); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 794, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = PyTuple_New(1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 794, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_INCREF(__pyx_v_a);
  __Pyx_GIVEREF(__pyx_v_a);
  PyTuple_SET_ITEM(__pyx_t_2, 0, __pyx_v_a);
  __pyx_t_3 = __Pyx_PyDict_NewPresized(5); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 794, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  if (PyDict_SetItem(__pyx_t_3, __pyx_n_s_dtype, __pyx_v_dtype) < 0) __PYX_ERR(0, 794, __pyx_L1_error)
  if (PyDict_SetItem(__pyx_t_3, __pyx_n_s_order, __pyx_v_order) < 0) __PYX_ERR(0, 794, __pyx_L1_error)
  if (PyDict_SetItem(__pyx_t_3, __pyx_n_s_copy, Py_False) < 0) __PYX_ERR(0, 794, __pyx_L1_error)
  if (PyDict_SetItem(__pyx_t_3, __pyx_n_s_context, ((PyObject *)__pyx_v_context)) < 0) __PYX_ERR(0, 794, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":795
 *     """
 *     return array(a, dtype=dtype, order=order, copy=False, context=context,
 *                  cls=GpuArray)             # <<<<<<<<<<<<<<
 * 
 * def ascontiguousarray(a, dtype=None, GpuContext context=None):
 */
  if (PyDict_SetItem(__pyx_t_3, __pyx_n_s_cls, ((PyObject *)__pyx_ptype_5pygpu_8gpuarray_GpuArray)) < 0) __PYX_ERR(0, 794, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":794
 * 
 *     """
 *     return array(a, dtype=dtype, order=order, copy=False, context=context,             # <<<<<<<<<<<<<<
 *                  cls=GpuArray)
 * 
 */
  __pyx_t_4 = __Pyx_PyObject_Call(__pyx_t_1, __pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 794, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_r = __pyx_t_4;
  __pyx_t_4 = 0;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":768
 *         free(cdims)
 * 
 * def asarray(a, dtype=None, order='A', GpuContext context=None):             # <<<<<<<<<<<<<<
 *     """
 *     asarray(a, dtype=None, order='A', context=None)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_AddTraceback("pygpu.gpuarray.asarray", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":797
 *                  cls=GpuArray)
 * 
 * def ascontiguousarray(a, dtype=None, GpuContext context=None):             # <<<<<<<<<<<<<<
 *     """
 *     ascontiguousarray(a, dtype=None, context=None)
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_31ascontiguousarray(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static char __pyx_doc_5pygpu_8gpuarray_30ascontiguousarray[] = "\n    ascontiguousarray(a, dtype=None, context=None)\n\n    Returns a contiguous array in device memory (C order).\n\n    `context` is optional if `a` is a GpuArray (but must match exactly\n    the context of `a` if specified) and is mandatory otherwise.\n\n    Parameters\n    ----------\n    a: array-like\n        input\n    dtype: str, numpy.dtype or int\n        type of the return array\n    context: GpuContext\n        context to use for a new array\n\n    ";
static PyMethodDef __pyx_mdef_5pygpu_8gpuarray_31ascontiguousarray = {"ascontiguousarray", (PyCFunction)__pyx_pw_5pygpu_8gpuarray_31ascontiguousarray, METH_VARARGS|METH_KEYWORDS, __pyx_doc_5pygpu_8gpuarray_30ascontiguousarray};
static PyObject *__pyx_pw_5pygpu_8gpuarray_31ascontiguousarray(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_a = 0;
  PyObject *__pyx_v_dtype = 0;
  struct PyGpuContextObject *__pyx_v_context = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("ascontiguousarray (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_a,&__pyx_n_s_dtype,&__pyx_n_s_context,0};
    PyObject* values[3] = {0,0,0};
    values[1] = ((PyObject *)Py_None);
    values[2] = (PyObject *)((struct PyGpuContextObject *)Py_None);
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_a)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_dtype);
          if (value) { values[1] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_context);
          if (value) { values[2] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "ascontiguousarray") < 0)) __PYX_ERR(0, 797, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    __pyx_v_a = values[0];
    __pyx_v_dtype = values[1];
    __pyx_v_context = ((struct PyGpuContextObject *)values[2]);
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("ascontiguousarray", 0, 1, 3, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 797, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("pygpu.gpuarray.ascontiguousarray", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_context), __pyx_ptype_5pygpu_8gpuarray_GpuContext, 1, "context", 0))) __PYX_ERR(0, 797, __pyx_L1_error)
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_30ascontiguousarray(__pyx_self, __pyx_v_a, __pyx_v_dtype, __pyx_v_context);

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_30ascontiguousarray(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_a, PyObject *__pyx_v_dtype, struct PyGpuContextObject *__pyx_v_context) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  __Pyx_RefNannySetupContext("ascontiguousarray", 0);

  /* "pygpu/gpuarray.pyx":816
 * 
 *     """
 *     return array(a, order='C', dtype=dtype, ndmin=1, copy=False,             # <<<<<<<<<<<<<<
 *                  context=context)
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_array); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 816, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = PyTuple_New(1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 816, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_INCREF(__pyx_v_a);
  __Pyx_GIVEREF(__pyx_v_a);
  PyTuple_SET_ITEM(__pyx_t_2, 0, __pyx_v_a);
  __pyx_t_3 = __Pyx_PyDict_NewPresized(5); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 816, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  if (PyDict_SetItem(__pyx_t_3, __pyx_n_s_order, __pyx_n_s_C) < 0) __PYX_ERR(0, 816, __pyx_L1_error)
  if (PyDict_SetItem(__pyx_t_3, __pyx_n_s_dtype, __pyx_v_dtype) < 0) __PYX_ERR(0, 816, __pyx_L1_error)
  if (PyDict_SetItem(__pyx_t_3, __pyx_n_s_ndmin, __pyx_int_1) < 0) __PYX_ERR(0, 816, __pyx_L1_error)
  if (PyDict_SetItem(__pyx_t_3, __pyx_n_s_copy, Py_False) < 0) __PYX_ERR(0, 816, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":817
 *     """
 *     return array(a, order='C', dtype=dtype, ndmin=1, copy=False,
 *                  context=context)             # <<<<<<<<<<<<<<
 * 
 * def asfortranarray(a, dtype=None, GpuArray context=None):
 */
  if (PyDict_SetItem(__pyx_t_3, __pyx_n_s_context, ((PyObject *)__pyx_v_context)) < 0) __PYX_ERR(0, 816, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":816
 * 
 *     """
 *     return array(a, order='C', dtype=dtype, ndmin=1, copy=False,             # <<<<<<<<<<<<<<
 *                  context=context)
 * 
 */
  __pyx_t_4 = __Pyx_PyObject_Call(__pyx_t_1, __pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 816, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_r = __pyx_t_4;
  __pyx_t_4 = 0;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":797
 *                  cls=GpuArray)
 * 
 * def ascontiguousarray(a, dtype=None, GpuContext context=None):             # <<<<<<<<<<<<<<
 *     """
 *     ascontiguousarray(a, dtype=None, context=None)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_AddTraceback("pygpu.gpuarray.ascontiguousarray", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":819
 *                  context=context)
 * 
 * def asfortranarray(a, dtype=None, GpuArray context=None):             # <<<<<<<<<<<<<<
 *     """
 *     asfortranarray(a, dtype=None, context=None)
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_33asfortranarray(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static char __pyx_doc_5pygpu_8gpuarray_32asfortranarray[] = "\n    asfortranarray(a, dtype=None, context=None)\n\n    Returns a contiguous array in device memory (Fortran order)\n\n    `context` is optional if `a` is a GpuArray (but must match exactly\n    the context of `a` if specified) and is mandatory otherwise.\n\n    Parameters\n    ----------\n    a: array-like\n        input\n    dtype: str, numpy.dtype or int\n        type of the elements\n    context: GpuContext\n        context in which to do the allocation\n\n    ";
static PyMethodDef __pyx_mdef_5pygpu_8gpuarray_33asfortranarray = {"asfortranarray", (PyCFunction)__pyx_pw_5pygpu_8gpuarray_33asfortranarray, METH_VARARGS|METH_KEYWORDS, __pyx_doc_5pygpu_8gpuarray_32asfortranarray};
static PyObject *__pyx_pw_5pygpu_8gpuarray_33asfortranarray(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_a = 0;
  PyObject *__pyx_v_dtype = 0;
  struct PyGpuArrayObject *__pyx_v_context = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("asfortranarray (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_a,&__pyx_n_s_dtype,&__pyx_n_s_context,0};
    PyObject* values[3] = {0,0,0};
    values[1] = ((PyObject *)Py_None);
    values[2] = (PyObject *)((struct PyGpuArrayObject *)Py_None);
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_a)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_dtype);
          if (value) { values[1] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_context);
          if (value) { values[2] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "asfortranarray") < 0)) __PYX_ERR(0, 819, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    __pyx_v_a = values[0];
    __pyx_v_dtype = values[1];
    __pyx_v_context = ((struct PyGpuArrayObject *)values[2]);
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("asfortranarray", 0, 1, 3, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 819, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("pygpu.gpuarray.asfortranarray", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_context), __pyx_ptype_5pygpu_8gpuarray_GpuArray, 1, "context", 0))) __PYX_ERR(0, 819, __pyx_L1_error)
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_32asfortranarray(__pyx_self, __pyx_v_a, __pyx_v_dtype, __pyx_v_context);

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_32asfortranarray(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_a, PyObject *__pyx_v_dtype, struct PyGpuArrayObject *__pyx_v_context) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  __Pyx_RefNannySetupContext("asfortranarray", 0);

  /* "pygpu/gpuarray.pyx":838
 * 
 *     """
 *     return array(a, order='F', dtype=dtype, ndmin=1, copy=False,             # <<<<<<<<<<<<<<
 *                  context=context)
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_array); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 838, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = PyTuple_New(1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 838, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_INCREF(__pyx_v_a);
  __Pyx_GIVEREF(__pyx_v_a);
  PyTuple_SET_ITEM(__pyx_t_2, 0, __pyx_v_a);
  __pyx_t_3 = __Pyx_PyDict_NewPresized(5); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 838, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  if (PyDict_SetItem(__pyx_t_3, __pyx_n_s_order, __pyx_n_s_F) < 0) __PYX_ERR(0, 838, __pyx_L1_error)
  if (PyDict_SetItem(__pyx_t_3, __pyx_n_s_dtype, __pyx_v_dtype) < 0) __PYX_ERR(0, 838, __pyx_L1_error)
  if (PyDict_SetItem(__pyx_t_3, __pyx_n_s_ndmin, __pyx_int_1) < 0) __PYX_ERR(0, 838, __pyx_L1_error)
  if (PyDict_SetItem(__pyx_t_3, __pyx_n_s_copy, Py_False) < 0) __PYX_ERR(0, 838, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":839
 *     """
 *     return array(a, order='F', dtype=dtype, ndmin=1, copy=False,
 *                  context=context)             # <<<<<<<<<<<<<<
 * 
 * def may_share_memory(GpuArray a not None, GpuArray b not None):
 */
  if (PyDict_SetItem(__pyx_t_3, __pyx_n_s_context, ((PyObject *)__pyx_v_context)) < 0) __PYX_ERR(0, 838, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":838
 * 
 *     """
 *     return array(a, order='F', dtype=dtype, ndmin=1, copy=False,             # <<<<<<<<<<<<<<
 *                  context=context)
 * 
 */
  __pyx_t_4 = __Pyx_PyObject_Call(__pyx_t_1, __pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 838, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_r = __pyx_t_4;
  __pyx_t_4 = 0;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":819
 *                  context=context)
 * 
 * def asfortranarray(a, dtype=None, GpuArray context=None):             # <<<<<<<<<<<<<<
 *     """
 *     asfortranarray(a, dtype=None, context=None)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_AddTraceback("pygpu.gpuarray.asfortranarray", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":841
 *                  context=context)
 * 
 * def may_share_memory(GpuArray a not None, GpuArray b not None):             # <<<<<<<<<<<<<<
 *     """
 *     may_share_memory(a, b)
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_35may_share_memory(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static char __pyx_doc_5pygpu_8gpuarray_34may_share_memory[] = "\n    may_share_memory(a, b)\n\n    Returns True if `a` and `b` may share memory, False otherwise.\n    ";
static PyMethodDef __pyx_mdef_5pygpu_8gpuarray_35may_share_memory = {"may_share_memory", (PyCFunction)__pyx_pw_5pygpu_8gpuarray_35may_share_memory, METH_VARARGS|METH_KEYWORDS, __pyx_doc_5pygpu_8gpuarray_34may_share_memory};
static PyObject *__pyx_pw_5pygpu_8gpuarray_35may_share_memory(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  struct PyGpuArrayObject *__pyx_v_a = 0;
  struct PyGpuArrayObject *__pyx_v_b = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("may_share_memory (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_a,&__pyx_n_s_b,0};
    PyObject* values[2] = {0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_a)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_b)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("may_share_memory", 1, 2, 2, 1); __PYX_ERR(0, 841, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "may_share_memory") < 0)) __PYX_ERR(0, 841, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 2) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
    }
    __pyx_v_a = ((struct PyGpuArrayObject *)values[0]);
    __pyx_v_b = ((struct PyGpuArrayObject *)values[1]);
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("may_share_memory", 1, 2, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 841, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("pygpu.gpuarray.may_share_memory", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_a), __pyx_ptype_5pygpu_8gpuarray_GpuArray, 0, "a", 0))) __PYX_ERR(0, 841, __pyx_L1_error)
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_b), __pyx_ptype_5pygpu_8gpuarray_GpuArray, 0, "b", 0))) __PYX_ERR(0, 841, __pyx_L1_error)
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_34may_share_memory(__pyx_self, __pyx_v_a, __pyx_v_b);

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_34may_share_memory(CYTHON_UNUSED PyObject *__pyx_self, struct PyGpuArrayObject *__pyx_v_a, struct PyGpuArrayObject *__pyx_v_b) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("may_share_memory", 0);

  /* "pygpu/gpuarray.pyx":847
 *     Returns True if `a` and `b` may share memory, False otherwise.
 *     """
 *     return array_share(a, b)             # <<<<<<<<<<<<<<
 * 
 * def from_gpudata(size_t data, offset, dtype, shape, GpuContext context=None,
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyBool_FromLong(__pyx_f_5pygpu_8gpuarray_array_share(__pyx_v_a, __pyx_v_b)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 847, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":841
 *                  context=context)
 * 
 * def may_share_memory(GpuArray a not None, GpuArray b not None):             # <<<<<<<<<<<<<<
 *     """
 *     may_share_memory(a, b)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("pygpu.gpuarray.may_share_memory", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":849
 *     return array_share(a, b)
 * 
 * def from_gpudata(size_t data, offset, dtype, shape, GpuContext context=None,             # <<<<<<<<<<<<<<
 *                  strides=None, writable=True, base=None, cls=None):
 *     """
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_37from_gpudata(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static char __pyx_doc_5pygpu_8gpuarray_36from_gpudata[] = "\n    from_gpudata(data, offset, dtype, shape, context=None, strides=None, writable=True, base=None, cls=None)\n\n    Build a GpuArray from pre-allocated gpudata\n\n    Parameters\n    ----------\n    data: int\n        pointer to a gpudata structure\n    offset: int\n        offset to the data location inside the gpudata\n    dtype: numpy.dtype\n        data type of the gpudata elements\n    shape: iterable of ints\n        shape to use for the result\n    context: GpuContext\n        context of the gpudata\n    strides: iterable of ints\n        strides for the results (C contiguous if not specified)\n    writable: bool\n        is the data writable?\n    base: object\n        base object that keeps gpudata alive\n    cls: type\n        view type of the result\n\n    Notes\n    -----\n    This function might be deprecated in a later relase since the only\n    way to create gpudata pointers is through libgpuarray functions\n    that aren't exposed at the python level. It can be used with the\n    value of the `gpudata` attribute of an existing GpuArray.\n\n    .. warning::\n        This function is intended for advanced use and will crash the\n        interpreter if used improperly.\n\n\n    ";
static PyMethodDef __pyx_mdef_5pygpu_8gpuarray_37from_gpudata = {"from_gpudata", (PyCFunction)__pyx_pw_5pygpu_8gpuarray_37from_gpudata, METH_VARARGS|METH_KEYWORDS, __pyx_doc_5pygpu_8gpuarray_36from_gpudata};
static PyObject *__pyx_pw_5pygpu_8gpuarray_37from_gpudata(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  size_t __pyx_v_data;
  PyObject *__pyx_v_offset = 0;
  PyObject *__pyx_v_dtype = 0;
  PyObject *__pyx_v_shape = 0;
  struct PyGpuContextObject *__pyx_v_context = 0;
  PyObject *__pyx_v_strides = 0;
  PyObject *__pyx_v_writable = 0;
  PyObject *__pyx_v_base = 0;
  PyObject *__pyx_v_cls = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("from_gpudata (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_data,&__pyx_n_s_offset,&__pyx_n_s_dtype,&__pyx_n_s_shape,&__pyx_n_s_context,&__pyx_n_s_strides,&__pyx_n_s_writable,&__pyx_n_s_base,&__pyx_n_s_cls,0};
    PyObject* values[9] = {0,0,0,0,0,0,0,0,0};
    values[4] = (PyObject *)((struct PyGpuContextObject *)Py_None);

    /* "pygpu/gpuarray.pyx":850
 * 
 * def from_gpudata(size_t data, offset, dtype, shape, GpuContext context=None,
 *                  strides=None, writable=True, base=None, cls=None):             # <<<<<<<<<<<<<<
 *     """
 *     from_gpudata(data, offset, dtype, shape, context=None, strides=None, writable=True, base=None, cls=None)
 */
    values[5] = ((PyObject *)Py_None);
    values[6] = ((PyObject *)Py_True);
    values[7] = ((PyObject *)Py_None);
    values[8] = ((PyObject *)Py_None);
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  9: values[8] = PyTuple_GET_ITEM(__pyx_args, 8);
        CYTHON_FALLTHROUGH;
        case  8: values[7] = PyTuple_GET_ITEM(__pyx_args, 7);
        CYTHON_FALLTHROUGH;
        case  7: values[6] = PyTuple_GET_ITEM(__pyx_args, 6);
        CYTHON_FALLTHROUGH;
        case  6: values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
        CYTHON_FALLTHROUGH;
        case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
        CYTHON_FALLTHROUGH;
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_data)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_offset)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("from_gpudata", 0, 4, 9, 1); __PYX_ERR(0, 849, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_dtype)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("from_gpudata", 0, 4, 9, 2); __PYX_ERR(0, 849, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  3:
        if (likely((values[3] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_shape)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("from_gpudata", 0, 4, 9, 3); __PYX_ERR(0, 849, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  4:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_context);
          if (value) { values[4] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  5:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_strides);
          if (value) { values[5] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  6:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_writable);
          if (value) { values[6] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  7:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_base);
          if (value) { values[7] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  8:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_cls);
          if (value) { values[8] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "from_gpudata") < 0)) __PYX_ERR(0, 849, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  9: values[8] = PyTuple_GET_ITEM(__pyx_args, 8);
        CYTHON_FALLTHROUGH;
        case  8: values[7] = PyTuple_GET_ITEM(__pyx_args, 7);
        CYTHON_FALLTHROUGH;
        case  7: values[6] = PyTuple_GET_ITEM(__pyx_args, 6);
        CYTHON_FALLTHROUGH;
        case  6: values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
        CYTHON_FALLTHROUGH;
        case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
        CYTHON_FALLTHROUGH;
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    __pyx_v_data = __Pyx_PyInt_As_size_t(values[0]); if (unlikely((__pyx_v_data == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 849, __pyx_L3_error)
    __pyx_v_offset = values[1];
    __pyx_v_dtype = values[2];
    __pyx_v_shape = values[3];
    __pyx_v_context = ((struct PyGpuContextObject *)values[4]);
    __pyx_v_strides = values[5];
    __pyx_v_writable = values[6];
    __pyx_v_base = values[7];
    __pyx_v_cls = values[8];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("from_gpudata", 0, 4, 9, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 849, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("pygpu.gpuarray.from_gpudata", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_context), __pyx_ptype_5pygpu_8gpuarray_GpuContext, 1, "context", 0))) __PYX_ERR(0, 849, __pyx_L1_error)
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_36from_gpudata(__pyx_self, __pyx_v_data, __pyx_v_offset, __pyx_v_dtype, __pyx_v_shape, __pyx_v_context, __pyx_v_strides, __pyx_v_writable, __pyx_v_base, __pyx_v_cls);

  /* "pygpu/gpuarray.pyx":849
 *     return array_share(a, b)
 * 
 * def from_gpudata(size_t data, offset, dtype, shape, GpuContext context=None,             # <<<<<<<<<<<<<<
 *                  strides=None, writable=True, base=None, cls=None):
 *     """
 */

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_36from_gpudata(CYTHON_UNUSED PyObject *__pyx_self, size_t __pyx_v_data, PyObject *__pyx_v_offset, PyObject *__pyx_v_dtype, PyObject *__pyx_v_shape, struct PyGpuContextObject *__pyx_v_context, PyObject *__pyx_v_strides, PyObject *__pyx_v_writable, PyObject *__pyx_v_base, PyObject *__pyx_v_cls) {
  size_t *__pyx_v_cdims;
  Py_ssize_t *__pyx_v_cstrides;
  unsigned int __pyx_v_nd;
  size_t __pyx_v_size;
  int __pyx_v_typecode;
  PyObject *__pyx_v_i = NULL;
  PyObject *__pyx_v_d = NULL;
  PyObject *__pyx_v_s = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  Py_ssize_t __pyx_t_5;
  int __pyx_t_6;
  PyObject *__pyx_t_7 = NULL;
  PyObject *__pyx_t_8 = NULL;
  PyObject *__pyx_t_9 = NULL;
  int __pyx_t_10;
  int __pyx_t_11;
  int __pyx_t_12;
  PyObject *(*__pyx_t_13)(PyObject *);
  size_t __pyx_t_14;
  Py_ssize_t __pyx_t_15;
  Py_ssize_t __pyx_t_16;
  int __pyx_t_17;
  char const *__pyx_t_18;
  PyObject *__pyx_t_19 = NULL;
  PyObject *__pyx_t_20 = NULL;
  PyObject *__pyx_t_21 = NULL;
  __Pyx_RefNannySetupContext("from_gpudata", 0);
  __Pyx_INCREF(__pyx_v_shape);
  __Pyx_INCREF((PyObject *)__pyx_v_context);

  /* "pygpu/gpuarray.pyx":890
 * 
 *     """
 *     cdef size_t *cdims = NULL             # <<<<<<<<<<<<<<
 *     cdef ssize_t *cstrides = NULL
 *     cdef unsigned int nd
 */
  __pyx_v_cdims = NULL;

  /* "pygpu/gpuarray.pyx":891
 *     """
 *     cdef size_t *cdims = NULL
 *     cdef ssize_t *cstrides = NULL             # <<<<<<<<<<<<<<
 *     cdef unsigned int nd
 *     cdef size_t size
 */
  __pyx_v_cstrides = NULL;

  /* "pygpu/gpuarray.pyx":896
 *     cdef int typecode
 * 
 *     context = ensure_context(context)             # <<<<<<<<<<<<<<
 * 
 *     try:
 */
  __pyx_t_1 = ((PyObject *)__pyx_f_5pygpu_8gpuarray_ensure_context(__pyx_v_context)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 896, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF_SET(__pyx_v_context, ((struct PyGpuContextObject *)__pyx_t_1));
  __pyx_t_1 = 0;

  /* "pygpu/gpuarray.pyx":898
 *     context = ensure_context(context)
 * 
 *     try:             # <<<<<<<<<<<<<<
 *         nd = <unsigned int>len(shape)
 *     except TypeError:
 */
  {
    __Pyx_PyThreadState_declare
    __Pyx_PyThreadState_assign
    __Pyx_ExceptionSave(&__pyx_t_2, &__pyx_t_3, &__pyx_t_4);
    __Pyx_XGOTREF(__pyx_t_2);
    __Pyx_XGOTREF(__pyx_t_3);
    __Pyx_XGOTREF(__pyx_t_4);
    /*try:*/ {

      /* "pygpu/gpuarray.pyx":899
 * 
 *     try:
 *         nd = <unsigned int>len(shape)             # <<<<<<<<<<<<<<
 *     except TypeError:
 *         nd = 1
 */
      __pyx_t_5 = PyObject_Length(__pyx_v_shape); if (unlikely(__pyx_t_5 == ((Py_ssize_t)-1))) __PYX_ERR(0, 899, __pyx_L3_error)
      __pyx_v_nd = ((unsigned int)__pyx_t_5);

      /* "pygpu/gpuarray.pyx":898
 *     context = ensure_context(context)
 * 
 *     try:             # <<<<<<<<<<<<<<
 *         nd = <unsigned int>len(shape)
 *     except TypeError:
 */
    }
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
    goto __pyx_L8_try_end;
    __pyx_L3_error:;
    __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;

    /* "pygpu/gpuarray.pyx":900
 *     try:
 *         nd = <unsigned int>len(shape)
 *     except TypeError:             # <<<<<<<<<<<<<<
 *         nd = 1
 *         shape = [shape]
 */
    __pyx_t_6 = __Pyx_PyErr_ExceptionMatches(__pyx_builtin_TypeError);
    if (__pyx_t_6) {
      __Pyx_AddTraceback("pygpu.gpuarray.from_gpudata", __pyx_clineno, __pyx_lineno, __pyx_filename);
      if (__Pyx_GetException(&__pyx_t_1, &__pyx_t_7, &__pyx_t_8) < 0) __PYX_ERR(0, 900, __pyx_L5_except_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_GOTREF(__pyx_t_7);
      __Pyx_GOTREF(__pyx_t_8);

      /* "pygpu/gpuarray.pyx":901
 *         nd = <unsigned int>len(shape)
 *     except TypeError:
 *         nd = 1             # <<<<<<<<<<<<<<
 *         shape = [shape]
 * 
 */
      __pyx_v_nd = 1;

      /* "pygpu/gpuarray.pyx":902
 *     except TypeError:
 *         nd = 1
 *         shape = [shape]             # <<<<<<<<<<<<<<
 * 
 *     if strides is not None and len(strides) != nd:
 */
      __pyx_t_9 = PyList_New(1); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 902, __pyx_L5_except_error)
      __Pyx_GOTREF(__pyx_t_9);
      __Pyx_INCREF(__pyx_v_shape);
      __Pyx_GIVEREF(__pyx_v_shape);
      PyList_SET_ITEM(__pyx_t_9, 0, __pyx_v_shape);
      __Pyx_DECREF_SET(__pyx_v_shape, __pyx_t_9);
      __pyx_t_9 = 0;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      goto __pyx_L4_exception_handled;
    }
    goto __pyx_L5_except_error;
    __pyx_L5_except_error:;

    /* "pygpu/gpuarray.pyx":898
 *     context = ensure_context(context)
 * 
 *     try:             # <<<<<<<<<<<<<<
 *         nd = <unsigned int>len(shape)
 *     except TypeError:
 */
    __Pyx_XGIVEREF(__pyx_t_2);
    __Pyx_XGIVEREF(__pyx_t_3);
    __Pyx_XGIVEREF(__pyx_t_4);
    __Pyx_ExceptionReset(__pyx_t_2, __pyx_t_3, __pyx_t_4);
    goto __pyx_L1_error;
    __pyx_L4_exception_handled:;
    __Pyx_XGIVEREF(__pyx_t_2);
    __Pyx_XGIVEREF(__pyx_t_3);
    __Pyx_XGIVEREF(__pyx_t_4);
    __Pyx_ExceptionReset(__pyx_t_2, __pyx_t_3, __pyx_t_4);
    __pyx_L8_try_end:;
  }

  /* "pygpu/gpuarray.pyx":904
 *         shape = [shape]
 * 
 *     if strides is not None and len(strides) != nd:             # <<<<<<<<<<<<<<
 *         raise ValueError, "strides must be the same length as shape"
 * 
 */
  __pyx_t_11 = (__pyx_v_strides != Py_None);
  __pyx_t_12 = (__pyx_t_11 != 0);
  if (__pyx_t_12) {
  } else {
    __pyx_t_10 = __pyx_t_12;
    goto __pyx_L12_bool_binop_done;
  }
  __pyx_t_5 = PyObject_Length(__pyx_v_strides); if (unlikely(__pyx_t_5 == ((Py_ssize_t)-1))) __PYX_ERR(0, 904, __pyx_L1_error)
  __pyx_t_12 = ((__pyx_t_5 != __pyx_v_nd) != 0);
  __pyx_t_10 = __pyx_t_12;
  __pyx_L12_bool_binop_done:;
  if (__pyx_t_10) {

    /* "pygpu/gpuarray.pyx":905
 * 
 *     if strides is not None and len(strides) != nd:
 *         raise ValueError, "strides must be the same length as shape"             # <<<<<<<<<<<<<<
 * 
 *     typecode = dtype_to_typecode(dtype)
 */
    __Pyx_Raise(__pyx_builtin_ValueError, __pyx_kp_s_strides_must_be_the_same_length, 0, 0);
    __PYX_ERR(0, 905, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":904
 *         shape = [shape]
 * 
 *     if strides is not None and len(strides) != nd:             # <<<<<<<<<<<<<<
 *         raise ValueError, "strides must be the same length as shape"
 * 
 */
  }

  /* "pygpu/gpuarray.pyx":907
 *         raise ValueError, "strides must be the same length as shape"
 * 
 *     typecode = dtype_to_typecode(dtype)             # <<<<<<<<<<<<<<
 * 
 *     try:
 */
  __pyx_t_6 = __pyx_f_5pygpu_8gpuarray_dtype_to_typecode(__pyx_v_dtype, 0); if (unlikely(__pyx_t_6 == ((int)-1))) __PYX_ERR(0, 907, __pyx_L1_error)
  __pyx_v_typecode = __pyx_t_6;

  /* "pygpu/gpuarray.pyx":909
 *     typecode = dtype_to_typecode(dtype)
 * 
 *     try:             # <<<<<<<<<<<<<<
 *         cdims = <size_t *>calloc(nd, sizeof(size_t))
 *         cstrides = <ssize_t *>calloc(nd, sizeof(ssize_t))
 */
  /*try:*/ {

    /* "pygpu/gpuarray.pyx":910
 * 
 *     try:
 *         cdims = <size_t *>calloc(nd, sizeof(size_t))             # <<<<<<<<<<<<<<
 *         cstrides = <ssize_t *>calloc(nd, sizeof(ssize_t))
 *         if cdims == NULL or cstrides == NULL:
 */
    __pyx_v_cdims = ((size_t *)calloc(__pyx_v_nd, (sizeof(size_t))));

    /* "pygpu/gpuarray.pyx":911
 *     try:
 *         cdims = <size_t *>calloc(nd, sizeof(size_t))
 *         cstrides = <ssize_t *>calloc(nd, sizeof(ssize_t))             # <<<<<<<<<<<<<<
 *         if cdims == NULL or cstrides == NULL:
 *             raise MemoryError
 */
    __pyx_v_cstrides = ((Py_ssize_t *)calloc(__pyx_v_nd, (sizeof(Py_ssize_t))));

    /* "pygpu/gpuarray.pyx":912
 *         cdims = <size_t *>calloc(nd, sizeof(size_t))
 *         cstrides = <ssize_t *>calloc(nd, sizeof(ssize_t))
 *         if cdims == NULL or cstrides == NULL:             # <<<<<<<<<<<<<<
 *             raise MemoryError
 *         for i, d in enumerate(shape):
 */
    __pyx_t_12 = ((__pyx_v_cdims == NULL) != 0);
    if (!__pyx_t_12) {
    } else {
      __pyx_t_10 = __pyx_t_12;
      goto __pyx_L18_bool_binop_done;
    }
    __pyx_t_12 = ((__pyx_v_cstrides == NULL) != 0);
    __pyx_t_10 = __pyx_t_12;
    __pyx_L18_bool_binop_done:;
    if (__pyx_t_10) {

      /* "pygpu/gpuarray.pyx":913
 *         cstrides = <ssize_t *>calloc(nd, sizeof(ssize_t))
 *         if cdims == NULL or cstrides == NULL:
 *             raise MemoryError             # <<<<<<<<<<<<<<
 *         for i, d in enumerate(shape):
 *             cdims[i] = d
 */
      PyErr_NoMemory(); __PYX_ERR(0, 913, __pyx_L15_error)

      /* "pygpu/gpuarray.pyx":912
 *         cdims = <size_t *>calloc(nd, sizeof(size_t))
 *         cstrides = <ssize_t *>calloc(nd, sizeof(ssize_t))
 *         if cdims == NULL or cstrides == NULL:             # <<<<<<<<<<<<<<
 *             raise MemoryError
 *         for i, d in enumerate(shape):
 */
    }

    /* "pygpu/gpuarray.pyx":914
 *         if cdims == NULL or cstrides == NULL:
 *             raise MemoryError
 *         for i, d in enumerate(shape):             # <<<<<<<<<<<<<<
 *             cdims[i] = d
 *         if strides:
 */
    __Pyx_INCREF(__pyx_int_0);
    __pyx_t_8 = __pyx_int_0;
    if (likely(PyList_CheckExact(__pyx_v_shape)) || PyTuple_CheckExact(__pyx_v_shape)) {
      __pyx_t_7 = __pyx_v_shape; __Pyx_INCREF(__pyx_t_7); __pyx_t_5 = 0;
      __pyx_t_13 = NULL;
    } else {
      __pyx_t_5 = -1; __pyx_t_7 = PyObject_GetIter(__pyx_v_shape); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 914, __pyx_L15_error)
      __Pyx_GOTREF(__pyx_t_7);
      __pyx_t_13 = Py_TYPE(__pyx_t_7)->tp_iternext; if (unlikely(!__pyx_t_13)) __PYX_ERR(0, 914, __pyx_L15_error)
    }
    for (;;) {
      if (likely(!__pyx_t_13)) {
        if (likely(PyList_CheckExact(__pyx_t_7))) {
          if (__pyx_t_5 >= PyList_GET_SIZE(__pyx_t_7)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_1 = PyList_GET_ITEM(__pyx_t_7, __pyx_t_5); __Pyx_INCREF(__pyx_t_1); __pyx_t_5++; if (unlikely(0 < 0)) __PYX_ERR(0, 914, __pyx_L15_error)
          #else
          __pyx_t_1 = PySequence_ITEM(__pyx_t_7, __pyx_t_5); __pyx_t_5++; if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 914, __pyx_L15_error)
          __Pyx_GOTREF(__pyx_t_1);
          #endif
        } else {
          if (__pyx_t_5 >= PyTuple_GET_SIZE(__pyx_t_7)) break;
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_1 = PyTuple_GET_ITEM(__pyx_t_7, __pyx_t_5); __Pyx_INCREF(__pyx_t_1); __pyx_t_5++; if (unlikely(0 < 0)) __PYX_ERR(0, 914, __pyx_L15_error)
          #else
          __pyx_t_1 = PySequence_ITEM(__pyx_t_7, __pyx_t_5); __pyx_t_5++; if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 914, __pyx_L15_error)
          __Pyx_GOTREF(__pyx_t_1);
          #endif
        }
      } else {
        __pyx_t_1 = __pyx_t_13(__pyx_t_7);
        if (unlikely(!__pyx_t_1)) {
          PyObject* exc_type = PyErr_Occurred();
          if (exc_type) {
            if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
            else __PYX_ERR(0, 914, __pyx_L15_error)
          }
          break;
        }
        __Pyx_GOTREF(__pyx_t_1);
      }
      __Pyx_XDECREF_SET(__pyx_v_d, __pyx_t_1);
      __pyx_t_1 = 0;
      __Pyx_INCREF(__pyx_t_8);
      __Pyx_XDECREF_SET(__pyx_v_i, __pyx_t_8);
      __pyx_t_1 = __Pyx_PyInt_AddObjC(__pyx_t_8, __pyx_int_1, 1, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 914, __pyx_L15_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_8);
      __pyx_t_8 = __pyx_t_1;
      __pyx_t_1 = 0;

      /* "pygpu/gpuarray.pyx":915
 *             raise MemoryError
 *         for i, d in enumerate(shape):
 *             cdims[i] = d             # <<<<<<<<<<<<<<
 *         if strides:
 *             for i, s in enumerate(strides):
 */
      __pyx_t_14 = __Pyx_PyInt_As_size_t(__pyx_v_d); if (unlikely((__pyx_t_14 == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 915, __pyx_L15_error)
      __pyx_t_15 = __Pyx_PyIndex_AsSsize_t(__pyx_v_i); if (unlikely((__pyx_t_15 == (Py_ssize_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 915, __pyx_L15_error)
      (__pyx_v_cdims[__pyx_t_15]) = __pyx_t_14;

      /* "pygpu/gpuarray.pyx":914
 *         if cdims == NULL or cstrides == NULL:
 *             raise MemoryError
 *         for i, d in enumerate(shape):             # <<<<<<<<<<<<<<
 *             cdims[i] = d
 *         if strides:
 */
    }
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;

    /* "pygpu/gpuarray.pyx":916
 *         for i, d in enumerate(shape):
 *             cdims[i] = d
 *         if strides:             # <<<<<<<<<<<<<<
 *             for i, s in enumerate(strides):
 *                 cstrides[i] = s
 */
    __pyx_t_10 = __Pyx_PyObject_IsTrue(__pyx_v_strides); if (unlikely(__pyx_t_10 < 0)) __PYX_ERR(0, 916, __pyx_L15_error)
    if (__pyx_t_10) {

      /* "pygpu/gpuarray.pyx":917
 *             cdims[i] = d
 *         if strides:
 *             for i, s in enumerate(strides):             # <<<<<<<<<<<<<<
 *                 cstrides[i] = s
 *         else:
 */
      __Pyx_INCREF(__pyx_int_0);
      __pyx_t_8 = __pyx_int_0;
      if (likely(PyList_CheckExact(__pyx_v_strides)) || PyTuple_CheckExact(__pyx_v_strides)) {
        __pyx_t_7 = __pyx_v_strides; __Pyx_INCREF(__pyx_t_7); __pyx_t_5 = 0;
        __pyx_t_13 = NULL;
      } else {
        __pyx_t_5 = -1; __pyx_t_7 = PyObject_GetIter(__pyx_v_strides); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 917, __pyx_L15_error)
        __Pyx_GOTREF(__pyx_t_7);
        __pyx_t_13 = Py_TYPE(__pyx_t_7)->tp_iternext; if (unlikely(!__pyx_t_13)) __PYX_ERR(0, 917, __pyx_L15_error)
      }
      for (;;) {
        if (likely(!__pyx_t_13)) {
          if (likely(PyList_CheckExact(__pyx_t_7))) {
            if (__pyx_t_5 >= PyList_GET_SIZE(__pyx_t_7)) break;
            #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
            __pyx_t_1 = PyList_GET_ITEM(__pyx_t_7, __pyx_t_5); __Pyx_INCREF(__pyx_t_1); __pyx_t_5++; if (unlikely(0 < 0)) __PYX_ERR(0, 917, __pyx_L15_error)
            #else
            __pyx_t_1 = PySequence_ITEM(__pyx_t_7, __pyx_t_5); __pyx_t_5++; if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 917, __pyx_L15_error)
            __Pyx_GOTREF(__pyx_t_1);
            #endif
          } else {
            if (__pyx_t_5 >= PyTuple_GET_SIZE(__pyx_t_7)) break;
            #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
            __pyx_t_1 = PyTuple_GET_ITEM(__pyx_t_7, __pyx_t_5); __Pyx_INCREF(__pyx_t_1); __pyx_t_5++; if (unlikely(0 < 0)) __PYX_ERR(0, 917, __pyx_L15_error)
            #else
            __pyx_t_1 = PySequence_ITEM(__pyx_t_7, __pyx_t_5); __pyx_t_5++; if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 917, __pyx_L15_error)
            __Pyx_GOTREF(__pyx_t_1);
            #endif
          }
        } else {
          __pyx_t_1 = __pyx_t_13(__pyx_t_7);
          if (unlikely(!__pyx_t_1)) {
            PyObject* exc_type = PyErr_Occurred();
            if (exc_type) {
              if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
              else __PYX_ERR(0, 917, __pyx_L15_error)
            }
            break;
          }
          __Pyx_GOTREF(__pyx_t_1);
        }
        __Pyx_XDECREF_SET(__pyx_v_s, __pyx_t_1);
        __pyx_t_1 = 0;
        __Pyx_INCREF(__pyx_t_8);
        __Pyx_XDECREF_SET(__pyx_v_i, __pyx_t_8);
        __pyx_t_1 = __Pyx_PyInt_AddObjC(__pyx_t_8, __pyx_int_1, 1, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 917, __pyx_L15_error)
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_8);
        __pyx_t_8 = __pyx_t_1;
        __pyx_t_1 = 0;

        /* "pygpu/gpuarray.pyx":918
 *         if strides:
 *             for i, s in enumerate(strides):
 *                 cstrides[i] = s             # <<<<<<<<<<<<<<
 *         else:
 *             size = gpuarray_get_elsize(typecode)
 */
        __pyx_t_16 = PyInt_AsSsize_t(__pyx_v_s); if (unlikely((__pyx_t_16 == (Py_ssize_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 918, __pyx_L15_error)
        __pyx_t_15 = __Pyx_PyIndex_AsSsize_t(__pyx_v_i); if (unlikely((__pyx_t_15 == (Py_ssize_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 918, __pyx_L15_error)
        (__pyx_v_cstrides[__pyx_t_15]) = __pyx_t_16;

        /* "pygpu/gpuarray.pyx":917
 *             cdims[i] = d
 *         if strides:
 *             for i, s in enumerate(strides):             # <<<<<<<<<<<<<<
 *                 cstrides[i] = s
 *         else:
 */
      }
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;

      /* "pygpu/gpuarray.pyx":916
 *         for i, d in enumerate(shape):
 *             cdims[i] = d
 *         if strides:             # <<<<<<<<<<<<<<
 *             for i, s in enumerate(strides):
 *                 cstrides[i] = s
 */
      goto __pyx_L22;
    }

    /* "pygpu/gpuarray.pyx":920
 *                 cstrides[i] = s
 *         else:
 *             size = gpuarray_get_elsize(typecode)             # <<<<<<<<<<<<<<
 *             for i in range(nd-1, -1, -1):
 *                 cstrides[i] = size
 */
    /*else*/ {
      __pyx_v_size = gpuarray_get_elsize(__pyx_v_typecode);

      /* "pygpu/gpuarray.pyx":921
 *         else:
 *             size = gpuarray_get_elsize(typecode)
 *             for i in range(nd-1, -1, -1):             # <<<<<<<<<<<<<<
 *                 cstrides[i] = size
 *                 size *= cdims[i]
 */
      __pyx_t_8 = __Pyx_PyInt_From_long((__pyx_v_nd - 1)); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 921, __pyx_L15_error)
      __Pyx_GOTREF(__pyx_t_8);
      __pyx_t_7 = PyTuple_New(3); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 921, __pyx_L15_error)
      __Pyx_GOTREF(__pyx_t_7);
      __Pyx_GIVEREF(__pyx_t_8);
      PyTuple_SET_ITEM(__pyx_t_7, 0, __pyx_t_8);
      __Pyx_INCREF(__pyx_int_neg_1);
      __Pyx_GIVEREF(__pyx_int_neg_1);
      PyTuple_SET_ITEM(__pyx_t_7, 1, __pyx_int_neg_1);
      __Pyx_INCREF(__pyx_int_neg_1);
      __Pyx_GIVEREF(__pyx_int_neg_1);
      PyTuple_SET_ITEM(__pyx_t_7, 2, __pyx_int_neg_1);
      __pyx_t_8 = 0;
      __pyx_t_8 = __Pyx_PyObject_Call(__pyx_builtin_range, __pyx_t_7, NULL); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 921, __pyx_L15_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      if (likely(PyList_CheckExact(__pyx_t_8)) || PyTuple_CheckExact(__pyx_t_8)) {
        __pyx_t_7 = __pyx_t_8; __Pyx_INCREF(__pyx_t_7); __pyx_t_5 = 0;
        __pyx_t_13 = NULL;
      } else {
        __pyx_t_5 = -1; __pyx_t_7 = PyObject_GetIter(__pyx_t_8); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 921, __pyx_L15_error)
        __Pyx_GOTREF(__pyx_t_7);
        __pyx_t_13 = Py_TYPE(__pyx_t_7)->tp_iternext; if (unlikely(!__pyx_t_13)) __PYX_ERR(0, 921, __pyx_L15_error)
      }
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      for (;;) {
        if (likely(!__pyx_t_13)) {
          if (likely(PyList_CheckExact(__pyx_t_7))) {
            if (__pyx_t_5 >= PyList_GET_SIZE(__pyx_t_7)) break;
            #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
            __pyx_t_8 = PyList_GET_ITEM(__pyx_t_7, __pyx_t_5); __Pyx_INCREF(__pyx_t_8); __pyx_t_5++; if (unlikely(0 < 0)) __PYX_ERR(0, 921, __pyx_L15_error)
            #else
            __pyx_t_8 = PySequence_ITEM(__pyx_t_7, __pyx_t_5); __pyx_t_5++; if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 921, __pyx_L15_error)
            __Pyx_GOTREF(__pyx_t_8);
            #endif
          } else {
            if (__pyx_t_5 >= PyTuple_GET_SIZE(__pyx_t_7)) break;
            #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
            __pyx_t_8 = PyTuple_GET_ITEM(__pyx_t_7, __pyx_t_5); __Pyx_INCREF(__pyx_t_8); __pyx_t_5++; if (unlikely(0 < 0)) __PYX_ERR(0, 921, __pyx_L15_error)
            #else
            __pyx_t_8 = PySequence_ITEM(__pyx_t_7, __pyx_t_5); __pyx_t_5++; if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 921, __pyx_L15_error)
            __Pyx_GOTREF(__pyx_t_8);
            #endif
          }
        } else {
          __pyx_t_8 = __pyx_t_13(__pyx_t_7);
          if (unlikely(!__pyx_t_8)) {
            PyObject* exc_type = PyErr_Occurred();
            if (exc_type) {
              if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
              else __PYX_ERR(0, 921, __pyx_L15_error)
            }
            break;
          }
          __Pyx_GOTREF(__pyx_t_8);
        }
        __Pyx_XDECREF_SET(__pyx_v_i, __pyx_t_8);
        __pyx_t_8 = 0;

        /* "pygpu/gpuarray.pyx":922
 *             size = gpuarray_get_elsize(typecode)
 *             for i in range(nd-1, -1, -1):
 *                 cstrides[i] = size             # <<<<<<<<<<<<<<
 *                 size *= cdims[i]
 * 
 */
        __pyx_t_15 = __Pyx_PyIndex_AsSsize_t(__pyx_v_i); if (unlikely((__pyx_t_15 == (Py_ssize_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 922, __pyx_L15_error)
        (__pyx_v_cstrides[__pyx_t_15]) = __pyx_v_size;

        /* "pygpu/gpuarray.pyx":923
 *             for i in range(nd-1, -1, -1):
 *                 cstrides[i] = size
 *                 size *= cdims[i]             # <<<<<<<<<<<<<<
 * 
 *         return pygpu_fromgpudata(<gpudata *>data, offset, typecode, nd, cdims,
 */
        __pyx_t_15 = __Pyx_PyIndex_AsSsize_t(__pyx_v_i); if (unlikely((__pyx_t_15 == (Py_ssize_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 923, __pyx_L15_error)
        __pyx_v_size = (__pyx_v_size * (__pyx_v_cdims[__pyx_t_15]));

        /* "pygpu/gpuarray.pyx":921
 *         else:
 *             size = gpuarray_get_elsize(typecode)
 *             for i in range(nd-1, -1, -1):             # <<<<<<<<<<<<<<
 *                 cstrides[i] = size
 *                 size *= cdims[i]
 */
      }
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    }
    __pyx_L22:;

    /* "pygpu/gpuarray.pyx":925
 *                 size *= cdims[i]
 * 
 *         return pygpu_fromgpudata(<gpudata *>data, offset, typecode, nd, cdims,             # <<<<<<<<<<<<<<
 *                                  cstrides, context, writable, base, cls)
 *     finally:
 */
    __Pyx_XDECREF(__pyx_r);
    __pyx_t_14 = __Pyx_PyInt_As_size_t(__pyx_v_offset); if (unlikely((__pyx_t_14 == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 925, __pyx_L15_error)

    /* "pygpu/gpuarray.pyx":926
 * 
 *         return pygpu_fromgpudata(<gpudata *>data, offset, typecode, nd, cdims,
 *                                  cstrides, context, writable, base, cls)             # <<<<<<<<<<<<<<
 *     finally:
 *         free(cdims)
 */
    __pyx_t_10 = __Pyx_PyObject_IsTrue(__pyx_v_writable); if (unlikely((__pyx_t_10 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 926, __pyx_L15_error)

    /* "pygpu/gpuarray.pyx":925
 *                 size *= cdims[i]
 * 
 *         return pygpu_fromgpudata(<gpudata *>data, offset, typecode, nd, cdims,             # <<<<<<<<<<<<<<
 *                                  cstrides, context, writable, base, cls)
 *     finally:
 */
    __pyx_t_7 = ((PyObject *)__pyx_f_5pygpu_8gpuarray_pygpu_fromgpudata(((gpudata *)__pyx_v_data), __pyx_t_14, __pyx_v_typecode, __pyx_v_nd, __pyx_v_cdims, __pyx_v_cstrides, __pyx_v_context, __pyx_t_10, __pyx_v_base, __pyx_v_cls)); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 925, __pyx_L15_error)
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_r = __pyx_t_7;
    __pyx_t_7 = 0;
    goto __pyx_L14_return;
  }

  /* "pygpu/gpuarray.pyx":928
 *                                  cstrides, context, writable, base, cls)
 *     finally:
 *         free(cdims)             # <<<<<<<<<<<<<<
 *         free(cstrides)
 * 
 */
  /*finally:*/ {
    __pyx_L15_error:;
    /*exception exit:*/{
      __Pyx_PyThreadState_declare
      __Pyx_PyThreadState_assign
      __pyx_t_4 = 0; __pyx_t_3 = 0; __pyx_t_2 = 0; __pyx_t_19 = 0; __pyx_t_20 = 0; __pyx_t_21 = 0;
      __Pyx_XDECREF(__pyx_t_9); __pyx_t_9 = 0;
      __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
      __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
      __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
      if (PY_MAJOR_VERSION >= 3) __Pyx_ExceptionSwap(&__pyx_t_19, &__pyx_t_20, &__pyx_t_21);
      if ((PY_MAJOR_VERSION < 3) || unlikely(__Pyx_GetException(&__pyx_t_4, &__pyx_t_3, &__pyx_t_2) < 0)) __Pyx_ErrFetch(&__pyx_t_4, &__pyx_t_3, &__pyx_t_2);
      __Pyx_XGOTREF(__pyx_t_4);
      __Pyx_XGOTREF(__pyx_t_3);
      __Pyx_XGOTREF(__pyx_t_2);
      __Pyx_XGOTREF(__pyx_t_19);
      __Pyx_XGOTREF(__pyx_t_20);
      __Pyx_XGOTREF(__pyx_t_21);
      __pyx_t_6 = __pyx_lineno; __pyx_t_17 = __pyx_clineno; __pyx_t_18 = __pyx_filename;
      {
        free(__pyx_v_cdims);

        /* "pygpu/gpuarray.pyx":929
 *     finally:
 *         free(cdims)
 *         free(cstrides)             # <<<<<<<<<<<<<<
 * 
 * def array(proto, dtype=None, copy=True, order=None, unsigned int ndmin=0,
 */
        free(__pyx_v_cstrides);
      }
      if (PY_MAJOR_VERSION >= 3) {
        __Pyx_XGIVEREF(__pyx_t_19);
        __Pyx_XGIVEREF(__pyx_t_20);
        __Pyx_XGIVEREF(__pyx_t_21);
        __Pyx_ExceptionReset(__pyx_t_19, __pyx_t_20, __pyx_t_21);
      }
      __Pyx_XGIVEREF(__pyx_t_4);
      __Pyx_XGIVEREF(__pyx_t_3);
      __Pyx_XGIVEREF(__pyx_t_2);
      __Pyx_ErrRestore(__pyx_t_4, __pyx_t_3, __pyx_t_2);
      __pyx_t_4 = 0; __pyx_t_3 = 0; __pyx_t_2 = 0; __pyx_t_19 = 0; __pyx_t_20 = 0; __pyx_t_21 = 0;
      __pyx_lineno = __pyx_t_6; __pyx_clineno = __pyx_t_17; __pyx_filename = __pyx_t_18;
      goto __pyx_L1_error;
    }
    __pyx_L14_return: {
      __pyx_t_21 = __pyx_r;
      __pyx_r = 0;

      /* "pygpu/gpuarray.pyx":928
 *                                  cstrides, context, writable, base, cls)
 *     finally:
 *         free(cdims)             # <<<<<<<<<<<<<<
 *         free(cstrides)
 * 
 */
      free(__pyx_v_cdims);

      /* "pygpu/gpuarray.pyx":929
 *     finally:
 *         free(cdims)
 *         free(cstrides)             # <<<<<<<<<<<<<<
 * 
 * def array(proto, dtype=None, copy=True, order=None, unsigned int ndmin=0,
 */
      free(__pyx_v_cstrides);
      __pyx_r = __pyx_t_21;
      __pyx_t_21 = 0;
      goto __pyx_L0;
    }
  }

  /* "pygpu/gpuarray.pyx":849
 *     return array_share(a, b)
 * 
 * def from_gpudata(size_t data, offset, dtype, shape, GpuContext context=None,             # <<<<<<<<<<<<<<
 *                  strides=None, writable=True, base=None, cls=None):
 *     """
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_XDECREF(__pyx_t_9);
  __Pyx_AddTraceback("pygpu.gpuarray.from_gpudata", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_i);
  __Pyx_XDECREF(__pyx_v_d);
  __Pyx_XDECREF(__pyx_v_s);
  __Pyx_XDECREF(__pyx_v_shape);
  __Pyx_XDECREF((PyObject *)__pyx_v_context);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":931
 *         free(cstrides)
 * 
 * def array(proto, dtype=None, copy=True, order=None, unsigned int ndmin=0,             # <<<<<<<<<<<<<<
 *           GpuContext context=None, cls=None):
 *     """
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_39array(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static char __pyx_doc_5pygpu_8gpuarray_38array[] = "\n    array(obj, dtype='float64', copy=True, order=None, ndmin=0, context=None, cls=None)\n\n    Create a GpuArray from existing data\n\n    This function creates a new GpuArray from the data provided in\n    `obj` except if `obj` is already a GpuArray and all the parameters\n    match its properties and `copy` is False.\n\n    The properties of the resulting array depend on the input data\n    except if overriden by other parameters.\n\n    This function is similar to :meth:`numpy.array` except that it returns\n    GpuArrays.\n\n    Parameters\n    ----------\n    obj: array-like\n        data to initialize the result\n    dtype: string or numpy.dtype or int\n        data type of the result elements\n    copy: bool\n        return a copy?\n    order: str\n        memory layout of the result\n    ndmin: int\n        minimum number of result dimensions\n    context: GpuContext\n        allocation context\n    cls: type\n        result class (must inherit from GpuArray)\n\n    ";
static PyMethodDef __pyx_mdef_5pygpu_8gpuarray_39array = {"array", (PyCFunction)__pyx_pw_5pygpu_8gpuarray_39array, METH_VARARGS|METH_KEYWORDS, __pyx_doc_5pygpu_8gpuarray_38array};
static PyObject *__pyx_pw_5pygpu_8gpuarray_39array(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_proto = 0;
  PyObject *__pyx_v_dtype = 0;
  PyObject *__pyx_v_copy = 0;
  PyObject *__pyx_v_order = 0;
  unsigned int __pyx_v_ndmin;
  struct PyGpuContextObject *__pyx_v_context = 0;
  PyObject *__pyx_v_cls = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("array (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_proto,&__pyx_n_s_dtype,&__pyx_n_s_copy,&__pyx_n_s_order,&__pyx_n_s_ndmin,&__pyx_n_s_context,&__pyx_n_s_cls,0};
    PyObject* values[7] = {0,0,0,0,0,0,0};
    values[1] = ((PyObject *)Py_None);
    values[2] = ((PyObject *)Py_True);
    values[3] = ((PyObject *)Py_None);

    /* "pygpu/gpuarray.pyx":932
 * 
 * def array(proto, dtype=None, copy=True, order=None, unsigned int ndmin=0,
 *           GpuContext context=None, cls=None):             # <<<<<<<<<<<<<<
 *     """
 *     array(obj, dtype='float64', copy=True, order=None, ndmin=0, context=None, cls=None)
 */
    values[5] = (PyObject *)((struct PyGpuContextObject *)Py_None);
    values[6] = ((PyObject *)Py_None);
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  7: values[6] = PyTuple_GET_ITEM(__pyx_args, 6);
        CYTHON_FALLTHROUGH;
        case  6: values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
        CYTHON_FALLTHROUGH;
        case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
        CYTHON_FALLTHROUGH;
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_proto)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_dtype);
          if (value) { values[1] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_copy);
          if (value) { values[2] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  3:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_order);
          if (value) { values[3] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  4:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_ndmin);
          if (value) { values[4] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  5:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_context);
          if (value) { values[5] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  6:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_cls);
          if (value) { values[6] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "array") < 0)) __PYX_ERR(0, 931, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  7: values[6] = PyTuple_GET_ITEM(__pyx_args, 6);
        CYTHON_FALLTHROUGH;
        case  6: values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
        CYTHON_FALLTHROUGH;
        case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
        CYTHON_FALLTHROUGH;
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    __pyx_v_proto = values[0];
    __pyx_v_dtype = values[1];
    __pyx_v_copy = values[2];
    __pyx_v_order = values[3];
    if (values[4]) {
      __pyx_v_ndmin = __Pyx_PyInt_As_unsigned_int(values[4]); if (unlikely((__pyx_v_ndmin == (unsigned int)-1) && PyErr_Occurred())) __PYX_ERR(0, 931, __pyx_L3_error)
    } else {
      __pyx_v_ndmin = ((unsigned int)0);
    }
    __pyx_v_context = ((struct PyGpuContextObject *)values[5]);
    __pyx_v_cls = values[6];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("array", 0, 1, 7, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 931, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("pygpu.gpuarray.array", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_context), __pyx_ptype_5pygpu_8gpuarray_GpuContext, 1, "context", 0))) __PYX_ERR(0, 932, __pyx_L1_error)
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_38array(__pyx_self, __pyx_v_proto, __pyx_v_dtype, __pyx_v_copy, __pyx_v_order, __pyx_v_ndmin, __pyx_v_context, __pyx_v_cls);

  /* "pygpu/gpuarray.pyx":931
 *         free(cstrides)
 * 
 * def array(proto, dtype=None, copy=True, order=None, unsigned int ndmin=0,             # <<<<<<<<<<<<<<
 *           GpuContext context=None, cls=None):
 *     """
 */

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_38array(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_proto, PyObject *__pyx_v_dtype, PyObject *__pyx_v_copy, PyObject *__pyx_v_order, unsigned int __pyx_v_ndmin, struct PyGpuContextObject *__pyx_v_context, PyObject *__pyx_v_cls) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("array", 0);

  /* "pygpu/gpuarray.pyx":966
 * 
 *     """
 *     return carray(proto, dtype, copy, order, ndmin, context, cls)             # <<<<<<<<<<<<<<
 * 
 * cdef carray(proto, dtype, copy, order, unsigned int ndmin,
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __pyx_f_5pygpu_8gpuarray_carray(__pyx_v_proto, __pyx_v_dtype, __pyx_v_copy, __pyx_v_order, __pyx_v_ndmin, __pyx_v_context, __pyx_v_cls); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 966, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":931
 *         free(cstrides)
 * 
 * def array(proto, dtype=None, copy=True, order=None, unsigned int ndmin=0,             # <<<<<<<<<<<<<<
 *           GpuContext context=None, cls=None):
 *     """
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("pygpu.gpuarray.array", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":968
 *     return carray(proto, dtype, copy, order, ndmin, context, cls)
 * 
 * cdef carray(proto, dtype, copy, order, unsigned int ndmin,             # <<<<<<<<<<<<<<
 *             GpuContext context, cls):
 *     cdef GpuArray res
 */

static PyObject *__pyx_f_5pygpu_8gpuarray_carray(PyObject *__pyx_v_proto, PyObject *__pyx_v_dtype, PyObject *__pyx_v_copy, PyObject *__pyx_v_order, unsigned int __pyx_v_ndmin, struct PyGpuContextObject *__pyx_v_context, PyObject *__pyx_v_cls) {
  struct PyGpuArrayObject *__pyx_v_res = 0;
  struct PyGpuArrayObject *__pyx_v_arg = 0;
  struct PyGpuArrayObject *__pyx_v_tmp = 0;
  PyArrayObject *__pyx_v_a = 0;
  PyObject *__pyx_v_shp = NULL;
  PyObject *__pyx_v_idx = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_t_2;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  gpucontext *__pyx_t_5;
  int __pyx_t_6;
  PyObject *__pyx_t_7 = NULL;
  PyObject *__pyx_t_8 = NULL;
  Py_ssize_t __pyx_t_9;
  PyObject *__pyx_t_10 = NULL;
  PyObject *__pyx_t_11 = NULL;
  ga_order __pyx_t_12;
  __Pyx_RefNannySetupContext("carray", 0);
  __Pyx_INCREF(__pyx_v_order);
  __Pyx_INCREF((PyObject *)__pyx_v_context);
  __Pyx_INCREF(__pyx_v_cls);

  /* "pygpu/gpuarray.pyx":975
 *     cdef np.ndarray a
 * 
 *     if isinstance(proto, GpuArray):             # <<<<<<<<<<<<<<
 *         arg = proto
 * 
 */
  __pyx_t_1 = __Pyx_TypeCheck(__pyx_v_proto, __pyx_ptype_5pygpu_8gpuarray_GpuArray); 
  __pyx_t_2 = (__pyx_t_1 != 0);
  if (__pyx_t_2) {

    /* "pygpu/gpuarray.pyx":976
 * 
 *     if isinstance(proto, GpuArray):
 *         arg = proto             # <<<<<<<<<<<<<<
 * 
 *         if context is not None and  context.ctx != array_context(arg):
 */
    if (!(likely(((__pyx_v_proto) == Py_None) || likely(__Pyx_TypeTest(__pyx_v_proto, __pyx_ptype_5pygpu_8gpuarray_GpuArray))))) __PYX_ERR(0, 976, __pyx_L1_error)
    __pyx_t_3 = __pyx_v_proto;
    __Pyx_INCREF(__pyx_t_3);
    __pyx_v_arg = ((struct PyGpuArrayObject *)__pyx_t_3);
    __pyx_t_3 = 0;

    /* "pygpu/gpuarray.pyx":978
 *         arg = proto
 * 
 *         if context is not None and  context.ctx != array_context(arg):             # <<<<<<<<<<<<<<
 *             raise ValueError, "cannot copy an array to a different context"
 * 
 */
    __pyx_t_1 = (((PyObject *)__pyx_v_context) != Py_None);
    __pyx_t_4 = (__pyx_t_1 != 0);
    if (__pyx_t_4) {
    } else {
      __pyx_t_2 = __pyx_t_4;
      goto __pyx_L5_bool_binop_done;
    }
    __pyx_t_5 = __pyx_f_5pygpu_8gpuarray_array_context(__pyx_v_arg); if (unlikely(__pyx_t_5 == ((gpucontext *)NULL))) __PYX_ERR(0, 978, __pyx_L1_error)
    __pyx_t_4 = ((__pyx_v_context->ctx != __pyx_t_5) != 0);
    __pyx_t_2 = __pyx_t_4;
    __pyx_L5_bool_binop_done:;
    if (__pyx_t_2) {

      /* "pygpu/gpuarray.pyx":979
 * 
 *         if context is not None and  context.ctx != array_context(arg):
 *             raise ValueError, "cannot copy an array to a different context"             # <<<<<<<<<<<<<<
 * 
 *         if (not copy
 */
      __Pyx_Raise(__pyx_builtin_ValueError, __pyx_kp_s_cannot_copy_an_array_to_a_differ, 0, 0);
      __PYX_ERR(0, 979, __pyx_L1_error)

      /* "pygpu/gpuarray.pyx":978
 *         arg = proto
 * 
 *         if context is not None and  context.ctx != array_context(arg):             # <<<<<<<<<<<<<<
 *             raise ValueError, "cannot copy an array to a different context"
 * 
 */
    }

    /* "pygpu/gpuarray.pyx":981
 *             raise ValueError, "cannot copy an array to a different context"
 * 
 *         if (not copy             # <<<<<<<<<<<<<<
 *             and (dtype is None or dtype_to_typecode(dtype) == arg.typecode)
 *             and (order is None or order == 'A' or
 */
    __pyx_t_4 = __Pyx_PyObject_IsTrue(__pyx_v_copy); if (unlikely(__pyx_t_4 < 0)) __PYX_ERR(0, 981, __pyx_L1_error)
    __pyx_t_1 = ((!__pyx_t_4) != 0);
    if (__pyx_t_1) {
    } else {
      __pyx_t_2 = __pyx_t_1;
      goto __pyx_L8_bool_binop_done;
    }

    /* "pygpu/gpuarray.pyx":982
 * 
 *         if (not copy
 *             and (dtype is None or dtype_to_typecode(dtype) == arg.typecode)             # <<<<<<<<<<<<<<
 *             and (order is None or order == 'A' or
 *                  (order == 'C' and py_CHKFLAGS(arg, GA_C_CONTIGUOUS)) or
 */
    __pyx_t_1 = (__pyx_v_dtype == Py_None);
    __pyx_t_4 = (__pyx_t_1 != 0);
    if (!__pyx_t_4) {
    } else {
      goto __pyx_L10_next_and;
    }
    __pyx_t_6 = __pyx_f_5pygpu_8gpuarray_dtype_to_typecode(__pyx_v_dtype, 0); if (unlikely(__pyx_t_6 == ((int)-1))) __PYX_ERR(0, 982, __pyx_L1_error)
    __pyx_t_3 = __Pyx_PyInt_From_int(__pyx_t_6); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 982, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_7 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_arg), __pyx_n_s_typecode); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 982, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_t_8 = PyObject_RichCompare(__pyx_t_3, __pyx_t_7, Py_EQ); __Pyx_XGOTREF(__pyx_t_8); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 982, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __pyx_t_4 = __Pyx_PyObject_IsTrue(__pyx_t_8); if (unlikely(__pyx_t_4 < 0)) __PYX_ERR(0, 982, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    if (__pyx_t_4) {
    } else {
      __pyx_t_2 = __pyx_t_4;
      goto __pyx_L8_bool_binop_done;
    }
    __pyx_L10_next_and:;

    /* "pygpu/gpuarray.pyx":983
 *         if (not copy
 *             and (dtype is None or dtype_to_typecode(dtype) == arg.typecode)
 *             and (order is None or order == 'A' or             # <<<<<<<<<<<<<<
 *                  (order == 'C' and py_CHKFLAGS(arg, GA_C_CONTIGUOUS)) or
 *                  (order == 'F' and py_CHKFLAGS(arg, GA_F_CONTIGUOUS)))):
 */
    __pyx_t_4 = (__pyx_v_order == Py_None);
    __pyx_t_1 = (__pyx_t_4 != 0);
    if (!__pyx_t_1) {
    } else {
      __pyx_t_2 = __pyx_t_1;
      goto __pyx_L8_bool_binop_done;
    }
    __pyx_t_1 = (__Pyx_PyString_Equals(__pyx_v_order, __pyx_n_s_A, Py_EQ)); if (unlikely(__pyx_t_1 < 0)) __PYX_ERR(0, 983, __pyx_L1_error)
    if (!__pyx_t_1) {
    } else {
      __pyx_t_2 = __pyx_t_1;
      goto __pyx_L8_bool_binop_done;
    }

    /* "pygpu/gpuarray.pyx":984
 *             and (dtype is None or dtype_to_typecode(dtype) == arg.typecode)
 *             and (order is None or order == 'A' or
 *                  (order == 'C' and py_CHKFLAGS(arg, GA_C_CONTIGUOUS)) or             # <<<<<<<<<<<<<<
 *                  (order == 'F' and py_CHKFLAGS(arg, GA_F_CONTIGUOUS)))):
 *             if arg.ga.nd < ndmin:
 */
    __pyx_t_1 = (__Pyx_PyString_Equals(__pyx_v_order, __pyx_n_s_C, Py_EQ)); if (unlikely(__pyx_t_1 < 0)) __PYX_ERR(0, 984, __pyx_L1_error)
    if (!__pyx_t_1) {
      goto __pyx_L14_next_or;
    } else {
    }
    __pyx_t_1 = (__pyx_f_5pygpu_8gpuarray_py_CHKFLAGS(__pyx_v_arg, GA_C_CONTIGUOUS) != 0);
    if (!__pyx_t_1) {
    } else {
      __pyx_t_2 = __pyx_t_1;
      goto __pyx_L8_bool_binop_done;
    }
    __pyx_L14_next_or:;

    /* "pygpu/gpuarray.pyx":985
 *             and (order is None or order == 'A' or
 *                  (order == 'C' and py_CHKFLAGS(arg, GA_C_CONTIGUOUS)) or
 *                  (order == 'F' and py_CHKFLAGS(arg, GA_F_CONTIGUOUS)))):             # <<<<<<<<<<<<<<
 *             if arg.ga.nd < ndmin:
 *                 shp = arg.shape
 */
    __pyx_t_1 = (__Pyx_PyString_Equals(__pyx_v_order, __pyx_n_s_F, Py_EQ)); if (unlikely(__pyx_t_1 < 0)) __PYX_ERR(0, 985, __pyx_L1_error)
    if (__pyx_t_1) {
    } else {
      __pyx_t_2 = __pyx_t_1;
      goto __pyx_L8_bool_binop_done;
    }
    __pyx_t_1 = (__pyx_f_5pygpu_8gpuarray_py_CHKFLAGS(__pyx_v_arg, GA_F_CONTIGUOUS) != 0);
    __pyx_t_2 = __pyx_t_1;
    __pyx_L8_bool_binop_done:;

    /* "pygpu/gpuarray.pyx":981
 *             raise ValueError, "cannot copy an array to a different context"
 * 
 *         if (not copy             # <<<<<<<<<<<<<<
 *             and (dtype is None or dtype_to_typecode(dtype) == arg.typecode)
 *             and (order is None or order == 'A' or
 */
    if (__pyx_t_2) {

      /* "pygpu/gpuarray.pyx":986
 *                  (order == 'C' and py_CHKFLAGS(arg, GA_C_CONTIGUOUS)) or
 *                  (order == 'F' and py_CHKFLAGS(arg, GA_F_CONTIGUOUS)))):
 *             if arg.ga.nd < ndmin:             # <<<<<<<<<<<<<<
 *                 shp = arg.shape
 *                 idx = (1,)*(ndmin-len(shp))
 */
      __pyx_t_2 = ((__pyx_v_arg->ga.nd < __pyx_v_ndmin) != 0);
      if (__pyx_t_2) {

        /* "pygpu/gpuarray.pyx":987
 *                  (order == 'F' and py_CHKFLAGS(arg, GA_F_CONTIGUOUS)))):
 *             if arg.ga.nd < ndmin:
 *                 shp = arg.shape             # <<<<<<<<<<<<<<
 *                 idx = (1,)*(ndmin-len(shp))
 *                 shp = idx + shp
 */
        __pyx_t_8 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_arg), __pyx_n_s_shape); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 987, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_8);
        __pyx_v_shp = __pyx_t_8;
        __pyx_t_8 = 0;

        /* "pygpu/gpuarray.pyx":988
 *             if arg.ga.nd < ndmin:
 *                 shp = arg.shape
 *                 idx = (1,)*(ndmin-len(shp))             # <<<<<<<<<<<<<<
 *                 shp = idx + shp
 *                 arg = arg.reshape(shp)
 */
        __pyx_t_9 = PyObject_Length(__pyx_v_shp); if (unlikely(__pyx_t_9 == ((Py_ssize_t)-1))) __PYX_ERR(0, 988, __pyx_L1_error)
        __pyx_t_8 = PyInt_FromSsize_t((__pyx_v_ndmin - __pyx_t_9)); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 988, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_8);
        __pyx_t_7 = PyNumber_Multiply(__pyx_tuple__13, __pyx_t_8); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 988, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_7);
        __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
        __pyx_v_idx = ((PyObject*)__pyx_t_7);
        __pyx_t_7 = 0;

        /* "pygpu/gpuarray.pyx":989
 *                 shp = arg.shape
 *                 idx = (1,)*(ndmin-len(shp))
 *                 shp = idx + shp             # <<<<<<<<<<<<<<
 *                 arg = arg.reshape(shp)
 *             if not (cls is None or arg.__class__ is cls):
 */
        __pyx_t_7 = PyNumber_Add(__pyx_v_idx, __pyx_v_shp); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 989, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_7);
        __Pyx_DECREF_SET(__pyx_v_shp, __pyx_t_7);
        __pyx_t_7 = 0;

        /* "pygpu/gpuarray.pyx":990
 *                 idx = (1,)*(ndmin-len(shp))
 *                 shp = idx + shp
 *                 arg = arg.reshape(shp)             # <<<<<<<<<<<<<<
 *             if not (cls is None or arg.__class__ is cls):
 *                 arg = arg.view(cls)
 */
        __pyx_t_8 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_arg), __pyx_n_s_reshape); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 990, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_8);
        __pyx_t_3 = NULL;
        if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_8))) {
          __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_8);
          if (likely(__pyx_t_3)) {
            PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_8);
            __Pyx_INCREF(__pyx_t_3);
            __Pyx_INCREF(function);
            __Pyx_DECREF_SET(__pyx_t_8, function);
          }
        }
        if (!__pyx_t_3) {
          __pyx_t_7 = __Pyx_PyObject_CallOneArg(__pyx_t_8, __pyx_v_shp); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 990, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_7);
        } else {
          #if CYTHON_FAST_PYCALL
          if (PyFunction_Check(__pyx_t_8)) {
            PyObject *__pyx_temp[2] = {__pyx_t_3, __pyx_v_shp};
            __pyx_t_7 = __Pyx_PyFunction_FastCall(__pyx_t_8, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 990, __pyx_L1_error)
            __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
            __Pyx_GOTREF(__pyx_t_7);
          } else
          #endif
          #if CYTHON_FAST_PYCCALL
          if (__Pyx_PyFastCFunction_Check(__pyx_t_8)) {
            PyObject *__pyx_temp[2] = {__pyx_t_3, __pyx_v_shp};
            __pyx_t_7 = __Pyx_PyCFunction_FastCall(__pyx_t_8, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 990, __pyx_L1_error)
            __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
            __Pyx_GOTREF(__pyx_t_7);
          } else
          #endif
          {
            __pyx_t_10 = PyTuple_New(1+1); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 990, __pyx_L1_error)
            __Pyx_GOTREF(__pyx_t_10);
            __Pyx_GIVEREF(__pyx_t_3); PyTuple_SET_ITEM(__pyx_t_10, 0, __pyx_t_3); __pyx_t_3 = NULL;
            __Pyx_INCREF(__pyx_v_shp);
            __Pyx_GIVEREF(__pyx_v_shp);
            PyTuple_SET_ITEM(__pyx_t_10, 0+1, __pyx_v_shp);
            __pyx_t_7 = __Pyx_PyObject_Call(__pyx_t_8, __pyx_t_10, NULL); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 990, __pyx_L1_error)
            __Pyx_GOTREF(__pyx_t_7);
            __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
          }
        }
        __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
        if (!(likely(((__pyx_t_7) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_7, __pyx_ptype_5pygpu_8gpuarray_GpuArray))))) __PYX_ERR(0, 990, __pyx_L1_error)
        __Pyx_DECREF_SET(__pyx_v_arg, ((struct PyGpuArrayObject *)__pyx_t_7));
        __pyx_t_7 = 0;

        /* "pygpu/gpuarray.pyx":986
 *                  (order == 'C' and py_CHKFLAGS(arg, GA_C_CONTIGUOUS)) or
 *                  (order == 'F' and py_CHKFLAGS(arg, GA_F_CONTIGUOUS)))):
 *             if arg.ga.nd < ndmin:             # <<<<<<<<<<<<<<
 *                 shp = arg.shape
 *                 idx = (1,)*(ndmin-len(shp))
 */
      }

      /* "pygpu/gpuarray.pyx":991
 *                 shp = idx + shp
 *                 arg = arg.reshape(shp)
 *             if not (cls is None or arg.__class__ is cls):             # <<<<<<<<<<<<<<
 *                 arg = arg.view(cls)
 *             return arg
 */
      __pyx_t_1 = (__pyx_v_cls == Py_None);
      __pyx_t_4 = (__pyx_t_1 != 0);
      if (!__pyx_t_4) {
      } else {
        __pyx_t_2 = __pyx_t_4;
        goto __pyx_L19_bool_binop_done;
      }
      __pyx_t_7 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_arg), __pyx_n_s_class); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 991, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      __pyx_t_4 = (__pyx_t_7 == __pyx_v_cls);
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      __pyx_t_1 = (__pyx_t_4 != 0);
      __pyx_t_2 = __pyx_t_1;
      __pyx_L19_bool_binop_done:;
      __pyx_t_1 = ((!__pyx_t_2) != 0);
      if (__pyx_t_1) {

        /* "pygpu/gpuarray.pyx":992
 *                 arg = arg.reshape(shp)
 *             if not (cls is None or arg.__class__ is cls):
 *                 arg = arg.view(cls)             # <<<<<<<<<<<<<<
 *             return arg
 *         shp = arg.shape
 */
        __pyx_t_8 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_arg), __pyx_n_s_view); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 992, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_8);
        __pyx_t_10 = NULL;
        if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_8))) {
          __pyx_t_10 = PyMethod_GET_SELF(__pyx_t_8);
          if (likely(__pyx_t_10)) {
            PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_8);
            __Pyx_INCREF(__pyx_t_10);
            __Pyx_INCREF(function);
            __Pyx_DECREF_SET(__pyx_t_8, function);
          }
        }
        if (!__pyx_t_10) {
          __pyx_t_7 = __Pyx_PyObject_CallOneArg(__pyx_t_8, __pyx_v_cls); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 992, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_7);
        } else {
          #if CYTHON_FAST_PYCALL
          if (PyFunction_Check(__pyx_t_8)) {
            PyObject *__pyx_temp[2] = {__pyx_t_10, __pyx_v_cls};
            __pyx_t_7 = __Pyx_PyFunction_FastCall(__pyx_t_8, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 992, __pyx_L1_error)
            __Pyx_XDECREF(__pyx_t_10); __pyx_t_10 = 0;
            __Pyx_GOTREF(__pyx_t_7);
          } else
          #endif
          #if CYTHON_FAST_PYCCALL
          if (__Pyx_PyFastCFunction_Check(__pyx_t_8)) {
            PyObject *__pyx_temp[2] = {__pyx_t_10, __pyx_v_cls};
            __pyx_t_7 = __Pyx_PyCFunction_FastCall(__pyx_t_8, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 992, __pyx_L1_error)
            __Pyx_XDECREF(__pyx_t_10); __pyx_t_10 = 0;
            __Pyx_GOTREF(__pyx_t_7);
          } else
          #endif
          {
            __pyx_t_3 = PyTuple_New(1+1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 992, __pyx_L1_error)
            __Pyx_GOTREF(__pyx_t_3);
            __Pyx_GIVEREF(__pyx_t_10); PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_10); __pyx_t_10 = NULL;
            __Pyx_INCREF(__pyx_v_cls);
            __Pyx_GIVEREF(__pyx_v_cls);
            PyTuple_SET_ITEM(__pyx_t_3, 0+1, __pyx_v_cls);
            __pyx_t_7 = __Pyx_PyObject_Call(__pyx_t_8, __pyx_t_3, NULL); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 992, __pyx_L1_error)
            __Pyx_GOTREF(__pyx_t_7);
            __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
          }
        }
        __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
        if (!(likely(((__pyx_t_7) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_7, __pyx_ptype_5pygpu_8gpuarray_GpuArray))))) __PYX_ERR(0, 992, __pyx_L1_error)
        __Pyx_DECREF_SET(__pyx_v_arg, ((struct PyGpuArrayObject *)__pyx_t_7));
        __pyx_t_7 = 0;

        /* "pygpu/gpuarray.pyx":991
 *                 shp = idx + shp
 *                 arg = arg.reshape(shp)
 *             if not (cls is None or arg.__class__ is cls):             # <<<<<<<<<<<<<<
 *                 arg = arg.view(cls)
 *             return arg
 */
      }

      /* "pygpu/gpuarray.pyx":993
 *             if not (cls is None or arg.__class__ is cls):
 *                 arg = arg.view(cls)
 *             return arg             # <<<<<<<<<<<<<<
 *         shp = arg.shape
 *         if len(shp) < ndmin:
 */
      __Pyx_XDECREF(__pyx_r);
      __Pyx_INCREF(((PyObject *)__pyx_v_arg));
      __pyx_r = ((PyObject *)__pyx_v_arg);
      goto __pyx_L0;

      /* "pygpu/gpuarray.pyx":981
 *             raise ValueError, "cannot copy an array to a different context"
 * 
 *         if (not copy             # <<<<<<<<<<<<<<
 *             and (dtype is None or dtype_to_typecode(dtype) == arg.typecode)
 *             and (order is None or order == 'A' or
 */
    }

    /* "pygpu/gpuarray.pyx":994
 *                 arg = arg.view(cls)
 *             return arg
 *         shp = arg.shape             # <<<<<<<<<<<<<<
 *         if len(shp) < ndmin:
 *             idx = (1,)*(ndmin-len(shp))
 */
    __pyx_t_7 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_arg), __pyx_n_s_shape); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 994, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_v_shp = __pyx_t_7;
    __pyx_t_7 = 0;

    /* "pygpu/gpuarray.pyx":995
 *             return arg
 *         shp = arg.shape
 *         if len(shp) < ndmin:             # <<<<<<<<<<<<<<
 *             idx = (1,)*(ndmin-len(shp))
 *             shp = idx + shp
 */
    __pyx_t_9 = PyObject_Length(__pyx_v_shp); if (unlikely(__pyx_t_9 == ((Py_ssize_t)-1))) __PYX_ERR(0, 995, __pyx_L1_error)
    __pyx_t_1 = ((__pyx_t_9 < __pyx_v_ndmin) != 0);
    if (__pyx_t_1) {

      /* "pygpu/gpuarray.pyx":996
 *         shp = arg.shape
 *         if len(shp) < ndmin:
 *             idx = (1,)*(ndmin-len(shp))             # <<<<<<<<<<<<<<
 *             shp = idx + shp
 *         if order is None or order == 'A':
 */
      __pyx_t_9 = PyObject_Length(__pyx_v_shp); if (unlikely(__pyx_t_9 == ((Py_ssize_t)-1))) __PYX_ERR(0, 996, __pyx_L1_error)
      __pyx_t_7 = PyInt_FromSsize_t((__pyx_v_ndmin - __pyx_t_9)); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 996, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      __pyx_t_8 = PyNumber_Multiply(__pyx_tuple__14, __pyx_t_7); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 996, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      __pyx_v_idx = ((PyObject*)__pyx_t_8);
      __pyx_t_8 = 0;

      /* "pygpu/gpuarray.pyx":997
 *         if len(shp) < ndmin:
 *             idx = (1,)*(ndmin-len(shp))
 *             shp = idx + shp             # <<<<<<<<<<<<<<
 *         if order is None or order == 'A':
 *             if py_CHKFLAGS(arg, GA_C_CONTIGUOUS):
 */
      __pyx_t_8 = PyNumber_Add(__pyx_v_idx, __pyx_v_shp); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 997, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_DECREF_SET(__pyx_v_shp, __pyx_t_8);
      __pyx_t_8 = 0;

      /* "pygpu/gpuarray.pyx":995
 *             return arg
 *         shp = arg.shape
 *         if len(shp) < ndmin:             # <<<<<<<<<<<<<<
 *             idx = (1,)*(ndmin-len(shp))
 *             shp = idx + shp
 */
    }

    /* "pygpu/gpuarray.pyx":998
 *             idx = (1,)*(ndmin-len(shp))
 *             shp = idx + shp
 *         if order is None or order == 'A':             # <<<<<<<<<<<<<<
 *             if py_CHKFLAGS(arg, GA_C_CONTIGUOUS):
 *                 order = 'C'
 */
    __pyx_t_2 = (__pyx_v_order == Py_None);
    __pyx_t_4 = (__pyx_t_2 != 0);
    if (!__pyx_t_4) {
    } else {
      __pyx_t_1 = __pyx_t_4;
      goto __pyx_L23_bool_binop_done;
    }
    __pyx_t_4 = (__Pyx_PyString_Equals(__pyx_v_order, __pyx_n_s_A, Py_EQ)); if (unlikely(__pyx_t_4 < 0)) __PYX_ERR(0, 998, __pyx_L1_error)
    __pyx_t_1 = __pyx_t_4;
    __pyx_L23_bool_binop_done:;
    if (__pyx_t_1) {

      /* "pygpu/gpuarray.pyx":999
 *             shp = idx + shp
 *         if order is None or order == 'A':
 *             if py_CHKFLAGS(arg, GA_C_CONTIGUOUS):             # <<<<<<<<<<<<<<
 *                 order = 'C'
 *             elif py_CHKFLAGS(arg, GA_F_CONTIGUOUS):
 */
      __pyx_t_1 = (__pyx_f_5pygpu_8gpuarray_py_CHKFLAGS(__pyx_v_arg, GA_C_CONTIGUOUS) != 0);
      if (__pyx_t_1) {

        /* "pygpu/gpuarray.pyx":1000
 *         if order is None or order == 'A':
 *             if py_CHKFLAGS(arg, GA_C_CONTIGUOUS):
 *                 order = 'C'             # <<<<<<<<<<<<<<
 *             elif py_CHKFLAGS(arg, GA_F_CONTIGUOUS):
 *                 order = 'F'
 */
        __Pyx_INCREF(__pyx_n_s_C);
        __Pyx_DECREF_SET(__pyx_v_order, __pyx_n_s_C);

        /* "pygpu/gpuarray.pyx":999
 *             shp = idx + shp
 *         if order is None or order == 'A':
 *             if py_CHKFLAGS(arg, GA_C_CONTIGUOUS):             # <<<<<<<<<<<<<<
 *                 order = 'C'
 *             elif py_CHKFLAGS(arg, GA_F_CONTIGUOUS):
 */
        goto __pyx_L25;
      }

      /* "pygpu/gpuarray.pyx":1001
 *             if py_CHKFLAGS(arg, GA_C_CONTIGUOUS):
 *                 order = 'C'
 *             elif py_CHKFLAGS(arg, GA_F_CONTIGUOUS):             # <<<<<<<<<<<<<<
 *                 order = 'F'
 *         if cls is None:
 */
      __pyx_t_1 = (__pyx_f_5pygpu_8gpuarray_py_CHKFLAGS(__pyx_v_arg, GA_F_CONTIGUOUS) != 0);
      if (__pyx_t_1) {

        /* "pygpu/gpuarray.pyx":1002
 *                 order = 'C'
 *             elif py_CHKFLAGS(arg, GA_F_CONTIGUOUS):
 *                 order = 'F'             # <<<<<<<<<<<<<<
 *         if cls is None:
 *             cls = type(proto)
 */
        __Pyx_INCREF(__pyx_n_s_F);
        __Pyx_DECREF_SET(__pyx_v_order, __pyx_n_s_F);

        /* "pygpu/gpuarray.pyx":1001
 *             if py_CHKFLAGS(arg, GA_C_CONTIGUOUS):
 *                 order = 'C'
 *             elif py_CHKFLAGS(arg, GA_F_CONTIGUOUS):             # <<<<<<<<<<<<<<
 *                 order = 'F'
 *         if cls is None:
 */
      }
      __pyx_L25:;

      /* "pygpu/gpuarray.pyx":998
 *             idx = (1,)*(ndmin-len(shp))
 *             shp = idx + shp
 *         if order is None or order == 'A':             # <<<<<<<<<<<<<<
 *             if py_CHKFLAGS(arg, GA_C_CONTIGUOUS):
 *                 order = 'C'
 */
    }

    /* "pygpu/gpuarray.pyx":1003
 *             elif py_CHKFLAGS(arg, GA_F_CONTIGUOUS):
 *                 order = 'F'
 *         if cls is None:             # <<<<<<<<<<<<<<
 *             cls = type(proto)
 *         res = empty(shp, dtype=(dtype or arg.dtype), order=order, cls=cls,
 */
    __pyx_t_1 = (__pyx_v_cls == Py_None);
    __pyx_t_4 = (__pyx_t_1 != 0);
    if (__pyx_t_4) {

      /* "pygpu/gpuarray.pyx":1004
 *                 order = 'F'
 *         if cls is None:
 *             cls = type(proto)             # <<<<<<<<<<<<<<
 *         res = empty(shp, dtype=(dtype or arg.dtype), order=order, cls=cls,
 *                     context=arg.context)
 */
      __Pyx_INCREF(((PyObject *)Py_TYPE(__pyx_v_proto)));
      __Pyx_DECREF_SET(__pyx_v_cls, ((PyObject *)Py_TYPE(__pyx_v_proto)));

      /* "pygpu/gpuarray.pyx":1003
 *             elif py_CHKFLAGS(arg, GA_F_CONTIGUOUS):
 *                 order = 'F'
 *         if cls is None:             # <<<<<<<<<<<<<<
 *             cls = type(proto)
 *         res = empty(shp, dtype=(dtype or arg.dtype), order=order, cls=cls,
 */
    }

    /* "pygpu/gpuarray.pyx":1005
 *         if cls is None:
 *             cls = type(proto)
 *         res = empty(shp, dtype=(dtype or arg.dtype), order=order, cls=cls,             # <<<<<<<<<<<<<<
 *                     context=arg.context)
 *         res.base = arg.base
 */
    __pyx_t_8 = __Pyx_GetModuleGlobalName(__pyx_n_s_empty); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1005, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __pyx_t_7 = PyTuple_New(1); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 1005, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_INCREF(__pyx_v_shp);
    __Pyx_GIVEREF(__pyx_v_shp);
    PyTuple_SET_ITEM(__pyx_t_7, 0, __pyx_v_shp);
    __pyx_t_3 = __Pyx_PyDict_NewPresized(4); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1005, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_4 = __Pyx_PyObject_IsTrue(__pyx_v_dtype); if (unlikely(__pyx_t_4 < 0)) __PYX_ERR(0, 1005, __pyx_L1_error)
    if (!__pyx_t_4) {
    } else {
      __Pyx_INCREF(__pyx_v_dtype);
      __pyx_t_10 = __pyx_v_dtype;
      goto __pyx_L27_bool_binop_done;
    }
    __pyx_t_11 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_arg), __pyx_n_s_dtype); if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 1005, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_11);
    __Pyx_INCREF(__pyx_t_11);
    __pyx_t_10 = __pyx_t_11;
    __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
    __pyx_L27_bool_binop_done:;
    if (PyDict_SetItem(__pyx_t_3, __pyx_n_s_dtype, __pyx_t_10) < 0) __PYX_ERR(0, 1005, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
    if (PyDict_SetItem(__pyx_t_3, __pyx_n_s_order, __pyx_v_order) < 0) __PYX_ERR(0, 1005, __pyx_L1_error)
    if (PyDict_SetItem(__pyx_t_3, __pyx_n_s_cls, __pyx_v_cls) < 0) __PYX_ERR(0, 1005, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":1006
 *             cls = type(proto)
 *         res = empty(shp, dtype=(dtype or arg.dtype), order=order, cls=cls,
 *                     context=arg.context)             # <<<<<<<<<<<<<<
 *         res.base = arg.base
 *         if len(shp) < ndmin:
 */
    if (PyDict_SetItem(__pyx_t_3, __pyx_n_s_context, ((PyObject *)__pyx_v_arg->context)) < 0) __PYX_ERR(0, 1005, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":1005
 *         if cls is None:
 *             cls = type(proto)
 *         res = empty(shp, dtype=(dtype or arg.dtype), order=order, cls=cls,             # <<<<<<<<<<<<<<
 *                     context=arg.context)
 *         res.base = arg.base
 */
    __pyx_t_10 = __Pyx_PyObject_Call(__pyx_t_8, __pyx_t_7, __pyx_t_3); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 1005, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    if (!(likely(((__pyx_t_10) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_10, __pyx_ptype_5pygpu_8gpuarray_GpuArray))))) __PYX_ERR(0, 1005, __pyx_L1_error)
    __pyx_v_res = ((struct PyGpuArrayObject *)__pyx_t_10);
    __pyx_t_10 = 0;

    /* "pygpu/gpuarray.pyx":1007
 *         res = empty(shp, dtype=(dtype or arg.dtype), order=order, cls=cls,
 *                     context=arg.context)
 *         res.base = arg.base             # <<<<<<<<<<<<<<
 *         if len(shp) < ndmin:
 *             tmp = res[idx]
 */
    __pyx_t_10 = __pyx_v_arg->base;
    __Pyx_INCREF(__pyx_t_10);
    __Pyx_GIVEREF(__pyx_t_10);
    __Pyx_GOTREF(__pyx_v_res->base);
    __Pyx_DECREF(__pyx_v_res->base);
    __pyx_v_res->base = __pyx_t_10;
    __pyx_t_10 = 0;

    /* "pygpu/gpuarray.pyx":1008
 *                     context=arg.context)
 *         res.base = arg.base
 *         if len(shp) < ndmin:             # <<<<<<<<<<<<<<
 *             tmp = res[idx]
 *         else:
 */
    __pyx_t_9 = PyObject_Length(__pyx_v_shp); if (unlikely(__pyx_t_9 == ((Py_ssize_t)-1))) __PYX_ERR(0, 1008, __pyx_L1_error)
    __pyx_t_4 = ((__pyx_t_9 < __pyx_v_ndmin) != 0);
    if (__pyx_t_4) {

      /* "pygpu/gpuarray.pyx":1009
 *         res.base = arg.base
 *         if len(shp) < ndmin:
 *             tmp = res[idx]             # <<<<<<<<<<<<<<
 *         else:
 *             tmp = res
 */
      if (unlikely(!__pyx_v_idx)) { __Pyx_RaiseUnboundLocalError("idx"); __PYX_ERR(0, 1009, __pyx_L1_error) }
      __pyx_t_10 = PyObject_GetItem(((PyObject *)__pyx_v_res), __pyx_v_idx); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 1009, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_10);
      if (!(likely(((__pyx_t_10) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_10, __pyx_ptype_5pygpu_8gpuarray_GpuArray))))) __PYX_ERR(0, 1009, __pyx_L1_error)
      __pyx_v_tmp = ((struct PyGpuArrayObject *)__pyx_t_10);
      __pyx_t_10 = 0;

      /* "pygpu/gpuarray.pyx":1008
 *                     context=arg.context)
 *         res.base = arg.base
 *         if len(shp) < ndmin:             # <<<<<<<<<<<<<<
 *             tmp = res[idx]
 *         else:
 */
      goto __pyx_L29;
    }

    /* "pygpu/gpuarray.pyx":1011
 *             tmp = res[idx]
 *         else:
 *             tmp = res             # <<<<<<<<<<<<<<
 *         array_move(tmp, arg)
 *         return res
 */
    /*else*/ {
      __Pyx_INCREF(((PyObject *)__pyx_v_res));
      __pyx_v_tmp = __pyx_v_res;
    }
    __pyx_L29:;

    /* "pygpu/gpuarray.pyx":1012
 *         else:
 *             tmp = res
 *         array_move(tmp, arg)             # <<<<<<<<<<<<<<
 *         return res
 * 
 */
    __pyx_t_6 = __pyx_f_5pygpu_8gpuarray_array_move(__pyx_v_tmp, __pyx_v_arg); if (unlikely(__pyx_t_6 == ((int)-1))) __PYX_ERR(0, 1012, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":1013
 *             tmp = res
 *         array_move(tmp, arg)
 *         return res             # <<<<<<<<<<<<<<
 * 
 *     context = ensure_context(context)
 */
    __Pyx_XDECREF(__pyx_r);
    __Pyx_INCREF(((PyObject *)__pyx_v_res));
    __pyx_r = ((PyObject *)__pyx_v_res);
    goto __pyx_L0;

    /* "pygpu/gpuarray.pyx":975
 *     cdef np.ndarray a
 * 
 *     if isinstance(proto, GpuArray):             # <<<<<<<<<<<<<<
 *         arg = proto
 * 
 */
  }

  /* "pygpu/gpuarray.pyx":1015
 *         return res
 * 
 *     context = ensure_context(context)             # <<<<<<<<<<<<<<
 * 
 *     # We need a contiguous array for the copy
 */
  __pyx_t_10 = ((PyObject *)__pyx_f_5pygpu_8gpuarray_ensure_context(__pyx_v_context)); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 1015, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_10);
  __Pyx_DECREF_SET(__pyx_v_context, ((struct PyGpuContextObject *)__pyx_t_10));
  __pyx_t_10 = 0;

  /* "pygpu/gpuarray.pyx":1018
 * 
 *     # We need a contiguous array for the copy
 *     if order != 'C' and order != 'F':             # <<<<<<<<<<<<<<
 *         order = 'C'
 * 
 */
  __pyx_t_1 = (__Pyx_PyString_Equals(__pyx_v_order, __pyx_n_s_C, Py_NE)); if (unlikely(__pyx_t_1 < 0)) __PYX_ERR(0, 1018, __pyx_L1_error)
  if (__pyx_t_1) {
  } else {
    __pyx_t_4 = __pyx_t_1;
    goto __pyx_L31_bool_binop_done;
  }
  __pyx_t_1 = (__Pyx_PyString_Equals(__pyx_v_order, __pyx_n_s_F, Py_NE)); if (unlikely(__pyx_t_1 < 0)) __PYX_ERR(0, 1018, __pyx_L1_error)
  __pyx_t_4 = __pyx_t_1;
  __pyx_L31_bool_binop_done:;
  if (__pyx_t_4) {

    /* "pygpu/gpuarray.pyx":1019
 *     # We need a contiguous array for the copy
 *     if order != 'C' and order != 'F':
 *         order = 'C'             # <<<<<<<<<<<<<<
 * 
 *     a = numpy.array(proto, dtype=dtype_to_npdtype(dtype), order=order,
 */
    __Pyx_INCREF(__pyx_n_s_C);
    __Pyx_DECREF_SET(__pyx_v_order, __pyx_n_s_C);

    /* "pygpu/gpuarray.pyx":1018
 * 
 *     # We need a contiguous array for the copy
 *     if order != 'C' and order != 'F':             # <<<<<<<<<<<<<<
 *         order = 'C'
 * 
 */
  }

  /* "pygpu/gpuarray.pyx":1021
 *         order = 'C'
 * 
 *     a = numpy.array(proto, dtype=dtype_to_npdtype(dtype), order=order,             # <<<<<<<<<<<<<<
 *                     ndmin=ndmin, copy=False)
 * 
 */
  __pyx_t_10 = __Pyx_GetModuleGlobalName(__pyx_n_s_numpy); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 1021, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_10);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_10, __pyx_n_s_array); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1021, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
  __pyx_t_10 = PyTuple_New(1); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 1021, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_10);
  __Pyx_INCREF(__pyx_v_proto);
  __Pyx_GIVEREF(__pyx_v_proto);
  PyTuple_SET_ITEM(__pyx_t_10, 0, __pyx_v_proto);
  __pyx_t_7 = __Pyx_PyDict_NewPresized(4); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 1021, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __pyx_t_8 = ((PyObject *)__pyx_f_5pygpu_8gpuarray_dtype_to_npdtype(__pyx_v_dtype)); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1021, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  if (PyDict_SetItem(__pyx_t_7, __pyx_n_s_dtype, __pyx_t_8) < 0) __PYX_ERR(0, 1021, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  if (PyDict_SetItem(__pyx_t_7, __pyx_n_s_order, __pyx_v_order) < 0) __PYX_ERR(0, 1021, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":1022
 * 
 *     a = numpy.array(proto, dtype=dtype_to_npdtype(dtype), order=order,
 *                     ndmin=ndmin, copy=False)             # <<<<<<<<<<<<<<
 * 
 *     res = pygpu_empty(np.PyArray_NDIM(a), <size_t *>np.PyArray_DIMS(a),
 */
  __pyx_t_8 = __Pyx_PyInt_From_unsigned_int(__pyx_v_ndmin); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1022, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  if (PyDict_SetItem(__pyx_t_7, __pyx_n_s_ndmin, __pyx_t_8) < 0) __PYX_ERR(0, 1021, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  if (PyDict_SetItem(__pyx_t_7, __pyx_n_s_copy, Py_False) < 0) __PYX_ERR(0, 1021, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":1021
 *         order = 'C'
 * 
 *     a = numpy.array(proto, dtype=dtype_to_npdtype(dtype), order=order,             # <<<<<<<<<<<<<<
 *                     ndmin=ndmin, copy=False)
 * 
 */
  __pyx_t_8 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_10, __pyx_t_7); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1021, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  if (!(likely(((__pyx_t_8) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_8, __pyx_ptype_5numpy_ndarray))))) __PYX_ERR(0, 1021, __pyx_L1_error)
  __pyx_v_a = ((PyArrayObject *)__pyx_t_8);
  __pyx_t_8 = 0;

  /* "pygpu/gpuarray.pyx":1025
 * 
 *     res = pygpu_empty(np.PyArray_NDIM(a), <size_t *>np.PyArray_DIMS(a),
 *                       dtype_to_typecode(a.dtype), to_ga_order(order),             # <<<<<<<<<<<<<<
 *                       context, cls)
 *     array_write(res, np.PyArray_DATA(a), np.PyArray_NBYTES(a))
 */
  __pyx_t_8 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_a), __pyx_n_s_dtype); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1025, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __pyx_t_6 = __pyx_f_5pygpu_8gpuarray_dtype_to_typecode(__pyx_t_8, 0); if (unlikely(__pyx_t_6 == ((int)-1))) __PYX_ERR(0, 1025, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  __pyx_t_12 = __pyx_f_5pygpu_8gpuarray_to_ga_order(__pyx_v_order); if (unlikely(__pyx_t_12 == ((ga_order)((ga_order)-2L)))) __PYX_ERR(0, 1025, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":1024
 *                     ndmin=ndmin, copy=False)
 * 
 *     res = pygpu_empty(np.PyArray_NDIM(a), <size_t *>np.PyArray_DIMS(a),             # <<<<<<<<<<<<<<
 *                       dtype_to_typecode(a.dtype), to_ga_order(order),
 *                       context, cls)
 */
  __pyx_t_8 = ((PyObject *)__pyx_f_5pygpu_8gpuarray_pygpu_empty(PyArray_NDIM(__pyx_v_a), ((size_t *)PyArray_DIMS(__pyx_v_a)), __pyx_t_6, __pyx_t_12, __pyx_v_context, __pyx_v_cls)); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1024, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __pyx_v_res = ((struct PyGpuArrayObject *)__pyx_t_8);
  __pyx_t_8 = 0;

  /* "pygpu/gpuarray.pyx":1027
 *                       dtype_to_typecode(a.dtype), to_ga_order(order),
 *                       context, cls)
 *     array_write(res, np.PyArray_DATA(a), np.PyArray_NBYTES(a))             # <<<<<<<<<<<<<<
 *     return res
 * 
 */
  __pyx_t_6 = __pyx_f_5pygpu_8gpuarray_array_write(__pyx_v_res, PyArray_DATA(__pyx_v_a), PyArray_NBYTES(__pyx_v_a)); if (unlikely(__pyx_t_6 == ((int)-1))) __PYX_ERR(0, 1027, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":1028
 *                       context, cls)
 *     array_write(res, np.PyArray_DATA(a), np.PyArray_NBYTES(a))
 *     return res             # <<<<<<<<<<<<<<
 * 
 * cdef void (*cuda_enter)(gpucontext *)
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_res));
  __pyx_r = ((PyObject *)__pyx_v_res);
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":968
 *     return carray(proto, dtype, copy, order, ndmin, context, cls)
 * 
 * cdef carray(proto, dtype, copy, order, unsigned int ndmin,             # <<<<<<<<<<<<<<
 *             GpuContext context, cls):
 *     cdef GpuArray res
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_XDECREF(__pyx_t_10);
  __Pyx_XDECREF(__pyx_t_11);
  __Pyx_AddTraceback("pygpu.gpuarray.carray", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_res);
  __Pyx_XDECREF((PyObject *)__pyx_v_arg);
  __Pyx_XDECREF((PyObject *)__pyx_v_tmp);
  __Pyx_XDECREF((PyObject *)__pyx_v_a);
  __Pyx_XDECREF(__pyx_v_shp);
  __Pyx_XDECREF(__pyx_v_idx);
  __Pyx_XDECREF(__pyx_v_order);
  __Pyx_XDECREF((PyObject *)__pyx_v_context);
  __Pyx_XDECREF(__pyx_v_cls);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":1060
 * 
 *     """
 *     def __dealloc__(self):             # <<<<<<<<<<<<<<
 *         if self.ctx != NULL:
 *             gpucontext_deref(self.ctx)
 */

/* Python wrapper */
static void __pyx_pw_5pygpu_8gpuarray_10GpuContext_1__dealloc__(PyObject *__pyx_v_self); /*proto*/
static void __pyx_pw_5pygpu_8gpuarray_10GpuContext_1__dealloc__(PyObject *__pyx_v_self) {
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__dealloc__ (wrapper)", 0);
  __pyx_pf_5pygpu_8gpuarray_10GpuContext___dealloc__(((struct PyGpuContextObject *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
}

static void __pyx_pf_5pygpu_8gpuarray_10GpuContext___dealloc__(struct PyGpuContextObject *__pyx_v_self) {
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  __Pyx_RefNannySetupContext("__dealloc__", 0);

  /* "pygpu/gpuarray.pyx":1061
 *     """
 *     def __dealloc__(self):
 *         if self.ctx != NULL:             # <<<<<<<<<<<<<<
 *             gpucontext_deref(self.ctx)
 * 
 */
  __pyx_t_1 = ((__pyx_v_self->ctx != NULL) != 0);
  if (__pyx_t_1) {

    /* "pygpu/gpuarray.pyx":1062
 *     def __dealloc__(self):
 *         if self.ctx != NULL:
 *             gpucontext_deref(self.ctx)             # <<<<<<<<<<<<<<
 * 
 *     def __reduce__(self):
 */
    gpucontext_deref(__pyx_v_self->ctx);

    /* "pygpu/gpuarray.pyx":1061
 *     """
 *     def __dealloc__(self):
 *         if self.ctx != NULL:             # <<<<<<<<<<<<<<
 *             gpucontext_deref(self.ctx)
 * 
 */
  }

  /* "pygpu/gpuarray.pyx":1060
 * 
 *     """
 *     def __dealloc__(self):             # <<<<<<<<<<<<<<
 *         if self.ctx != NULL:
 *             gpucontext_deref(self.ctx)
 */

  /* function exit code */
  __Pyx_RefNannyFinishContext();
}

/* "pygpu/gpuarray.pyx":1064
 *             gpucontext_deref(self.ctx)
 * 
 *     def __reduce__(self):             # <<<<<<<<<<<<<<
 *         raise RuntimeError, "Cannot pickle GpuContext object"
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_10GpuContext_3__reduce__(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_pw_5pygpu_8gpuarray_10GpuContext_3__reduce__(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__reduce__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_10GpuContext_2__reduce__(((struct PyGpuContextObject *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_10GpuContext_2__reduce__(CYTHON_UNUSED struct PyGpuContextObject *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__reduce__", 0);

  /* "pygpu/gpuarray.pyx":1065
 * 
 *     def __reduce__(self):
 *         raise RuntimeError, "Cannot pickle GpuContext object"             # <<<<<<<<<<<<<<
 * 
 *     def __init__(self):
 */
  __Pyx_Raise(__pyx_builtin_RuntimeError, __pyx_kp_s_Cannot_pickle_GpuContext_object, 0, 0);
  __PYX_ERR(0, 1065, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":1064
 *             gpucontext_deref(self.ctx)
 * 
 *     def __reduce__(self):             # <<<<<<<<<<<<<<
 *         raise RuntimeError, "Cannot pickle GpuContext object"
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_AddTraceback("pygpu.gpuarray.GpuContext.__reduce__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":1067
 *         raise RuntimeError, "Cannot pickle GpuContext object"
 * 
 *     def __init__(self):             # <<<<<<<<<<<<<<
 *         if type(self) is GpuContext:
 *             raise RuntimeError, "Called raw GpuContext.__init__"
 */

/* Python wrapper */
static int __pyx_pw_5pygpu_8gpuarray_10GpuContext_5__init__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static int __pyx_pw_5pygpu_8gpuarray_10GpuContext_5__init__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__init__ (wrapper)", 0);
  if (unlikely(PyTuple_GET_SIZE(__pyx_args) > 0)) {
    __Pyx_RaiseArgtupleInvalid("__init__", 1, 0, 0, PyTuple_GET_SIZE(__pyx_args)); return -1;}
  if (unlikely(__pyx_kwds) && unlikely(PyDict_Size(__pyx_kwds) > 0) && unlikely(!__Pyx_CheckKeywordStrings(__pyx_kwds, "__init__", 0))) return -1;
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_10GpuContext_4__init__(((struct PyGpuContextObject *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_5pygpu_8gpuarray_10GpuContext_4__init__(struct PyGpuContextObject *__pyx_v_self) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_t_2;
  __Pyx_RefNannySetupContext("__init__", 0);

  /* "pygpu/gpuarray.pyx":1068
 * 
 *     def __init__(self):
 *         if type(self) is GpuContext:             # <<<<<<<<<<<<<<
 *             raise RuntimeError, "Called raw GpuContext.__init__"
 * 
 */
  __pyx_t_1 = (((PyObject *)Py_TYPE(((PyObject *)__pyx_v_self))) == ((PyObject *)__pyx_ptype_5pygpu_8gpuarray_GpuContext));
  __pyx_t_2 = (__pyx_t_1 != 0);
  if (__pyx_t_2) {

    /* "pygpu/gpuarray.pyx":1069
 *     def __init__(self):
 *         if type(self) is GpuContext:
 *             raise RuntimeError, "Called raw GpuContext.__init__"             # <<<<<<<<<<<<<<
 * 
 *     def __enter__(self):
 */
    __Pyx_Raise(__pyx_builtin_RuntimeError, __pyx_kp_s_Called_raw_GpuContext___init, 0, 0);
    __PYX_ERR(0, 1069, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":1068
 * 
 *     def __init__(self):
 *         if type(self) is GpuContext:             # <<<<<<<<<<<<<<
 *             raise RuntimeError, "Called raw GpuContext.__init__"
 * 
 */
  }

  /* "pygpu/gpuarray.pyx":1067
 *         raise RuntimeError, "Cannot pickle GpuContext object"
 * 
 *     def __init__(self):             # <<<<<<<<<<<<<<
 *         if type(self) is GpuContext:
 *             raise RuntimeError, "Called raw GpuContext.__init__"
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_AddTraceback("pygpu.gpuarray.GpuContext.__init__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":1071
 *             raise RuntimeError, "Called raw GpuContext.__init__"
 * 
 *     def __enter__(self):             # <<<<<<<<<<<<<<
 *         if cuda_enter == NULL:
 *             raise RuntimeError("cuda_enter not available")
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_10GpuContext_7__enter__(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_pw_5pygpu_8gpuarray_10GpuContext_7__enter__(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__enter__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_10GpuContext_6__enter__(((struct PyGpuContextObject *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_10GpuContext_6__enter__(struct PyGpuContextObject *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  int __pyx_t_3;
  __Pyx_RefNannySetupContext("__enter__", 0);

  /* "pygpu/gpuarray.pyx":1072
 * 
 *     def __enter__(self):
 *         if cuda_enter == NULL:             # <<<<<<<<<<<<<<
 *             raise RuntimeError("cuda_enter not available")
 *         if cuda_exit == NULL:
 */
  __pyx_t_1 = ((__pyx_v_5pygpu_8gpuarray_cuda_enter == NULL) != 0);
  if (__pyx_t_1) {

    /* "pygpu/gpuarray.pyx":1073
 *     def __enter__(self):
 *         if cuda_enter == NULL:
 *             raise RuntimeError("cuda_enter not available")             # <<<<<<<<<<<<<<
 *         if cuda_exit == NULL:
 *             raise RuntimeError("cuda_exit not available")
 */
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_RuntimeError, __pyx_tuple__15, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1073, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(0, 1073, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":1072
 * 
 *     def __enter__(self):
 *         if cuda_enter == NULL:             # <<<<<<<<<<<<<<
 *             raise RuntimeError("cuda_enter not available")
 *         if cuda_exit == NULL:
 */
  }

  /* "pygpu/gpuarray.pyx":1074
 *         if cuda_enter == NULL:
 *             raise RuntimeError("cuda_enter not available")
 *         if cuda_exit == NULL:             # <<<<<<<<<<<<<<
 *             raise RuntimeError("cuda_exit not available")
 *         if self.kind != b"cuda":
 */
  __pyx_t_1 = ((__pyx_v_5pygpu_8gpuarray_cuda_exit == NULL) != 0);
  if (__pyx_t_1) {

    /* "pygpu/gpuarray.pyx":1075
 *             raise RuntimeError("cuda_enter not available")
 *         if cuda_exit == NULL:
 *             raise RuntimeError("cuda_exit not available")             # <<<<<<<<<<<<<<
 *         if self.kind != b"cuda":
 *             raise ValueError("Context manager only works for cuda")
 */
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_RuntimeError, __pyx_tuple__16, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1075, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(0, 1075, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":1074
 *         if cuda_enter == NULL:
 *             raise RuntimeError("cuda_enter not available")
 *         if cuda_exit == NULL:             # <<<<<<<<<<<<<<
 *             raise RuntimeError("cuda_exit not available")
 *         if self.kind != b"cuda":
 */
  }

  /* "pygpu/gpuarray.pyx":1076
 *         if cuda_exit == NULL:
 *             raise RuntimeError("cuda_exit not available")
 *         if self.kind != b"cuda":             # <<<<<<<<<<<<<<
 *             raise ValueError("Context manager only works for cuda")
 *         cuda_enter(self.ctx)
 */
  __pyx_t_1 = (__Pyx_PyBytes_Equals(__pyx_v_self->kind, __pyx_n_b_cuda, Py_NE)); if (unlikely(__pyx_t_1 < 0)) __PYX_ERR(0, 1076, __pyx_L1_error)
  __pyx_t_3 = (__pyx_t_1 != 0);
  if (__pyx_t_3) {

    /* "pygpu/gpuarray.pyx":1077
 *             raise RuntimeError("cuda_exit not available")
 *         if self.kind != b"cuda":
 *             raise ValueError("Context manager only works for cuda")             # <<<<<<<<<<<<<<
 *         cuda_enter(self.ctx)
 *         return self
 */
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__17, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1077, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(0, 1077, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":1076
 *         if cuda_exit == NULL:
 *             raise RuntimeError("cuda_exit not available")
 *         if self.kind != b"cuda":             # <<<<<<<<<<<<<<
 *             raise ValueError("Context manager only works for cuda")
 *         cuda_enter(self.ctx)
 */
  }

  /* "pygpu/gpuarray.pyx":1078
 *         if self.kind != b"cuda":
 *             raise ValueError("Context manager only works for cuda")
 *         cuda_enter(self.ctx)             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
  __pyx_v_5pygpu_8gpuarray_cuda_enter(__pyx_v_self->ctx);

  /* "pygpu/gpuarray.pyx":1079
 *             raise ValueError("Context manager only works for cuda")
 *         cuda_enter(self.ctx)
 *         return self             # <<<<<<<<<<<<<<
 * 
 *     def __exit__(self, t, v, tb):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":1071
 *             raise RuntimeError, "Called raw GpuContext.__init__"
 * 
 *     def __enter__(self):             # <<<<<<<<<<<<<<
 *         if cuda_enter == NULL:
 *             raise RuntimeError("cuda_enter not available")
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("pygpu.gpuarray.GpuContext.__enter__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":1081
 *         return self
 * 
 *     def __exit__(self, t, v, tb):             # <<<<<<<<<<<<<<
 *         cuda_exit(self.ctx)
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_10GpuContext_9__exit__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyObject *__pyx_pw_5pygpu_8gpuarray_10GpuContext_9__exit__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  CYTHON_UNUSED PyObject *__pyx_v_t = 0;
  CYTHON_UNUSED PyObject *__pyx_v_v = 0;
  CYTHON_UNUSED PyObject *__pyx_v_tb = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__exit__ (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_t,&__pyx_n_s_v,&__pyx_n_s_tb,0};
    PyObject* values[3] = {0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_t)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_v)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("__exit__", 1, 3, 3, 1); __PYX_ERR(0, 1081, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_tb)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("__exit__", 1, 3, 3, 2); __PYX_ERR(0, 1081, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "__exit__") < 0)) __PYX_ERR(0, 1081, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 3) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
    }
    __pyx_v_t = values[0];
    __pyx_v_v = values[1];
    __pyx_v_tb = values[2];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("__exit__", 1, 3, 3, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 1081, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("pygpu.gpuarray.GpuContext.__exit__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_10GpuContext_8__exit__(((struct PyGpuContextObject *)__pyx_v_self), __pyx_v_t, __pyx_v_v, __pyx_v_tb);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_10GpuContext_8__exit__(struct PyGpuContextObject *__pyx_v_self, CYTHON_UNUSED PyObject *__pyx_v_t, CYTHON_UNUSED PyObject *__pyx_v_v, CYTHON_UNUSED PyObject *__pyx_v_tb) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__exit__", 0);

  /* "pygpu/gpuarray.pyx":1082
 * 
 *     def __exit__(self, t, v, tb):
 *         cuda_exit(self.ctx)             # <<<<<<<<<<<<<<
 * 
 *     property ptr:
 */
  __pyx_v_5pygpu_8gpuarray_cuda_exit(__pyx_v_self->ctx);

  /* "pygpu/gpuarray.pyx":1081
 *         return self
 * 
 *     def __exit__(self, t, v, tb):             # <<<<<<<<<<<<<<
 *         cuda_exit(self.ctx)
 * 
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":1086
 *     property ptr:
 *         "Raw pointer value for the context object"
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             return <size_t>self.ctx
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_10GpuContext_3ptr_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_5pygpu_8gpuarray_10GpuContext_3ptr_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_10GpuContext_3ptr___get__(((struct PyGpuContextObject *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_10GpuContext_3ptr___get__(struct PyGpuContextObject *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("__get__", 0);

  /* "pygpu/gpuarray.pyx":1087
 *         "Raw pointer value for the context object"
 *         def __get__(self):
 *             return <size_t>self.ctx             # <<<<<<<<<<<<<<
 * 
 *     property devname:
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyInt_FromSize_t(((size_t)__pyx_v_self->ctx)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1087, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":1086
 *     property ptr:
 *         "Raw pointer value for the context object"
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             return <size_t>self.ctx
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("pygpu.gpuarray.GpuContext.ptr.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":1091
 *     property devname:
 *         "Device name for this context"
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             cdef char tmp[256]
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_10GpuContext_7devname_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_5pygpu_8gpuarray_10GpuContext_7devname_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_10GpuContext_7devname___get__(((struct PyGpuContextObject *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_10GpuContext_7devname___get__(struct PyGpuContextObject *__pyx_v_self) {
  char __pyx_v_tmp[0x100];
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  __Pyx_RefNannySetupContext("__get__", 0);

  /* "pygpu/gpuarray.pyx":1094
 *             cdef char tmp[256]
 * 
 *             ctx_property(self, GA_CTX_PROP_DEVNAME, tmp)             # <<<<<<<<<<<<<<
 *             return tmp.decode('ascii')
 * 
 */
  __pyx_t_1 = __pyx_f_5pygpu_8gpuarray_ctx_property(__pyx_v_self, GA_CTX_PROP_DEVNAME, __pyx_v_tmp); if (unlikely(__pyx_t_1 == ((int)-1))) __PYX_ERR(0, 1094, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":1095
 * 
 *             ctx_property(self, GA_CTX_PROP_DEVNAME, tmp)
 *             return tmp.decode('ascii')             # <<<<<<<<<<<<<<
 * 
 *     property unique_id:
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_2 = __Pyx_decode_c_string(__pyx_v_tmp, 0, strlen(__pyx_v_tmp), NULL, NULL, PyUnicode_DecodeASCII); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1095, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_r = __pyx_t_2;
  __pyx_t_2 = 0;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":1091
 *     property devname:
 *         "Device name for this context"
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             cdef char tmp[256]
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("pygpu.gpuarray.GpuContext.devname.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":1099
 *     property unique_id:
 *         "Device PCI Bus ID for this context"
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             cdef char tmp[16]
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_10GpuContext_9unique_id_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_5pygpu_8gpuarray_10GpuContext_9unique_id_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_10GpuContext_9unique_id___get__(((struct PyGpuContextObject *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_10GpuContext_9unique_id___get__(struct PyGpuContextObject *__pyx_v_self) {
  char __pyx_v_tmp[16];
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  __Pyx_RefNannySetupContext("__get__", 0);

  /* "pygpu/gpuarray.pyx":1102
 *             cdef char tmp[16]
 * 
 *             ctx_property(self, GA_CTX_PROP_UNIQUE_ID, tmp)             # <<<<<<<<<<<<<<
 *             return tmp.decode('ascii')
 * 
 */
  __pyx_t_1 = __pyx_f_5pygpu_8gpuarray_ctx_property(__pyx_v_self, GA_CTX_PROP_UNIQUE_ID, __pyx_v_tmp); if (unlikely(__pyx_t_1 == ((int)-1))) __PYX_ERR(0, 1102, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":1103
 * 
 *             ctx_property(self, GA_CTX_PROP_UNIQUE_ID, tmp)
 *             return tmp.decode('ascii')             # <<<<<<<<<<<<<<
 * 
 *     property lmemsize:
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_2 = __Pyx_decode_c_string(__pyx_v_tmp, 0, strlen(__pyx_v_tmp), NULL, NULL, PyUnicode_DecodeASCII); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1103, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_r = __pyx_t_2;
  __pyx_t_2 = 0;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":1099
 *     property unique_id:
 *         "Device PCI Bus ID for this context"
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             cdef char tmp[16]
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("pygpu.gpuarray.GpuContext.unique_id.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":1107
 *     property lmemsize:
 *         "Size of the local (shared) memory, in bytes, for this context"
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             cdef size_t res
 *             ctx_property(self, GA_CTX_PROP_LMEMSIZE, &res)
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_10GpuContext_8lmemsize_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_5pygpu_8gpuarray_10GpuContext_8lmemsize_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_10GpuContext_8lmemsize___get__(((struct PyGpuContextObject *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_10GpuContext_8lmemsize___get__(struct PyGpuContextObject *__pyx_v_self) {
  size_t __pyx_v_res;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  __Pyx_RefNannySetupContext("__get__", 0);

  /* "pygpu/gpuarray.pyx":1109
 *         def __get__(self):
 *             cdef size_t res
 *             ctx_property(self, GA_CTX_PROP_LMEMSIZE, &res)             # <<<<<<<<<<<<<<
 *             return res
 * 
 */
  __pyx_t_1 = __pyx_f_5pygpu_8gpuarray_ctx_property(__pyx_v_self, GA_CTX_PROP_LMEMSIZE, (&__pyx_v_res)); if (unlikely(__pyx_t_1 == ((int)-1))) __PYX_ERR(0, 1109, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":1110
 *             cdef size_t res
 *             ctx_property(self, GA_CTX_PROP_LMEMSIZE, &res)
 *             return res             # <<<<<<<<<<<<<<
 * 
 *     property numprocs:
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_2 = __Pyx_PyInt_FromSize_t(__pyx_v_res); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1110, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_r = __pyx_t_2;
  __pyx_t_2 = 0;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":1107
 *     property lmemsize:
 *         "Size of the local (shared) memory, in bytes, for this context"
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             cdef size_t res
 *             ctx_property(self, GA_CTX_PROP_LMEMSIZE, &res)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("pygpu.gpuarray.GpuContext.lmemsize.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":1114
 *     property numprocs:
 *         "Number of compute units for this context"
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             cdef unsigned int res
 *             ctx_property(self, GA_CTX_PROP_NUMPROCS, &res)
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_10GpuContext_8numprocs_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_5pygpu_8gpuarray_10GpuContext_8numprocs_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_10GpuContext_8numprocs___get__(((struct PyGpuContextObject *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_10GpuContext_8numprocs___get__(struct PyGpuContextObject *__pyx_v_self) {
  unsigned int __pyx_v_res;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  __Pyx_RefNannySetupContext("__get__", 0);

  /* "pygpu/gpuarray.pyx":1116
 *         def __get__(self):
 *             cdef unsigned int res
 *             ctx_property(self, GA_CTX_PROP_NUMPROCS, &res)             # <<<<<<<<<<<<<<
 *             return res
 * 
 */
  __pyx_t_1 = __pyx_f_5pygpu_8gpuarray_ctx_property(__pyx_v_self, GA_CTX_PROP_NUMPROCS, (&__pyx_v_res)); if (unlikely(__pyx_t_1 == ((int)-1))) __PYX_ERR(0, 1116, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":1117
 *             cdef unsigned int res
 *             ctx_property(self, GA_CTX_PROP_NUMPROCS, &res)
 *             return res             # <<<<<<<<<<<<<<
 * 
 *     property bin_id:
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_2 = __Pyx_PyInt_From_unsigned_int(__pyx_v_res); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1117, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_r = __pyx_t_2;
  __pyx_t_2 = 0;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":1114
 *     property numprocs:
 *         "Number of compute units for this context"
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             cdef unsigned int res
 *             ctx_property(self, GA_CTX_PROP_NUMPROCS, &res)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("pygpu.gpuarray.GpuContext.numprocs.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":1121
 *     property bin_id:
 *         "Binary compatibility id"
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             cdef const char *res
 *             ctx_property(self, GA_CTX_PROP_BIN_ID, &res)
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_10GpuContext_6bin_id_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_5pygpu_8gpuarray_10GpuContext_6bin_id_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_10GpuContext_6bin_id___get__(((struct PyGpuContextObject *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_10GpuContext_6bin_id___get__(struct PyGpuContextObject *__pyx_v_self) {
  char const *__pyx_v_res;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  __Pyx_RefNannySetupContext("__get__", 0);

  /* "pygpu/gpuarray.pyx":1123
 *         def __get__(self):
 *             cdef const char *res
 *             ctx_property(self, GA_CTX_PROP_BIN_ID, &res)             # <<<<<<<<<<<<<<
 *             return res;
 * 
 */
  __pyx_t_1 = __pyx_f_5pygpu_8gpuarray_ctx_property(__pyx_v_self, GA_CTX_PROP_BIN_ID, (&__pyx_v_res)); if (unlikely(__pyx_t_1 == ((int)-1))) __PYX_ERR(0, 1123, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":1124
 *             cdef const char *res
 *             ctx_property(self, GA_CTX_PROP_BIN_ID, &res)
 *             return res;             # <<<<<<<<<<<<<<
 * 
 *     property total_gmem:
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_2 = __Pyx_PyBytes_FromString(__pyx_v_res); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1124, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_r = __pyx_t_2;
  __pyx_t_2 = 0;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":1121
 *     property bin_id:
 *         "Binary compatibility id"
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             cdef const char *res
 *             ctx_property(self, GA_CTX_PROP_BIN_ID, &res)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("pygpu.gpuarray.GpuContext.bin_id.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":1128
 *     property total_gmem:
 *         "Total size of global memory on the device"
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             cdef size_t res
 *             ctx_property(self, GA_CTX_PROP_TOTAL_GMEM, &res)
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_10GpuContext_10total_gmem_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_5pygpu_8gpuarray_10GpuContext_10total_gmem_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_10GpuContext_10total_gmem___get__(((struct PyGpuContextObject *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_10GpuContext_10total_gmem___get__(struct PyGpuContextObject *__pyx_v_self) {
  size_t __pyx_v_res;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  __Pyx_RefNannySetupContext("__get__", 0);

  /* "pygpu/gpuarray.pyx":1130
 *         def __get__(self):
 *             cdef size_t res
 *             ctx_property(self, GA_CTX_PROP_TOTAL_GMEM, &res)             # <<<<<<<<<<<<<<
 *             return res
 * 
 */
  __pyx_t_1 = __pyx_f_5pygpu_8gpuarray_ctx_property(__pyx_v_self, GA_CTX_PROP_TOTAL_GMEM, (&__pyx_v_res)); if (unlikely(__pyx_t_1 == ((int)-1))) __PYX_ERR(0, 1130, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":1131
 *             cdef size_t res
 *             ctx_property(self, GA_CTX_PROP_TOTAL_GMEM, &res)
 *             return res             # <<<<<<<<<<<<<<
 * 
 *     property free_gmem:
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_2 = __Pyx_PyInt_FromSize_t(__pyx_v_res); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1131, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_r = __pyx_t_2;
  __pyx_t_2 = 0;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":1128
 *     property total_gmem:
 *         "Total size of global memory on the device"
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             cdef size_t res
 *             ctx_property(self, GA_CTX_PROP_TOTAL_GMEM, &res)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("pygpu.gpuarray.GpuContext.total_gmem.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":1135
 *     property free_gmem:
 *         "Size of free global memory on the device"
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             cdef size_t res
 *             ctx_property(self, GA_CTX_PROP_FREE_GMEM, &res)
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_10GpuContext_9free_gmem_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_5pygpu_8gpuarray_10GpuContext_9free_gmem_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_10GpuContext_9free_gmem___get__(((struct PyGpuContextObject *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_10GpuContext_9free_gmem___get__(struct PyGpuContextObject *__pyx_v_self) {
  size_t __pyx_v_res;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  __Pyx_RefNannySetupContext("__get__", 0);

  /* "pygpu/gpuarray.pyx":1137
 *         def __get__(self):
 *             cdef size_t res
 *             ctx_property(self, GA_CTX_PROP_FREE_GMEM, &res)             # <<<<<<<<<<<<<<
 *             return res
 * 
 */
  __pyx_t_1 = __pyx_f_5pygpu_8gpuarray_ctx_property(__pyx_v_self, GA_CTX_PROP_FREE_GMEM, (&__pyx_v_res)); if (unlikely(__pyx_t_1 == ((int)-1))) __PYX_ERR(0, 1137, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":1138
 *             cdef size_t res
 *             ctx_property(self, GA_CTX_PROP_FREE_GMEM, &res)
 *             return res             # <<<<<<<<<<<<<<
 * 
 *     property maxlsize0:
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_2 = __Pyx_PyInt_FromSize_t(__pyx_v_res); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1138, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_r = __pyx_t_2;
  __pyx_t_2 = 0;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":1135
 *     property free_gmem:
 *         "Size of free global memory on the device"
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             cdef size_t res
 *             ctx_property(self, GA_CTX_PROP_FREE_GMEM, &res)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("pygpu.gpuarray.GpuContext.free_gmem.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":1142
 *     property maxlsize0:
 *         "Maximum local size for dimension 0"
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             cdef size_t res
 *             ctx_property(self, GA_CTX_PROP_MAXLSIZE0, &res)
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_10GpuContext_9maxlsize0_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_5pygpu_8gpuarray_10GpuContext_9maxlsize0_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_10GpuContext_9maxlsize0___get__(((struct PyGpuContextObject *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_10GpuContext_9maxlsize0___get__(struct PyGpuContextObject *__pyx_v_self) {
  size_t __pyx_v_res;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  __Pyx_RefNannySetupContext("__get__", 0);

  /* "pygpu/gpuarray.pyx":1144
 *         def __get__(self):
 *             cdef size_t res
 *             ctx_property(self, GA_CTX_PROP_MAXLSIZE0, &res)             # <<<<<<<<<<<<<<
 *             return res
 * 
 */
  __pyx_t_1 = __pyx_f_5pygpu_8gpuarray_ctx_property(__pyx_v_self, GA_CTX_PROP_MAXLSIZE0, (&__pyx_v_res)); if (unlikely(__pyx_t_1 == ((int)-1))) __PYX_ERR(0, 1144, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":1145
 *             cdef size_t res
 *             ctx_property(self, GA_CTX_PROP_MAXLSIZE0, &res)
 *             return res             # <<<<<<<<<<<<<<
 * 
 *     property maxlsize1:
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_2 = __Pyx_PyInt_FromSize_t(__pyx_v_res); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1145, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_r = __pyx_t_2;
  __pyx_t_2 = 0;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":1142
 *     property maxlsize0:
 *         "Maximum local size for dimension 0"
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             cdef size_t res
 *             ctx_property(self, GA_CTX_PROP_MAXLSIZE0, &res)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("pygpu.gpuarray.GpuContext.maxlsize0.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":1149
 *     property maxlsize1:
 *         "Maximum local size for dimension 1"
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             cdef size_t res
 *             ctx_property(self, GA_CTX_PROP_MAXLSIZE1, &res)
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_10GpuContext_9maxlsize1_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_5pygpu_8gpuarray_10GpuContext_9maxlsize1_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_10GpuContext_9maxlsize1___get__(((struct PyGpuContextObject *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_10GpuContext_9maxlsize1___get__(struct PyGpuContextObject *__pyx_v_self) {
  size_t __pyx_v_res;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  __Pyx_RefNannySetupContext("__get__", 0);

  /* "pygpu/gpuarray.pyx":1151
 *         def __get__(self):
 *             cdef size_t res
 *             ctx_property(self, GA_CTX_PROP_MAXLSIZE1, &res)             # <<<<<<<<<<<<<<
 *             return res
 * 
 */
  __pyx_t_1 = __pyx_f_5pygpu_8gpuarray_ctx_property(__pyx_v_self, GA_CTX_PROP_MAXLSIZE1, (&__pyx_v_res)); if (unlikely(__pyx_t_1 == ((int)-1))) __PYX_ERR(0, 1151, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":1152
 *             cdef size_t res
 *             ctx_property(self, GA_CTX_PROP_MAXLSIZE1, &res)
 *             return res             # <<<<<<<<<<<<<<
 * 
 *     property maxlsize2:
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_2 = __Pyx_PyInt_FromSize_t(__pyx_v_res); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1152, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_r = __pyx_t_2;
  __pyx_t_2 = 0;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":1149
 *     property maxlsize1:
 *         "Maximum local size for dimension 1"
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             cdef size_t res
 *             ctx_property(self, GA_CTX_PROP_MAXLSIZE1, &res)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("pygpu.gpuarray.GpuContext.maxlsize1.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":1156
 *     property maxlsize2:
 *         "Maximum local size for dimension 2"
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             cdef size_t res
 *             ctx_property(self, GA_CTX_PROP_MAXLSIZE2, &res)
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_10GpuContext_9maxlsize2_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_5pygpu_8gpuarray_10GpuContext_9maxlsize2_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_10GpuContext_9maxlsize2___get__(((struct PyGpuContextObject *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_10GpuContext_9maxlsize2___get__(struct PyGpuContextObject *__pyx_v_self) {
  size_t __pyx_v_res;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  __Pyx_RefNannySetupContext("__get__", 0);

  /* "pygpu/gpuarray.pyx":1158
 *         def __get__(self):
 *             cdef size_t res
 *             ctx_property(self, GA_CTX_PROP_MAXLSIZE2, &res)             # <<<<<<<<<<<<<<
 *             return res
 * 
 */
  __pyx_t_1 = __pyx_f_5pygpu_8gpuarray_ctx_property(__pyx_v_self, GA_CTX_PROP_MAXLSIZE2, (&__pyx_v_res)); if (unlikely(__pyx_t_1 == ((int)-1))) __PYX_ERR(0, 1158, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":1159
 *             cdef size_t res
 *             ctx_property(self, GA_CTX_PROP_MAXLSIZE2, &res)
 *             return res             # <<<<<<<<<<<<<<
 * 
 *     property maxgsize0:
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_2 = __Pyx_PyInt_FromSize_t(__pyx_v_res); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1159, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_r = __pyx_t_2;
  __pyx_t_2 = 0;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":1156
 *     property maxlsize2:
 *         "Maximum local size for dimension 2"
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             cdef size_t res
 *             ctx_property(self, GA_CTX_PROP_MAXLSIZE2, &res)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("pygpu.gpuarray.GpuContext.maxlsize2.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":1163
 *     property maxgsize0:
 *         "Maximum global size for dimension 0"
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             cdef size_t res
 *             ctx_property(self, GA_CTX_PROP_MAXGSIZE0, &res)
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_10GpuContext_9maxgsize0_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_5pygpu_8gpuarray_10GpuContext_9maxgsize0_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_10GpuContext_9maxgsize0___get__(((struct PyGpuContextObject *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_10GpuContext_9maxgsize0___get__(struct PyGpuContextObject *__pyx_v_self) {
  size_t __pyx_v_res;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  __Pyx_RefNannySetupContext("__get__", 0);

  /* "pygpu/gpuarray.pyx":1165
 *         def __get__(self):
 *             cdef size_t res
 *             ctx_property(self, GA_CTX_PROP_MAXGSIZE0, &res)             # <<<<<<<<<<<<<<
 *             return res
 * 
 */
  __pyx_t_1 = __pyx_f_5pygpu_8gpuarray_ctx_property(__pyx_v_self, GA_CTX_PROP_MAXGSIZE0, (&__pyx_v_res)); if (unlikely(__pyx_t_1 == ((int)-1))) __PYX_ERR(0, 1165, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":1166
 *             cdef size_t res
 *             ctx_property(self, GA_CTX_PROP_MAXGSIZE0, &res)
 *             return res             # <<<<<<<<<<<<<<
 * 
 *     property maxgsize1:
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_2 = __Pyx_PyInt_FromSize_t(__pyx_v_res); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1166, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_r = __pyx_t_2;
  __pyx_t_2 = 0;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":1163
 *     property maxgsize0:
 *         "Maximum global size for dimension 0"
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             cdef size_t res
 *             ctx_property(self, GA_CTX_PROP_MAXGSIZE0, &res)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("pygpu.gpuarray.GpuContext.maxgsize0.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":1170
 *     property maxgsize1:
 *         "Maximum global size for dimension 1"
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             cdef size_t res
 *             ctx_property(self, GA_CTX_PROP_MAXGSIZE1, &res)
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_10GpuContext_9maxgsize1_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_5pygpu_8gpuarray_10GpuContext_9maxgsize1_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_10GpuContext_9maxgsize1___get__(((struct PyGpuContextObject *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_10GpuContext_9maxgsize1___get__(struct PyGpuContextObject *__pyx_v_self) {
  size_t __pyx_v_res;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  __Pyx_RefNannySetupContext("__get__", 0);

  /* "pygpu/gpuarray.pyx":1172
 *         def __get__(self):
 *             cdef size_t res
 *             ctx_property(self, GA_CTX_PROP_MAXGSIZE1, &res)             # <<<<<<<<<<<<<<
 *             return res
 * 
 */
  __pyx_t_1 = __pyx_f_5pygpu_8gpuarray_ctx_property(__pyx_v_self, GA_CTX_PROP_MAXGSIZE1, (&__pyx_v_res)); if (unlikely(__pyx_t_1 == ((int)-1))) __PYX_ERR(0, 1172, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":1173
 *             cdef size_t res
 *             ctx_property(self, GA_CTX_PROP_MAXGSIZE1, &res)
 *             return res             # <<<<<<<<<<<<<<
 * 
 *     property maxgsize2:
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_2 = __Pyx_PyInt_FromSize_t(__pyx_v_res); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1173, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_r = __pyx_t_2;
  __pyx_t_2 = 0;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":1170
 *     property maxgsize1:
 *         "Maximum global size for dimension 1"
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             cdef size_t res
 *             ctx_property(self, GA_CTX_PROP_MAXGSIZE1, &res)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("pygpu.gpuarray.GpuContext.maxgsize1.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":1177
 *     property maxgsize2:
 *         "Maximum global size for dimension 2"
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             cdef size_t res
 *             ctx_property(self, GA_CTX_PROP_MAXGSIZE2, &res)
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_10GpuContext_9maxgsize2_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_5pygpu_8gpuarray_10GpuContext_9maxgsize2_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_10GpuContext_9maxgsize2___get__(((struct PyGpuContextObject *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_10GpuContext_9maxgsize2___get__(struct PyGpuContextObject *__pyx_v_self) {
  size_t __pyx_v_res;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  __Pyx_RefNannySetupContext("__get__", 0);

  /* "pygpu/gpuarray.pyx":1179
 *         def __get__(self):
 *             cdef size_t res
 *             ctx_property(self, GA_CTX_PROP_MAXGSIZE2, &res)             # <<<<<<<<<<<<<<
 *             return res
 * 
 */
  __pyx_t_1 = __pyx_f_5pygpu_8gpuarray_ctx_property(__pyx_v_self, GA_CTX_PROP_MAXGSIZE2, (&__pyx_v_res)); if (unlikely(__pyx_t_1 == ((int)-1))) __PYX_ERR(0, 1179, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":1180
 *             cdef size_t res
 *             ctx_property(self, GA_CTX_PROP_MAXGSIZE2, &res)
 *             return res             # <<<<<<<<<<<<<<
 * 
 *     property largest_memblock:
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_2 = __Pyx_PyInt_FromSize_t(__pyx_v_res); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1180, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_r = __pyx_t_2;
  __pyx_t_2 = 0;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":1177
 *     property maxgsize2:
 *         "Maximum global size for dimension 2"
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             cdef size_t res
 *             ctx_property(self, GA_CTX_PROP_MAXGSIZE2, &res)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("pygpu.gpuarray.GpuContext.maxgsize2.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":1184
 *     property largest_memblock:
 *         "Size of the largest memory block you can allocate"
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             cdef size_t res
 *             ctx_property(self, GA_CTX_PROP_LARGEST_MEMBLOCK, &res)
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_10GpuContext_16largest_memblock_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_5pygpu_8gpuarray_10GpuContext_16largest_memblock_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_10GpuContext_16largest_memblock___get__(((struct PyGpuContextObject *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_10GpuContext_16largest_memblock___get__(struct PyGpuContextObject *__pyx_v_self) {
  size_t __pyx_v_res;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  __Pyx_RefNannySetupContext("__get__", 0);

  /* "pygpu/gpuarray.pyx":1186
 *         def __get__(self):
 *             cdef size_t res
 *             ctx_property(self, GA_CTX_PROP_LARGEST_MEMBLOCK, &res)             # <<<<<<<<<<<<<<
 *             return res
 * 
 */
  __pyx_t_1 = __pyx_f_5pygpu_8gpuarray_ctx_property(__pyx_v_self, GA_CTX_PROP_LARGEST_MEMBLOCK, (&__pyx_v_res)); if (unlikely(__pyx_t_1 == ((int)-1))) __PYX_ERR(0, 1186, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":1187
 *             cdef size_t res
 *             ctx_property(self, GA_CTX_PROP_LARGEST_MEMBLOCK, &res)
 *             return res             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_2 = __Pyx_PyInt_FromSize_t(__pyx_v_res); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1187, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_r = __pyx_t_2;
  __pyx_t_2 = 0;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":1184
 *     property largest_memblock:
 *         "Size of the largest memory block you can allocate"
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             cdef size_t res
 *             ctx_property(self, GA_CTX_PROP_LARGEST_MEMBLOCK, &res)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("pygpu.gpuarray.GpuContext.largest_memblock.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pxd":324
 *     cdef dict __dict__
 *     cdef gpucontext* ctx
 *     cdef readonly bytes kind             # <<<<<<<<<<<<<<
 *     cdef object __weakref__
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_10GpuContext_4kind_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_5pygpu_8gpuarray_10GpuContext_4kind_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_10GpuContext_4kind___get__(((struct PyGpuContextObject *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_10GpuContext_4kind___get__(struct PyGpuContextObject *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__", 0);
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_self->kind);
  __pyx_r = __pyx_v_self->kind;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":1193
 *     cdef int fl
 * 
 *     def __cinit__(self, fl):             # <<<<<<<<<<<<<<
 *         self.fl = fl
 * 
 */

/* Python wrapper */
static int __pyx_pw_5pygpu_8gpuarray_5flags_1__cinit__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static int __pyx_pw_5pygpu_8gpuarray_5flags_1__cinit__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_fl = 0;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__cinit__ (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_fl,0};
    PyObject* values[1] = {0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_fl)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "__cinit__") < 0)) __PYX_ERR(0, 1193, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 1) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
    }
    __pyx_v_fl = values[0];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("__cinit__", 1, 1, 1, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 1193, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("pygpu.gpuarray.flags.__cinit__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return -1;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_5flags___cinit__(((struct __pyx_obj_5pygpu_8gpuarray_flags *)__pyx_v_self), __pyx_v_fl);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_5pygpu_8gpuarray_5flags___cinit__(struct __pyx_obj_5pygpu_8gpuarray_flags *__pyx_v_self, PyObject *__pyx_v_fl) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  __Pyx_RefNannySetupContext("__cinit__", 0);

  /* "pygpu/gpuarray.pyx":1194
 * 
 *     def __cinit__(self, fl):
 *         self.fl = fl             # <<<<<<<<<<<<<<
 * 
 *     def __reduce__(self):
 */
  __pyx_t_1 = __Pyx_PyInt_As_int(__pyx_v_fl); if (unlikely((__pyx_t_1 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 1194, __pyx_L1_error)
  __pyx_v_self->fl = __pyx_t_1;

  /* "pygpu/gpuarray.pyx":1193
 *     cdef int fl
 * 
 *     def __cinit__(self, fl):             # <<<<<<<<<<<<<<
 *         self.fl = fl
 * 
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_AddTraceback("pygpu.gpuarray.flags.__cinit__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":1196
 *         self.fl = fl
 * 
 *     def __reduce__(self):             # <<<<<<<<<<<<<<
 *         return (flags, (self.fl,))
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_5flags_3__reduce__(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_pw_5pygpu_8gpuarray_5flags_3__reduce__(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__reduce__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_5flags_2__reduce__(((struct __pyx_obj_5pygpu_8gpuarray_flags *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_5flags_2__reduce__(struct __pyx_obj_5pygpu_8gpuarray_flags *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  __Pyx_RefNannySetupContext("__reduce__", 0);

  /* "pygpu/gpuarray.pyx":1197
 * 
 *     def __reduce__(self):
 *         return (flags, (self.fl,))             # <<<<<<<<<<<<<<
 * 
 *     def __getitem__(self, idx):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyInt_From_int(__pyx_v_self->fl); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1197, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = PyTuple_New(1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1197, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_GIVEREF(__pyx_t_1);
  PyTuple_SET_ITEM(__pyx_t_2, 0, __pyx_t_1);
  __pyx_t_1 = 0;
  __pyx_t_1 = PyTuple_New(2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1197, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_INCREF(((PyObject *)__pyx_ptype_5pygpu_8gpuarray_flags));
  __Pyx_GIVEREF(((PyObject *)__pyx_ptype_5pygpu_8gpuarray_flags));
  PyTuple_SET_ITEM(__pyx_t_1, 0, ((PyObject *)__pyx_ptype_5pygpu_8gpuarray_flags));
  __Pyx_GIVEREF(__pyx_t_2);
  PyTuple_SET_ITEM(__pyx_t_1, 1, __pyx_t_2);
  __pyx_t_2 = 0;
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":1196
 *         self.fl = fl
 * 
 *     def __reduce__(self):             # <<<<<<<<<<<<<<
 *         return (flags, (self.fl,))
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("pygpu.gpuarray.flags.__reduce__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":1199
 *         return (flags, (self.fl,))
 * 
 *     def __getitem__(self, idx):             # <<<<<<<<<<<<<<
 *         cdef const char *key
 *         cdef size_t n
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_5flags_5__getitem__(PyObject *__pyx_v_self, PyObject *__pyx_v_idx); /*proto*/
static PyObject *__pyx_pw_5pygpu_8gpuarray_5flags_5__getitem__(PyObject *__pyx_v_self, PyObject *__pyx_v_idx) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__getitem__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_5flags_4__getitem__(((struct __pyx_obj_5pygpu_8gpuarray_flags *)__pyx_v_self), ((PyObject *)__pyx_v_idx));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_5flags_4__getitem__(struct __pyx_obj_5pygpu_8gpuarray_flags *__pyx_v_self, PyObject *__pyx_v_idx) {
  char const *__pyx_v_key;
  size_t __pyx_v_n;
  char __pyx_v_c;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_t_2;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  char const *__pyx_t_5;
  Py_ssize_t __pyx_t_6;
  __Pyx_RefNannySetupContext("__getitem__", 0);
  __Pyx_INCREF(__pyx_v_idx);

  /* "pygpu/gpuarray.pyx":1204
 *         cdef char c
 * 
 *         if isinstance(idx, unicode):             # <<<<<<<<<<<<<<
 *             idx = idx.encode('UTF-8')
 *         if isinstance(idx, bytes):
 */
  __pyx_t_1 = PyUnicode_Check(__pyx_v_idx); 
  __pyx_t_2 = (__pyx_t_1 != 0);
  if (__pyx_t_2) {

    /* "pygpu/gpuarray.pyx":1205
 * 
 *         if isinstance(idx, unicode):
 *             idx = idx.encode('UTF-8')             # <<<<<<<<<<<<<<
 *         if isinstance(idx, bytes):
 *             key = idx
 */
    __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_idx, __pyx_n_s_encode); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1205, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_4 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_tuple__18, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1205, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_DECREF_SET(__pyx_v_idx, __pyx_t_4);
    __pyx_t_4 = 0;

    /* "pygpu/gpuarray.pyx":1204
 *         cdef char c
 * 
 *         if isinstance(idx, unicode):             # <<<<<<<<<<<<<<
 *             idx = idx.encode('UTF-8')
 *         if isinstance(idx, bytes):
 */
  }

  /* "pygpu/gpuarray.pyx":1206
 *         if isinstance(idx, unicode):
 *             idx = idx.encode('UTF-8')
 *         if isinstance(idx, bytes):             # <<<<<<<<<<<<<<
 *             key = idx
 *             n = len(idx)
 */
  __pyx_t_2 = PyBytes_Check(__pyx_v_idx); 
  __pyx_t_1 = (__pyx_t_2 != 0);
  if (__pyx_t_1) {

    /* "pygpu/gpuarray.pyx":1207
 *             idx = idx.encode('UTF-8')
 *         if isinstance(idx, bytes):
 *             key = idx             # <<<<<<<<<<<<<<
 *             n = len(idx)
 *         else:
 */
    __pyx_t_5 = __Pyx_PyObject_AsString(__pyx_v_idx); if (unlikely((!__pyx_t_5) && PyErr_Occurred())) __PYX_ERR(0, 1207, __pyx_L1_error)
    __pyx_v_key = __pyx_t_5;

    /* "pygpu/gpuarray.pyx":1208
 *         if isinstance(idx, bytes):
 *             key = idx
 *             n = len(idx)             # <<<<<<<<<<<<<<
 *         else:
 *             raise KeyError, "Unknown flag"
 */
    __pyx_t_6 = PyObject_Length(__pyx_v_idx); if (unlikely(__pyx_t_6 == ((Py_ssize_t)-1))) __PYX_ERR(0, 1208, __pyx_L1_error)
    __pyx_v_n = __pyx_t_6;

    /* "pygpu/gpuarray.pyx":1206
 *         if isinstance(idx, unicode):
 *             idx = idx.encode('UTF-8')
 *         if isinstance(idx, bytes):             # <<<<<<<<<<<<<<
 *             key = idx
 *             n = len(idx)
 */
    goto __pyx_L4;
  }

  /* "pygpu/gpuarray.pyx":1210
 *             n = len(idx)
 *         else:
 *             raise KeyError, "Unknown flag"             # <<<<<<<<<<<<<<
 *         if n == 1:
 *             c = key[0]
 */
  /*else*/ {
    __Pyx_Raise(__pyx_builtin_KeyError, __pyx_kp_s_Unknown_flag, 0, 0);
    __PYX_ERR(0, 1210, __pyx_L1_error)
  }
  __pyx_L4:;

  /* "pygpu/gpuarray.pyx":1211
 *         else:
 *             raise KeyError, "Unknown flag"
 *         if n == 1:             # <<<<<<<<<<<<<<
 *             c = key[0]
 *             if c == 'C':
 */
  switch (__pyx_v_n) {
    case 1:

    /* "pygpu/gpuarray.pyx":1212
 *             raise KeyError, "Unknown flag"
 *         if n == 1:
 *             c = key[0]             # <<<<<<<<<<<<<<
 *             if c == 'C':
 *                 return self.c_contiguous
 */
    __pyx_v_c = (__pyx_v_key[0]);

    /* "pygpu/gpuarray.pyx":1213
 *         if n == 1:
 *             c = key[0]
 *             if c == 'C':             # <<<<<<<<<<<<<<
 *                 return self.c_contiguous
 *             elif c == 'F':
 */
    __pyx_t_1 = ((__pyx_v_c == 'C') != 0);
    if (__pyx_t_1) {

      /* "pygpu/gpuarray.pyx":1214
 *             c = key[0]
 *             if c == 'C':
 *                 return self.c_contiguous             # <<<<<<<<<<<<<<
 *             elif c == 'F':
 *                 return self.f_contiguous
 */
      __Pyx_XDECREF(__pyx_r);
      __pyx_t_4 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_c_contiguous); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1214, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __pyx_r = __pyx_t_4;
      __pyx_t_4 = 0;
      goto __pyx_L0;

      /* "pygpu/gpuarray.pyx":1213
 *         if n == 1:
 *             c = key[0]
 *             if c == 'C':             # <<<<<<<<<<<<<<
 *                 return self.c_contiguous
 *             elif c == 'F':
 */
    }

    /* "pygpu/gpuarray.pyx":1215
 *             if c == 'C':
 *                 return self.c_contiguous
 *             elif c == 'F':             # <<<<<<<<<<<<<<
 *                 return self.f_contiguous
 *             elif c == 'W':
 */
    __pyx_t_1 = ((__pyx_v_c == 'F') != 0);
    if (__pyx_t_1) {

      /* "pygpu/gpuarray.pyx":1216
 *                 return self.c_contiguous
 *             elif c == 'F':
 *                 return self.f_contiguous             # <<<<<<<<<<<<<<
 *             elif c == 'W':
 *                 return self.writeable
 */
      __Pyx_XDECREF(__pyx_r);
      __pyx_t_4 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_f_contiguous); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1216, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __pyx_r = __pyx_t_4;
      __pyx_t_4 = 0;
      goto __pyx_L0;

      /* "pygpu/gpuarray.pyx":1215
 *             if c == 'C':
 *                 return self.c_contiguous
 *             elif c == 'F':             # <<<<<<<<<<<<<<
 *                 return self.f_contiguous
 *             elif c == 'W':
 */
    }

    /* "pygpu/gpuarray.pyx":1217
 *             elif c == 'F':
 *                 return self.f_contiguous
 *             elif c == 'W':             # <<<<<<<<<<<<<<
 *                 return self.writeable
 *             elif c == 'B':
 */
    __pyx_t_1 = ((__pyx_v_c == 'W') != 0);
    if (__pyx_t_1) {

      /* "pygpu/gpuarray.pyx":1218
 *                 return self.f_contiguous
 *             elif c == 'W':
 *                 return self.writeable             # <<<<<<<<<<<<<<
 *             elif c == 'B':
 *                 return self.behaved
 */
      __Pyx_XDECREF(__pyx_r);
      __pyx_t_4 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_writeable); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1218, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __pyx_r = __pyx_t_4;
      __pyx_t_4 = 0;
      goto __pyx_L0;

      /* "pygpu/gpuarray.pyx":1217
 *             elif c == 'F':
 *                 return self.f_contiguous
 *             elif c == 'W':             # <<<<<<<<<<<<<<
 *                 return self.writeable
 *             elif c == 'B':
 */
    }

    /* "pygpu/gpuarray.pyx":1219
 *             elif c == 'W':
 *                 return self.writeable
 *             elif c == 'B':             # <<<<<<<<<<<<<<
 *                 return self.behaved
 *             elif c == 'O':
 */
    __pyx_t_1 = ((__pyx_v_c == 'B') != 0);
    if (__pyx_t_1) {

      /* "pygpu/gpuarray.pyx":1220
 *                 return self.writeable
 *             elif c == 'B':
 *                 return self.behaved             # <<<<<<<<<<<<<<
 *             elif c == 'O':
 *                 return self.owndata
 */
      __Pyx_XDECREF(__pyx_r);
      __pyx_t_4 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_behaved); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1220, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __pyx_r = __pyx_t_4;
      __pyx_t_4 = 0;
      goto __pyx_L0;

      /* "pygpu/gpuarray.pyx":1219
 *             elif c == 'W':
 *                 return self.writeable
 *             elif c == 'B':             # <<<<<<<<<<<<<<
 *                 return self.behaved
 *             elif c == 'O':
 */
    }

    /* "pygpu/gpuarray.pyx":1221
 *             elif c == 'B':
 *                 return self.behaved
 *             elif c == 'O':             # <<<<<<<<<<<<<<
 *                 return self.owndata
 *             elif c == 'A':
 */
    __pyx_t_1 = ((__pyx_v_c == 'O') != 0);
    if (__pyx_t_1) {

      /* "pygpu/gpuarray.pyx":1222
 *                 return self.behaved
 *             elif c == 'O':
 *                 return self.owndata             # <<<<<<<<<<<<<<
 *             elif c == 'A':
 *                 return self.aligned
 */
      __Pyx_XDECREF(__pyx_r);
      __pyx_t_4 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_owndata); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1222, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __pyx_r = __pyx_t_4;
      __pyx_t_4 = 0;
      goto __pyx_L0;

      /* "pygpu/gpuarray.pyx":1221
 *             elif c == 'B':
 *                 return self.behaved
 *             elif c == 'O':             # <<<<<<<<<<<<<<
 *                 return self.owndata
 *             elif c == 'A':
 */
    }

    /* "pygpu/gpuarray.pyx":1223
 *             elif c == 'O':
 *                 return self.owndata
 *             elif c == 'A':             # <<<<<<<<<<<<<<
 *                 return self.aligned
 *             elif c == 'U':
 */
    __pyx_t_1 = ((__pyx_v_c == 'A') != 0);
    if (__pyx_t_1) {

      /* "pygpu/gpuarray.pyx":1224
 *                 return self.owndata
 *             elif c == 'A':
 *                 return self.aligned             # <<<<<<<<<<<<<<
 *             elif c == 'U':
 *                 return self.updateifcopy
 */
      __Pyx_XDECREF(__pyx_r);
      __pyx_t_4 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_aligned); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1224, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __pyx_r = __pyx_t_4;
      __pyx_t_4 = 0;
      goto __pyx_L0;

      /* "pygpu/gpuarray.pyx":1223
 *             elif c == 'O':
 *                 return self.owndata
 *             elif c == 'A':             # <<<<<<<<<<<<<<
 *                 return self.aligned
 *             elif c == 'U':
 */
    }

    /* "pygpu/gpuarray.pyx":1225
 *             elif c == 'A':
 *                 return self.aligned
 *             elif c == 'U':             # <<<<<<<<<<<<<<
 *                 return self.updateifcopy
 *         elif n == 2:
 */
    __pyx_t_1 = ((__pyx_v_c == 'U') != 0);
    if (__pyx_t_1) {

      /* "pygpu/gpuarray.pyx":1226
 *                 return self.aligned
 *             elif c == 'U':
 *                 return self.updateifcopy             # <<<<<<<<<<<<<<
 *         elif n == 2:
 *             if strncmp(key, "CA", n) == 0:
 */
      __Pyx_XDECREF(__pyx_r);
      __pyx_t_4 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_updateifcopy); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1226, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __pyx_r = __pyx_t_4;
      __pyx_t_4 = 0;
      goto __pyx_L0;

      /* "pygpu/gpuarray.pyx":1225
 *             elif c == 'A':
 *                 return self.aligned
 *             elif c == 'U':             # <<<<<<<<<<<<<<
 *                 return self.updateifcopy
 *         elif n == 2:
 */
    }

    /* "pygpu/gpuarray.pyx":1211
 *         else:
 *             raise KeyError, "Unknown flag"
 *         if n == 1:             # <<<<<<<<<<<<<<
 *             c = key[0]
 *             if c == 'C':
 */
    break;

    /* "pygpu/gpuarray.pyx":1227
 *             elif c == 'U':
 *                 return self.updateifcopy
 *         elif n == 2:             # <<<<<<<<<<<<<<
 *             if strncmp(key, "CA", n) == 0:
 *                 return self.carray
 */
    case 2:

    /* "pygpu/gpuarray.pyx":1228
 *                 return self.updateifcopy
 *         elif n == 2:
 *             if strncmp(key, "CA", n) == 0:             # <<<<<<<<<<<<<<
 *                 return self.carray
 *             if strncmp(key, "FA", n) == 0:
 */
    __pyx_t_1 = ((strncmp(__pyx_v_key, ((char const *)"CA"), __pyx_v_n) == 0) != 0);
    if (__pyx_t_1) {

      /* "pygpu/gpuarray.pyx":1229
 *         elif n == 2:
 *             if strncmp(key, "CA", n) == 0:
 *                 return self.carray             # <<<<<<<<<<<<<<
 *             if strncmp(key, "FA", n) == 0:
 *                 return self.farray
 */
      __Pyx_XDECREF(__pyx_r);
      __pyx_t_4 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_carray); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1229, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __pyx_r = __pyx_t_4;
      __pyx_t_4 = 0;
      goto __pyx_L0;

      /* "pygpu/gpuarray.pyx":1228
 *                 return self.updateifcopy
 *         elif n == 2:
 *             if strncmp(key, "CA", n) == 0:             # <<<<<<<<<<<<<<
 *                 return self.carray
 *             if strncmp(key, "FA", n) == 0:
 */
    }

    /* "pygpu/gpuarray.pyx":1230
 *             if strncmp(key, "CA", n) == 0:
 *                 return self.carray
 *             if strncmp(key, "FA", n) == 0:             # <<<<<<<<<<<<<<
 *                 return self.farray
 *         elif n == 3:
 */
    __pyx_t_1 = ((strncmp(__pyx_v_key, ((char const *)"FA"), __pyx_v_n) == 0) != 0);
    if (__pyx_t_1) {

      /* "pygpu/gpuarray.pyx":1231
 *                 return self.carray
 *             if strncmp(key, "FA", n) == 0:
 *                 return self.farray             # <<<<<<<<<<<<<<
 *         elif n == 3:
 *             if strncmp(key, "FNC", n) == 0:
 */
      __Pyx_XDECREF(__pyx_r);
      __pyx_t_4 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_farray); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1231, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __pyx_r = __pyx_t_4;
      __pyx_t_4 = 0;
      goto __pyx_L0;

      /* "pygpu/gpuarray.pyx":1230
 *             if strncmp(key, "CA", n) == 0:
 *                 return self.carray
 *             if strncmp(key, "FA", n) == 0:             # <<<<<<<<<<<<<<
 *                 return self.farray
 *         elif n == 3:
 */
    }

    /* "pygpu/gpuarray.pyx":1227
 *             elif c == 'U':
 *                 return self.updateifcopy
 *         elif n == 2:             # <<<<<<<<<<<<<<
 *             if strncmp(key, "CA", n) == 0:
 *                 return self.carray
 */
    break;

    /* "pygpu/gpuarray.pyx":1232
 *             if strncmp(key, "FA", n) == 0:
 *                 return self.farray
 *         elif n == 3:             # <<<<<<<<<<<<<<
 *             if strncmp(key, "FNC", n) == 0:
 *                 return self.fnc
 */
    case 3:

    /* "pygpu/gpuarray.pyx":1233
 *                 return self.farray
 *         elif n == 3:
 *             if strncmp(key, "FNC", n) == 0:             # <<<<<<<<<<<<<<
 *                 return self.fnc
 *         elif n == 4:
 */
    __pyx_t_1 = ((strncmp(__pyx_v_key, ((char const *)"FNC"), __pyx_v_n) == 0) != 0);
    if (__pyx_t_1) {

      /* "pygpu/gpuarray.pyx":1234
 *         elif n == 3:
 *             if strncmp(key, "FNC", n) == 0:
 *                 return self.fnc             # <<<<<<<<<<<<<<
 *         elif n == 4:
 *             if strncmp(key, "FORC", n) == 0:
 */
      __Pyx_XDECREF(__pyx_r);
      __pyx_t_4 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_fnc); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1234, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __pyx_r = __pyx_t_4;
      __pyx_t_4 = 0;
      goto __pyx_L0;

      /* "pygpu/gpuarray.pyx":1233
 *                 return self.farray
 *         elif n == 3:
 *             if strncmp(key, "FNC", n) == 0:             # <<<<<<<<<<<<<<
 *                 return self.fnc
 *         elif n == 4:
 */
    }

    /* "pygpu/gpuarray.pyx":1232
 *             if strncmp(key, "FA", n) == 0:
 *                 return self.farray
 *         elif n == 3:             # <<<<<<<<<<<<<<
 *             if strncmp(key, "FNC", n) == 0:
 *                 return self.fnc
 */
    break;

    /* "pygpu/gpuarray.pyx":1235
 *             if strncmp(key, "FNC", n) == 0:
 *                 return self.fnc
 *         elif n == 4:             # <<<<<<<<<<<<<<
 *             if strncmp(key, "FORC", n) == 0:
 *                 return self.forc
 */
    case 4:

    /* "pygpu/gpuarray.pyx":1236
 *                 return self.fnc
 *         elif n == 4:
 *             if strncmp(key, "FORC", n) == 0:             # <<<<<<<<<<<<<<
 *                 return self.forc
 *         elif n == 6:
 */
    __pyx_t_1 = ((strncmp(__pyx_v_key, ((char const *)"FORC"), __pyx_v_n) == 0) != 0);
    if (__pyx_t_1) {

      /* "pygpu/gpuarray.pyx":1237
 *         elif n == 4:
 *             if strncmp(key, "FORC", n) == 0:
 *                 return self.forc             # <<<<<<<<<<<<<<
 *         elif n == 6:
 *             if strncmp(key, "CARRAY", n) == 0:
 */
      __Pyx_XDECREF(__pyx_r);
      __pyx_t_4 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_forc); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1237, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __pyx_r = __pyx_t_4;
      __pyx_t_4 = 0;
      goto __pyx_L0;

      /* "pygpu/gpuarray.pyx":1236
 *                 return self.fnc
 *         elif n == 4:
 *             if strncmp(key, "FORC", n) == 0:             # <<<<<<<<<<<<<<
 *                 return self.forc
 *         elif n == 6:
 */
    }

    /* "pygpu/gpuarray.pyx":1235
 *             if strncmp(key, "FNC", n) == 0:
 *                 return self.fnc
 *         elif n == 4:             # <<<<<<<<<<<<<<
 *             if strncmp(key, "FORC", n) == 0:
 *                 return self.forc
 */
    break;

    /* "pygpu/gpuarray.pyx":1238
 *             if strncmp(key, "FORC", n) == 0:
 *                 return self.forc
 *         elif n == 6:             # <<<<<<<<<<<<<<
 *             if strncmp(key, "CARRAY", n) == 0:
 *                 return self.carray
 */
    case 6:

    /* "pygpu/gpuarray.pyx":1239
 *                 return self.forc
 *         elif n == 6:
 *             if strncmp(key, "CARRAY", n) == 0:             # <<<<<<<<<<<<<<
 *                 return self.carray
 *             if strncmp(key, "FARRAY", n) == 0:
 */
    __pyx_t_1 = ((strncmp(__pyx_v_key, ((char const *)"CARRAY"), __pyx_v_n) == 0) != 0);
    if (__pyx_t_1) {

      /* "pygpu/gpuarray.pyx":1240
 *         elif n == 6:
 *             if strncmp(key, "CARRAY", n) == 0:
 *                 return self.carray             # <<<<<<<<<<<<<<
 *             if strncmp(key, "FARRAY", n) == 0:
 *                 return self.farray
 */
      __Pyx_XDECREF(__pyx_r);
      __pyx_t_4 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_carray); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1240, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __pyx_r = __pyx_t_4;
      __pyx_t_4 = 0;
      goto __pyx_L0;

      /* "pygpu/gpuarray.pyx":1239
 *                 return self.forc
 *         elif n == 6:
 *             if strncmp(key, "CARRAY", n) == 0:             # <<<<<<<<<<<<<<
 *                 return self.carray
 *             if strncmp(key, "FARRAY", n) == 0:
 */
    }

    /* "pygpu/gpuarray.pyx":1241
 *             if strncmp(key, "CARRAY", n) == 0:
 *                 return self.carray
 *             if strncmp(key, "FARRAY", n) == 0:             # <<<<<<<<<<<<<<
 *                 return self.farray
 *         elif n == 7:
 */
    __pyx_t_1 = ((strncmp(__pyx_v_key, ((char const *)"FARRAY"), __pyx_v_n) == 0) != 0);
    if (__pyx_t_1) {

      /* "pygpu/gpuarray.pyx":1242
 *                 return self.carray
 *             if strncmp(key, "FARRAY", n) == 0:
 *                 return self.farray             # <<<<<<<<<<<<<<
 *         elif n == 7:
 *             if strncmp(key, "FORTRAN", n) == 0:
 */
      __Pyx_XDECREF(__pyx_r);
      __pyx_t_4 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_farray); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1242, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __pyx_r = __pyx_t_4;
      __pyx_t_4 = 0;
      goto __pyx_L0;

      /* "pygpu/gpuarray.pyx":1241
 *             if strncmp(key, "CARRAY", n) == 0:
 *                 return self.carray
 *             if strncmp(key, "FARRAY", n) == 0:             # <<<<<<<<<<<<<<
 *                 return self.farray
 *         elif n == 7:
 */
    }

    /* "pygpu/gpuarray.pyx":1238
 *             if strncmp(key, "FORC", n) == 0:
 *                 return self.forc
 *         elif n == 6:             # <<<<<<<<<<<<<<
 *             if strncmp(key, "CARRAY", n) == 0:
 *                 return self.carray
 */
    break;

    /* "pygpu/gpuarray.pyx":1243
 *             if strncmp(key, "FARRAY", n) == 0:
 *                 return self.farray
 *         elif n == 7:             # <<<<<<<<<<<<<<
 *             if strncmp(key, "FORTRAN", n) == 0:
 *                 return self.fortran
 */
    case 7:

    /* "pygpu/gpuarray.pyx":1244
 *                 return self.farray
 *         elif n == 7:
 *             if strncmp(key, "FORTRAN", n) == 0:             # <<<<<<<<<<<<<<
 *                 return self.fortran
 *             if strncmp(key, "BEHAVED", n) == 0:
 */
    __pyx_t_1 = ((strncmp(__pyx_v_key, ((char const *)"FORTRAN"), __pyx_v_n) == 0) != 0);
    if (__pyx_t_1) {

      /* "pygpu/gpuarray.pyx":1245
 *         elif n == 7:
 *             if strncmp(key, "FORTRAN", n) == 0:
 *                 return self.fortran             # <<<<<<<<<<<<<<
 *             if strncmp(key, "BEHAVED", n) == 0:
 *                 return self.behaved
 */
      __Pyx_XDECREF(__pyx_r);
      __pyx_t_4 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_fortran); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1245, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __pyx_r = __pyx_t_4;
      __pyx_t_4 = 0;
      goto __pyx_L0;

      /* "pygpu/gpuarray.pyx":1244
 *                 return self.farray
 *         elif n == 7:
 *             if strncmp(key, "FORTRAN", n) == 0:             # <<<<<<<<<<<<<<
 *                 return self.fortran
 *             if strncmp(key, "BEHAVED", n) == 0:
 */
    }

    /* "pygpu/gpuarray.pyx":1246
 *             if strncmp(key, "FORTRAN", n) == 0:
 *                 return self.fortran
 *             if strncmp(key, "BEHAVED", n) == 0:             # <<<<<<<<<<<<<<
 *                 return self.behaved
 *             if strncmp(key, "OWNDATA", n) == 0:
 */
    __pyx_t_1 = ((strncmp(__pyx_v_key, ((char const *)"BEHAVED"), __pyx_v_n) == 0) != 0);
    if (__pyx_t_1) {

      /* "pygpu/gpuarray.pyx":1247
 *                 return self.fortran
 *             if strncmp(key, "BEHAVED", n) == 0:
 *                 return self.behaved             # <<<<<<<<<<<<<<
 *             if strncmp(key, "OWNDATA", n) == 0:
 *                 return self.owndata
 */
      __Pyx_XDECREF(__pyx_r);
      __pyx_t_4 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_behaved); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1247, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __pyx_r = __pyx_t_4;
      __pyx_t_4 = 0;
      goto __pyx_L0;

      /* "pygpu/gpuarray.pyx":1246
 *             if strncmp(key, "FORTRAN", n) == 0:
 *                 return self.fortran
 *             if strncmp(key, "BEHAVED", n) == 0:             # <<<<<<<<<<<<<<
 *                 return self.behaved
 *             if strncmp(key, "OWNDATA", n) == 0:
 */
    }

    /* "pygpu/gpuarray.pyx":1248
 *             if strncmp(key, "BEHAVED", n) == 0:
 *                 return self.behaved
 *             if strncmp(key, "OWNDATA", n) == 0:             # <<<<<<<<<<<<<<
 *                 return self.owndata
 *             if strncmp(key, "ALIGNED", n) == 0:
 */
    __pyx_t_1 = ((strncmp(__pyx_v_key, ((char const *)"OWNDATA"), __pyx_v_n) == 0) != 0);
    if (__pyx_t_1) {

      /* "pygpu/gpuarray.pyx":1249
 *                 return self.behaved
 *             if strncmp(key, "OWNDATA", n) == 0:
 *                 return self.owndata             # <<<<<<<<<<<<<<
 *             if strncmp(key, "ALIGNED", n) == 0:
 *                 return self.aligned
 */
      __Pyx_XDECREF(__pyx_r);
      __pyx_t_4 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_owndata); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1249, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __pyx_r = __pyx_t_4;
      __pyx_t_4 = 0;
      goto __pyx_L0;

      /* "pygpu/gpuarray.pyx":1248
 *             if strncmp(key, "BEHAVED", n) == 0:
 *                 return self.behaved
 *             if strncmp(key, "OWNDATA", n) == 0:             # <<<<<<<<<<<<<<
 *                 return self.owndata
 *             if strncmp(key, "ALIGNED", n) == 0:
 */
    }

    /* "pygpu/gpuarray.pyx":1250
 *             if strncmp(key, "OWNDATA", n) == 0:
 *                 return self.owndata
 *             if strncmp(key, "ALIGNED", n) == 0:             # <<<<<<<<<<<<<<
 *                 return self.aligned
 *         elif n == 9:
 */
    __pyx_t_1 = ((strncmp(__pyx_v_key, ((char const *)"ALIGNED"), __pyx_v_n) == 0) != 0);
    if (__pyx_t_1) {

      /* "pygpu/gpuarray.pyx":1251
 *                 return self.owndata
 *             if strncmp(key, "ALIGNED", n) == 0:
 *                 return self.aligned             # <<<<<<<<<<<<<<
 *         elif n == 9:
 *             if strncmp(key, "WRITEABLE", n) == 0:
 */
      __Pyx_XDECREF(__pyx_r);
      __pyx_t_4 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_aligned); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1251, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __pyx_r = __pyx_t_4;
      __pyx_t_4 = 0;
      goto __pyx_L0;

      /* "pygpu/gpuarray.pyx":1250
 *             if strncmp(key, "OWNDATA", n) == 0:
 *                 return self.owndata
 *             if strncmp(key, "ALIGNED", n) == 0:             # <<<<<<<<<<<<<<
 *                 return self.aligned
 *         elif n == 9:
 */
    }

    /* "pygpu/gpuarray.pyx":1243
 *             if strncmp(key, "FARRAY", n) == 0:
 *                 return self.farray
 *         elif n == 7:             # <<<<<<<<<<<<<<
 *             if strncmp(key, "FORTRAN", n) == 0:
 *                 return self.fortran
 */
    break;

    /* "pygpu/gpuarray.pyx":1252
 *             if strncmp(key, "ALIGNED", n) == 0:
 *                 return self.aligned
 *         elif n == 9:             # <<<<<<<<<<<<<<
 *             if strncmp(key, "WRITEABLE", n) == 0:
 *                 return self.writeable
 */
    case 9:

    /* "pygpu/gpuarray.pyx":1253
 *                 return self.aligned
 *         elif n == 9:
 *             if strncmp(key, "WRITEABLE", n) == 0:             # <<<<<<<<<<<<<<
 *                 return self.writeable
 *         elif n == 10:
 */
    __pyx_t_1 = ((strncmp(__pyx_v_key, ((char const *)"WRITEABLE"), __pyx_v_n) == 0) != 0);
    if (__pyx_t_1) {

      /* "pygpu/gpuarray.pyx":1254
 *         elif n == 9:
 *             if strncmp(key, "WRITEABLE", n) == 0:
 *                 return self.writeable             # <<<<<<<<<<<<<<
 *         elif n == 10:
 *             if strncmp(key, "CONTIGUOUS", n) == 0:
 */
      __Pyx_XDECREF(__pyx_r);
      __pyx_t_4 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_writeable); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1254, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __pyx_r = __pyx_t_4;
      __pyx_t_4 = 0;
      goto __pyx_L0;

      /* "pygpu/gpuarray.pyx":1253
 *                 return self.aligned
 *         elif n == 9:
 *             if strncmp(key, "WRITEABLE", n) == 0:             # <<<<<<<<<<<<<<
 *                 return self.writeable
 *         elif n == 10:
 */
    }

    /* "pygpu/gpuarray.pyx":1252
 *             if strncmp(key, "ALIGNED", n) == 0:
 *                 return self.aligned
 *         elif n == 9:             # <<<<<<<<<<<<<<
 *             if strncmp(key, "WRITEABLE", n) == 0:
 *                 return self.writeable
 */
    break;

    /* "pygpu/gpuarray.pyx":1255
 *             if strncmp(key, "WRITEABLE", n) == 0:
 *                 return self.writeable
 *         elif n == 10:             # <<<<<<<<<<<<<<
 *             if strncmp(key, "CONTIGUOUS", n) == 0:
 *                 return self.c_contiguous
 */
    case 10:

    /* "pygpu/gpuarray.pyx":1256
 *                 return self.writeable
 *         elif n == 10:
 *             if strncmp(key, "CONTIGUOUS", n) == 0:             # <<<<<<<<<<<<<<
 *                 return self.c_contiguous
 *         elif n == 12:
 */
    __pyx_t_1 = ((strncmp(__pyx_v_key, ((char const *)"CONTIGUOUS"), __pyx_v_n) == 0) != 0);
    if (__pyx_t_1) {

      /* "pygpu/gpuarray.pyx":1257
 *         elif n == 10:
 *             if strncmp(key, "CONTIGUOUS", n) == 0:
 *                 return self.c_contiguous             # <<<<<<<<<<<<<<
 *         elif n == 12:
 *             if strncmp(key, "UPDATEIFCOPY", n) == 0:
 */
      __Pyx_XDECREF(__pyx_r);
      __pyx_t_4 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_c_contiguous); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1257, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __pyx_r = __pyx_t_4;
      __pyx_t_4 = 0;
      goto __pyx_L0;

      /* "pygpu/gpuarray.pyx":1256
 *                 return self.writeable
 *         elif n == 10:
 *             if strncmp(key, "CONTIGUOUS", n) == 0:             # <<<<<<<<<<<<<<
 *                 return self.c_contiguous
 *         elif n == 12:
 */
    }

    /* "pygpu/gpuarray.pyx":1255
 *             if strncmp(key, "WRITEABLE", n) == 0:
 *                 return self.writeable
 *         elif n == 10:             # <<<<<<<<<<<<<<
 *             if strncmp(key, "CONTIGUOUS", n) == 0:
 *                 return self.c_contiguous
 */
    break;

    /* "pygpu/gpuarray.pyx":1258
 *             if strncmp(key, "CONTIGUOUS", n) == 0:
 *                 return self.c_contiguous
 *         elif n == 12:             # <<<<<<<<<<<<<<
 *             if strncmp(key, "UPDATEIFCOPY", n) == 0:
 *                 return self.updateifcopy
 */
    case 12:

    /* "pygpu/gpuarray.pyx":1259
 *                 return self.c_contiguous
 *         elif n == 12:
 *             if strncmp(key, "UPDATEIFCOPY", n) == 0:             # <<<<<<<<<<<<<<
 *                 return self.updateifcopy
 *             if strncmp(key, "C_CONTIGUOUS", n) == 0:
 */
    __pyx_t_1 = ((strncmp(__pyx_v_key, ((char const *)"UPDATEIFCOPY"), __pyx_v_n) == 0) != 0);
    if (__pyx_t_1) {

      /* "pygpu/gpuarray.pyx":1260
 *         elif n == 12:
 *             if strncmp(key, "UPDATEIFCOPY", n) == 0:
 *                 return self.updateifcopy             # <<<<<<<<<<<<<<
 *             if strncmp(key, "C_CONTIGUOUS", n) == 0:
 *                 return self.c_contiguous
 */
      __Pyx_XDECREF(__pyx_r);
      __pyx_t_4 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_updateifcopy); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1260, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __pyx_r = __pyx_t_4;
      __pyx_t_4 = 0;
      goto __pyx_L0;

      /* "pygpu/gpuarray.pyx":1259
 *                 return self.c_contiguous
 *         elif n == 12:
 *             if strncmp(key, "UPDATEIFCOPY", n) == 0:             # <<<<<<<<<<<<<<
 *                 return self.updateifcopy
 *             if strncmp(key, "C_CONTIGUOUS", n) == 0:
 */
    }

    /* "pygpu/gpuarray.pyx":1261
 *             if strncmp(key, "UPDATEIFCOPY", n) == 0:
 *                 return self.updateifcopy
 *             if strncmp(key, "C_CONTIGUOUS", n) == 0:             # <<<<<<<<<<<<<<
 *                 return self.c_contiguous
 *             if strncmp(key, "F_CONTIGUOUS", n) == 0:
 */
    __pyx_t_1 = ((strncmp(__pyx_v_key, ((char const *)"C_CONTIGUOUS"), __pyx_v_n) == 0) != 0);
    if (__pyx_t_1) {

      /* "pygpu/gpuarray.pyx":1262
 *                 return self.updateifcopy
 *             if strncmp(key, "C_CONTIGUOUS", n) == 0:
 *                 return self.c_contiguous             # <<<<<<<<<<<<<<
 *             if strncmp(key, "F_CONTIGUOUS", n) == 0:
 *                 return self.f_contiguous
 */
      __Pyx_XDECREF(__pyx_r);
      __pyx_t_4 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_c_contiguous); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1262, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __pyx_r = __pyx_t_4;
      __pyx_t_4 = 0;
      goto __pyx_L0;

      /* "pygpu/gpuarray.pyx":1261
 *             if strncmp(key, "UPDATEIFCOPY", n) == 0:
 *                 return self.updateifcopy
 *             if strncmp(key, "C_CONTIGUOUS", n) == 0:             # <<<<<<<<<<<<<<
 *                 return self.c_contiguous
 *             if strncmp(key, "F_CONTIGUOUS", n) == 0:
 */
    }

    /* "pygpu/gpuarray.pyx":1263
 *             if strncmp(key, "C_CONTIGUOUS", n) == 0:
 *                 return self.c_contiguous
 *             if strncmp(key, "F_CONTIGUOUS", n) == 0:             # <<<<<<<<<<<<<<
 *                 return self.f_contiguous
 * 
 */
    __pyx_t_1 = ((strncmp(__pyx_v_key, ((char const *)"F_CONTIGUOUS"), __pyx_v_n) == 0) != 0);
    if (__pyx_t_1) {

      /* "pygpu/gpuarray.pyx":1264
 *                 return self.c_contiguous
 *             if strncmp(key, "F_CONTIGUOUS", n) == 0:
 *                 return self.f_contiguous             # <<<<<<<<<<<<<<
 * 
 *         raise KeyError, "Unknown flag"
 */
      __Pyx_XDECREF(__pyx_r);
      __pyx_t_4 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_f_contiguous); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1264, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __pyx_r = __pyx_t_4;
      __pyx_t_4 = 0;
      goto __pyx_L0;

      /* "pygpu/gpuarray.pyx":1263
 *             if strncmp(key, "C_CONTIGUOUS", n) == 0:
 *                 return self.c_contiguous
 *             if strncmp(key, "F_CONTIGUOUS", n) == 0:             # <<<<<<<<<<<<<<
 *                 return self.f_contiguous
 * 
 */
    }

    /* "pygpu/gpuarray.pyx":1258
 *             if strncmp(key, "CONTIGUOUS", n) == 0:
 *                 return self.c_contiguous
 *         elif n == 12:             # <<<<<<<<<<<<<<
 *             if strncmp(key, "UPDATEIFCOPY", n) == 0:
 *                 return self.updateifcopy
 */
    break;
    default: break;
  }

  /* "pygpu/gpuarray.pyx":1266
 *                 return self.f_contiguous
 * 
 *         raise KeyError, "Unknown flag"             # <<<<<<<<<<<<<<
 * 
 *     def __repr__(self):
 */
  __Pyx_Raise(__pyx_builtin_KeyError, __pyx_kp_s_Unknown_flag, 0, 0);
  __PYX_ERR(0, 1266, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":1199
 *         return (flags, (self.fl,))
 * 
 *     def __getitem__(self, idx):             # <<<<<<<<<<<<<<
 *         cdef const char *key
 *         cdef size_t n
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_AddTraceback("pygpu.gpuarray.flags.__getitem__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_idx);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":1268
 *         raise KeyError, "Unknown flag"
 * 
 *     def __repr__(self):             # <<<<<<<<<<<<<<
 *         return '\n'.join(" %s : %s" % (name.upper(), getattr(self, name))
 *                          for name in ["c_contiguous", "f_contiguous",
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_5flags_7__repr__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_5pygpu_8gpuarray_5flags_7__repr__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__repr__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_5flags_6__repr__(((struct __pyx_obj_5pygpu_8gpuarray_flags *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}
static PyObject *__pyx_gb_5pygpu_8gpuarray_5flags_8__repr___2generator1(__pyx_CoroutineObject *__pyx_generator, CYTHON_UNUSED PyThreadState *__pyx_tstate, PyObject *__pyx_sent_value); /* proto */

/* "pygpu/gpuarray.pyx":1269
 * 
 *     def __repr__(self):
 *         return '\n'.join(" %s : %s" % (name.upper(), getattr(self, name))             # <<<<<<<<<<<<<<
 *                          for name in ["c_contiguous", "f_contiguous",
 *                                       "owndata", "writeable", "aligned",
 */

static PyObject *__pyx_pf_5pygpu_8gpuarray_5flags_8__repr___genexpr(PyObject *__pyx_self) {
  struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_2_genexpr *__pyx_cur_scope;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("genexpr", 0);
  __pyx_cur_scope = (struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_2_genexpr *)__pyx_tp_new_5pygpu_8gpuarray___pyx_scope_struct_2_genexpr(__pyx_ptype_5pygpu_8gpuarray___pyx_scope_struct_2_genexpr, __pyx_empty_tuple, NULL);
  if (unlikely(!__pyx_cur_scope)) {
    __pyx_cur_scope = ((struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_2_genexpr *)Py_None);
    __Pyx_INCREF(Py_None);
    __PYX_ERR(0, 1269, __pyx_L1_error)
  } else {
    __Pyx_GOTREF(__pyx_cur_scope);
  }
  __pyx_cur_scope->__pyx_outer_scope = (struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_1___repr__ *) __pyx_self;
  __Pyx_INCREF(((PyObject *)__pyx_cur_scope->__pyx_outer_scope));
  __Pyx_GIVEREF(__pyx_cur_scope->__pyx_outer_scope);
  {
    __pyx_CoroutineObject *gen = __Pyx_Generator_New((__pyx_coroutine_body_t) __pyx_gb_5pygpu_8gpuarray_5flags_8__repr___2generator1, (PyObject *) __pyx_cur_scope, __pyx_n_s_genexpr, __pyx_n_s_repr___locals_genexpr, __pyx_n_s_pygpu_gpuarray); if (unlikely(!gen)) __PYX_ERR(0, 1269, __pyx_L1_error)
    __Pyx_DECREF(__pyx_cur_scope);
    __Pyx_RefNannyFinishContext();
    return (PyObject *) gen;
  }

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_AddTraceback("pygpu.gpuarray.flags.__repr__.genexpr", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __Pyx_DECREF(((PyObject *)__pyx_cur_scope));
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_gb_5pygpu_8gpuarray_5flags_8__repr___2generator1(__pyx_CoroutineObject *__pyx_generator, CYTHON_UNUSED PyThreadState *__pyx_tstate, PyObject *__pyx_sent_value) /* generator body */
{
  struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_2_genexpr *__pyx_cur_scope = ((struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_2_genexpr *)__pyx_generator->closure);
  PyObject *__pyx_r = NULL;
  PyObject *__pyx_t_1 = NULL;
  Py_ssize_t __pyx_t_2;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("genexpr", 0);
  switch (__pyx_generator->resume_label) {
    case 0: goto __pyx_L3_first_run;
    case 1: goto __pyx_L6_resume_from_yield;
    default: /* CPython raises the right error here */
    __Pyx_RefNannyFinishContext();
    return NULL;
  }
  __pyx_L3_first_run:;
  if (unlikely(!__pyx_sent_value)) __PYX_ERR(0, 1269, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":1270
 *     def __repr__(self):
 *         return '\n'.join(" %s : %s" % (name.upper(), getattr(self, name))
 *                          for name in ["c_contiguous", "f_contiguous",             # <<<<<<<<<<<<<<
 *                                       "owndata", "writeable", "aligned",
 *                                       "updateifcopy"])
 */
  __pyx_t_1 = __pyx_tuple__19; __Pyx_INCREF(__pyx_t_1); __pyx_t_2 = 0;
  for (;;) {
    if (__pyx_t_2 >= 6) break;
    #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    __pyx_t_3 = PyTuple_GET_ITEM(__pyx_t_1, __pyx_t_2); __Pyx_INCREF(__pyx_t_3); __pyx_t_2++; if (unlikely(0 < 0)) __PYX_ERR(0, 1270, __pyx_L1_error)
    #else
    __pyx_t_3 = PySequence_ITEM(__pyx_t_1, __pyx_t_2); __pyx_t_2++; if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1270, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    #endif
    __Pyx_XGOTREF(__pyx_cur_scope->__pyx_v_name);
    __Pyx_XDECREF_SET(__pyx_cur_scope->__pyx_v_name, __pyx_t_3);
    __Pyx_GIVEREF(__pyx_t_3);
    __pyx_t_3 = 0;

    /* "pygpu/gpuarray.pyx":1269
 * 
 *     def __repr__(self):
 *         return '\n'.join(" %s : %s" % (name.upper(), getattr(self, name))             # <<<<<<<<<<<<<<
 *                          for name in ["c_contiguous", "f_contiguous",
 *                                       "owndata", "writeable", "aligned",
 */
    __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_cur_scope->__pyx_v_name, __pyx_n_s_upper); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1269, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_5 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_4))) {
      __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_4);
      if (likely(__pyx_t_5)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_4);
        __Pyx_INCREF(__pyx_t_5);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_4, function);
      }
    }
    if (__pyx_t_5) {
      __pyx_t_3 = __Pyx_PyObject_CallOneArg(__pyx_t_4, __pyx_t_5); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1269, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    } else {
      __pyx_t_3 = __Pyx_PyObject_CallNoArg(__pyx_t_4); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1269, __pyx_L1_error)
    }
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    if (unlikely(!__pyx_cur_scope->__pyx_outer_scope->__pyx_v_self)) { __Pyx_RaiseClosureNameError("self"); __PYX_ERR(0, 1269, __pyx_L1_error) }
    __pyx_t_4 = ((PyObject *)__pyx_cur_scope->__pyx_outer_scope->__pyx_v_self);
    __Pyx_INCREF(__pyx_t_4);
    __pyx_t_5 = __Pyx_GetAttr(__pyx_t_4, __pyx_cur_scope->__pyx_v_name); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 1269, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_t_4 = PyTuple_New(2); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1269, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_GIVEREF(__pyx_t_3);
    PyTuple_SET_ITEM(__pyx_t_4, 0, __pyx_t_3);
    __Pyx_GIVEREF(__pyx_t_5);
    PyTuple_SET_ITEM(__pyx_t_4, 1, __pyx_t_5);
    __pyx_t_3 = 0;
    __pyx_t_5 = 0;
    __pyx_t_5 = __Pyx_PyString_Format(__pyx_kp_s_s_s, __pyx_t_4); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 1269, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_r = __pyx_t_5;
    __pyx_t_5 = 0;
    __Pyx_XGIVEREF(__pyx_t_1);
    __pyx_cur_scope->__pyx_t_0 = __pyx_t_1;
    __pyx_cur_scope->__pyx_t_1 = __pyx_t_2;
    __Pyx_XGIVEREF(__pyx_r);
    __Pyx_RefNannyFinishContext();
    __Pyx_Coroutine_ResetAndClearException(__pyx_generator);
    /* return from generator, yielding value */
    __pyx_generator->resume_label = 1;
    return __pyx_r;
    __pyx_L6_resume_from_yield:;
    __pyx_t_1 = __pyx_cur_scope->__pyx_t_0;
    __pyx_cur_scope->__pyx_t_0 = 0;
    __Pyx_XGOTREF(__pyx_t_1);
    __pyx_t_2 = __pyx_cur_scope->__pyx_t_1;
    if (unlikely(!__pyx_sent_value)) __PYX_ERR(0, 1269, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":1270
 *     def __repr__(self):
 *         return '\n'.join(" %s : %s" % (name.upper(), getattr(self, name))
 *                          for name in ["c_contiguous", "f_contiguous",             # <<<<<<<<<<<<<<
 *                                       "owndata", "writeable", "aligned",
 *                                       "updateifcopy"])
 */
  }
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  CYTHON_MAYBE_UNUSED_VAR(__pyx_cur_scope);

  /* "pygpu/gpuarray.pyx":1269
 * 
 *     def __repr__(self):
 *         return '\n'.join(" %s : %s" % (name.upper(), getattr(self, name))             # <<<<<<<<<<<<<<
 *                          for name in ["c_contiguous", "f_contiguous",
 *                                       "owndata", "writeable", "aligned",
 */

  /* function exit code */
  PyErr_SetNone(PyExc_StopIteration);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("genexpr", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_r); __pyx_r = 0;
  __Pyx_Coroutine_ResetAndClearException(__pyx_generator);
  __pyx_generator->resume_label = -1;
  __Pyx_Coroutine_clear((PyObject*)__pyx_generator);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":1268
 *         raise KeyError, "Unknown flag"
 * 
 *     def __repr__(self):             # <<<<<<<<<<<<<<
 *         return '\n'.join(" %s : %s" % (name.upper(), getattr(self, name))
 *                          for name in ["c_contiguous", "f_contiguous",
 */

static PyObject *__pyx_pf_5pygpu_8gpuarray_5flags_6__repr__(struct __pyx_obj_5pygpu_8gpuarray_flags *__pyx_v_self) {
  struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_1___repr__ *__pyx_cur_scope;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  __Pyx_RefNannySetupContext("__repr__", 0);
  __pyx_cur_scope = (struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_1___repr__ *)__pyx_tp_new_5pygpu_8gpuarray___pyx_scope_struct_1___repr__(__pyx_ptype_5pygpu_8gpuarray___pyx_scope_struct_1___repr__, __pyx_empty_tuple, NULL);
  if (unlikely(!__pyx_cur_scope)) {
    __pyx_cur_scope = ((struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_1___repr__ *)Py_None);
    __Pyx_INCREF(Py_None);
    __PYX_ERR(0, 1268, __pyx_L1_error)
  } else {
    __Pyx_GOTREF(__pyx_cur_scope);
  }
  __pyx_cur_scope->__pyx_v_self = __pyx_v_self;
  __Pyx_INCREF((PyObject *)__pyx_cur_scope->__pyx_v_self);
  __Pyx_GIVEREF((PyObject *)__pyx_cur_scope->__pyx_v_self);

  /* "pygpu/gpuarray.pyx":1269
 * 
 *     def __repr__(self):
 *         return '\n'.join(" %s : %s" % (name.upper(), getattr(self, name))             # <<<<<<<<<<<<<<
 *                          for name in ["c_contiguous", "f_contiguous",
 *                                       "owndata", "writeable", "aligned",
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __pyx_pf_5pygpu_8gpuarray_5flags_8__repr___genexpr(((PyObject*)__pyx_cur_scope)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1269, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyString_Join(__pyx_kp_s__20, __pyx_t_1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1269, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_r = __pyx_t_2;
  __pyx_t_2 = 0;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":1268
 *         raise KeyError, "Unknown flag"
 * 
 *     def __repr__(self):             # <<<<<<<<<<<<<<
 *         return '\n'.join(" %s : %s" % (name.upper(), getattr(self, name))
 *                          for name in ["c_contiguous", "f_contiguous",
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("pygpu.gpuarray.flags.__repr__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_DECREF(((PyObject *)__pyx_cur_scope));
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":1274
 *                                       "updateifcopy"])
 * 
 *     def __richcmp__(self, other, int op):             # <<<<<<<<<<<<<<
 *         cdef flags a
 *         cdef flags b
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_5flags_9__richcmp__(PyObject *__pyx_v_self, PyObject *__pyx_v_other, int __pyx_v_op); /*proto*/
static PyObject *__pyx_pw_5pygpu_8gpuarray_5flags_9__richcmp__(PyObject *__pyx_v_self, PyObject *__pyx_v_other, int __pyx_v_op) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__richcmp__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_5flags_8__richcmp__(((PyObject *)__pyx_v_self), ((PyObject *)__pyx_v_other), ((int)__pyx_v_op));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_5flags_8__richcmp__(PyObject *__pyx_v_self, PyObject *__pyx_v_other, int __pyx_v_op) {
  struct __pyx_obj_5pygpu_8gpuarray_flags *__pyx_v_a = 0;
  struct __pyx_obj_5pygpu_8gpuarray_flags *__pyx_v_b = 0;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_t_2;
  int __pyx_t_3;
  PyObject *__pyx_t_4 = NULL;
  __Pyx_RefNannySetupContext("__richcmp__", 0);

  /* "pygpu/gpuarray.pyx":1277
 *         cdef flags a
 *         cdef flags b
 *         if not isinstance(self, flags) or not isinstance(other, flags):             # <<<<<<<<<<<<<<
 *             return NotImplemented
 *         a = self
 */
  __pyx_t_2 = __Pyx_TypeCheck(__pyx_v_self, __pyx_ptype_5pygpu_8gpuarray_flags); 
  __pyx_t_3 = ((!(__pyx_t_2 != 0)) != 0);
  if (!__pyx_t_3) {
  } else {
    __pyx_t_1 = __pyx_t_3;
    goto __pyx_L4_bool_binop_done;
  }
  __pyx_t_3 = __Pyx_TypeCheck(__pyx_v_other, __pyx_ptype_5pygpu_8gpuarray_flags); 
  __pyx_t_2 = ((!(__pyx_t_3 != 0)) != 0);
  __pyx_t_1 = __pyx_t_2;
  __pyx_L4_bool_binop_done:;
  if (__pyx_t_1) {

    /* "pygpu/gpuarray.pyx":1278
 *         cdef flags b
 *         if not isinstance(self, flags) or not isinstance(other, flags):
 *             return NotImplemented             # <<<<<<<<<<<<<<
 *         a = self
 *         b = other
 */
    __Pyx_XDECREF(__pyx_r);
    __Pyx_INCREF(__pyx_builtin_NotImplemented);
    __pyx_r = __pyx_builtin_NotImplemented;
    goto __pyx_L0;

    /* "pygpu/gpuarray.pyx":1277
 *         cdef flags a
 *         cdef flags b
 *         if not isinstance(self, flags) or not isinstance(other, flags):             # <<<<<<<<<<<<<<
 *             return NotImplemented
 *         a = self
 */
  }

  /* "pygpu/gpuarray.pyx":1279
 *         if not isinstance(self, flags) or not isinstance(other, flags):
 *             return NotImplemented
 *         a = self             # <<<<<<<<<<<<<<
 *         b = other
 *         if op == Py_EQ:
 */
  if (!(likely(((__pyx_v_self) == Py_None) || likely(__Pyx_TypeTest(__pyx_v_self, __pyx_ptype_5pygpu_8gpuarray_flags))))) __PYX_ERR(0, 1279, __pyx_L1_error)
  __pyx_t_4 = __pyx_v_self;
  __Pyx_INCREF(__pyx_t_4);
  __pyx_v_a = ((struct __pyx_obj_5pygpu_8gpuarray_flags *)__pyx_t_4);
  __pyx_t_4 = 0;

  /* "pygpu/gpuarray.pyx":1280
 *             return NotImplemented
 *         a = self
 *         b = other             # <<<<<<<<<<<<<<
 *         if op == Py_EQ:
 *             return a.fl == b.fl
 */
  if (!(likely(((__pyx_v_other) == Py_None) || likely(__Pyx_TypeTest(__pyx_v_other, __pyx_ptype_5pygpu_8gpuarray_flags))))) __PYX_ERR(0, 1280, __pyx_L1_error)
  __pyx_t_4 = __pyx_v_other;
  __Pyx_INCREF(__pyx_t_4);
  __pyx_v_b = ((struct __pyx_obj_5pygpu_8gpuarray_flags *)__pyx_t_4);
  __pyx_t_4 = 0;

  /* "pygpu/gpuarray.pyx":1281
 *         a = self
 *         b = other
 *         if op == Py_EQ:             # <<<<<<<<<<<<<<
 *             return a.fl == b.fl
 *         elif op == Py_NE:
 */
  __pyx_t_1 = ((__pyx_v_op == Py_EQ) != 0);
  if (__pyx_t_1) {

    /* "pygpu/gpuarray.pyx":1282
 *         b = other
 *         if op == Py_EQ:
 *             return a.fl == b.fl             # <<<<<<<<<<<<<<
 *         elif op == Py_NE:
 *             return a.fl != b.fl
 */
    __Pyx_XDECREF(__pyx_r);
    __pyx_t_4 = __Pyx_PyBool_FromLong((__pyx_v_a->fl == __pyx_v_b->fl)); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1282, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_r = __pyx_t_4;
    __pyx_t_4 = 0;
    goto __pyx_L0;

    /* "pygpu/gpuarray.pyx":1281
 *         a = self
 *         b = other
 *         if op == Py_EQ:             # <<<<<<<<<<<<<<
 *             return a.fl == b.fl
 *         elif op == Py_NE:
 */
  }

  /* "pygpu/gpuarray.pyx":1283
 *         if op == Py_EQ:
 *             return a.fl == b.fl
 *         elif op == Py_NE:             # <<<<<<<<<<<<<<
 *             return a.fl != b.fl
 *         raise TypeError, "undefined comparison for flag object"
 */
  __pyx_t_1 = ((__pyx_v_op == Py_NE) != 0);
  if (__pyx_t_1) {

    /* "pygpu/gpuarray.pyx":1284
 *             return a.fl == b.fl
 *         elif op == Py_NE:
 *             return a.fl != b.fl             # <<<<<<<<<<<<<<
 *         raise TypeError, "undefined comparison for flag object"
 * 
 */
    __Pyx_XDECREF(__pyx_r);
    __pyx_t_4 = __Pyx_PyBool_FromLong((__pyx_v_a->fl != __pyx_v_b->fl)); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1284, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_r = __pyx_t_4;
    __pyx_t_4 = 0;
    goto __pyx_L0;

    /* "pygpu/gpuarray.pyx":1283
 *         if op == Py_EQ:
 *             return a.fl == b.fl
 *         elif op == Py_NE:             # <<<<<<<<<<<<<<
 *             return a.fl != b.fl
 *         raise TypeError, "undefined comparison for flag object"
 */
  }

  /* "pygpu/gpuarray.pyx":1285
 *         elif op == Py_NE:
 *             return a.fl != b.fl
 *         raise TypeError, "undefined comparison for flag object"             # <<<<<<<<<<<<<<
 * 
 *     property c_contiguous:
 */
  __Pyx_Raise(__pyx_builtin_TypeError, __pyx_kp_s_undefined_comparison_for_flag_ob, 0, 0);
  __PYX_ERR(0, 1285, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":1274
 *                                       "updateifcopy"])
 * 
 *     def __richcmp__(self, other, int op):             # <<<<<<<<<<<<<<
 *         cdef flags a
 *         cdef flags b
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_AddTraceback("pygpu.gpuarray.flags.__richcmp__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_a);
  __Pyx_XDECREF((PyObject *)__pyx_v_b);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":1288
 * 
 *     property c_contiguous:
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             return bool(self.fl & GA_C_CONTIGUOUS)
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_5flags_12c_contiguous_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_5pygpu_8gpuarray_5flags_12c_contiguous_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_5flags_12c_contiguous___get__(((struct __pyx_obj_5pygpu_8gpuarray_flags *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_5flags_12c_contiguous___get__(struct __pyx_obj_5pygpu_8gpuarray_flags *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_t_2;
  __Pyx_RefNannySetupContext("__get__", 0);

  /* "pygpu/gpuarray.pyx":1289
 *     property c_contiguous:
 *         def __get__(self):
 *             return bool(self.fl & GA_C_CONTIGUOUS)             # <<<<<<<<<<<<<<
 * 
 *     property contiguous:
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyInt_From_int((__pyx_v_self->fl & GA_C_CONTIGUOUS)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1289, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_IsTrue(__pyx_t_1); if (unlikely(__pyx_t_2 < 0)) __PYX_ERR(0, 1289, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyBool_FromLong((!(!__pyx_t_2))); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1289, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":1288
 * 
 *     property c_contiguous:
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             return bool(self.fl & GA_C_CONTIGUOUS)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("pygpu.gpuarray.flags.c_contiguous.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":1292
 * 
 *     property contiguous:
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             return self.c_contiguous
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_5flags_10contiguous_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_5pygpu_8gpuarray_5flags_10contiguous_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_5flags_10contiguous___get__(((struct __pyx_obj_5pygpu_8gpuarray_flags *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_5flags_10contiguous___get__(struct __pyx_obj_5pygpu_8gpuarray_flags *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("__get__", 0);

  /* "pygpu/gpuarray.pyx":1293
 *     property contiguous:
 *         def __get__(self):
 *             return self.c_contiguous             # <<<<<<<<<<<<<<
 * 
 *     property f_contiguous:
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_c_contiguous); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1293, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":1292
 * 
 *     property contiguous:
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             return self.c_contiguous
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("pygpu.gpuarray.flags.contiguous.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":1296
 * 
 *     property f_contiguous:
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             return bool(self.fl & GA_F_CONTIGUOUS)
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_5flags_12f_contiguous_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_5pygpu_8gpuarray_5flags_12f_contiguous_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_5flags_12f_contiguous___get__(((struct __pyx_obj_5pygpu_8gpuarray_flags *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_5flags_12f_contiguous___get__(struct __pyx_obj_5pygpu_8gpuarray_flags *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_t_2;
  __Pyx_RefNannySetupContext("__get__", 0);

  /* "pygpu/gpuarray.pyx":1297
 *     property f_contiguous:
 *         def __get__(self):
 *             return bool(self.fl & GA_F_CONTIGUOUS)             # <<<<<<<<<<<<<<
 * 
 *     property fortran:
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyInt_From_int((__pyx_v_self->fl & GA_F_CONTIGUOUS)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1297, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_IsTrue(__pyx_t_1); if (unlikely(__pyx_t_2 < 0)) __PYX_ERR(0, 1297, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyBool_FromLong((!(!__pyx_t_2))); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1297, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":1296
 * 
 *     property f_contiguous:
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             return bool(self.fl & GA_F_CONTIGUOUS)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("pygpu.gpuarray.flags.f_contiguous.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":1300
 * 
 *     property fortran:
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             return self.f_contiguous
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_5flags_7fortran_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_5pygpu_8gpuarray_5flags_7fortran_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_5flags_7fortran___get__(((struct __pyx_obj_5pygpu_8gpuarray_flags *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_5flags_7fortran___get__(struct __pyx_obj_5pygpu_8gpuarray_flags *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("__get__", 0);

  /* "pygpu/gpuarray.pyx":1301
 *     property fortran:
 *         def __get__(self):
 *             return self.f_contiguous             # <<<<<<<<<<<<<<
 * 
 *     property updateifcopy:
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_f_contiguous); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1301, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":1300
 * 
 *     property fortran:
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             return self.f_contiguous
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("pygpu.gpuarray.flags.fortran.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":1305
 *     property updateifcopy:
 *         # Not supported.
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             return False
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_5flags_12updateifcopy_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_5pygpu_8gpuarray_5flags_12updateifcopy_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_5flags_12updateifcopy___get__(((struct __pyx_obj_5pygpu_8gpuarray_flags *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_5flags_12updateifcopy___get__(CYTHON_UNUSED struct __pyx_obj_5pygpu_8gpuarray_flags *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__", 0);

  /* "pygpu/gpuarray.pyx":1306
 *         # Not supported.
 *         def __get__(self):
 *             return False             # <<<<<<<<<<<<<<
 * 
 *     property owndata:
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(Py_False);
  __pyx_r = Py_False;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":1305
 *     property updateifcopy:
 *         # Not supported.
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             return False
 * 
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":1310
 *     property owndata:
 *         # There is no equivalent for GpuArrays and it is always "True".
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             return True
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_5flags_7owndata_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_5pygpu_8gpuarray_5flags_7owndata_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_5flags_7owndata___get__(((struct __pyx_obj_5pygpu_8gpuarray_flags *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_5flags_7owndata___get__(CYTHON_UNUSED struct __pyx_obj_5pygpu_8gpuarray_flags *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__", 0);

  /* "pygpu/gpuarray.pyx":1311
 *         # There is no equivalent for GpuArrays and it is always "True".
 *         def __get__(self):
 *             return True             # <<<<<<<<<<<<<<
 * 
 *     property aligned:
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(Py_True);
  __pyx_r = Py_True;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":1310
 *     property owndata:
 *         # There is no equivalent for GpuArrays and it is always "True".
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             return True
 * 
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":1314
 * 
 *     property aligned:
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             return bool(self.fl & GA_ALIGNED)
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_5flags_7aligned_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_5pygpu_8gpuarray_5flags_7aligned_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_5flags_7aligned___get__(((struct __pyx_obj_5pygpu_8gpuarray_flags *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_5flags_7aligned___get__(struct __pyx_obj_5pygpu_8gpuarray_flags *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_t_2;
  __Pyx_RefNannySetupContext("__get__", 0);

  /* "pygpu/gpuarray.pyx":1315
 *     property aligned:
 *         def __get__(self):
 *             return bool(self.fl & GA_ALIGNED)             # <<<<<<<<<<<<<<
 * 
 *     property writeable:
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyInt_From_int((__pyx_v_self->fl & GA_ALIGNED)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1315, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_IsTrue(__pyx_t_1); if (unlikely(__pyx_t_2 < 0)) __PYX_ERR(0, 1315, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyBool_FromLong((!(!__pyx_t_2))); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1315, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":1314
 * 
 *     property aligned:
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             return bool(self.fl & GA_ALIGNED)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("pygpu.gpuarray.flags.aligned.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":1318
 * 
 *     property writeable:
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             return bool(self.fl & GA_WRITEABLE)
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_5flags_9writeable_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_5pygpu_8gpuarray_5flags_9writeable_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_5flags_9writeable___get__(((struct __pyx_obj_5pygpu_8gpuarray_flags *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_5flags_9writeable___get__(struct __pyx_obj_5pygpu_8gpuarray_flags *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_t_2;
  __Pyx_RefNannySetupContext("__get__", 0);

  /* "pygpu/gpuarray.pyx":1319
 *     property writeable:
 *         def __get__(self):
 *             return bool(self.fl & GA_WRITEABLE)             # <<<<<<<<<<<<<<
 * 
 *     property behaved:
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyInt_From_int((__pyx_v_self->fl & GA_WRITEABLE)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1319, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_IsTrue(__pyx_t_1); if (unlikely(__pyx_t_2 < 0)) __PYX_ERR(0, 1319, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyBool_FromLong((!(!__pyx_t_2))); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1319, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":1318
 * 
 *     property writeable:
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             return bool(self.fl & GA_WRITEABLE)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("pygpu.gpuarray.flags.writeable.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":1322
 * 
 *     property behaved:
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             return (self.fl & GA_BEHAVED) == GA_BEHAVED
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_5flags_7behaved_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_5pygpu_8gpuarray_5flags_7behaved_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_5flags_7behaved___get__(((struct __pyx_obj_5pygpu_8gpuarray_flags *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_5flags_7behaved___get__(struct __pyx_obj_5pygpu_8gpuarray_flags *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("__get__", 0);

  /* "pygpu/gpuarray.pyx":1323
 *     property behaved:
 *         def __get__(self):
 *             return (self.fl & GA_BEHAVED) == GA_BEHAVED             # <<<<<<<<<<<<<<
 * 
 *     property carray:
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyBool_FromLong(((__pyx_v_self->fl & GA_BEHAVED) == GA_BEHAVED)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1323, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":1322
 * 
 *     property behaved:
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             return (self.fl & GA_BEHAVED) == GA_BEHAVED
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("pygpu.gpuarray.flags.behaved.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":1326
 * 
 *     property carray:
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             return (self.fl & GA_CARRAY) == GA_CARRAY
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_5flags_6carray_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_5pygpu_8gpuarray_5flags_6carray_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_5flags_6carray___get__(((struct __pyx_obj_5pygpu_8gpuarray_flags *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_5flags_6carray___get__(struct __pyx_obj_5pygpu_8gpuarray_flags *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("__get__", 0);

  /* "pygpu/gpuarray.pyx":1327
 *     property carray:
 *         def __get__(self):
 *             return (self.fl & GA_CARRAY) == GA_CARRAY             # <<<<<<<<<<<<<<
 * 
 *     # Yes these are really defined like that according to numpy sources.
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyBool_FromLong(((__pyx_v_self->fl & GA_CARRAY) == GA_CARRAY)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1327, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":1326
 * 
 *     property carray:
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             return (self.fl & GA_CARRAY) == GA_CARRAY
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("pygpu.gpuarray.flags.carray.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":1332
 *     # I don't know why.
 *     property forc:
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             return ((self.fl & GA_F_CONTIGUOUS) == GA_F_CONTIGUOUS or
 *                     (self.fl & GA_C_CONTIGUOUS) == GA_C_CONTIGUOUS)
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_5flags_4forc_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_5pygpu_8gpuarray_5flags_4forc_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_5flags_4forc___get__(((struct __pyx_obj_5pygpu_8gpuarray_flags *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_5flags_4forc___get__(struct __pyx_obj_5pygpu_8gpuarray_flags *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_t_2;
  PyObject *__pyx_t_3 = NULL;
  __Pyx_RefNannySetupContext("__get__", 0);

  /* "pygpu/gpuarray.pyx":1333
 *     property forc:
 *         def __get__(self):
 *             return ((self.fl & GA_F_CONTIGUOUS) == GA_F_CONTIGUOUS or             # <<<<<<<<<<<<<<
 *                     (self.fl & GA_C_CONTIGUOUS) == GA_C_CONTIGUOUS)
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_2 = ((__pyx_v_self->fl & GA_F_CONTIGUOUS) == GA_F_CONTIGUOUS);
  if (!__pyx_t_2) {
  } else {
    __pyx_t_3 = __Pyx_PyBool_FromLong(__pyx_t_2); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1333, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_1 = __pyx_t_3;
    __pyx_t_3 = 0;
    goto __pyx_L3_bool_binop_done;
  }

  /* "pygpu/gpuarray.pyx":1334
 *         def __get__(self):
 *             return ((self.fl & GA_F_CONTIGUOUS) == GA_F_CONTIGUOUS or
 *                     (self.fl & GA_C_CONTIGUOUS) == GA_C_CONTIGUOUS)             # <<<<<<<<<<<<<<
 * 
 *     property fnc:
 */
  __pyx_t_2 = ((__pyx_v_self->fl & GA_C_CONTIGUOUS) == GA_C_CONTIGUOUS);
  __pyx_t_3 = __Pyx_PyBool_FromLong(__pyx_t_2); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1334, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_1 = __pyx_t_3;
  __pyx_t_3 = 0;
  __pyx_L3_bool_binop_done:;
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":1332
 *     # I don't know why.
 *     property forc:
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             return ((self.fl & GA_F_CONTIGUOUS) == GA_F_CONTIGUOUS or
 *                     (self.fl & GA_C_CONTIGUOUS) == GA_C_CONTIGUOUS)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("pygpu.gpuarray.flags.forc.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":1337
 * 
 *     property fnc:
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             return ((self.fl & GA_F_CONTIGUOUS) == GA_F_CONTIGUOUS and
 *                     not (self.fl & GA_C_CONTIGUOUS) == GA_C_CONTIGUOUS)
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_5flags_3fnc_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_5pygpu_8gpuarray_5flags_3fnc_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_5flags_3fnc___get__(((struct __pyx_obj_5pygpu_8gpuarray_flags *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_5flags_3fnc___get__(struct __pyx_obj_5pygpu_8gpuarray_flags *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_t_2;
  PyObject *__pyx_t_3 = NULL;
  __Pyx_RefNannySetupContext("__get__", 0);

  /* "pygpu/gpuarray.pyx":1338
 *     property fnc:
 *         def __get__(self):
 *             return ((self.fl & GA_F_CONTIGUOUS) == GA_F_CONTIGUOUS and             # <<<<<<<<<<<<<<
 *                     not (self.fl & GA_C_CONTIGUOUS) == GA_C_CONTIGUOUS)
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_2 = ((__pyx_v_self->fl & GA_F_CONTIGUOUS) == GA_F_CONTIGUOUS);
  if (__pyx_t_2) {
  } else {
    __pyx_t_3 = __Pyx_PyBool_FromLong(__pyx_t_2); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1338, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_1 = __pyx_t_3;
    __pyx_t_3 = 0;
    goto __pyx_L3_bool_binop_done;
  }

  /* "pygpu/gpuarray.pyx":1339
 *         def __get__(self):
 *             return ((self.fl & GA_F_CONTIGUOUS) == GA_F_CONTIGUOUS and
 *                     not (self.fl & GA_C_CONTIGUOUS) == GA_C_CONTIGUOUS)             # <<<<<<<<<<<<<<
 * 
 *     property farray:
 */
  __pyx_t_2 = (!(((__pyx_v_self->fl & GA_C_CONTIGUOUS) == GA_C_CONTIGUOUS) != 0));
  __pyx_t_3 = __Pyx_PyBool_FromLong(__pyx_t_2); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1339, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_1 = __pyx_t_3;
  __pyx_t_3 = 0;
  __pyx_L3_bool_binop_done:;
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":1337
 * 
 *     property fnc:
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             return ((self.fl & GA_F_CONTIGUOUS) == GA_F_CONTIGUOUS and
 *                     not (self.fl & GA_C_CONTIGUOUS) == GA_C_CONTIGUOUS)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("pygpu.gpuarray.flags.fnc.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":1342
 * 
 *     property farray:
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             return ((self.fl & GA_FARRAY) != 0 and
 *                     not ((self.fl & GA_C_CONTIGUOUS) != 0))
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_5flags_6farray_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_5pygpu_8gpuarray_5flags_6farray_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_5flags_6farray___get__(((struct __pyx_obj_5pygpu_8gpuarray_flags *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_5flags_6farray___get__(struct __pyx_obj_5pygpu_8gpuarray_flags *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_t_2;
  PyObject *__pyx_t_3 = NULL;
  __Pyx_RefNannySetupContext("__get__", 0);

  /* "pygpu/gpuarray.pyx":1343
 *     property farray:
 *         def __get__(self):
 *             return ((self.fl & GA_FARRAY) != 0 and             # <<<<<<<<<<<<<<
 *                     not ((self.fl & GA_C_CONTIGUOUS) != 0))
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_2 = ((__pyx_v_self->fl & GA_FARRAY) != 0);
  if (__pyx_t_2) {
  } else {
    __pyx_t_3 = __Pyx_PyBool_FromLong(__pyx_t_2); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1343, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_1 = __pyx_t_3;
    __pyx_t_3 = 0;
    goto __pyx_L3_bool_binop_done;
  }

  /* "pygpu/gpuarray.pyx":1344
 *         def __get__(self):
 *             return ((self.fl & GA_FARRAY) != 0 and
 *                     not ((self.fl & GA_C_CONTIGUOUS) != 0))             # <<<<<<<<<<<<<<
 * 
 *     property num:
 */
  __pyx_t_2 = (!(((__pyx_v_self->fl & GA_C_CONTIGUOUS) != 0) != 0));
  __pyx_t_3 = __Pyx_PyBool_FromLong(__pyx_t_2); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1344, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_1 = __pyx_t_3;
  __pyx_t_3 = 0;
  __pyx_L3_bool_binop_done:;
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":1342
 * 
 *     property farray:
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             return ((self.fl & GA_FARRAY) != 0 and
 *                     not ((self.fl & GA_C_CONTIGUOUS) != 0))
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("pygpu.gpuarray.flags.farray.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":1347
 * 
 *     property num:
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             return self.fl
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_5flags_3num_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_5pygpu_8gpuarray_5flags_3num_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_5flags_3num___get__(((struct __pyx_obj_5pygpu_8gpuarray_flags *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_5flags_3num___get__(struct __pyx_obj_5pygpu_8gpuarray_flags *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("__get__", 0);

  /* "pygpu/gpuarray.pyx":1348
 *     property num:
 *         def __get__(self):
 *             return self.fl             # <<<<<<<<<<<<<<
 * 
 * cdef GpuArray new_GpuArray(object cls, GpuContext ctx, object base):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyInt_From_int(__pyx_v_self->fl); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1348, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":1347
 * 
 *     property num:
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             return self.fl
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("pygpu.gpuarray.flags.num.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":1350
 *             return self.fl
 * 
 * cdef GpuArray new_GpuArray(object cls, GpuContext ctx, object base):             # <<<<<<<<<<<<<<
 *     cdef GpuArray res
 *     if ctx is None:
 */

static struct PyGpuArrayObject *__pyx_f_5pygpu_8gpuarray_new_GpuArray(PyObject *__pyx_v_cls, struct PyGpuContextObject *__pyx_v_ctx, PyObject *__pyx_v_base) {
  struct PyGpuArrayObject *__pyx_v_res = 0;
  struct PyGpuArrayObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_t_2;
  int __pyx_t_3;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  __Pyx_RefNannySetupContext("new_GpuArray", 0);

  /* "pygpu/gpuarray.pyx":1352
 * cdef GpuArray new_GpuArray(object cls, GpuContext ctx, object base):
 *     cdef GpuArray res
 *     if ctx is None:             # <<<<<<<<<<<<<<
 *         raise RuntimeError, "ctx is None in new_GpuArray"
 *     if cls is None or cls is GpuArray:
 */
  __pyx_t_1 = (((PyObject *)__pyx_v_ctx) == Py_None);
  __pyx_t_2 = (__pyx_t_1 != 0);
  if (__pyx_t_2) {

    /* "pygpu/gpuarray.pyx":1353
 *     cdef GpuArray res
 *     if ctx is None:
 *         raise RuntimeError, "ctx is None in new_GpuArray"             # <<<<<<<<<<<<<<
 *     if cls is None or cls is GpuArray:
 *         res = GpuArray.__new__(GpuArray)
 */
    __Pyx_Raise(__pyx_builtin_RuntimeError, __pyx_kp_s_ctx_is_None_in_new_GpuArray, 0, 0);
    __PYX_ERR(0, 1353, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":1352
 * cdef GpuArray new_GpuArray(object cls, GpuContext ctx, object base):
 *     cdef GpuArray res
 *     if ctx is None:             # <<<<<<<<<<<<<<
 *         raise RuntimeError, "ctx is None in new_GpuArray"
 *     if cls is None or cls is GpuArray:
 */
  }

  /* "pygpu/gpuarray.pyx":1354
 *     if ctx is None:
 *         raise RuntimeError, "ctx is None in new_GpuArray"
 *     if cls is None or cls is GpuArray:             # <<<<<<<<<<<<<<
 *         res = GpuArray.__new__(GpuArray)
 *     else:
 */
  __pyx_t_1 = (__pyx_v_cls == Py_None);
  __pyx_t_3 = (__pyx_t_1 != 0);
  if (!__pyx_t_3) {
  } else {
    __pyx_t_2 = __pyx_t_3;
    goto __pyx_L5_bool_binop_done;
  }
  __pyx_t_3 = (__pyx_v_cls == ((PyObject *)__pyx_ptype_5pygpu_8gpuarray_GpuArray));
  __pyx_t_1 = (__pyx_t_3 != 0);
  __pyx_t_2 = __pyx_t_1;
  __pyx_L5_bool_binop_done:;
  if (__pyx_t_2) {

    /* "pygpu/gpuarray.pyx":1355
 *         raise RuntimeError, "ctx is None in new_GpuArray"
 *     if cls is None or cls is GpuArray:
 *         res = GpuArray.__new__(GpuArray)             # <<<<<<<<<<<<<<
 *     else:
 *         res = GpuArray.__new__(cls)
 */
    __pyx_t_4 = __pyx_tp_new_5pygpu_8gpuarray_GpuArray(((PyTypeObject *)__pyx_ptype_5pygpu_8gpuarray_GpuArray), __pyx_empty_tuple, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1355, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    if (!(likely(__Pyx_TypeTest(__pyx_t_4, __pyx_ptype_5pygpu_8gpuarray_GpuArray)))) __PYX_ERR(0, 1355, __pyx_L1_error)
    __pyx_v_res = ((struct PyGpuArrayObject *)__pyx_t_4);
    __pyx_t_4 = 0;

    /* "pygpu/gpuarray.pyx":1354
 *     if ctx is None:
 *         raise RuntimeError, "ctx is None in new_GpuArray"
 *     if cls is None or cls is GpuArray:             # <<<<<<<<<<<<<<
 *         res = GpuArray.__new__(GpuArray)
 *     else:
 */
    goto __pyx_L4;
  }

  /* "pygpu/gpuarray.pyx":1357
 *         res = GpuArray.__new__(GpuArray)
 *     else:
 *         res = GpuArray.__new__(cls)             # <<<<<<<<<<<<<<
 *     res.base = base
 *     res.context = ctx
 */
  /*else*/ {
    __pyx_t_5 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_ptype_5pygpu_8gpuarray_GpuArray), __pyx_n_s_new); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 1357, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_6 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_5))) {
      __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_5);
      if (likely(__pyx_t_6)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
        __Pyx_INCREF(__pyx_t_6);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_5, function);
      }
    }
    if (!__pyx_t_6) {
      __pyx_t_4 = __Pyx_PyObject_CallOneArg(__pyx_t_5, __pyx_v_cls); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1357, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
    } else {
      #if CYTHON_FAST_PYCALL
      if (PyFunction_Check(__pyx_t_5)) {
        PyObject *__pyx_temp[2] = {__pyx_t_6, __pyx_v_cls};
        __pyx_t_4 = __Pyx_PyFunction_FastCall(__pyx_t_5, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1357, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
        __Pyx_GOTREF(__pyx_t_4);
      } else
      #endif
      #if CYTHON_FAST_PYCCALL
      if (__Pyx_PyFastCFunction_Check(__pyx_t_5)) {
        PyObject *__pyx_temp[2] = {__pyx_t_6, __pyx_v_cls};
        __pyx_t_4 = __Pyx_PyCFunction_FastCall(__pyx_t_5, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1357, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
        __Pyx_GOTREF(__pyx_t_4);
      } else
      #endif
      {
        __pyx_t_7 = PyTuple_New(1+1); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 1357, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_7);
        __Pyx_GIVEREF(__pyx_t_6); PyTuple_SET_ITEM(__pyx_t_7, 0, __pyx_t_6); __pyx_t_6 = NULL;
        __Pyx_INCREF(__pyx_v_cls);
        __Pyx_GIVEREF(__pyx_v_cls);
        PyTuple_SET_ITEM(__pyx_t_7, 0+1, __pyx_v_cls);
        __pyx_t_4 = __Pyx_PyObject_Call(__pyx_t_5, __pyx_t_7, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1357, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_4);
        __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      }
    }
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    if (!(likely(((__pyx_t_4) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_4, __pyx_ptype_5pygpu_8gpuarray_GpuArray))))) __PYX_ERR(0, 1357, __pyx_L1_error)
    __pyx_v_res = ((struct PyGpuArrayObject *)__pyx_t_4);
    __pyx_t_4 = 0;
  }
  __pyx_L4:;

  /* "pygpu/gpuarray.pyx":1358
 *     else:
 *         res = GpuArray.__new__(cls)
 *     res.base = base             # <<<<<<<<<<<<<<
 *     res.context = ctx
 *     return res
 */
  __Pyx_INCREF(__pyx_v_base);
  __Pyx_GIVEREF(__pyx_v_base);
  __Pyx_GOTREF(__pyx_v_res->base);
  __Pyx_DECREF(__pyx_v_res->base);
  __pyx_v_res->base = __pyx_v_base;

  /* "pygpu/gpuarray.pyx":1359
 *         res = GpuArray.__new__(cls)
 *     res.base = base
 *     res.context = ctx             # <<<<<<<<<<<<<<
 *     return res
 * 
 */
  __Pyx_INCREF(((PyObject *)__pyx_v_ctx));
  __Pyx_GIVEREF(((PyObject *)__pyx_v_ctx));
  __Pyx_GOTREF(__pyx_v_res->context);
  __Pyx_DECREF(((PyObject *)__pyx_v_res->context));
  __pyx_v_res->context = __pyx_v_ctx;

  /* "pygpu/gpuarray.pyx":1360
 *     res.base = base
 *     res.context = ctx
 *     return res             # <<<<<<<<<<<<<<
 * 
 * cdef GpuArray pygpu_view(GpuArray a, object cls):
 */
  __Pyx_XDECREF(((PyObject *)__pyx_r));
  __Pyx_INCREF(((PyObject *)__pyx_v_res));
  __pyx_r = __pyx_v_res;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":1350
 *             return self.fl
 * 
 * cdef GpuArray new_GpuArray(object cls, GpuContext ctx, object base):             # <<<<<<<<<<<<<<
 *     cdef GpuArray res
 *     if ctx is None:
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_AddTraceback("pygpu.gpuarray.new_GpuArray", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_res);
  __Pyx_XGIVEREF((PyObject *)__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":1362
 *     return res
 * 
 * cdef GpuArray pygpu_view(GpuArray a, object cls):             # <<<<<<<<<<<<<<
 *     cdef GpuArray res = new_GpuArray(cls, a.context, a.base)
 *     array_view(res, a)
 */

static struct PyGpuArrayObject *__pyx_f_5pygpu_8gpuarray_pygpu_view(struct PyGpuArrayObject *__pyx_v_a, PyObject *__pyx_v_cls) {
  struct PyGpuArrayObject *__pyx_v_res = 0;
  struct PyGpuArrayObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  __Pyx_RefNannySetupContext("pygpu_view", 0);

  /* "pygpu/gpuarray.pyx":1363
 * 
 * cdef GpuArray pygpu_view(GpuArray a, object cls):
 *     cdef GpuArray res = new_GpuArray(cls, a.context, a.base)             # <<<<<<<<<<<<<<
 *     array_view(res, a)
 *     return res
 */
  __pyx_t_1 = ((PyObject *)__pyx_v_a->context);
  __Pyx_INCREF(__pyx_t_1);
  __pyx_t_2 = __pyx_v_a->base;
  __Pyx_INCREF(__pyx_t_2);
  __pyx_t_3 = ((PyObject *)__pyx_f_5pygpu_8gpuarray_new_GpuArray(__pyx_v_cls, ((struct PyGpuContextObject *)__pyx_t_1), __pyx_t_2)); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1363, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_res = ((struct PyGpuArrayObject *)__pyx_t_3);
  __pyx_t_3 = 0;

  /* "pygpu/gpuarray.pyx":1364
 * cdef GpuArray pygpu_view(GpuArray a, object cls):
 *     cdef GpuArray res = new_GpuArray(cls, a.context, a.base)
 *     array_view(res, a)             # <<<<<<<<<<<<<<
 *     return res
 * 
 */
  __pyx_t_4 = __pyx_f_5pygpu_8gpuarray_array_view(__pyx_v_res, __pyx_v_a); if (unlikely(__pyx_t_4 == ((int)-1))) __PYX_ERR(0, 1364, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":1365
 *     cdef GpuArray res = new_GpuArray(cls, a.context, a.base)
 *     array_view(res, a)
 *     return res             # <<<<<<<<<<<<<<
 * 
 * cdef int pygpu_sync(GpuArray a) except -1:
 */
  __Pyx_XDECREF(((PyObject *)__pyx_r));
  __Pyx_INCREF(((PyObject *)__pyx_v_res));
  __pyx_r = __pyx_v_res;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":1362
 *     return res
 * 
 * cdef GpuArray pygpu_view(GpuArray a, object cls):             # <<<<<<<<<<<<<<
 *     cdef GpuArray res = new_GpuArray(cls, a.context, a.base)
 *     array_view(res, a)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("pygpu.gpuarray.pygpu_view", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_res);
  __Pyx_XGIVEREF((PyObject *)__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":1367
 *     return res
 * 
 * cdef int pygpu_sync(GpuArray a) except -1:             # <<<<<<<<<<<<<<
 *     array_sync(a)
 *     return 0
 */

static int __pyx_f_5pygpu_8gpuarray_pygpu_sync(struct PyGpuArrayObject *__pyx_v_a) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  __Pyx_RefNannySetupContext("pygpu_sync", 0);

  /* "pygpu/gpuarray.pyx":1368
 * 
 * cdef int pygpu_sync(GpuArray a) except -1:
 *     array_sync(a)             # <<<<<<<<<<<<<<
 *     return 0
 * 
 */
  __pyx_t_1 = __pyx_f_5pygpu_8gpuarray_array_sync(__pyx_v_a); if (unlikely(__pyx_t_1 == ((int)-1))) __PYX_ERR(0, 1368, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":1369
 * cdef int pygpu_sync(GpuArray a) except -1:
 *     array_sync(a)
 *     return 0             # <<<<<<<<<<<<<<
 * 
 * cdef GpuArray pygpu_empty_like(GpuArray a, ga_order ord, int typecode):
 */
  __pyx_r = 0;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":1367
 *     return res
 * 
 * cdef int pygpu_sync(GpuArray a) except -1:             # <<<<<<<<<<<<<<
 *     array_sync(a)
 *     return 0
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_AddTraceback("pygpu.gpuarray.pygpu_sync", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":1371
 *     return 0
 * 
 * cdef GpuArray pygpu_empty_like(GpuArray a, ga_order ord, int typecode):             # <<<<<<<<<<<<<<
 *     cdef GpuArray res
 * 
 */

static struct PyGpuArrayObject *__pyx_f_5pygpu_8gpuarray_pygpu_empty_like(struct PyGpuArrayObject *__pyx_v_a, ga_order __pyx_v_ord, int __pyx_v_typecode) {
  struct PyGpuArrayObject *__pyx_v_res = 0;
  struct PyGpuArrayObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_t_2;
  int __pyx_t_3;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  __Pyx_RefNannySetupContext("pygpu_empty_like", 0);

  /* "pygpu/gpuarray.pyx":1374
 *     cdef GpuArray res
 * 
 *     if ord == GA_ANY_ORDER:             # <<<<<<<<<<<<<<
 *         if (py_CHKFLAGS(a, GA_F_CONTIGUOUS) and
 *                 not py_CHKFLAGS(a, GA_C_CONTIGUOUS)):
 */
  __pyx_t_1 = ((__pyx_v_ord == GA_ANY_ORDER) != 0);
  if (__pyx_t_1) {

    /* "pygpu/gpuarray.pyx":1375
 * 
 *     if ord == GA_ANY_ORDER:
 *         if (py_CHKFLAGS(a, GA_F_CONTIGUOUS) and             # <<<<<<<<<<<<<<
 *                 not py_CHKFLAGS(a, GA_C_CONTIGUOUS)):
 *             ord = GA_F_ORDER
 */
    __pyx_t_2 = (__pyx_f_5pygpu_8gpuarray_py_CHKFLAGS(__pyx_v_a, GA_F_CONTIGUOUS) != 0);
    if (__pyx_t_2) {
    } else {
      __pyx_t_1 = __pyx_t_2;
      goto __pyx_L5_bool_binop_done;
    }

    /* "pygpu/gpuarray.pyx":1376
 *     if ord == GA_ANY_ORDER:
 *         if (py_CHKFLAGS(a, GA_F_CONTIGUOUS) and
 *                 not py_CHKFLAGS(a, GA_C_CONTIGUOUS)):             # <<<<<<<<<<<<<<
 *             ord = GA_F_ORDER
 *         else:
 */
    __pyx_t_2 = ((!(__pyx_f_5pygpu_8gpuarray_py_CHKFLAGS(__pyx_v_a, GA_C_CONTIGUOUS) != 0)) != 0);
    __pyx_t_1 = __pyx_t_2;
    __pyx_L5_bool_binop_done:;

    /* "pygpu/gpuarray.pyx":1375
 * 
 *     if ord == GA_ANY_ORDER:
 *         if (py_CHKFLAGS(a, GA_F_CONTIGUOUS) and             # <<<<<<<<<<<<<<
 *                 not py_CHKFLAGS(a, GA_C_CONTIGUOUS)):
 *             ord = GA_F_ORDER
 */
    if (__pyx_t_1) {

      /* "pygpu/gpuarray.pyx":1377
 *         if (py_CHKFLAGS(a, GA_F_CONTIGUOUS) and
 *                 not py_CHKFLAGS(a, GA_C_CONTIGUOUS)):
 *             ord = GA_F_ORDER             # <<<<<<<<<<<<<<
 *         else:
 *             ord = GA_C_ORDER
 */
      __pyx_v_ord = GA_F_ORDER;

      /* "pygpu/gpuarray.pyx":1375
 * 
 *     if ord == GA_ANY_ORDER:
 *         if (py_CHKFLAGS(a, GA_F_CONTIGUOUS) and             # <<<<<<<<<<<<<<
 *                 not py_CHKFLAGS(a, GA_C_CONTIGUOUS)):
 *             ord = GA_F_ORDER
 */
      goto __pyx_L4;
    }

    /* "pygpu/gpuarray.pyx":1379
 *             ord = GA_F_ORDER
 *         else:
 *             ord = GA_C_ORDER             # <<<<<<<<<<<<<<
 * 
 *     if typecode == -1:
 */
    /*else*/ {
      __pyx_v_ord = GA_C_ORDER;
    }
    __pyx_L4:;

    /* "pygpu/gpuarray.pyx":1374
 *     cdef GpuArray res
 * 
 *     if ord == GA_ANY_ORDER:             # <<<<<<<<<<<<<<
 *         if (py_CHKFLAGS(a, GA_F_CONTIGUOUS) and
 *                 not py_CHKFLAGS(a, GA_C_CONTIGUOUS)):
 */
  }

  /* "pygpu/gpuarray.pyx":1381
 *             ord = GA_C_ORDER
 * 
 *     if typecode == -1:             # <<<<<<<<<<<<<<
 *         typecode = a.ga.typecode
 * 
 */
  __pyx_t_1 = ((__pyx_v_typecode == -1L) != 0);
  if (__pyx_t_1) {

    /* "pygpu/gpuarray.pyx":1382
 * 
 *     if typecode == -1:
 *         typecode = a.ga.typecode             # <<<<<<<<<<<<<<
 * 
 *     res = new_GpuArray(type(a), a.context, None)
 */
    __pyx_t_3 = __pyx_v_a->ga.typecode;
    __pyx_v_typecode = __pyx_t_3;

    /* "pygpu/gpuarray.pyx":1381
 *             ord = GA_C_ORDER
 * 
 *     if typecode == -1:             # <<<<<<<<<<<<<<
 *         typecode = a.ga.typecode
 * 
 */
  }

  /* "pygpu/gpuarray.pyx":1384
 *         typecode = a.ga.typecode
 * 
 *     res = new_GpuArray(type(a), a.context, None)             # <<<<<<<<<<<<<<
 *     array_empty(res, a.context.ctx, typecode,
 *                 a.ga.nd, a.ga.dimensions, ord)
 */
  __pyx_t_4 = ((PyObject *)__pyx_v_a->context);
  __Pyx_INCREF(__pyx_t_4);
  __pyx_t_5 = ((PyObject *)__pyx_f_5pygpu_8gpuarray_new_GpuArray(((PyObject *)Py_TYPE(((PyObject *)__pyx_v_a))), ((struct PyGpuContextObject *)__pyx_t_4), Py_None)); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 1384, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_v_res = ((struct PyGpuArrayObject *)__pyx_t_5);
  __pyx_t_5 = 0;

  /* "pygpu/gpuarray.pyx":1385
 * 
 *     res = new_GpuArray(type(a), a.context, None)
 *     array_empty(res, a.context.ctx, typecode,             # <<<<<<<<<<<<<<
 *                 a.ga.nd, a.ga.dimensions, ord)
 *     return res
 */
  __pyx_t_3 = __pyx_f_5pygpu_8gpuarray_array_empty(__pyx_v_res, __pyx_v_a->context->ctx, __pyx_v_typecode, __pyx_v_a->ga.nd, __pyx_v_a->ga.dimensions, __pyx_v_ord); if (unlikely(__pyx_t_3 == ((int)-1))) __PYX_ERR(0, 1385, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":1387
 *     array_empty(res, a.context.ctx, typecode,
 *                 a.ga.nd, a.ga.dimensions, ord)
 *     return res             # <<<<<<<<<<<<<<
 * 
 * cdef np.ndarray pygpu_as_ndarray(GpuArray a):
 */
  __Pyx_XDECREF(((PyObject *)__pyx_r));
  __Pyx_INCREF(((PyObject *)__pyx_v_res));
  __pyx_r = __pyx_v_res;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":1371
 *     return 0
 * 
 * cdef GpuArray pygpu_empty_like(GpuArray a, ga_order ord, int typecode):             # <<<<<<<<<<<<<<
 *     cdef GpuArray res
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("pygpu.gpuarray.pygpu_empty_like", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_res);
  __Pyx_XGIVEREF((PyObject *)__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":1389
 *     return res
 * 
 * cdef np.ndarray pygpu_as_ndarray(GpuArray a):             # <<<<<<<<<<<<<<
 *     return _pygpu_as_ndarray(a, None)
 * 
 */

static PyArrayObject *__pyx_f_5pygpu_8gpuarray_pygpu_as_ndarray(struct PyGpuArrayObject *__pyx_v_a) {
  PyArrayObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("pygpu_as_ndarray", 0);

  /* "pygpu/gpuarray.pyx":1390
 * 
 * cdef np.ndarray pygpu_as_ndarray(GpuArray a):
 *     return _pygpu_as_ndarray(a, None)             # <<<<<<<<<<<<<<
 * 
 * cdef np.ndarray _pygpu_as_ndarray(GpuArray a, np.dtype ldtype):
 */
  __Pyx_XDECREF(((PyObject *)__pyx_r));
  __pyx_t_1 = ((PyObject *)__pyx_f_5pygpu_8gpuarray__pygpu_as_ndarray(__pyx_v_a, ((PyArray_Descr *)Py_None))); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1390, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = ((PyArrayObject *)__pyx_t_1);
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":1389
 *     return res
 * 
 * cdef np.ndarray pygpu_as_ndarray(GpuArray a):             # <<<<<<<<<<<<<<
 *     return _pygpu_as_ndarray(a, None)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("pygpu.gpuarray.pygpu_as_ndarray", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XGIVEREF((PyObject *)__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":1392
 *     return _pygpu_as_ndarray(a, None)
 * 
 * cdef np.ndarray _pygpu_as_ndarray(GpuArray a, np.dtype ldtype):             # <<<<<<<<<<<<<<
 *     cdef np.ndarray res
 * 
 */

static PyArrayObject *__pyx_f_5pygpu_8gpuarray__pygpu_as_ndarray(struct PyGpuArrayObject *__pyx_v_a, PyArray_Descr *__pyx_v_ldtype) {
  PyArrayObject *__pyx_v_res = 0;
  PyArrayObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  int __pyx_t_3;
  int __pyx_t_4;
  __Pyx_RefNannySetupContext("_pygpu_as_ndarray", 0);
  __Pyx_INCREF((PyObject *)__pyx_v_a);
  __Pyx_INCREF((PyObject *)__pyx_v_ldtype);

  /* "pygpu/gpuarray.pyx":1395
 *     cdef np.ndarray res
 * 
 *     if not py_ISONESEGMENT(a):             # <<<<<<<<<<<<<<
 *         a = pygpu_copy(a, GA_ANY_ORDER)
 * 
 */
  __pyx_t_1 = ((!(__pyx_f_5pygpu_8gpuarray_py_ISONESEGMENT(__pyx_v_a) != 0)) != 0);
  if (__pyx_t_1) {

    /* "pygpu/gpuarray.pyx":1396
 * 
 *     if not py_ISONESEGMENT(a):
 *         a = pygpu_copy(a, GA_ANY_ORDER)             # <<<<<<<<<<<<<<
 * 
 *     if ldtype is None:
 */
    __pyx_t_2 = ((PyObject *)__pyx_f_5pygpu_8gpuarray_pygpu_copy(__pyx_v_a, GA_ANY_ORDER)); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1396, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF_SET(__pyx_v_a, ((struct PyGpuArrayObject *)__pyx_t_2));
    __pyx_t_2 = 0;

    /* "pygpu/gpuarray.pyx":1395
 *     cdef np.ndarray res
 * 
 *     if not py_ISONESEGMENT(a):             # <<<<<<<<<<<<<<
 *         a = pygpu_copy(a, GA_ANY_ORDER)
 * 
 */
  }

  /* "pygpu/gpuarray.pyx":1398
 *         a = pygpu_copy(a, GA_ANY_ORDER)
 * 
 *     if ldtype is None:             # <<<<<<<<<<<<<<
 *         ldtype = a.dtype
 * 
 */
  __pyx_t_1 = (((PyObject *)__pyx_v_ldtype) == Py_None);
  __pyx_t_3 = (__pyx_t_1 != 0);
  if (__pyx_t_3) {

    /* "pygpu/gpuarray.pyx":1399
 * 
 *     if ldtype is None:
 *         ldtype = a.dtype             # <<<<<<<<<<<<<<
 * 
 *     res = PyArray_Empty(a.ga.nd, <np.npy_intp *>a.ga.dimensions,
 */
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_a), __pyx_n_s_dtype); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1399, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    if (!(likely(((__pyx_t_2) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_2, __pyx_ptype_5numpy_dtype))))) __PYX_ERR(0, 1399, __pyx_L1_error)
    __Pyx_DECREF_SET(__pyx_v_ldtype, ((PyArray_Descr *)__pyx_t_2));
    __pyx_t_2 = 0;

    /* "pygpu/gpuarray.pyx":1398
 *         a = pygpu_copy(a, GA_ANY_ORDER)
 * 
 *     if ldtype is None:             # <<<<<<<<<<<<<<
 *         ldtype = a.dtype
 * 
 */
  }

  /* "pygpu/gpuarray.pyx":1402
 * 
 *     res = PyArray_Empty(a.ga.nd, <np.npy_intp *>a.ga.dimensions,
 *                         ldtype, (py_CHKFLAGS(a, GA_F_CONTIGUOUS) and             # <<<<<<<<<<<<<<
 *                                  not py_CHKFLAGS(a, GA_C_CONTIGUOUS)))
 * 
 */
  __pyx_t_3 = __pyx_f_5pygpu_8gpuarray_py_CHKFLAGS(__pyx_v_a, GA_F_CONTIGUOUS);
  if (__pyx_t_3) {
  } else {
    __pyx_t_4 = __pyx_t_3;
    goto __pyx_L5_bool_binop_done;
  }

  /* "pygpu/gpuarray.pyx":1403
 *     res = PyArray_Empty(a.ga.nd, <np.npy_intp *>a.ga.dimensions,
 *                         ldtype, (py_CHKFLAGS(a, GA_F_CONTIGUOUS) and
 *                                  not py_CHKFLAGS(a, GA_C_CONTIGUOUS)))             # <<<<<<<<<<<<<<
 * 
 *     array_read(np.PyArray_DATA(res), np.PyArray_NBYTES(res), a)
 */
  __pyx_t_3 = (!(__pyx_f_5pygpu_8gpuarray_py_CHKFLAGS(__pyx_v_a, GA_C_CONTIGUOUS) != 0));
  __pyx_t_4 = __pyx_t_3;
  __pyx_L5_bool_binop_done:;

  /* "pygpu/gpuarray.pyx":1401
 *         ldtype = a.dtype
 * 
 *     res = PyArray_Empty(a.ga.nd, <np.npy_intp *>a.ga.dimensions,             # <<<<<<<<<<<<<<
 *                         ldtype, (py_CHKFLAGS(a, GA_F_CONTIGUOUS) and
 *                                  not py_CHKFLAGS(a, GA_C_CONTIGUOUS)))
 */
  __pyx_t_2 = __pyx_f_5pygpu_8gpuarray_PyArray_Empty(__pyx_v_a->ga.nd, ((npy_intp *)__pyx_v_a->ga.dimensions), __pyx_v_ldtype, __pyx_t_4); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1401, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (!(likely(((__pyx_t_2) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_2, __pyx_ptype_5numpy_ndarray))))) __PYX_ERR(0, 1401, __pyx_L1_error)
  __pyx_v_res = ((PyArrayObject *)__pyx_t_2);
  __pyx_t_2 = 0;

  /* "pygpu/gpuarray.pyx":1405
 *                                  not py_CHKFLAGS(a, GA_C_CONTIGUOUS)))
 * 
 *     array_read(np.PyArray_DATA(res), np.PyArray_NBYTES(res), a)             # <<<<<<<<<<<<<<
 * 
 *     return res
 */
  __pyx_t_4 = __pyx_f_5pygpu_8gpuarray_array_read(PyArray_DATA(__pyx_v_res), PyArray_NBYTES(__pyx_v_res), __pyx_v_a); if (unlikely(__pyx_t_4 == ((int)-1))) __PYX_ERR(0, 1405, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":1407
 *     array_read(np.PyArray_DATA(res), np.PyArray_NBYTES(res), a)
 * 
 *     return res             # <<<<<<<<<<<<<<
 * 
 * cdef GpuArray pygpu_index(GpuArray a, const ssize_t *starts,
 */
  __Pyx_XDECREF(((PyObject *)__pyx_r));
  __Pyx_INCREF(((PyObject *)__pyx_v_res));
  __pyx_r = __pyx_v_res;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":1392
 *     return _pygpu_as_ndarray(a, None)
 * 
 * cdef np.ndarray _pygpu_as_ndarray(GpuArray a, np.dtype ldtype):             # <<<<<<<<<<<<<<
 *     cdef np.ndarray res
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("pygpu.gpuarray._pygpu_as_ndarray", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_res);
  __Pyx_XDECREF((PyObject *)__pyx_v_a);
  __Pyx_XDECREF((PyObject *)__pyx_v_ldtype);
  __Pyx_XGIVEREF((PyObject *)__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":1409
 *     return res
 * 
 * cdef GpuArray pygpu_index(GpuArray a, const ssize_t *starts,             # <<<<<<<<<<<<<<
 *                           const ssize_t *stops, const ssize_t *steps):
 *     cdef GpuArray res
 */

static struct PyGpuArrayObject *__pyx_f_5pygpu_8gpuarray_pygpu_index(struct PyGpuArrayObject *__pyx_v_a, Py_ssize_t const *__pyx_v_starts, Py_ssize_t const *__pyx_v_stops, Py_ssize_t const *__pyx_v_steps) {
  struct PyGpuArrayObject *__pyx_v_res = 0;
  CYTHON_UNUSED PyObject *__pyx_v_e = NULL;
  struct PyGpuArrayObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  int __pyx_t_7;
  __Pyx_RefNannySetupContext("pygpu_index", 0);

  /* "pygpu/gpuarray.pyx":1412
 *                           const ssize_t *stops, const ssize_t *steps):
 *     cdef GpuArray res
 *     res = new_GpuArray(type(a), a.context, a.base)             # <<<<<<<<<<<<<<
 *     try:
 *         array_index(res, a, starts, stops, steps)
 */
  __pyx_t_1 = ((PyObject *)__pyx_v_a->context);
  __Pyx_INCREF(__pyx_t_1);
  __pyx_t_2 = __pyx_v_a->base;
  __Pyx_INCREF(__pyx_t_2);
  __pyx_t_3 = ((PyObject *)__pyx_f_5pygpu_8gpuarray_new_GpuArray(((PyObject *)Py_TYPE(((PyObject *)__pyx_v_a))), ((struct PyGpuContextObject *)__pyx_t_1), __pyx_t_2)); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1412, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_res = ((struct PyGpuArrayObject *)__pyx_t_3);
  __pyx_t_3 = 0;

  /* "pygpu/gpuarray.pyx":1413
 *     cdef GpuArray res
 *     res = new_GpuArray(type(a), a.context, a.base)
 *     try:             # <<<<<<<<<<<<<<
 *         array_index(res, a, starts, stops, steps)
 *     except ValueError, e:
 */
  {
    __Pyx_PyThreadState_declare
    __Pyx_PyThreadState_assign
    __Pyx_ExceptionSave(&__pyx_t_4, &__pyx_t_5, &__pyx_t_6);
    __Pyx_XGOTREF(__pyx_t_4);
    __Pyx_XGOTREF(__pyx_t_5);
    __Pyx_XGOTREF(__pyx_t_6);
    /*try:*/ {

      /* "pygpu/gpuarray.pyx":1414
 *     res = new_GpuArray(type(a), a.context, a.base)
 *     try:
 *         array_index(res, a, starts, stops, steps)             # <<<<<<<<<<<<<<
 *     except ValueError, e:
 *         raise IndexError, "index out of bounds"
 */
      __pyx_t_7 = __pyx_f_5pygpu_8gpuarray_array_index(__pyx_v_res, __pyx_v_a, __pyx_v_starts, __pyx_v_stops, __pyx_v_steps); if (unlikely(__pyx_t_7 == ((int)-1))) __PYX_ERR(0, 1414, __pyx_L3_error)

      /* "pygpu/gpuarray.pyx":1413
 *     cdef GpuArray res
 *     res = new_GpuArray(type(a), a.context, a.base)
 *     try:             # <<<<<<<<<<<<<<
 *         array_index(res, a, starts, stops, steps)
 *     except ValueError, e:
 */
    }
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
    goto __pyx_L8_try_end;
    __pyx_L3_error:;
    __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;

    /* "pygpu/gpuarray.pyx":1415
 *     try:
 *         array_index(res, a, starts, stops, steps)
 *     except ValueError, e:             # <<<<<<<<<<<<<<
 *         raise IndexError, "index out of bounds"
 *     return res
 */
    __pyx_t_7 = __Pyx_PyErr_ExceptionMatches(__pyx_builtin_ValueError);
    if (__pyx_t_7) {
      __Pyx_AddTraceback("pygpu.gpuarray.pygpu_index", __pyx_clineno, __pyx_lineno, __pyx_filename);
      if (__Pyx_GetException(&__pyx_t_3, &__pyx_t_2, &__pyx_t_1) < 0) __PYX_ERR(0, 1415, __pyx_L5_except_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_INCREF(__pyx_t_2);
      __pyx_v_e = __pyx_t_2;

      /* "pygpu/gpuarray.pyx":1416
 *         array_index(res, a, starts, stops, steps)
 *     except ValueError, e:
 *         raise IndexError, "index out of bounds"             # <<<<<<<<<<<<<<
 *     return res
 * 
 */
      __Pyx_Raise(__pyx_builtin_IndexError, __pyx_kp_s_index_out_of_bounds, 0, 0);
      __PYX_ERR(0, 1416, __pyx_L5_except_error)
    }
    goto __pyx_L5_except_error;
    __pyx_L5_except_error:;

    /* "pygpu/gpuarray.pyx":1413
 *     cdef GpuArray res
 *     res = new_GpuArray(type(a), a.context, a.base)
 *     try:             # <<<<<<<<<<<<<<
 *         array_index(res, a, starts, stops, steps)
 *     except ValueError, e:
 */
    __Pyx_XGIVEREF(__pyx_t_4);
    __Pyx_XGIVEREF(__pyx_t_5);
    __Pyx_XGIVEREF(__pyx_t_6);
    __Pyx_ExceptionReset(__pyx_t_4, __pyx_t_5, __pyx_t_6);
    goto __pyx_L1_error;
    __pyx_L8_try_end:;
  }

  /* "pygpu/gpuarray.pyx":1417
 *     except ValueError, e:
 *         raise IndexError, "index out of bounds"
 *     return res             # <<<<<<<<<<<<<<
 * 
 * cdef GpuArray pygpu_reshape(GpuArray a, unsigned int nd, const size_t *newdims,
 */
  __Pyx_XDECREF(((PyObject *)__pyx_r));
  __Pyx_INCREF(((PyObject *)__pyx_v_res));
  __pyx_r = __pyx_v_res;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":1409
 *     return res
 * 
 * cdef GpuArray pygpu_index(GpuArray a, const ssize_t *starts,             # <<<<<<<<<<<<<<
 *                           const ssize_t *stops, const ssize_t *steps):
 *     cdef GpuArray res
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("pygpu.gpuarray.pygpu_index", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_res);
  __Pyx_XDECREF(__pyx_v_e);
  __Pyx_XGIVEREF((PyObject *)__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":1419
 *     return res
 * 
 * cdef GpuArray pygpu_reshape(GpuArray a, unsigned int nd, const size_t *newdims,             # <<<<<<<<<<<<<<
 *                             ga_order ord, bint nocopy, int compute_axis):
 *     cdef GpuArray res
 */

static struct PyGpuArrayObject *__pyx_f_5pygpu_8gpuarray_pygpu_reshape(struct PyGpuArrayObject *__pyx_v_a, unsigned int __pyx_v_nd, size_t const *__pyx_v_newdims, ga_order __pyx_v_ord, int __pyx_v_nocopy, int __pyx_v_compute_axis) {
  struct PyGpuArrayObject *__pyx_v_res = 0;
  unsigned int __pyx_v_caxis;
  size_t *__pyx_v_cdims;
  size_t __pyx_v_tot;
  unsigned int __pyx_v_i;
  size_t __pyx_v_d;
  struct PyGpuArrayObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  int __pyx_t_5;
  unsigned int __pyx_t_6;
  unsigned int __pyx_t_7;
  size_t __pyx_t_8;
  int __pyx_t_9;
  char const *__pyx_t_10;
  PyObject *__pyx_t_11 = NULL;
  PyObject *__pyx_t_12 = NULL;
  PyObject *__pyx_t_13 = NULL;
  PyObject *__pyx_t_14 = NULL;
  PyObject *__pyx_t_15 = NULL;
  PyObject *__pyx_t_16 = NULL;
  struct PyGpuArrayObject *__pyx_t_17 = NULL;
  __Pyx_RefNannySetupContext("pygpu_reshape", 0);

  /* "pygpu/gpuarray.pyx":1422
 *                             ga_order ord, bint nocopy, int compute_axis):
 *     cdef GpuArray res
 *     res = new_GpuArray(type(a), a.context, a.base)             # <<<<<<<<<<<<<<
 *     if compute_axis < 0:
 *         array_reshape(res, a, nd, newdims, ord, nocopy)
 */
  __pyx_t_1 = ((PyObject *)__pyx_v_a->context);
  __Pyx_INCREF(__pyx_t_1);
  __pyx_t_2 = __pyx_v_a->base;
  __Pyx_INCREF(__pyx_t_2);
  __pyx_t_3 = ((PyObject *)__pyx_f_5pygpu_8gpuarray_new_GpuArray(((PyObject *)Py_TYPE(((PyObject *)__pyx_v_a))), ((struct PyGpuContextObject *)__pyx_t_1), __pyx_t_2)); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1422, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_res = ((struct PyGpuArrayObject *)__pyx_t_3);
  __pyx_t_3 = 0;

  /* "pygpu/gpuarray.pyx":1423
 *     cdef GpuArray res
 *     res = new_GpuArray(type(a), a.context, a.base)
 *     if compute_axis < 0:             # <<<<<<<<<<<<<<
 *         array_reshape(res, a, nd, newdims, ord, nocopy)
 *         return res
 */
  __pyx_t_4 = ((__pyx_v_compute_axis < 0) != 0);
  if (__pyx_t_4) {

    /* "pygpu/gpuarray.pyx":1424
 *     res = new_GpuArray(type(a), a.context, a.base)
 *     if compute_axis < 0:
 *         array_reshape(res, a, nd, newdims, ord, nocopy)             # <<<<<<<<<<<<<<
 *         return res
 *     cdef unsigned int caxis = <unsigned int>compute_axis
 */
    __pyx_t_5 = __pyx_f_5pygpu_8gpuarray_array_reshape(__pyx_v_res, __pyx_v_a, __pyx_v_nd, __pyx_v_newdims, __pyx_v_ord, __pyx_v_nocopy); if (unlikely(__pyx_t_5 == ((int)-1))) __PYX_ERR(0, 1424, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":1425
 *     if compute_axis < 0:
 *         array_reshape(res, a, nd, newdims, ord, nocopy)
 *         return res             # <<<<<<<<<<<<<<
 *     cdef unsigned int caxis = <unsigned int>compute_axis
 *     if caxis >= nd:
 */
    __Pyx_XDECREF(((PyObject *)__pyx_r));
    __Pyx_INCREF(((PyObject *)__pyx_v_res));
    __pyx_r = __pyx_v_res;
    goto __pyx_L0;

    /* "pygpu/gpuarray.pyx":1423
 *     cdef GpuArray res
 *     res = new_GpuArray(type(a), a.context, a.base)
 *     if compute_axis < 0:             # <<<<<<<<<<<<<<
 *         array_reshape(res, a, nd, newdims, ord, nocopy)
 *         return res
 */
  }

  /* "pygpu/gpuarray.pyx":1426
 *         array_reshape(res, a, nd, newdims, ord, nocopy)
 *         return res
 *     cdef unsigned int caxis = <unsigned int>compute_axis             # <<<<<<<<<<<<<<
 *     if caxis >= nd:
 *         raise ValueError("compute_axis is out of bounds")
 */
  __pyx_v_caxis = ((unsigned int)__pyx_v_compute_axis);

  /* "pygpu/gpuarray.pyx":1427
 *         return res
 *     cdef unsigned int caxis = <unsigned int>compute_axis
 *     if caxis >= nd:             # <<<<<<<<<<<<<<
 *         raise ValueError("compute_axis is out of bounds")
 * 
 */
  __pyx_t_4 = ((__pyx_v_caxis >= __pyx_v_nd) != 0);
  if (__pyx_t_4) {

    /* "pygpu/gpuarray.pyx":1428
 *     cdef unsigned int caxis = <unsigned int>compute_axis
 *     if caxis >= nd:
 *         raise ValueError("compute_axis is out of bounds")             # <<<<<<<<<<<<<<
 * 
 *     cdef size_t *cdims
 */
    __pyx_t_3 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__21, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1428, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_Raise(__pyx_t_3, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __PYX_ERR(0, 1428, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":1427
 *         return res
 *     cdef unsigned int caxis = <unsigned int>compute_axis
 *     if caxis >= nd:             # <<<<<<<<<<<<<<
 *         raise ValueError("compute_axis is out of bounds")
 * 
 */
  }

  /* "pygpu/gpuarray.pyx":1431
 * 
 *     cdef size_t *cdims
 *     cdef size_t tot = 1             # <<<<<<<<<<<<<<
 *     cdef unsigned int i
 *     for i in range(nd):
 */
  __pyx_v_tot = 1;

  /* "pygpu/gpuarray.pyx":1433
 *     cdef size_t tot = 1
 *     cdef unsigned int i
 *     for i in range(nd):             # <<<<<<<<<<<<<<
 *         if i != caxis:
 *             tot *= newdims[i]
 */
  __pyx_t_6 = __pyx_v_nd;
  for (__pyx_t_7 = 0; __pyx_t_7 < __pyx_t_6; __pyx_t_7+=1) {
    __pyx_v_i = __pyx_t_7;

    /* "pygpu/gpuarray.pyx":1434
 *     cdef unsigned int i
 *     for i in range(nd):
 *         if i != caxis:             # <<<<<<<<<<<<<<
 *             tot *= newdims[i]
 *     cdims = <size_t *>calloc(nd, sizeof(size_t))
 */
    __pyx_t_4 = ((__pyx_v_i != __pyx_v_caxis) != 0);
    if (__pyx_t_4) {

      /* "pygpu/gpuarray.pyx":1435
 *     for i in range(nd):
 *         if i != caxis:
 *             tot *= newdims[i]             # <<<<<<<<<<<<<<
 *     cdims = <size_t *>calloc(nd, sizeof(size_t))
 *     if cdims == NULL:
 */
      __pyx_v_tot = (__pyx_v_tot * (__pyx_v_newdims[__pyx_v_i]));

      /* "pygpu/gpuarray.pyx":1434
 *     cdef unsigned int i
 *     for i in range(nd):
 *         if i != caxis:             # <<<<<<<<<<<<<<
 *             tot *= newdims[i]
 *     cdims = <size_t *>calloc(nd, sizeof(size_t))
 */
    }
  }

  /* "pygpu/gpuarray.pyx":1436
 *         if i != caxis:
 *             tot *= newdims[i]
 *     cdims = <size_t *>calloc(nd, sizeof(size_t))             # <<<<<<<<<<<<<<
 *     if cdims == NULL:
 *         raise MemoryError, "could not allocate cdims"
 */
  __pyx_v_cdims = ((size_t *)calloc(__pyx_v_nd, (sizeof(size_t))));

  /* "pygpu/gpuarray.pyx":1437
 *             tot *= newdims[i]
 *     cdims = <size_t *>calloc(nd, sizeof(size_t))
 *     if cdims == NULL:             # <<<<<<<<<<<<<<
 *         raise MemoryError, "could not allocate cdims"
 * 
 */
  __pyx_t_4 = ((__pyx_v_cdims == NULL) != 0);
  if (__pyx_t_4) {

    /* "pygpu/gpuarray.pyx":1438
 *     cdims = <size_t *>calloc(nd, sizeof(size_t))
 *     if cdims == NULL:
 *         raise MemoryError, "could not allocate cdims"             # <<<<<<<<<<<<<<
 * 
 *     cdef size_t d
 */
    __Pyx_Raise(__pyx_builtin_MemoryError, __pyx_kp_s_could_not_allocate_cdims, 0, 0);
    __PYX_ERR(0, 1438, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":1437
 *             tot *= newdims[i]
 *     cdims = <size_t *>calloc(nd, sizeof(size_t))
 *     if cdims == NULL:             # <<<<<<<<<<<<<<
 *         raise MemoryError, "could not allocate cdims"
 * 
 */
  }

  /* "pygpu/gpuarray.pyx":1441
 * 
 *     cdef size_t d
 *     try:             # <<<<<<<<<<<<<<
 *         for i in range(nd):
 *             d = newdims[i]
 */
  /*try:*/ {

    /* "pygpu/gpuarray.pyx":1442
 *     cdef size_t d
 *     try:
 *         for i in range(nd):             # <<<<<<<<<<<<<<
 *             d = newdims[i]
 *             if i == caxis:
 */
    __pyx_t_6 = __pyx_v_nd;
    for (__pyx_t_7 = 0; __pyx_t_7 < __pyx_t_6; __pyx_t_7+=1) {
      __pyx_v_i = __pyx_t_7;

      /* "pygpu/gpuarray.pyx":1443
 *     try:
 *         for i in range(nd):
 *             d = newdims[i]             # <<<<<<<<<<<<<<
 *             if i == caxis:
 *                 d = a.size // tot
 */
      __pyx_v_d = (__pyx_v_newdims[__pyx_v_i]);

      /* "pygpu/gpuarray.pyx":1444
 *         for i in range(nd):
 *             d = newdims[i]
 *             if i == caxis:             # <<<<<<<<<<<<<<
 *                 d = a.size // tot
 * 
 */
      __pyx_t_4 = ((__pyx_v_i == __pyx_v_caxis) != 0);
      if (__pyx_t_4) {

        /* "pygpu/gpuarray.pyx":1445
 *             d = newdims[i]
 *             if i == caxis:
 *                 d = a.size // tot             # <<<<<<<<<<<<<<
 * 
 *                 if d * tot != a.size:
 */
        __pyx_t_3 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_a), __pyx_n_s_size); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1445, __pyx_L10_error)
        __Pyx_GOTREF(__pyx_t_3);
        __pyx_t_2 = __Pyx_PyInt_FromSize_t(__pyx_v_tot); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1445, __pyx_L10_error)
        __Pyx_GOTREF(__pyx_t_2);
        __pyx_t_1 = PyNumber_FloorDivide(__pyx_t_3, __pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1445, __pyx_L10_error)
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
        __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
        __pyx_t_8 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_8 == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 1445, __pyx_L10_error)
        __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
        __pyx_v_d = __pyx_t_8;

        /* "pygpu/gpuarray.pyx":1447
 *                 d = a.size // tot
 * 
 *                 if d * tot != a.size:             # <<<<<<<<<<<<<<
 *                     raise GpuArrayException, "..."
 *             cdims[i] = d
 */
        __pyx_t_1 = __Pyx_PyInt_FromSize_t((__pyx_v_d * __pyx_v_tot)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1447, __pyx_L10_error)
        __Pyx_GOTREF(__pyx_t_1);
        __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_a), __pyx_n_s_size); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1447, __pyx_L10_error)
        __Pyx_GOTREF(__pyx_t_2);
        __pyx_t_3 = PyObject_RichCompare(__pyx_t_1, __pyx_t_2, Py_NE); __Pyx_XGOTREF(__pyx_t_3); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1447, __pyx_L10_error)
        __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
        __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
        __pyx_t_4 = __Pyx_PyObject_IsTrue(__pyx_t_3); if (unlikely(__pyx_t_4 < 0)) __PYX_ERR(0, 1447, __pyx_L10_error)
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
        if (__pyx_t_4) {

          /* "pygpu/gpuarray.pyx":1448
 * 
 *                 if d * tot != a.size:
 *                     raise GpuArrayException, "..."             # <<<<<<<<<<<<<<
 *             cdims[i] = d
 * 
 */
          __pyx_t_3 = __Pyx_GetModuleGlobalName(__pyx_n_s_GpuArrayException); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1448, __pyx_L10_error)
          __Pyx_GOTREF(__pyx_t_3);
          __Pyx_Raise(__pyx_t_3, __pyx_kp_s__22, 0, 0);
          __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
          __PYX_ERR(0, 1448, __pyx_L10_error)

          /* "pygpu/gpuarray.pyx":1447
 *                 d = a.size // tot
 * 
 *                 if d * tot != a.size:             # <<<<<<<<<<<<<<
 *                     raise GpuArrayException, "..."
 *             cdims[i] = d
 */
        }

        /* "pygpu/gpuarray.pyx":1444
 *         for i in range(nd):
 *             d = newdims[i]
 *             if i == caxis:             # <<<<<<<<<<<<<<
 *                 d = a.size // tot
 * 
 */
      }

      /* "pygpu/gpuarray.pyx":1449
 *                 if d * tot != a.size:
 *                     raise GpuArrayException, "..."
 *             cdims[i] = d             # <<<<<<<<<<<<<<
 * 
 *         array_reshape(res, a, nd, cdims, ord, nocopy)
 */
      (__pyx_v_cdims[__pyx_v_i]) = __pyx_v_d;
    }

    /* "pygpu/gpuarray.pyx":1451
 *             cdims[i] = d
 * 
 *         array_reshape(res, a, nd, cdims, ord, nocopy)             # <<<<<<<<<<<<<<
 *         return res
 *     finally:
 */
    __pyx_t_5 = __pyx_f_5pygpu_8gpuarray_array_reshape(__pyx_v_res, __pyx_v_a, __pyx_v_nd, __pyx_v_cdims, __pyx_v_ord, __pyx_v_nocopy); if (unlikely(__pyx_t_5 == ((int)-1))) __PYX_ERR(0, 1451, __pyx_L10_error)

    /* "pygpu/gpuarray.pyx":1452
 * 
 *         array_reshape(res, a, nd, cdims, ord, nocopy)
 *         return res             # <<<<<<<<<<<<<<
 *     finally:
 *         free(cdims)
 */
    __Pyx_XDECREF(((PyObject *)__pyx_r));
    __Pyx_INCREF(((PyObject *)__pyx_v_res));
    __pyx_r = __pyx_v_res;
    goto __pyx_L9_return;
  }

  /* "pygpu/gpuarray.pyx":1454
 *         return res
 *     finally:
 *         free(cdims)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  /*finally:*/ {
    __pyx_L10_error:;
    /*exception exit:*/{
      __Pyx_PyThreadState_declare
      __Pyx_PyThreadState_assign
      __pyx_t_11 = 0; __pyx_t_12 = 0; __pyx_t_13 = 0; __pyx_t_14 = 0; __pyx_t_15 = 0; __pyx_t_16 = 0;
      __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
      __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
      __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
      if (PY_MAJOR_VERSION >= 3) __Pyx_ExceptionSwap(&__pyx_t_14, &__pyx_t_15, &__pyx_t_16);
      if ((PY_MAJOR_VERSION < 3) || unlikely(__Pyx_GetException(&__pyx_t_11, &__pyx_t_12, &__pyx_t_13) < 0)) __Pyx_ErrFetch(&__pyx_t_11, &__pyx_t_12, &__pyx_t_13);
      __Pyx_XGOTREF(__pyx_t_11);
      __Pyx_XGOTREF(__pyx_t_12);
      __Pyx_XGOTREF(__pyx_t_13);
      __Pyx_XGOTREF(__pyx_t_14);
      __Pyx_XGOTREF(__pyx_t_15);
      __Pyx_XGOTREF(__pyx_t_16);
      __pyx_t_5 = __pyx_lineno; __pyx_t_9 = __pyx_clineno; __pyx_t_10 = __pyx_filename;
      {
        free(__pyx_v_cdims);
      }
      if (PY_MAJOR_VERSION >= 3) {
        __Pyx_XGIVEREF(__pyx_t_14);
        __Pyx_XGIVEREF(__pyx_t_15);
        __Pyx_XGIVEREF(__pyx_t_16);
        __Pyx_ExceptionReset(__pyx_t_14, __pyx_t_15, __pyx_t_16);
      }
      __Pyx_XGIVEREF(__pyx_t_11);
      __Pyx_XGIVEREF(__pyx_t_12);
      __Pyx_XGIVEREF(__pyx_t_13);
      __Pyx_ErrRestore(__pyx_t_11, __pyx_t_12, __pyx_t_13);
      __pyx_t_11 = 0; __pyx_t_12 = 0; __pyx_t_13 = 0; __pyx_t_14 = 0; __pyx_t_15 = 0; __pyx_t_16 = 0;
      __pyx_lineno = __pyx_t_5; __pyx_clineno = __pyx_t_9; __pyx_filename = __pyx_t_10;
      goto __pyx_L1_error;
    }
    __pyx_L9_return: {
      __pyx_t_17 = __pyx_r;
      __pyx_r = 0;
      free(__pyx_v_cdims);
      __pyx_r = __pyx_t_17;
      __pyx_t_17 = 0;
      goto __pyx_L0;
    }
  }

  /* "pygpu/gpuarray.pyx":1419
 *     return res
 * 
 * cdef GpuArray pygpu_reshape(GpuArray a, unsigned int nd, const size_t *newdims,             # <<<<<<<<<<<<<<
 *                             ga_order ord, bint nocopy, int compute_axis):
 *     cdef GpuArray res
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("pygpu.gpuarray.pygpu_reshape", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_res);
  __Pyx_XGIVEREF((PyObject *)__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":1457
 * 
 * 
 * cdef GpuArray pygpu_transpose(GpuArray a, const unsigned int *newaxes):             # <<<<<<<<<<<<<<
 *     cdef GpuArray res
 *     res = new_GpuArray(type(a), a.context, a.base)
 */

static struct PyGpuArrayObject *__pyx_f_5pygpu_8gpuarray_pygpu_transpose(struct PyGpuArrayObject *__pyx_v_a, unsigned int const *__pyx_v_newaxes) {
  struct PyGpuArrayObject *__pyx_v_res = 0;
  struct PyGpuArrayObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  __Pyx_RefNannySetupContext("pygpu_transpose", 0);

  /* "pygpu/gpuarray.pyx":1459
 * cdef GpuArray pygpu_transpose(GpuArray a, const unsigned int *newaxes):
 *     cdef GpuArray res
 *     res = new_GpuArray(type(a), a.context, a.base)             # <<<<<<<<<<<<<<
 *     array_transpose(res, a, newaxes)
 *     return res
 */
  __pyx_t_1 = ((PyObject *)__pyx_v_a->context);
  __Pyx_INCREF(__pyx_t_1);
  __pyx_t_2 = __pyx_v_a->base;
  __Pyx_INCREF(__pyx_t_2);
  __pyx_t_3 = ((PyObject *)__pyx_f_5pygpu_8gpuarray_new_GpuArray(((PyObject *)Py_TYPE(((PyObject *)__pyx_v_a))), ((struct PyGpuContextObject *)__pyx_t_1), __pyx_t_2)); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1459, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_res = ((struct PyGpuArrayObject *)__pyx_t_3);
  __pyx_t_3 = 0;

  /* "pygpu/gpuarray.pyx":1460
 *     cdef GpuArray res
 *     res = new_GpuArray(type(a), a.context, a.base)
 *     array_transpose(res, a, newaxes)             # <<<<<<<<<<<<<<
 *     return res
 * 
 */
  __pyx_t_4 = __pyx_f_5pygpu_8gpuarray_array_transpose(__pyx_v_res, __pyx_v_a, __pyx_v_newaxes); if (unlikely(__pyx_t_4 == ((int)-1))) __PYX_ERR(0, 1460, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":1461
 *     res = new_GpuArray(type(a), a.context, a.base)
 *     array_transpose(res, a, newaxes)
 *     return res             # <<<<<<<<<<<<<<
 * 
 * cdef int pygpu_transfer(GpuArray res, GpuArray a) except -1:
 */
  __Pyx_XDECREF(((PyObject *)__pyx_r));
  __Pyx_INCREF(((PyObject *)__pyx_v_res));
  __pyx_r = __pyx_v_res;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":1457
 * 
 * 
 * cdef GpuArray pygpu_transpose(GpuArray a, const unsigned int *newaxes):             # <<<<<<<<<<<<<<
 *     cdef GpuArray res
 *     res = new_GpuArray(type(a), a.context, a.base)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("pygpu.gpuarray.pygpu_transpose", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_res);
  __Pyx_XGIVEREF((PyObject *)__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":1463
 *     return res
 * 
 * cdef int pygpu_transfer(GpuArray res, GpuArray a) except -1:             # <<<<<<<<<<<<<<
 *     array_transfer(res, a)
 *     return 0
 */

static int __pyx_f_5pygpu_8gpuarray_pygpu_transfer(struct PyGpuArrayObject *__pyx_v_res, struct PyGpuArrayObject *__pyx_v_a) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  __Pyx_RefNannySetupContext("pygpu_transfer", 0);

  /* "pygpu/gpuarray.pyx":1464
 * 
 * cdef int pygpu_transfer(GpuArray res, GpuArray a) except -1:
 *     array_transfer(res, a)             # <<<<<<<<<<<<<<
 *     return 0
 * 
 */
  __pyx_t_1 = __pyx_f_5pygpu_8gpuarray_array_transfer(__pyx_v_res, __pyx_v_a); if (unlikely(__pyx_t_1 == ((int)-1))) __PYX_ERR(0, 1464, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":1465
 * cdef int pygpu_transfer(GpuArray res, GpuArray a) except -1:
 *     array_transfer(res, a)
 *     return 0             # <<<<<<<<<<<<<<
 * 
 * def _split(GpuArray a, ind, unsigned int axis):
 */
  __pyx_r = 0;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":1463
 *     return res
 * 
 * cdef int pygpu_transfer(GpuArray res, GpuArray a) except -1:             # <<<<<<<<<<<<<<
 *     array_transfer(res, a)
 *     return 0
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_AddTraceback("pygpu.gpuarray.pygpu_transfer", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":1467
 *     return 0
 * 
 * def _split(GpuArray a, ind, unsigned int axis):             # <<<<<<<<<<<<<<
 *     """
 *     _split(a, ind, axis)
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_41_split(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static char __pyx_doc_5pygpu_8gpuarray_40_split[] = "\n    _split(a, ind, axis)\n    ";
static PyMethodDef __pyx_mdef_5pygpu_8gpuarray_41_split = {"_split", (PyCFunction)__pyx_pw_5pygpu_8gpuarray_41_split, METH_VARARGS|METH_KEYWORDS, __pyx_doc_5pygpu_8gpuarray_40_split};
static PyObject *__pyx_pw_5pygpu_8gpuarray_41_split(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  struct PyGpuArrayObject *__pyx_v_a = 0;
  PyObject *__pyx_v_ind = 0;
  unsigned int __pyx_v_axis;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("_split (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_a,&__pyx_n_s_ind,&__pyx_n_s_axis,0};
    PyObject* values[3] = {0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_a)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_ind)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("_split", 1, 3, 3, 1); __PYX_ERR(0, 1467, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_axis)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("_split", 1, 3, 3, 2); __PYX_ERR(0, 1467, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "_split") < 0)) __PYX_ERR(0, 1467, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 3) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
    }
    __pyx_v_a = ((struct PyGpuArrayObject *)values[0]);
    __pyx_v_ind = values[1];
    __pyx_v_axis = __Pyx_PyInt_As_unsigned_int(values[2]); if (unlikely((__pyx_v_axis == (unsigned int)-1) && PyErr_Occurred())) __PYX_ERR(0, 1467, __pyx_L3_error)
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("_split", 1, 3, 3, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 1467, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("pygpu.gpuarray._split", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_a), __pyx_ptype_5pygpu_8gpuarray_GpuArray, 1, "a", 0))) __PYX_ERR(0, 1467, __pyx_L1_error)
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_40_split(__pyx_self, __pyx_v_a, __pyx_v_ind, __pyx_v_axis);

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_40_split(CYTHON_UNUSED PyObject *__pyx_self, struct PyGpuArrayObject *__pyx_v_a, PyObject *__pyx_v_ind, unsigned int __pyx_v_axis) {
  PyObject *__pyx_v_r = 0;
  Py_ssize_t __pyx_v_i;
  size_t __pyx_v_m;
  size_t __pyx_v_v;
  size_t *__pyx_v_p;
  GpuArray **__pyx_v_rs;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  Py_ssize_t __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  int __pyx_t_3;
  Py_ssize_t __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  size_t __pyx_t_7;
  int __pyx_t_8;
  int __pyx_t_9;
  char const *__pyx_t_10;
  PyObject *__pyx_t_11 = NULL;
  PyObject *__pyx_t_12 = NULL;
  PyObject *__pyx_t_13 = NULL;
  PyObject *__pyx_t_14 = NULL;
  PyObject *__pyx_t_15 = NULL;
  PyObject *__pyx_t_16 = NULL;
  __Pyx_RefNannySetupContext("_split", 0);

  /* "pygpu/gpuarray.pyx":1471
 *     _split(a, ind, axis)
 *     """
 *     cdef list r = [None] * (len(ind) + 1)             # <<<<<<<<<<<<<<
 *     cdef Py_ssize_t i
 *     if not axis < a.ga.nd:
 */
  __pyx_t_1 = PyObject_Length(__pyx_v_ind); if (unlikely(__pyx_t_1 == ((Py_ssize_t)-1))) __PYX_ERR(0, 1471, __pyx_L1_error)
  __pyx_t_2 = PyList_New(1 * (((__pyx_t_1 + 1)<0) ? 0:(__pyx_t_1 + 1))); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1471, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  { Py_ssize_t __pyx_temp;
    for (__pyx_temp=0; __pyx_temp < (__pyx_t_1 + 1); __pyx_temp++) {
      __Pyx_INCREF(Py_None);
      __Pyx_GIVEREF(Py_None);
      PyList_SET_ITEM(__pyx_t_2, __pyx_temp, Py_None);
    }
  }
  __pyx_v_r = ((PyObject*)__pyx_t_2);
  __pyx_t_2 = 0;

  /* "pygpu/gpuarray.pyx":1473
 *     cdef list r = [None] * (len(ind) + 1)
 *     cdef Py_ssize_t i
 *     if not axis < a.ga.nd:             # <<<<<<<<<<<<<<
 *         raise ValueError, "split on non-existant axis"
 *     cdef size_t m = a.ga.dimensions[axis]
 */
  __pyx_t_3 = ((!((__pyx_v_axis < __pyx_v_a->ga.nd) != 0)) != 0);
  if (__pyx_t_3) {

    /* "pygpu/gpuarray.pyx":1474
 *     cdef Py_ssize_t i
 *     if not axis < a.ga.nd:
 *         raise ValueError, "split on non-existant axis"             # <<<<<<<<<<<<<<
 *     cdef size_t m = a.ga.dimensions[axis]
 *     cdef size_t v
 */
    __Pyx_Raise(__pyx_builtin_ValueError, __pyx_kp_s_split_on_non_existant_axis, 0, 0);
    __PYX_ERR(0, 1474, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":1473
 *     cdef list r = [None] * (len(ind) + 1)
 *     cdef Py_ssize_t i
 *     if not axis < a.ga.nd:             # <<<<<<<<<<<<<<
 *         raise ValueError, "split on non-existant axis"
 *     cdef size_t m = a.ga.dimensions[axis]
 */
  }

  /* "pygpu/gpuarray.pyx":1475
 *     if not axis < a.ga.nd:
 *         raise ValueError, "split on non-existant axis"
 *     cdef size_t m = a.ga.dimensions[axis]             # <<<<<<<<<<<<<<
 *     cdef size_t v
 *     cdef size_t *p = <size_t *>PyMem_Malloc(sizeof(size_t) * len(ind))
 */
  __pyx_v_m = (__pyx_v_a->ga.dimensions[__pyx_v_axis]);

  /* "pygpu/gpuarray.pyx":1477
 *     cdef size_t m = a.ga.dimensions[axis]
 *     cdef size_t v
 *     cdef size_t *p = <size_t *>PyMem_Malloc(sizeof(size_t) * len(ind))             # <<<<<<<<<<<<<<
 *     if p == NULL:
 *         raise MemoryError()
 */
  __pyx_t_1 = PyObject_Length(__pyx_v_ind); if (unlikely(__pyx_t_1 == ((Py_ssize_t)-1))) __PYX_ERR(0, 1477, __pyx_L1_error)
  __pyx_v_p = ((size_t *)PyMem_Malloc(((sizeof(size_t)) * __pyx_t_1)));

  /* "pygpu/gpuarray.pyx":1478
 *     cdef size_t v
 *     cdef size_t *p = <size_t *>PyMem_Malloc(sizeof(size_t) * len(ind))
 *     if p == NULL:             # <<<<<<<<<<<<<<
 *         raise MemoryError()
 *     cdef _GpuArray **rs = <_GpuArray **>PyMem_Malloc(sizeof(_GpuArray *) * len(r))
 */
  __pyx_t_3 = ((__pyx_v_p == NULL) != 0);
  if (__pyx_t_3) {

    /* "pygpu/gpuarray.pyx":1479
 *     cdef size_t *p = <size_t *>PyMem_Malloc(sizeof(size_t) * len(ind))
 *     if p == NULL:
 *         raise MemoryError()             # <<<<<<<<<<<<<<
 *     cdef _GpuArray **rs = <_GpuArray **>PyMem_Malloc(sizeof(_GpuArray *) * len(r))
 *     if rs == NULL:
 */
    PyErr_NoMemory(); __PYX_ERR(0, 1479, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":1478
 *     cdef size_t v
 *     cdef size_t *p = <size_t *>PyMem_Malloc(sizeof(size_t) * len(ind))
 *     if p == NULL:             # <<<<<<<<<<<<<<
 *         raise MemoryError()
 *     cdef _GpuArray **rs = <_GpuArray **>PyMem_Malloc(sizeof(_GpuArray *) * len(r))
 */
  }

  /* "pygpu/gpuarray.pyx":1480
 *     if p == NULL:
 *         raise MemoryError()
 *     cdef _GpuArray **rs = <_GpuArray **>PyMem_Malloc(sizeof(_GpuArray *) * len(r))             # <<<<<<<<<<<<<<
 *     if rs == NULL:
 *         PyMem_Free(p)
 */
  __pyx_t_1 = PyList_GET_SIZE(__pyx_v_r); if (unlikely(__pyx_t_1 == ((Py_ssize_t)-1))) __PYX_ERR(0, 1480, __pyx_L1_error)
  __pyx_v_rs = ((GpuArray **)PyMem_Malloc(((sizeof(GpuArray *)) * __pyx_t_1)));

  /* "pygpu/gpuarray.pyx":1481
 *         raise MemoryError()
 *     cdef _GpuArray **rs = <_GpuArray **>PyMem_Malloc(sizeof(_GpuArray *) * len(r))
 *     if rs == NULL:             # <<<<<<<<<<<<<<
 *         PyMem_Free(p)
 *         raise MemoryError()
 */
  __pyx_t_3 = ((__pyx_v_rs == NULL) != 0);
  if (__pyx_t_3) {

    /* "pygpu/gpuarray.pyx":1482
 *     cdef _GpuArray **rs = <_GpuArray **>PyMem_Malloc(sizeof(_GpuArray *) * len(r))
 *     if rs == NULL:
 *         PyMem_Free(p)             # <<<<<<<<<<<<<<
 *         raise MemoryError()
 *     try:
 */
    PyMem_Free(__pyx_v_p);

    /* "pygpu/gpuarray.pyx":1483
 *     if rs == NULL:
 *         PyMem_Free(p)
 *         raise MemoryError()             # <<<<<<<<<<<<<<
 *     try:
 *         for i in range(len(r)):
 */
    PyErr_NoMemory(); __PYX_ERR(0, 1483, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":1481
 *         raise MemoryError()
 *     cdef _GpuArray **rs = <_GpuArray **>PyMem_Malloc(sizeof(_GpuArray *) * len(r))
 *     if rs == NULL:             # <<<<<<<<<<<<<<
 *         PyMem_Free(p)
 *         raise MemoryError()
 */
  }

  /* "pygpu/gpuarray.pyx":1484
 *         PyMem_Free(p)
 *         raise MemoryError()
 *     try:             # <<<<<<<<<<<<<<
 *         for i in range(len(r)):
 *             r[i] = new_GpuArray(type(a), a.context, a.base)
 */
  /*try:*/ {

    /* "pygpu/gpuarray.pyx":1485
 *         raise MemoryError()
 *     try:
 *         for i in range(len(r)):             # <<<<<<<<<<<<<<
 *             r[i] = new_GpuArray(type(a), a.context, a.base)
 *             rs[i] = &(<GpuArray>r[i]).ga
 */
    __pyx_t_1 = PyList_GET_SIZE(__pyx_v_r); if (unlikely(__pyx_t_1 == ((Py_ssize_t)-1))) __PYX_ERR(0, 1485, __pyx_L7_error)
    for (__pyx_t_4 = 0; __pyx_t_4 < __pyx_t_1; __pyx_t_4+=1) {
      __pyx_v_i = __pyx_t_4;

      /* "pygpu/gpuarray.pyx":1486
 *     try:
 *         for i in range(len(r)):
 *             r[i] = new_GpuArray(type(a), a.context, a.base)             # <<<<<<<<<<<<<<
 *             rs[i] = &(<GpuArray>r[i]).ga
 *         for i in range(len(ind)):
 */
      __pyx_t_2 = ((PyObject *)__pyx_v_a->context);
      __Pyx_INCREF(__pyx_t_2);
      __pyx_t_5 = __pyx_v_a->base;
      __Pyx_INCREF(__pyx_t_5);
      __pyx_t_6 = ((PyObject *)__pyx_f_5pygpu_8gpuarray_new_GpuArray(((PyObject *)Py_TYPE(((PyObject *)__pyx_v_a))), ((struct PyGpuContextObject *)__pyx_t_2), __pyx_t_5)); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1486, __pyx_L7_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      if (unlikely(__Pyx_SetItemInt(__pyx_v_r, __pyx_v_i, __pyx_t_6, Py_ssize_t, 1, PyInt_FromSsize_t, 1, 1, 1) < 0)) __PYX_ERR(0, 1486, __pyx_L7_error)
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;

      /* "pygpu/gpuarray.pyx":1487
 *         for i in range(len(r)):
 *             r[i] = new_GpuArray(type(a), a.context, a.base)
 *             rs[i] = &(<GpuArray>r[i]).ga             # <<<<<<<<<<<<<<
 *         for i in range(len(ind)):
 *             v = ind[i]
 */
      __pyx_t_6 = __Pyx_GetItemInt_List(__pyx_v_r, __pyx_v_i, Py_ssize_t, 1, PyInt_FromSsize_t, 1, 1, 1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1487, __pyx_L7_error)
      __Pyx_GOTREF(__pyx_t_6);
      (__pyx_v_rs[__pyx_v_i]) = (&((struct PyGpuArrayObject *)__pyx_t_6)->ga);
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    }

    /* "pygpu/gpuarray.pyx":1488
 *             r[i] = new_GpuArray(type(a), a.context, a.base)
 *             rs[i] = &(<GpuArray>r[i]).ga
 *         for i in range(len(ind)):             # <<<<<<<<<<<<<<
 *             v = ind[i]
 *             # cap the values to the end of the array
 */
    __pyx_t_1 = PyObject_Length(__pyx_v_ind); if (unlikely(__pyx_t_1 == ((Py_ssize_t)-1))) __PYX_ERR(0, 1488, __pyx_L7_error)
    for (__pyx_t_4 = 0; __pyx_t_4 < __pyx_t_1; __pyx_t_4+=1) {
      __pyx_v_i = __pyx_t_4;

      /* "pygpu/gpuarray.pyx":1489
 *             rs[i] = &(<GpuArray>r[i]).ga
 *         for i in range(len(ind)):
 *             v = ind[i]             # <<<<<<<<<<<<<<
 *             # cap the values to the end of the array
 *             p[i] = v if v < m else m
 */
      __pyx_t_6 = __Pyx_GetItemInt(__pyx_v_ind, __pyx_v_i, Py_ssize_t, 1, PyInt_FromSsize_t, 0, 1, 1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1489, __pyx_L7_error)
      __Pyx_GOTREF(__pyx_t_6);
      __pyx_t_7 = __Pyx_PyInt_As_size_t(__pyx_t_6); if (unlikely((__pyx_t_7 == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 1489, __pyx_L7_error)
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __pyx_v_v = __pyx_t_7;

      /* "pygpu/gpuarray.pyx":1491
 *             v = ind[i]
 *             # cap the values to the end of the array
 *             p[i] = v if v < m else m             # <<<<<<<<<<<<<<
 *         array_split(rs, a, len(ind), p, axis)
 *         return r
 */
      if (((__pyx_v_v < __pyx_v_m) != 0)) {
        __pyx_t_7 = __pyx_v_v;
      } else {
        __pyx_t_7 = __pyx_v_m;
      }
      (__pyx_v_p[__pyx_v_i]) = __pyx_t_7;
    }

    /* "pygpu/gpuarray.pyx":1492
 *             # cap the values to the end of the array
 *             p[i] = v if v < m else m
 *         array_split(rs, a, len(ind), p, axis)             # <<<<<<<<<<<<<<
 *         return r
 *     finally:
 */
    __pyx_t_1 = PyObject_Length(__pyx_v_ind); if (unlikely(__pyx_t_1 == ((Py_ssize_t)-1))) __PYX_ERR(0, 1492, __pyx_L7_error)
    __pyx_t_8 = __pyx_f_5pygpu_8gpuarray_array_split(__pyx_v_rs, __pyx_v_a, __pyx_t_1, __pyx_v_p, __pyx_v_axis); if (unlikely(__pyx_t_8 == ((int)-1))) __PYX_ERR(0, 1492, __pyx_L7_error)

    /* "pygpu/gpuarray.pyx":1493
 *             p[i] = v if v < m else m
 *         array_split(rs, a, len(ind), p, axis)
 *         return r             # <<<<<<<<<<<<<<
 *     finally:
 *         PyMem_Free(p)
 */
    __Pyx_XDECREF(__pyx_r);
    __Pyx_INCREF(__pyx_v_r);
    __pyx_r = __pyx_v_r;
    goto __pyx_L6_return;
  }

  /* "pygpu/gpuarray.pyx":1495
 *         return r
 *     finally:
 *         PyMem_Free(p)             # <<<<<<<<<<<<<<
 *         PyMem_Free(rs)
 * 
 */
  /*finally:*/ {
    __pyx_L7_error:;
    /*exception exit:*/{
      __Pyx_PyThreadState_declare
      __Pyx_PyThreadState_assign
      __pyx_t_11 = 0; __pyx_t_12 = 0; __pyx_t_13 = 0; __pyx_t_14 = 0; __pyx_t_15 = 0; __pyx_t_16 = 0;
      __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
      __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
      __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
      if (PY_MAJOR_VERSION >= 3) __Pyx_ExceptionSwap(&__pyx_t_14, &__pyx_t_15, &__pyx_t_16);
      if ((PY_MAJOR_VERSION < 3) || unlikely(__Pyx_GetException(&__pyx_t_11, &__pyx_t_12, &__pyx_t_13) < 0)) __Pyx_ErrFetch(&__pyx_t_11, &__pyx_t_12, &__pyx_t_13);
      __Pyx_XGOTREF(__pyx_t_11);
      __Pyx_XGOTREF(__pyx_t_12);
      __Pyx_XGOTREF(__pyx_t_13);
      __Pyx_XGOTREF(__pyx_t_14);
      __Pyx_XGOTREF(__pyx_t_15);
      __Pyx_XGOTREF(__pyx_t_16);
      __pyx_t_8 = __pyx_lineno; __pyx_t_9 = __pyx_clineno; __pyx_t_10 = __pyx_filename;
      {
        PyMem_Free(__pyx_v_p);

        /* "pygpu/gpuarray.pyx":1496
 *     finally:
 *         PyMem_Free(p)
 *         PyMem_Free(rs)             # <<<<<<<<<<<<<<
 * 
 * cdef GpuArray pygpu_concatenate(const _GpuArray **a, size_t n,
 */
        PyMem_Free(__pyx_v_rs);
      }
      if (PY_MAJOR_VERSION >= 3) {
        __Pyx_XGIVEREF(__pyx_t_14);
        __Pyx_XGIVEREF(__pyx_t_15);
        __Pyx_XGIVEREF(__pyx_t_16);
        __Pyx_ExceptionReset(__pyx_t_14, __pyx_t_15, __pyx_t_16);
      }
      __Pyx_XGIVEREF(__pyx_t_11);
      __Pyx_XGIVEREF(__pyx_t_12);
      __Pyx_XGIVEREF(__pyx_t_13);
      __Pyx_ErrRestore(__pyx_t_11, __pyx_t_12, __pyx_t_13);
      __pyx_t_11 = 0; __pyx_t_12 = 0; __pyx_t_13 = 0; __pyx_t_14 = 0; __pyx_t_15 = 0; __pyx_t_16 = 0;
      __pyx_lineno = __pyx_t_8; __pyx_clineno = __pyx_t_9; __pyx_filename = __pyx_t_10;
      goto __pyx_L1_error;
    }
    __pyx_L6_return: {
      __pyx_t_16 = __pyx_r;
      __pyx_r = 0;

      /* "pygpu/gpuarray.pyx":1495
 *         return r
 *     finally:
 *         PyMem_Free(p)             # <<<<<<<<<<<<<<
 *         PyMem_Free(rs)
 * 
 */
      PyMem_Free(__pyx_v_p);

      /* "pygpu/gpuarray.pyx":1496
 *     finally:
 *         PyMem_Free(p)
 *         PyMem_Free(rs)             # <<<<<<<<<<<<<<
 * 
 * cdef GpuArray pygpu_concatenate(const _GpuArray **a, size_t n,
 */
      PyMem_Free(__pyx_v_rs);
      __pyx_r = __pyx_t_16;
      __pyx_t_16 = 0;
      goto __pyx_L0;
    }
  }

  /* "pygpu/gpuarray.pyx":1467
 *     return 0
 * 
 * def _split(GpuArray a, ind, unsigned int axis):             # <<<<<<<<<<<<<<
 *     """
 *     _split(a, ind, axis)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_AddTraceback("pygpu.gpuarray._split", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_r);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":1498
 *         PyMem_Free(rs)
 * 
 * cdef GpuArray pygpu_concatenate(const _GpuArray **a, size_t n,             # <<<<<<<<<<<<<<
 *                                 unsigned int axis, int restype,
 *                                 object cls, GpuContext context):
 */

static struct PyGpuArrayObject *__pyx_f_5pygpu_8gpuarray_pygpu_concatenate(GpuArray const **__pyx_v_a, size_t __pyx_v_n, unsigned int __pyx_v_axis, int __pyx_v_restype, PyObject *__pyx_v_cls, struct PyGpuContextObject *__pyx_v_context) {
  PyObject *__pyx_v_res = 0;
  struct PyGpuArrayObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_t_2;
  __Pyx_RefNannySetupContext("pygpu_concatenate", 0);

  /* "pygpu/gpuarray.pyx":1501
 *                                 unsigned int axis, int restype,
 *                                 object cls, GpuContext context):
 *     cdef res = new_GpuArray(cls, context, None)             # <<<<<<<<<<<<<<
 *     array_concatenate(res, a, n, axis, restype)
 *     return res
 */
  __pyx_t_1 = ((PyObject *)__pyx_f_5pygpu_8gpuarray_new_GpuArray(__pyx_v_cls, __pyx_v_context, Py_None)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1501, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_v_res = __pyx_t_1;
  __pyx_t_1 = 0;

  /* "pygpu/gpuarray.pyx":1502
 *                                 object cls, GpuContext context):
 *     cdef res = new_GpuArray(cls, context, None)
 *     array_concatenate(res, a, n, axis, restype)             # <<<<<<<<<<<<<<
 *     return res
 * 
 */
  if (!(likely(((__pyx_v_res) == Py_None) || likely(__Pyx_TypeTest(__pyx_v_res, __pyx_ptype_5pygpu_8gpuarray_GpuArray))))) __PYX_ERR(0, 1502, __pyx_L1_error)
  __pyx_t_2 = __pyx_f_5pygpu_8gpuarray_array_concatenate(((struct PyGpuArrayObject *)__pyx_v_res), __pyx_v_a, __pyx_v_n, __pyx_v_axis, __pyx_v_restype); if (unlikely(__pyx_t_2 == ((int)-1))) __PYX_ERR(0, 1502, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":1503
 *     cdef res = new_GpuArray(cls, context, None)
 *     array_concatenate(res, a, n, axis, restype)
 *     return res             # <<<<<<<<<<<<<<
 * 
 * def _concatenate(list al, unsigned int axis, int restype, object cls,
 */
  __Pyx_XDECREF(((PyObject *)__pyx_r));
  if (!(likely(((__pyx_v_res) == Py_None) || likely(__Pyx_TypeTest(__pyx_v_res, __pyx_ptype_5pygpu_8gpuarray_GpuArray))))) __PYX_ERR(0, 1503, __pyx_L1_error)
  __Pyx_INCREF(__pyx_v_res);
  __pyx_r = ((struct PyGpuArrayObject *)__pyx_v_res);
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":1498
 *         PyMem_Free(rs)
 * 
 * cdef GpuArray pygpu_concatenate(const _GpuArray **a, size_t n,             # <<<<<<<<<<<<<<
 *                                 unsigned int axis, int restype,
 *                                 object cls, GpuContext context):
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("pygpu.gpuarray.pygpu_concatenate", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_res);
  __Pyx_XGIVEREF((PyObject *)__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":1505
 *     return res
 * 
 * def _concatenate(list al, unsigned int axis, int restype, object cls,             # <<<<<<<<<<<<<<
 *                  GpuContext context):
 *     """
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_43_concatenate(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static char __pyx_doc_5pygpu_8gpuarray_42_concatenate[] = "\n    _concatenate(al, axis, restype, cls, context)\n    ";
static PyMethodDef __pyx_mdef_5pygpu_8gpuarray_43_concatenate = {"_concatenate", (PyCFunction)__pyx_pw_5pygpu_8gpuarray_43_concatenate, METH_VARARGS|METH_KEYWORDS, __pyx_doc_5pygpu_8gpuarray_42_concatenate};
static PyObject *__pyx_pw_5pygpu_8gpuarray_43_concatenate(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_al = 0;
  unsigned int __pyx_v_axis;
  int __pyx_v_restype;
  PyObject *__pyx_v_cls = 0;
  struct PyGpuContextObject *__pyx_v_context = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("_concatenate (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_al,&__pyx_n_s_axis,&__pyx_n_s_restype,&__pyx_n_s_cls,&__pyx_n_s_context,0};
    PyObject* values[5] = {0,0,0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
        CYTHON_FALLTHROUGH;
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_al)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_axis)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("_concatenate", 1, 5, 5, 1); __PYX_ERR(0, 1505, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_restype)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("_concatenate", 1, 5, 5, 2); __PYX_ERR(0, 1505, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  3:
        if (likely((values[3] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_cls)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("_concatenate", 1, 5, 5, 3); __PYX_ERR(0, 1505, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  4:
        if (likely((values[4] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_context)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("_concatenate", 1, 5, 5, 4); __PYX_ERR(0, 1505, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "_concatenate") < 0)) __PYX_ERR(0, 1505, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 5) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
      values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
      values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
    }
    __pyx_v_al = ((PyObject*)values[0]);
    __pyx_v_axis = __Pyx_PyInt_As_unsigned_int(values[1]); if (unlikely((__pyx_v_axis == (unsigned int)-1) && PyErr_Occurred())) __PYX_ERR(0, 1505, __pyx_L3_error)
    __pyx_v_restype = __Pyx_PyInt_As_int(values[2]); if (unlikely((__pyx_v_restype == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 1505, __pyx_L3_error)
    __pyx_v_cls = values[3];
    __pyx_v_context = ((struct PyGpuContextObject *)values[4]);
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("_concatenate", 1, 5, 5, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 1505, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("pygpu.gpuarray._concatenate", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_al), (&PyList_Type), 1, "al", 1))) __PYX_ERR(0, 1505, __pyx_L1_error)
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_context), __pyx_ptype_5pygpu_8gpuarray_GpuContext, 1, "context", 0))) __PYX_ERR(0, 1506, __pyx_L1_error)
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_42_concatenate(__pyx_self, __pyx_v_al, __pyx_v_axis, __pyx_v_restype, __pyx_v_cls, __pyx_v_context);

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_42_concatenate(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_al, unsigned int __pyx_v_axis, int __pyx_v_restype, PyObject *__pyx_v_cls, struct PyGpuContextObject *__pyx_v_context) {
  Py_ssize_t __pyx_v_i;
  GpuArray const **__pyx_v_als;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  Py_ssize_t __pyx_t_2;
  int __pyx_t_3;
  Py_ssize_t __pyx_t_4;
  int __pyx_t_5;
  int __pyx_t_6;
  int __pyx_t_7;
  char const *__pyx_t_8;
  PyObject *__pyx_t_9 = NULL;
  PyObject *__pyx_t_10 = NULL;
  PyObject *__pyx_t_11 = NULL;
  PyObject *__pyx_t_12 = NULL;
  PyObject *__pyx_t_13 = NULL;
  PyObject *__pyx_t_14 = NULL;
  __Pyx_RefNannySetupContext("_concatenate", 0);
  __Pyx_INCREF((PyObject *)__pyx_v_context);

  /* "pygpu/gpuarray.pyx":1511
 *     """
 *     cdef Py_ssize_t i
 *     context = ensure_context(context)             # <<<<<<<<<<<<<<
 *     cdef const _GpuArray **als = <const _GpuArray **>PyMem_Malloc(sizeof(_GpuArray *) * len(al))
 *     if als == NULL:
 */
  __pyx_t_1 = ((PyObject *)__pyx_f_5pygpu_8gpuarray_ensure_context(__pyx_v_context)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1511, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF_SET(__pyx_v_context, ((struct PyGpuContextObject *)__pyx_t_1));
  __pyx_t_1 = 0;

  /* "pygpu/gpuarray.pyx":1512
 *     cdef Py_ssize_t i
 *     context = ensure_context(context)
 *     cdef const _GpuArray **als = <const _GpuArray **>PyMem_Malloc(sizeof(_GpuArray *) * len(al))             # <<<<<<<<<<<<<<
 *     if als == NULL:
 *         raise MemoryError()
 */
  if (unlikely(__pyx_v_al == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "object of type 'NoneType' has no len()");
    __PYX_ERR(0, 1512, __pyx_L1_error)
  }
  __pyx_t_2 = PyList_GET_SIZE(__pyx_v_al); if (unlikely(__pyx_t_2 == ((Py_ssize_t)-1))) __PYX_ERR(0, 1512, __pyx_L1_error)
  __pyx_v_als = ((GpuArray const **)PyMem_Malloc(((sizeof(GpuArray *)) * __pyx_t_2)));

  /* "pygpu/gpuarray.pyx":1513
 *     context = ensure_context(context)
 *     cdef const _GpuArray **als = <const _GpuArray **>PyMem_Malloc(sizeof(_GpuArray *) * len(al))
 *     if als == NULL:             # <<<<<<<<<<<<<<
 *         raise MemoryError()
 *     try:
 */
  __pyx_t_3 = ((__pyx_v_als == NULL) != 0);
  if (__pyx_t_3) {

    /* "pygpu/gpuarray.pyx":1514
 *     cdef const _GpuArray **als = <const _GpuArray **>PyMem_Malloc(sizeof(_GpuArray *) * len(al))
 *     if als == NULL:
 *         raise MemoryError()             # <<<<<<<<<<<<<<
 *     try:
 *         for i in range(len(al)):
 */
    PyErr_NoMemory(); __PYX_ERR(0, 1514, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":1513
 *     context = ensure_context(context)
 *     cdef const _GpuArray **als = <const _GpuArray **>PyMem_Malloc(sizeof(_GpuArray *) * len(al))
 *     if als == NULL:             # <<<<<<<<<<<<<<
 *         raise MemoryError()
 *     try:
 */
  }

  /* "pygpu/gpuarray.pyx":1515
 *     if als == NULL:
 *         raise MemoryError()
 *     try:             # <<<<<<<<<<<<<<
 *         for i in range(len(al)):
 *             if not isinstance(al[i], GpuArray):
 */
  /*try:*/ {

    /* "pygpu/gpuarray.pyx":1516
 *         raise MemoryError()
 *     try:
 *         for i in range(len(al)):             # <<<<<<<<<<<<<<
 *             if not isinstance(al[i], GpuArray):
 *                 raise TypeError, "expected GpuArrays to concatenate"
 */
    if (unlikely(__pyx_v_al == Py_None)) {
      PyErr_SetString(PyExc_TypeError, "object of type 'NoneType' has no len()");
      __PYX_ERR(0, 1516, __pyx_L5_error)
    }
    __pyx_t_2 = PyList_GET_SIZE(__pyx_v_al); if (unlikely(__pyx_t_2 == ((Py_ssize_t)-1))) __PYX_ERR(0, 1516, __pyx_L5_error)
    for (__pyx_t_4 = 0; __pyx_t_4 < __pyx_t_2; __pyx_t_4+=1) {
      __pyx_v_i = __pyx_t_4;

      /* "pygpu/gpuarray.pyx":1517
 *     try:
 *         for i in range(len(al)):
 *             if not isinstance(al[i], GpuArray):             # <<<<<<<<<<<<<<
 *                 raise TypeError, "expected GpuArrays to concatenate"
 *             als[i] = &(<GpuArray>al[i]).ga
 */
      if (unlikely(__pyx_v_al == Py_None)) {
        PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
        __PYX_ERR(0, 1517, __pyx_L5_error)
      }
      __pyx_t_1 = __Pyx_GetItemInt_List(__pyx_v_al, __pyx_v_i, Py_ssize_t, 1, PyInt_FromSsize_t, 1, 1, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1517, __pyx_L5_error)
      __Pyx_GOTREF(__pyx_t_1);
      __pyx_t_3 = __Pyx_TypeCheck(__pyx_t_1, __pyx_ptype_5pygpu_8gpuarray_GpuArray); 
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __pyx_t_5 = ((!(__pyx_t_3 != 0)) != 0);
      if (__pyx_t_5) {

        /* "pygpu/gpuarray.pyx":1518
 *         for i in range(len(al)):
 *             if not isinstance(al[i], GpuArray):
 *                 raise TypeError, "expected GpuArrays to concatenate"             # <<<<<<<<<<<<<<
 *             als[i] = &(<GpuArray>al[i]).ga
 *         return pygpu_concatenate(als, len(al), axis, restype, cls, context)
 */
        __Pyx_Raise(__pyx_builtin_TypeError, __pyx_kp_s_expected_GpuArrays_to_concatenat, 0, 0);
        __PYX_ERR(0, 1518, __pyx_L5_error)

        /* "pygpu/gpuarray.pyx":1517
 *     try:
 *         for i in range(len(al)):
 *             if not isinstance(al[i], GpuArray):             # <<<<<<<<<<<<<<
 *                 raise TypeError, "expected GpuArrays to concatenate"
 *             als[i] = &(<GpuArray>al[i]).ga
 */
      }

      /* "pygpu/gpuarray.pyx":1519
 *             if not isinstance(al[i], GpuArray):
 *                 raise TypeError, "expected GpuArrays to concatenate"
 *             als[i] = &(<GpuArray>al[i]).ga             # <<<<<<<<<<<<<<
 *         return pygpu_concatenate(als, len(al), axis, restype, cls, context)
 *     finally:
 */
      if (unlikely(__pyx_v_al == Py_None)) {
        PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
        __PYX_ERR(0, 1519, __pyx_L5_error)
      }
      __pyx_t_1 = __Pyx_GetItemInt_List(__pyx_v_al, __pyx_v_i, Py_ssize_t, 1, PyInt_FromSsize_t, 1, 1, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1519, __pyx_L5_error)
      __Pyx_GOTREF(__pyx_t_1);
      (__pyx_v_als[__pyx_v_i]) = (&((struct PyGpuArrayObject *)__pyx_t_1)->ga);
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    }

    /* "pygpu/gpuarray.pyx":1520
 *                 raise TypeError, "expected GpuArrays to concatenate"
 *             als[i] = &(<GpuArray>al[i]).ga
 *         return pygpu_concatenate(als, len(al), axis, restype, cls, context)             # <<<<<<<<<<<<<<
 *     finally:
 *         PyMem_Free(als)
 */
    __Pyx_XDECREF(__pyx_r);
    if (unlikely(__pyx_v_al == Py_None)) {
      PyErr_SetString(PyExc_TypeError, "object of type 'NoneType' has no len()");
      __PYX_ERR(0, 1520, __pyx_L5_error)
    }
    __pyx_t_2 = PyList_GET_SIZE(__pyx_v_al); if (unlikely(__pyx_t_2 == ((Py_ssize_t)-1))) __PYX_ERR(0, 1520, __pyx_L5_error)
    __pyx_t_1 = ((PyObject *)__pyx_f_5pygpu_8gpuarray_pygpu_concatenate(__pyx_v_als, __pyx_t_2, __pyx_v_axis, __pyx_v_restype, __pyx_v_cls, __pyx_v_context)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1520, __pyx_L5_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_r = __pyx_t_1;
    __pyx_t_1 = 0;
    goto __pyx_L4_return;
  }

  /* "pygpu/gpuarray.pyx":1522
 *         return pygpu_concatenate(als, len(al), axis, restype, cls, context)
 *     finally:
 *         PyMem_Free(als)             # <<<<<<<<<<<<<<
 * 
 * cdef int (*cuda_get_ipc_handle)(gpudata *, GpuArrayIpcMemHandle *)
 */
  /*finally:*/ {
    __pyx_L5_error:;
    /*exception exit:*/{
      __Pyx_PyThreadState_declare
      __Pyx_PyThreadState_assign
      __pyx_t_9 = 0; __pyx_t_10 = 0; __pyx_t_11 = 0; __pyx_t_12 = 0; __pyx_t_13 = 0; __pyx_t_14 = 0;
      __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
      if (PY_MAJOR_VERSION >= 3) __Pyx_ExceptionSwap(&__pyx_t_12, &__pyx_t_13, &__pyx_t_14);
      if ((PY_MAJOR_VERSION < 3) || unlikely(__Pyx_GetException(&__pyx_t_9, &__pyx_t_10, &__pyx_t_11) < 0)) __Pyx_ErrFetch(&__pyx_t_9, &__pyx_t_10, &__pyx_t_11);
      __Pyx_XGOTREF(__pyx_t_9);
      __Pyx_XGOTREF(__pyx_t_10);
      __Pyx_XGOTREF(__pyx_t_11);
      __Pyx_XGOTREF(__pyx_t_12);
      __Pyx_XGOTREF(__pyx_t_13);
      __Pyx_XGOTREF(__pyx_t_14);
      __pyx_t_6 = __pyx_lineno; __pyx_t_7 = __pyx_clineno; __pyx_t_8 = __pyx_filename;
      {
        PyMem_Free(__pyx_v_als);
      }
      if (PY_MAJOR_VERSION >= 3) {
        __Pyx_XGIVEREF(__pyx_t_12);
        __Pyx_XGIVEREF(__pyx_t_13);
        __Pyx_XGIVEREF(__pyx_t_14);
        __Pyx_ExceptionReset(__pyx_t_12, __pyx_t_13, __pyx_t_14);
      }
      __Pyx_XGIVEREF(__pyx_t_9);
      __Pyx_XGIVEREF(__pyx_t_10);
      __Pyx_XGIVEREF(__pyx_t_11);
      __Pyx_ErrRestore(__pyx_t_9, __pyx_t_10, __pyx_t_11);
      __pyx_t_9 = 0; __pyx_t_10 = 0; __pyx_t_11 = 0; __pyx_t_12 = 0; __pyx_t_13 = 0; __pyx_t_14 = 0;
      __pyx_lineno = __pyx_t_6; __pyx_clineno = __pyx_t_7; __pyx_filename = __pyx_t_8;
      goto __pyx_L1_error;
    }
    __pyx_L4_return: {
      __pyx_t_14 = __pyx_r;
      __pyx_r = 0;
      PyMem_Free(__pyx_v_als);
      __pyx_r = __pyx_t_14;
      __pyx_t_14 = 0;
      goto __pyx_L0;
    }
  }

  /* "pygpu/gpuarray.pyx":1505
 *     return res
 * 
 * def _concatenate(list al, unsigned int axis, int restype, object cls,             # <<<<<<<<<<<<<<
 *                  GpuContext context):
 *     """
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("pygpu.gpuarray._concatenate", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_context);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":1530
 * cuda_open_ipc_handle = <gpudata *(*)(gpucontext *, GpuArrayIpcMemHandle *, size_t)>gpuarray_get_extension("cuda_open_ipc_handle")
 * 
 * def open_ipc_handle(GpuContext c, bytes hpy, size_t l):             # <<<<<<<<<<<<<<
 *     """
 *     open_ipc_handle(c, hpy, l)
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_45open_ipc_handle(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static char __pyx_doc_5pygpu_8gpuarray_44open_ipc_handle[] = "\n    open_ipc_handle(c, hpy, l)\n\n    Open an IPC handle to get a new GpuArray from it.\n\n    Parameters\n    ----------\n    c: GpuContext\n        context\n    hpy: bytes\n        binary handle data received\n    l: int\n        size of the referred memory block\n\n    ";
static PyMethodDef __pyx_mdef_5pygpu_8gpuarray_45open_ipc_handle = {"open_ipc_handle", (PyCFunction)__pyx_pw_5pygpu_8gpuarray_45open_ipc_handle, METH_VARARGS|METH_KEYWORDS, __pyx_doc_5pygpu_8gpuarray_44open_ipc_handle};
static PyObject *__pyx_pw_5pygpu_8gpuarray_45open_ipc_handle(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  struct PyGpuContextObject *__pyx_v_c = 0;
  PyObject *__pyx_v_hpy = 0;
  size_t __pyx_v_l;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("open_ipc_handle (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_c,&__pyx_n_s_hpy,&__pyx_n_s_l,0};
    PyObject* values[3] = {0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_c)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_hpy)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("open_ipc_handle", 1, 3, 3, 1); __PYX_ERR(0, 1530, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_l)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("open_ipc_handle", 1, 3, 3, 2); __PYX_ERR(0, 1530, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "open_ipc_handle") < 0)) __PYX_ERR(0, 1530, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 3) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
    }
    __pyx_v_c = ((struct PyGpuContextObject *)values[0]);
    __pyx_v_hpy = ((PyObject*)values[1]);
    __pyx_v_l = __Pyx_PyInt_As_size_t(values[2]); if (unlikely((__pyx_v_l == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 1530, __pyx_L3_error)
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("open_ipc_handle", 1, 3, 3, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 1530, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("pygpu.gpuarray.open_ipc_handle", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_c), __pyx_ptype_5pygpu_8gpuarray_GpuContext, 1, "c", 0))) __PYX_ERR(0, 1530, __pyx_L1_error)
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_hpy), (&PyBytes_Type), 1, "hpy", 1))) __PYX_ERR(0, 1530, __pyx_L1_error)
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_44open_ipc_handle(__pyx_self, __pyx_v_c, __pyx_v_hpy, __pyx_v_l);

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_44open_ipc_handle(CYTHON_UNUSED PyObject *__pyx_self, struct PyGpuContextObject *__pyx_v_c, PyObject *__pyx_v_hpy, size_t __pyx_v_l) {
  char *__pyx_v_b;
  GpuArrayIpcMemHandle __pyx_v_h;
  gpudata *__pyx_v_d;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  char *__pyx_t_1;
  int __pyx_t_2;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  __Pyx_RefNannySetupContext("open_ipc_handle", 0);

  /* "pygpu/gpuarray.pyx":1550
 *     cdef gpudata *d
 * 
 *     b = hpy             # <<<<<<<<<<<<<<
 *     memcpy(&h, b, sizeof(h))
 * 
 */
  if (unlikely(__pyx_v_hpy == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "expected bytes, NoneType found");
    __PYX_ERR(0, 1550, __pyx_L1_error)
  }
  __pyx_t_1 = __Pyx_PyBytes_AsWritableString(__pyx_v_hpy); if (unlikely((!__pyx_t_1) && PyErr_Occurred())) __PYX_ERR(0, 1550, __pyx_L1_error)
  __pyx_v_b = __pyx_t_1;

  /* "pygpu/gpuarray.pyx":1551
 * 
 *     b = hpy
 *     memcpy(&h, b, sizeof(h))             # <<<<<<<<<<<<<<
 * 
 *     d = cuda_open_ipc_handle(c.ctx, &h, l)
 */
  memcpy((&__pyx_v_h), __pyx_v_b, (sizeof(__pyx_v_h)));

  /* "pygpu/gpuarray.pyx":1553
 *     memcpy(&h, b, sizeof(h))
 * 
 *     d = cuda_open_ipc_handle(c.ctx, &h, l)             # <<<<<<<<<<<<<<
 *     if d is NULL:
 *         raise GpuArrayException, gpucontext_error(c.ctx, 0)
 */
  __pyx_v_d = __pyx_v_5pygpu_8gpuarray_cuda_open_ipc_handle(__pyx_v_c->ctx, (&__pyx_v_h), __pyx_v_l);

  /* "pygpu/gpuarray.pyx":1554
 * 
 *     d = cuda_open_ipc_handle(c.ctx, &h, l)
 *     if d is NULL:             # <<<<<<<<<<<<<<
 *         raise GpuArrayException, gpucontext_error(c.ctx, 0)
 *     return <size_t>d
 */
  __pyx_t_2 = ((__pyx_v_d == NULL) != 0);
  if (__pyx_t_2) {

    /* "pygpu/gpuarray.pyx":1555
 *     d = cuda_open_ipc_handle(c.ctx, &h, l)
 *     if d is NULL:
 *         raise GpuArrayException, gpucontext_error(c.ctx, 0)             # <<<<<<<<<<<<<<
 *     return <size_t>d
 * 
 */
    __pyx_t_3 = __Pyx_GetModuleGlobalName(__pyx_n_s_GpuArrayException); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1555, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_4 = __Pyx_PyBytes_FromString(gpucontext_error(__pyx_v_c->ctx, 0)); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1555, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_Raise(__pyx_t_3, __pyx_t_4, 0, 0);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __PYX_ERR(0, 1555, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":1554
 * 
 *     d = cuda_open_ipc_handle(c.ctx, &h, l)
 *     if d is NULL:             # <<<<<<<<<<<<<<
 *         raise GpuArrayException, gpucontext_error(c.ctx, 0)
 *     return <size_t>d
 */
  }

  /* "pygpu/gpuarray.pyx":1556
 *     if d is NULL:
 *         raise GpuArrayException, gpucontext_error(c.ctx, 0)
 *     return <size_t>d             # <<<<<<<<<<<<<<
 * 
 * cdef class GpuArray:
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_4 = __Pyx_PyInt_FromSize_t(((size_t)__pyx_v_d)); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1556, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_r = __pyx_t_4;
  __pyx_t_4 = 0;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":1530
 * cuda_open_ipc_handle = <gpudata *(*)(gpucontext *, GpuArrayIpcMemHandle *, size_t)>gpuarray_get_extension("cuda_open_ipc_handle")
 * 
 * def open_ipc_handle(GpuContext c, bytes hpy, size_t l):             # <<<<<<<<<<<<<<
 *     """
 *     open_ipc_handle(c, hpy, l)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_AddTraceback("pygpu.gpuarray.open_ipc_handle", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":1577
 *     interpreter.
 *     """
 *     def __dealloc__(self):             # <<<<<<<<<<<<<<
 *         array_clear(self)
 * 
 */

/* Python wrapper */
static void __pyx_pw_5pygpu_8gpuarray_8GpuArray_1__dealloc__(PyObject *__pyx_v_self); /*proto*/
static void __pyx_pw_5pygpu_8gpuarray_8GpuArray_1__dealloc__(PyObject *__pyx_v_self) {
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__dealloc__ (wrapper)", 0);
  __pyx_pf_5pygpu_8gpuarray_8GpuArray___dealloc__(((struct PyGpuArrayObject *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
}

static void __pyx_pf_5pygpu_8gpuarray_8GpuArray___dealloc__(struct PyGpuArrayObject *__pyx_v_self) {
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  __Pyx_RefNannySetupContext("__dealloc__", 0);

  /* "pygpu/gpuarray.pyx":1578
 *     """
 *     def __dealloc__(self):
 *         array_clear(self)             # <<<<<<<<<<<<<<
 * 
 *     def __cinit__(self):
 */
  __pyx_t_1 = __pyx_f_5pygpu_8gpuarray_array_clear(__pyx_v_self); if (unlikely(__pyx_t_1 == ((int)-1))) __PYX_ERR(0, 1578, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":1577
 *     interpreter.
 *     """
 *     def __dealloc__(self):             # <<<<<<<<<<<<<<
 *         array_clear(self)
 * 
 */

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_WriteUnraisable("pygpu.gpuarray.GpuArray.__dealloc__", __pyx_clineno, __pyx_lineno, __pyx_filename, 1, 0);
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
}

/* "pygpu/gpuarray.pyx":1580
 *         array_clear(self)
 * 
 *     def __cinit__(self):             # <<<<<<<<<<<<<<
 *         memset(&self.ga, 0, sizeof(_GpuArray))
 * 
 */

/* Python wrapper */
static int __pyx_pw_5pygpu_8gpuarray_8GpuArray_3__cinit__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static int __pyx_pw_5pygpu_8gpuarray_8GpuArray_3__cinit__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__cinit__ (wrapper)", 0);
  if (unlikely(PyTuple_GET_SIZE(__pyx_args) > 0)) {
    __Pyx_RaiseArgtupleInvalid("__cinit__", 1, 0, 0, PyTuple_GET_SIZE(__pyx_args)); return -1;}
  if (unlikely(__pyx_kwds) && unlikely(PyDict_Size(__pyx_kwds) > 0) && unlikely(!__Pyx_CheckKeywordStrings(__pyx_kwds, "__cinit__", 0))) return -1;
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_8GpuArray_2__cinit__(((struct PyGpuArrayObject *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_5pygpu_8gpuarray_8GpuArray_2__cinit__(struct PyGpuArrayObject *__pyx_v_self) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__cinit__", 0);

  /* "pygpu/gpuarray.pyx":1581
 * 
 *     def __cinit__(self):
 *         memset(&self.ga, 0, sizeof(_GpuArray))             # <<<<<<<<<<<<<<
 * 
 *     def __init__(self):
 */
  memset((&__pyx_v_self->ga), 0, (sizeof(GpuArray)));

  /* "pygpu/gpuarray.pyx":1580
 *         array_clear(self)
 * 
 *     def __cinit__(self):             # <<<<<<<<<<<<<<
 *         memset(&self.ga, 0, sizeof(_GpuArray))
 * 
 */

  /* function exit code */
  __pyx_r = 0;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":1583
 *         memset(&self.ga, 0, sizeof(_GpuArray))
 * 
 *     def __init__(self):             # <<<<<<<<<<<<<<
 *         if type(self) is GpuArray:
 *             raise RuntimeError, "Called raw GpuArray.__init__"
 */

/* Python wrapper */
static int __pyx_pw_5pygpu_8gpuarray_8GpuArray_5__init__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static int __pyx_pw_5pygpu_8gpuarray_8GpuArray_5__init__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__init__ (wrapper)", 0);
  if (unlikely(PyTuple_GET_SIZE(__pyx_args) > 0)) {
    __Pyx_RaiseArgtupleInvalid("__init__", 1, 0, 0, PyTuple_GET_SIZE(__pyx_args)); return -1;}
  if (unlikely(__pyx_kwds) && unlikely(PyDict_Size(__pyx_kwds) > 0) && unlikely(!__Pyx_CheckKeywordStrings(__pyx_kwds, "__init__", 0))) return -1;
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_8GpuArray_4__init__(((struct PyGpuArrayObject *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_5pygpu_8gpuarray_8GpuArray_4__init__(struct PyGpuArrayObject *__pyx_v_self) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_t_2;
  __Pyx_RefNannySetupContext("__init__", 0);

  /* "pygpu/gpuarray.pyx":1584
 * 
 *     def __init__(self):
 *         if type(self) is GpuArray:             # <<<<<<<<<<<<<<
 *             raise RuntimeError, "Called raw GpuArray.__init__"
 * 
 */
  __pyx_t_1 = (((PyObject *)Py_TYPE(((PyObject *)__pyx_v_self))) == ((PyObject *)__pyx_ptype_5pygpu_8gpuarray_GpuArray));
  __pyx_t_2 = (__pyx_t_1 != 0);
  if (__pyx_t_2) {

    /* "pygpu/gpuarray.pyx":1585
 *     def __init__(self):
 *         if type(self) is GpuArray:
 *             raise RuntimeError, "Called raw GpuArray.__init__"             # <<<<<<<<<<<<<<
 * 
 *     def __reduce__(self):
 */
    __Pyx_Raise(__pyx_builtin_RuntimeError, __pyx_kp_s_Called_raw_GpuArray___init, 0, 0);
    __PYX_ERR(0, 1585, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":1584
 * 
 *     def __init__(self):
 *         if type(self) is GpuArray:             # <<<<<<<<<<<<<<
 *             raise RuntimeError, "Called raw GpuArray.__init__"
 * 
 */
  }

  /* "pygpu/gpuarray.pyx":1583
 *         memset(&self.ga, 0, sizeof(_GpuArray))
 * 
 *     def __init__(self):             # <<<<<<<<<<<<<<
 *         if type(self) is GpuArray:
 *             raise RuntimeError, "Called raw GpuArray.__init__"
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_AddTraceback("pygpu.gpuarray.GpuArray.__init__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":1587
 *             raise RuntimeError, "Called raw GpuArray.__init__"
 * 
 *     def __reduce__(self):             # <<<<<<<<<<<<<<
 *         raise RuntimeError, "Cannot pickle GpuArray object"
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_8GpuArray_7__reduce__(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_pw_5pygpu_8gpuarray_8GpuArray_7__reduce__(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__reduce__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_8GpuArray_6__reduce__(((struct PyGpuArrayObject *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_8GpuArray_6__reduce__(CYTHON_UNUSED struct PyGpuArrayObject *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__reduce__", 0);

  /* "pygpu/gpuarray.pyx":1588
 * 
 *     def __reduce__(self):
 *         raise RuntimeError, "Cannot pickle GpuArray object"             # <<<<<<<<<<<<<<
 * 
 *     cdef __index_helper(self, key, unsigned int i, ssize_t *start,
 */
  __Pyx_Raise(__pyx_builtin_RuntimeError, __pyx_kp_s_Cannot_pickle_GpuArray_object, 0, 0);
  __PYX_ERR(0, 1588, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":1587
 *             raise RuntimeError, "Called raw GpuArray.__init__"
 * 
 *     def __reduce__(self):             # <<<<<<<<<<<<<<
 *         raise RuntimeError, "Cannot pickle GpuArray object"
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_AddTraceback("pygpu.gpuarray.GpuArray.__reduce__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":1590
 *         raise RuntimeError, "Cannot pickle GpuArray object"
 * 
 *     cdef __index_helper(self, key, unsigned int i, ssize_t *start,             # <<<<<<<<<<<<<<
 *                         ssize_t *stop, ssize_t *step):
 *         cdef Py_ssize_t dummy
 */

static PyObject *__pyx_f_5pygpu_8gpuarray_8GpuArray___index_helper(struct PyGpuArrayObject *__pyx_v_self, PyObject *__pyx_v_key, unsigned int __pyx_v_i, Py_ssize_t *__pyx_v_start, Py_ssize_t *__pyx_v_stop, Py_ssize_t *__pyx_v_step) {
  Py_ssize_t __pyx_v_dummy;
  Py_ssize_t __pyx_v_k;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  Py_ssize_t __pyx_t_5;
  int __pyx_t_6;
  int __pyx_t_7;
  PyObject *__pyx_t_8 = NULL;
  int __pyx_t_9;
  __Pyx_RefNannySetupContext("__index_helper", 0);

  /* "pygpu/gpuarray.pyx":1594
 *         cdef Py_ssize_t dummy
 *         cdef Py_ssize_t k
 *         try:             # <<<<<<<<<<<<<<
 *             k = PyNumber_Index(key)
 *             if k < 0:
 */
  {
    __Pyx_PyThreadState_declare
    __Pyx_PyThreadState_assign
    __Pyx_ExceptionSave(&__pyx_t_1, &__pyx_t_2, &__pyx_t_3);
    __Pyx_XGOTREF(__pyx_t_1);
    __Pyx_XGOTREF(__pyx_t_2);
    __Pyx_XGOTREF(__pyx_t_3);
    /*try:*/ {

      /* "pygpu/gpuarray.pyx":1595
 *         cdef Py_ssize_t k
 *         try:
 *             k = PyNumber_Index(key)             # <<<<<<<<<<<<<<
 *             if k < 0:
 *                 k += self.ga.dimensions[i]
 */
      __pyx_t_4 = PyNumber_Index(__pyx_v_key); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1595, __pyx_L3_error)
      __Pyx_GOTREF(__pyx_t_4);
      __pyx_t_5 = __Pyx_PyIndex_AsSsize_t(__pyx_t_4); if (unlikely((__pyx_t_5 == (Py_ssize_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 1595, __pyx_L3_error)
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __pyx_v_k = __pyx_t_5;

      /* "pygpu/gpuarray.pyx":1596
 *         try:
 *             k = PyNumber_Index(key)
 *             if k < 0:             # <<<<<<<<<<<<<<
 *                 k += self.ga.dimensions[i]
 *             if k < 0 or (<size_t>k) >= self.ga.dimensions[i]:
 */
      __pyx_t_6 = ((__pyx_v_k < 0) != 0);
      if (__pyx_t_6) {

        /* "pygpu/gpuarray.pyx":1597
 *             k = PyNumber_Index(key)
 *             if k < 0:
 *                 k += self.ga.dimensions[i]             # <<<<<<<<<<<<<<
 *             if k < 0 or (<size_t>k) >= self.ga.dimensions[i]:
 *                 raise IndexError, "index %d out of bounds" % (i,)
 */
        __pyx_v_k = (__pyx_v_k + (__pyx_v_self->ga.dimensions[__pyx_v_i]));

        /* "pygpu/gpuarray.pyx":1596
 *         try:
 *             k = PyNumber_Index(key)
 *             if k < 0:             # <<<<<<<<<<<<<<
 *                 k += self.ga.dimensions[i]
 *             if k < 0 or (<size_t>k) >= self.ga.dimensions[i]:
 */
      }

      /* "pygpu/gpuarray.pyx":1598
 *             if k < 0:
 *                 k += self.ga.dimensions[i]
 *             if k < 0 or (<size_t>k) >= self.ga.dimensions[i]:             # <<<<<<<<<<<<<<
 *                 raise IndexError, "index %d out of bounds" % (i,)
 *             start[0] = k
 */
      __pyx_t_7 = ((__pyx_v_k < 0) != 0);
      if (!__pyx_t_7) {
      } else {
        __pyx_t_6 = __pyx_t_7;
        goto __pyx_L11_bool_binop_done;
      }
      __pyx_t_7 = ((((size_t)__pyx_v_k) >= (__pyx_v_self->ga.dimensions[__pyx_v_i])) != 0);
      __pyx_t_6 = __pyx_t_7;
      __pyx_L11_bool_binop_done:;
      if (__pyx_t_6) {

        /* "pygpu/gpuarray.pyx":1599
 *                 k += self.ga.dimensions[i]
 *             if k < 0 or (<size_t>k) >= self.ga.dimensions[i]:
 *                 raise IndexError, "index %d out of bounds" % (i,)             # <<<<<<<<<<<<<<
 *             start[0] = k
 *             step[0] = 0
 */
        __pyx_t_4 = __Pyx_PyInt_From_unsigned_int(__pyx_v_i); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1599, __pyx_L3_error)
        __Pyx_GOTREF(__pyx_t_4);
        __pyx_t_8 = PyTuple_New(1); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1599, __pyx_L3_error)
        __Pyx_GOTREF(__pyx_t_8);
        __Pyx_GIVEREF(__pyx_t_4);
        PyTuple_SET_ITEM(__pyx_t_8, 0, __pyx_t_4);
        __pyx_t_4 = 0;
        __pyx_t_4 = __Pyx_PyString_Format(__pyx_kp_s_index_d_out_of_bounds, __pyx_t_8); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1599, __pyx_L3_error)
        __Pyx_GOTREF(__pyx_t_4);
        __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
        __Pyx_Raise(__pyx_builtin_IndexError, __pyx_t_4, 0, 0);
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
        __PYX_ERR(0, 1599, __pyx_L3_error)

        /* "pygpu/gpuarray.pyx":1598
 *             if k < 0:
 *                 k += self.ga.dimensions[i]
 *             if k < 0 or (<size_t>k) >= self.ga.dimensions[i]:             # <<<<<<<<<<<<<<
 *                 raise IndexError, "index %d out of bounds" % (i,)
 *             start[0] = k
 */
      }

      /* "pygpu/gpuarray.pyx":1600
 *             if k < 0 or (<size_t>k) >= self.ga.dimensions[i]:
 *                 raise IndexError, "index %d out of bounds" % (i,)
 *             start[0] = k             # <<<<<<<<<<<<<<
 *             step[0] = 0
 *             return
 */
      (__pyx_v_start[0]) = __pyx_v_k;

      /* "pygpu/gpuarray.pyx":1601
 *                 raise IndexError, "index %d out of bounds" % (i,)
 *             start[0] = k
 *             step[0] = 0             # <<<<<<<<<<<<<<
 *             return
 *         except TypeError:
 */
      (__pyx_v_step[0]) = 0;

      /* "pygpu/gpuarray.pyx":1602
 *             start[0] = k
 *             step[0] = 0
 *             return             # <<<<<<<<<<<<<<
 *         except TypeError:
 *             pass
 */
      __Pyx_XDECREF(__pyx_r);
      __pyx_r = Py_None; __Pyx_INCREF(Py_None);
      goto __pyx_L7_try_return;

      /* "pygpu/gpuarray.pyx":1594
 *         cdef Py_ssize_t dummy
 *         cdef Py_ssize_t k
 *         try:             # <<<<<<<<<<<<<<
 *             k = PyNumber_Index(key)
 *             if k < 0:
 */
    }
    __pyx_L3_error:;
    __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;

    /* "pygpu/gpuarray.pyx":1603
 *             step[0] = 0
 *             return
 *         except TypeError:             # <<<<<<<<<<<<<<
 *             pass
 * 
 */
    __pyx_t_9 = __Pyx_PyErr_ExceptionMatches(__pyx_builtin_TypeError);
    if (__pyx_t_9) {
      __Pyx_ErrRestore(0,0,0);
      goto __pyx_L4_exception_handled;
    }
    goto __pyx_L5_except_error;
    __pyx_L5_except_error:;

    /* "pygpu/gpuarray.pyx":1594
 *         cdef Py_ssize_t dummy
 *         cdef Py_ssize_t k
 *         try:             # <<<<<<<<<<<<<<
 *             k = PyNumber_Index(key)
 *             if k < 0:
 */
    __Pyx_XGIVEREF(__pyx_t_1);
    __Pyx_XGIVEREF(__pyx_t_2);
    __Pyx_XGIVEREF(__pyx_t_3);
    __Pyx_ExceptionReset(__pyx_t_1, __pyx_t_2, __pyx_t_3);
    goto __pyx_L1_error;
    __pyx_L7_try_return:;
    __Pyx_XGIVEREF(__pyx_t_1);
    __Pyx_XGIVEREF(__pyx_t_2);
    __Pyx_XGIVEREF(__pyx_t_3);
    __Pyx_ExceptionReset(__pyx_t_1, __pyx_t_2, __pyx_t_3);
    goto __pyx_L0;
    __pyx_L4_exception_handled:;
    __Pyx_XGIVEREF(__pyx_t_1);
    __Pyx_XGIVEREF(__pyx_t_2);
    __Pyx_XGIVEREF(__pyx_t_3);
    __Pyx_ExceptionReset(__pyx_t_1, __pyx_t_2, __pyx_t_3);
  }

  /* "pygpu/gpuarray.pyx":1606
 *             pass
 * 
 *         if isinstance(key, slice):             # <<<<<<<<<<<<<<
 *             PySlice_GetIndicesEx(key, self.ga.dimensions[i],
 *                                  start, stop, step, &dummy)
 */
  __pyx_t_6 = PySlice_Check(__pyx_v_key); 
  __pyx_t_7 = (__pyx_t_6 != 0);
  if (__pyx_t_7) {

    /* "pygpu/gpuarray.pyx":1607
 * 
 *         if isinstance(key, slice):
 *             PySlice_GetIndicesEx(key, self.ga.dimensions[i],             # <<<<<<<<<<<<<<
 *                                  start, stop, step, &dummy)
 *             if stop[0] < start[0] and step[0] > 0:
 */
    __pyx_t_9 = PySlice_GetIndicesEx(__pyx_v_key, (__pyx_v_self->ga.dimensions[__pyx_v_i]), ((Py_ssize_t *)__pyx_v_start), ((Py_ssize_t *)__pyx_v_stop), ((Py_ssize_t *)__pyx_v_step), (&__pyx_v_dummy)); if (unlikely(__pyx_t_9 == ((int)-1))) __PYX_ERR(0, 1607, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":1609
 *             PySlice_GetIndicesEx(key, self.ga.dimensions[i],
 *                                  start, stop, step, &dummy)
 *             if stop[0] < start[0] and step[0] > 0:             # <<<<<<<<<<<<<<
 *                 stop[0] = start[0]
 *         elif key is Ellipsis:
 */
    __pyx_t_6 = (((__pyx_v_stop[0]) < (__pyx_v_start[0])) != 0);
    if (__pyx_t_6) {
    } else {
      __pyx_t_7 = __pyx_t_6;
      goto __pyx_L15_bool_binop_done;
    }
    __pyx_t_6 = (((__pyx_v_step[0]) > 0) != 0);
    __pyx_t_7 = __pyx_t_6;
    __pyx_L15_bool_binop_done:;
    if (__pyx_t_7) {

      /* "pygpu/gpuarray.pyx":1610
 *                                  start, stop, step, &dummy)
 *             if stop[0] < start[0] and step[0] > 0:
 *                 stop[0] = start[0]             # <<<<<<<<<<<<<<
 *         elif key is Ellipsis:
 *             start[0] = 0
 */
      (__pyx_v_stop[0]) = (__pyx_v_start[0]);

      /* "pygpu/gpuarray.pyx":1609
 *             PySlice_GetIndicesEx(key, self.ga.dimensions[i],
 *                                  start, stop, step, &dummy)
 *             if stop[0] < start[0] and step[0] > 0:             # <<<<<<<<<<<<<<
 *                 stop[0] = start[0]
 *         elif key is Ellipsis:
 */
    }

    /* "pygpu/gpuarray.pyx":1606
 *             pass
 * 
 *         if isinstance(key, slice):             # <<<<<<<<<<<<<<
 *             PySlice_GetIndicesEx(key, self.ga.dimensions[i],
 *                                  start, stop, step, &dummy)
 */
    goto __pyx_L13;
  }

  /* "pygpu/gpuarray.pyx":1611
 *             if stop[0] < start[0] and step[0] > 0:
 *                 stop[0] = start[0]
 *         elif key is Ellipsis:             # <<<<<<<<<<<<<<
 *             start[0] = 0
 *             stop[0] = self.ga.dimensions[i]
 */
  __pyx_t_7 = (__pyx_v_key == __pyx_builtin_Ellipsis);
  __pyx_t_6 = (__pyx_t_7 != 0);
  if (__pyx_t_6) {

    /* "pygpu/gpuarray.pyx":1612
 *                 stop[0] = start[0]
 *         elif key is Ellipsis:
 *             start[0] = 0             # <<<<<<<<<<<<<<
 *             stop[0] = self.ga.dimensions[i]
 *             step[0] = 1
 */
    (__pyx_v_start[0]) = 0;

    /* "pygpu/gpuarray.pyx":1613
 *         elif key is Ellipsis:
 *             start[0] = 0
 *             stop[0] = self.ga.dimensions[i]             # <<<<<<<<<<<<<<
 *             step[0] = 1
 *         else:
 */
    (__pyx_v_stop[0]) = (__pyx_v_self->ga.dimensions[__pyx_v_i]);

    /* "pygpu/gpuarray.pyx":1614
 *             start[0] = 0
 *             stop[0] = self.ga.dimensions[i]
 *             step[0] = 1             # <<<<<<<<<<<<<<
 *         else:
 *             raise IndexError, "cannot index with: %s" % (key,)
 */
    (__pyx_v_step[0]) = 1;

    /* "pygpu/gpuarray.pyx":1611
 *             if stop[0] < start[0] and step[0] > 0:
 *                 stop[0] = start[0]
 *         elif key is Ellipsis:             # <<<<<<<<<<<<<<
 *             start[0] = 0
 *             stop[0] = self.ga.dimensions[i]
 */
    goto __pyx_L13;
  }

  /* "pygpu/gpuarray.pyx":1616
 *             step[0] = 1
 *         else:
 *             raise IndexError, "cannot index with: %s" % (key,)             # <<<<<<<<<<<<<<
 * 
 *     def write(self, np.ndarray src not None):
 */
  /*else*/ {
    __pyx_t_4 = PyTuple_New(1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1616, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_INCREF(__pyx_v_key);
    __Pyx_GIVEREF(__pyx_v_key);
    PyTuple_SET_ITEM(__pyx_t_4, 0, __pyx_v_key);
    __pyx_t_8 = __Pyx_PyString_Format(__pyx_kp_s_cannot_index_with_s, __pyx_t_4); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1616, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_Raise(__pyx_builtin_IndexError, __pyx_t_8, 0, 0);
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __PYX_ERR(0, 1616, __pyx_L1_error)
  }
  __pyx_L13:;

  /* "pygpu/gpuarray.pyx":1590
 *         raise RuntimeError, "Cannot pickle GpuArray object"
 * 
 *     cdef __index_helper(self, key, unsigned int i, ssize_t *start,             # <<<<<<<<<<<<<<
 *                         ssize_t *stop, ssize_t *step):
 *         cdef Py_ssize_t dummy
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_AddTraceback("pygpu.gpuarray.GpuArray.__index_helper", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":1618
 *             raise IndexError, "cannot index with: %s" % (key,)
 * 
 *     def write(self, np.ndarray src not None):             # <<<<<<<<<<<<<<
 *         """
 *         write(src)
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_8GpuArray_9write(PyObject *__pyx_v_self, PyObject *__pyx_v_src); /*proto*/
static char __pyx_doc_5pygpu_8gpuarray_8GpuArray_8write[] = "\n        write(src)\n\n        Writes host's Numpy array to device's GpuArray.\n\n        This method is as fast as or even faster than :ref:asarray, because it\n        skips possible allocation of a buffer in device's memory. It uses this\n        already allocated GpuArray buffer to contain `src` array from host's\n        memory. It is required though that the GpuArray and the Numpy array are\n        compatible in byte size and data type. It is also needed for the\n        GpuArray to be well behaved and contiguous. If `src` is not aligned or\n        compatible in contiguity it will be copied to a new Numpy array in order\n        to be. It is allowed for this GpuArray and `src` to have different\n        shapes.\n\n        Parameters\n        ----------\n        src: numpy.ndarray\n            source array in host\n\n        Raises\n        ------\n        ValueError\n            If this GpuArray is not compatible with `src` or if it is\n            not well behaved or contiguous.\n\n        ";
static PyObject *__pyx_pw_5pygpu_8gpuarray_8GpuArray_9write(PyObject *__pyx_v_self, PyObject *__pyx_v_src) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("write (wrapper)", 0);
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_src), __pyx_ptype_5numpy_ndarray, 0, "src", 0))) __PYX_ERR(0, 1618, __pyx_L1_error)
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_8GpuArray_8write(((struct PyGpuArrayObject *)__pyx_v_self), ((PyArrayObject *)__pyx_v_src));

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_8GpuArray_8write(struct PyGpuArrayObject *__pyx_v_self, PyArrayObject *__pyx_v_src) {
  size_t __pyx_v_npsz;
  size_t __pyx_v_sz;
  unsigned int __pyx_v_i;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  int __pyx_t_3;
  int __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  unsigned int __pyx_t_7;
  unsigned int __pyx_t_8;
  int __pyx_t_9;
  __Pyx_RefNannySetupContext("write", 0);
  __Pyx_INCREF((PyObject *)__pyx_v_src);

  /* "pygpu/gpuarray.pyx":1646
 * 
 *         """
 *         if not self.flags.behaved:             # <<<<<<<<<<<<<<
 *             raise ValueError, "Destination GpuArray is not well behaved: aligned and writeable"
 *         if self.flags.c_contiguous:
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_flags); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1646, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_behaved); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1646, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_3 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely(__pyx_t_3 < 0)) __PYX_ERR(0, 1646, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_4 = ((!__pyx_t_3) != 0);
  if (__pyx_t_4) {

    /* "pygpu/gpuarray.pyx":1647
 *         """
 *         if not self.flags.behaved:
 *             raise ValueError, "Destination GpuArray is not well behaved: aligned and writeable"             # <<<<<<<<<<<<<<
 *         if self.flags.c_contiguous:
 *             src = np.asarray(src, order='C')
 */
    __Pyx_Raise(__pyx_builtin_ValueError, __pyx_kp_s_Destination_GpuArray_is_not_well, 0, 0);
    __PYX_ERR(0, 1647, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":1646
 * 
 *         """
 *         if not self.flags.behaved:             # <<<<<<<<<<<<<<
 *             raise ValueError, "Destination GpuArray is not well behaved: aligned and writeable"
 *         if self.flags.c_contiguous:
 */
  }

  /* "pygpu/gpuarray.pyx":1648
 *         if not self.flags.behaved:
 *             raise ValueError, "Destination GpuArray is not well behaved: aligned and writeable"
 *         if self.flags.c_contiguous:             # <<<<<<<<<<<<<<
 *             src = np.asarray(src, order='C')
 *         elif self.flags.f_contiguous:
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_flags); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1648, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_c_contiguous); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1648, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_4 = __Pyx_PyObject_IsTrue(__pyx_t_1); if (unlikely(__pyx_t_4 < 0)) __PYX_ERR(0, 1648, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  if (__pyx_t_4) {

    /* "pygpu/gpuarray.pyx":1649
 *             raise ValueError, "Destination GpuArray is not well behaved: aligned and writeable"
 *         if self.flags.c_contiguous:
 *             src = np.asarray(src, order='C')             # <<<<<<<<<<<<<<
 *         elif self.flags.f_contiguous:
 *             src = np.asarray(src, order='F')
 */
    __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_np); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1649, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_asarray); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1649, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_1 = PyTuple_New(1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1649, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_INCREF(((PyObject *)__pyx_v_src));
    __Pyx_GIVEREF(((PyObject *)__pyx_v_src));
    PyTuple_SET_ITEM(__pyx_t_1, 0, ((PyObject *)__pyx_v_src));
    __pyx_t_5 = __Pyx_PyDict_NewPresized(1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 1649, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    if (PyDict_SetItem(__pyx_t_5, __pyx_n_s_order, __pyx_n_s_C) < 0) __PYX_ERR(0, 1649, __pyx_L1_error)
    __pyx_t_6 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_1, __pyx_t_5); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1649, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    if (!(likely(((__pyx_t_6) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_6, __pyx_ptype_5numpy_ndarray))))) __PYX_ERR(0, 1649, __pyx_L1_error)
    __Pyx_DECREF_SET(__pyx_v_src, ((PyArrayObject *)__pyx_t_6));
    __pyx_t_6 = 0;

    /* "pygpu/gpuarray.pyx":1648
 *         if not self.flags.behaved:
 *             raise ValueError, "Destination GpuArray is not well behaved: aligned and writeable"
 *         if self.flags.c_contiguous:             # <<<<<<<<<<<<<<
 *             src = np.asarray(src, order='C')
 *         elif self.flags.f_contiguous:
 */
    goto __pyx_L4;
  }

  /* "pygpu/gpuarray.pyx":1650
 *         if self.flags.c_contiguous:
 *             src = np.asarray(src, order='C')
 *         elif self.flags.f_contiguous:             # <<<<<<<<<<<<<<
 *             src = np.asarray(src, order='F')
 *         else:
 */
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_flags); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1650, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_6, __pyx_n_s_f_contiguous); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 1650, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_4 = __Pyx_PyObject_IsTrue(__pyx_t_5); if (unlikely(__pyx_t_4 < 0)) __PYX_ERR(0, 1650, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  if (__pyx_t_4) {

    /* "pygpu/gpuarray.pyx":1651
 *             src = np.asarray(src, order='C')
 *         elif self.flags.f_contiguous:
 *             src = np.asarray(src, order='F')             # <<<<<<<<<<<<<<
 *         else:
 *             raise ValueError, "Destination GpuArray is not contiguous"
 */
    __pyx_t_5 = __Pyx_GetModuleGlobalName(__pyx_n_s_np); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 1651, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_t_5, __pyx_n_s_asarray); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1651, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_5 = PyTuple_New(1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 1651, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_INCREF(((PyObject *)__pyx_v_src));
    __Pyx_GIVEREF(((PyObject *)__pyx_v_src));
    PyTuple_SET_ITEM(__pyx_t_5, 0, ((PyObject *)__pyx_v_src));
    __pyx_t_1 = __Pyx_PyDict_NewPresized(1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1651, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    if (PyDict_SetItem(__pyx_t_1, __pyx_n_s_order, __pyx_n_s_F) < 0) __PYX_ERR(0, 1651, __pyx_L1_error)
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_t_5, __pyx_t_1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1651, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    if (!(likely(((__pyx_t_2) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_2, __pyx_ptype_5numpy_ndarray))))) __PYX_ERR(0, 1651, __pyx_L1_error)
    __Pyx_DECREF_SET(__pyx_v_src, ((PyArrayObject *)__pyx_t_2));
    __pyx_t_2 = 0;

    /* "pygpu/gpuarray.pyx":1650
 *         if self.flags.c_contiguous:
 *             src = np.asarray(src, order='C')
 *         elif self.flags.f_contiguous:             # <<<<<<<<<<<<<<
 *             src = np.asarray(src, order='F')
 *         else:
 */
    goto __pyx_L4;
  }

  /* "pygpu/gpuarray.pyx":1653
 *             src = np.asarray(src, order='F')
 *         else:
 *             raise ValueError, "Destination GpuArray is not contiguous"             # <<<<<<<<<<<<<<
 *         if self.dtype != src.dtype:
 *             raise ValueError, "GpuArray and Numpy array do not have matching data types"
 */
  /*else*/ {
    __Pyx_Raise(__pyx_builtin_ValueError, __pyx_kp_s_Destination_GpuArray_is_not_cont, 0, 0);
    __PYX_ERR(0, 1653, __pyx_L1_error)
  }
  __pyx_L4:;

  /* "pygpu/gpuarray.pyx":1654
 *         else:
 *             raise ValueError, "Destination GpuArray is not contiguous"
 *         if self.dtype != src.dtype:             # <<<<<<<<<<<<<<
 *             raise ValueError, "GpuArray and Numpy array do not have matching data types"
 *         cdef size_t npsz = np.PyArray_NBYTES(src)
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_dtype); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1654, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_src), __pyx_n_s_dtype); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1654, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_5 = PyObject_RichCompare(__pyx_t_2, __pyx_t_1, Py_NE); __Pyx_XGOTREF(__pyx_t_5); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 1654, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_4 = __Pyx_PyObject_IsTrue(__pyx_t_5); if (unlikely(__pyx_t_4 < 0)) __PYX_ERR(0, 1654, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  if (__pyx_t_4) {

    /* "pygpu/gpuarray.pyx":1655
 *             raise ValueError, "Destination GpuArray is not contiguous"
 *         if self.dtype != src.dtype:
 *             raise ValueError, "GpuArray and Numpy array do not have matching data types"             # <<<<<<<<<<<<<<
 *         cdef size_t npsz = np.PyArray_NBYTES(src)
 *         cdef size_t sz = gpuarray_get_elsize(self.ga.typecode)
 */
    __Pyx_Raise(__pyx_builtin_ValueError, __pyx_kp_s_GpuArray_and_Numpy_array_do_not, 0, 0);
    __PYX_ERR(0, 1655, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":1654
 *         else:
 *             raise ValueError, "Destination GpuArray is not contiguous"
 *         if self.dtype != src.dtype:             # <<<<<<<<<<<<<<
 *             raise ValueError, "GpuArray and Numpy array do not have matching data types"
 *         cdef size_t npsz = np.PyArray_NBYTES(src)
 */
  }

  /* "pygpu/gpuarray.pyx":1656
 *         if self.dtype != src.dtype:
 *             raise ValueError, "GpuArray and Numpy array do not have matching data types"
 *         cdef size_t npsz = np.PyArray_NBYTES(src)             # <<<<<<<<<<<<<<
 *         cdef size_t sz = gpuarray_get_elsize(self.ga.typecode)
 *         cdef unsigned i
 */
  __pyx_v_npsz = PyArray_NBYTES(__pyx_v_src);

  /* "pygpu/gpuarray.pyx":1657
 *             raise ValueError, "GpuArray and Numpy array do not have matching data types"
 *         cdef size_t npsz = np.PyArray_NBYTES(src)
 *         cdef size_t sz = gpuarray_get_elsize(self.ga.typecode)             # <<<<<<<<<<<<<<
 *         cdef unsigned i
 *         for i in range(self.ga.nd):
 */
  __pyx_v_sz = gpuarray_get_elsize(__pyx_v_self->ga.typecode);

  /* "pygpu/gpuarray.pyx":1659
 *         cdef size_t sz = gpuarray_get_elsize(self.ga.typecode)
 *         cdef unsigned i
 *         for i in range(self.ga.nd):             # <<<<<<<<<<<<<<
 *             sz *= self.ga.dimensions[i]
 *         if sz != npsz:
 */
  __pyx_t_7 = __pyx_v_self->ga.nd;
  for (__pyx_t_8 = 0; __pyx_t_8 < __pyx_t_7; __pyx_t_8+=1) {
    __pyx_v_i = __pyx_t_8;

    /* "pygpu/gpuarray.pyx":1660
 *         cdef unsigned i
 *         for i in range(self.ga.nd):
 *             sz *= self.ga.dimensions[i]             # <<<<<<<<<<<<<<
 *         if sz != npsz:
 *             raise ValueError, "GpuArray and Numpy array do not have the same size in bytes"
 */
    __pyx_v_sz = (__pyx_v_sz * (__pyx_v_self->ga.dimensions[__pyx_v_i]));
  }

  /* "pygpu/gpuarray.pyx":1661
 *         for i in range(self.ga.nd):
 *             sz *= self.ga.dimensions[i]
 *         if sz != npsz:             # <<<<<<<<<<<<<<
 *             raise ValueError, "GpuArray and Numpy array do not have the same size in bytes"
 *         array_write(self, np.PyArray_DATA(src), sz)
 */
  __pyx_t_4 = ((__pyx_v_sz != __pyx_v_npsz) != 0);
  if (__pyx_t_4) {

    /* "pygpu/gpuarray.pyx":1662
 *             sz *= self.ga.dimensions[i]
 *         if sz != npsz:
 *             raise ValueError, "GpuArray and Numpy array do not have the same size in bytes"             # <<<<<<<<<<<<<<
 *         array_write(self, np.PyArray_DATA(src), sz)
 * 
 */
    __Pyx_Raise(__pyx_builtin_ValueError, __pyx_kp_s_GpuArray_and_Numpy_array_do_not_2, 0, 0);
    __PYX_ERR(0, 1662, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":1661
 *         for i in range(self.ga.nd):
 *             sz *= self.ga.dimensions[i]
 *         if sz != npsz:             # <<<<<<<<<<<<<<
 *             raise ValueError, "GpuArray and Numpy array do not have the same size in bytes"
 *         array_write(self, np.PyArray_DATA(src), sz)
 */
  }

  /* "pygpu/gpuarray.pyx":1663
 *         if sz != npsz:
 *             raise ValueError, "GpuArray and Numpy array do not have the same size in bytes"
 *         array_write(self, np.PyArray_DATA(src), sz)             # <<<<<<<<<<<<<<
 * 
 *     def read(self, np.ndarray dst not None):
 */
  __pyx_t_9 = __pyx_f_5pygpu_8gpuarray_array_write(__pyx_v_self, PyArray_DATA(__pyx_v_src), __pyx_v_sz); if (unlikely(__pyx_t_9 == ((int)-1))) __PYX_ERR(0, 1663, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":1618
 *             raise IndexError, "cannot index with: %s" % (key,)
 * 
 *     def write(self, np.ndarray src not None):             # <<<<<<<<<<<<<<
 *         """
 *         write(src)
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_AddTraceback("pygpu.gpuarray.GpuArray.write", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_src);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":1665
 *         array_write(self, np.PyArray_DATA(src), sz)
 * 
 *     def read(self, np.ndarray dst not None):             # <<<<<<<<<<<<<<
 *         """
 *         read(dst)
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_8GpuArray_11read(PyObject *__pyx_v_self, PyObject *__pyx_v_dst); /*proto*/
static char __pyx_doc_5pygpu_8gpuarray_8GpuArray_10read[] = "\n        read(dst)\n\n        Reads from this GpuArray into host's Numpy array.\n\n        This method is as fast as or even faster than :ref:__array__ method and\n        thus :ref:numpy.asarray. This is because it skips allocation of a new\n        buffer in host's memory to contain device's GpuArray. It uses an\n        existing Numpy ndarray as a buffer to get the GpuArray. It is required\n        though that the GpuArray and the Numpy array to be compatible in byte\n        size, contiguity and data type. It is also needed for `dst` to be\n        writeable and properly aligned in host's memory and for `self` to be\n        contiguous. It is allowed for this GpuArray and `dst` to have different\n        shapes.\n\n        Parameters\n        ----------\n        dst: numpy.ndarray\n            destination array in host\n\n        Raises\n        ------\n        ValueError\n            If this GpuArray is not compatible with `src` or if `dst`\n            is not well behaved.\n\n        ";
static PyObject *__pyx_pw_5pygpu_8gpuarray_8GpuArray_11read(PyObject *__pyx_v_self, PyObject *__pyx_v_dst) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("read (wrapper)", 0);
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_dst), __pyx_ptype_5numpy_ndarray, 0, "dst", 0))) __PYX_ERR(0, 1665, __pyx_L1_error)
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_8GpuArray_10read(((struct PyGpuArrayObject *)__pyx_v_self), ((PyArrayObject *)__pyx_v_dst));

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_8GpuArray_10read(struct PyGpuArrayObject *__pyx_v_self, PyArrayObject *__pyx_v_dst) {
  size_t __pyx_v_npsz;
  size_t __pyx_v_sz;
  unsigned int __pyx_v_i;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  unsigned int __pyx_t_6;
  unsigned int __pyx_t_7;
  int __pyx_t_8;
  __Pyx_RefNannySetupContext("read", 0);

  /* "pygpu/gpuarray.pyx":1693
 * 
 *         """
 *         if not np.PyArray_ISBEHAVED(dst):             # <<<<<<<<<<<<<<
 *             raise ValueError, "Destination Numpy array is not well behaved: aligned and writeable"
 *         if (not ((self.flags.c_contiguous and self.flags.aligned and
 */
  __pyx_t_1 = ((!(PyArray_ISBEHAVED(__pyx_v_dst) != 0)) != 0);
  if (__pyx_t_1) {

    /* "pygpu/gpuarray.pyx":1694
 *         """
 *         if not np.PyArray_ISBEHAVED(dst):
 *             raise ValueError, "Destination Numpy array is not well behaved: aligned and writeable"             # <<<<<<<<<<<<<<
 *         if (not ((self.flags.c_contiguous and self.flags.aligned and
 *                   dst.flags['C_CONTIGUOUS']) or
 */
    __Pyx_Raise(__pyx_builtin_ValueError, __pyx_kp_s_Destination_Numpy_array_is_not_w, 0, 0);
    __PYX_ERR(0, 1694, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":1693
 * 
 *         """
 *         if not np.PyArray_ISBEHAVED(dst):             # <<<<<<<<<<<<<<
 *             raise ValueError, "Destination Numpy array is not well behaved: aligned and writeable"
 *         if (not ((self.flags.c_contiguous and self.flags.aligned and
 */
  }

  /* "pygpu/gpuarray.pyx":1695
 *         if not np.PyArray_ISBEHAVED(dst):
 *             raise ValueError, "Destination Numpy array is not well behaved: aligned and writeable"
 *         if (not ((self.flags.c_contiguous and self.flags.aligned and             # <<<<<<<<<<<<<<
 *                   dst.flags['C_CONTIGUOUS']) or
 *                 (self.flags.f_contiguous and self.flags.aligned and
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_flags); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1695, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_c_contiguous); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1695, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_4 = __Pyx_PyObject_IsTrue(__pyx_t_3); if (unlikely(__pyx_t_4 < 0)) __PYX_ERR(0, 1695, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (!__pyx_t_4) {
    goto __pyx_L6_next_or;
  } else {
  }
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_flags); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1695, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_3, __pyx_n_s_aligned); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1695, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_4 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely(__pyx_t_4 < 0)) __PYX_ERR(0, 1695, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (!__pyx_t_4) {
    goto __pyx_L6_next_or;
  } else {
  }

  /* "pygpu/gpuarray.pyx":1696
 *             raise ValueError, "Destination Numpy array is not well behaved: aligned and writeable"
 *         if (not ((self.flags.c_contiguous and self.flags.aligned and
 *                   dst.flags['C_CONTIGUOUS']) or             # <<<<<<<<<<<<<<
 *                 (self.flags.f_contiguous and self.flags.aligned and
 *                  dst.flags['F_CONTIGUOUS']))):
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_dst), __pyx_n_s_flags); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1696, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = PyObject_GetItem(__pyx_t_2, __pyx_n_s_C_CONTIGUOUS); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1696, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_4 = __Pyx_PyObject_IsTrue(__pyx_t_3); if (unlikely(__pyx_t_4 < 0)) __PYX_ERR(0, 1696, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (!__pyx_t_4) {
  } else {
    __pyx_t_1 = __pyx_t_4;
    goto __pyx_L5_bool_binop_done;
  }
  __pyx_L6_next_or:;

  /* "pygpu/gpuarray.pyx":1697
 *         if (not ((self.flags.c_contiguous and self.flags.aligned and
 *                   dst.flags['C_CONTIGUOUS']) or
 *                 (self.flags.f_contiguous and self.flags.aligned and             # <<<<<<<<<<<<<<
 *                  dst.flags['F_CONTIGUOUS']))):
 *             raise ValueError, "GpuArray and Numpy array do not match in contiguity or GpuArray is not aligned"
 */
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_flags); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1697, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_3, __pyx_n_s_f_contiguous); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1697, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_4 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely(__pyx_t_4 < 0)) __PYX_ERR(0, 1697, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (__pyx_t_4) {
  } else {
    __pyx_t_1 = __pyx_t_4;
    goto __pyx_L5_bool_binop_done;
  }
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_flags); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1697, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_aligned); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1697, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_4 = __Pyx_PyObject_IsTrue(__pyx_t_3); if (unlikely(__pyx_t_4 < 0)) __PYX_ERR(0, 1697, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (__pyx_t_4) {
  } else {
    __pyx_t_1 = __pyx_t_4;
    goto __pyx_L5_bool_binop_done;
  }

  /* "pygpu/gpuarray.pyx":1698
 *                   dst.flags['C_CONTIGUOUS']) or
 *                 (self.flags.f_contiguous and self.flags.aligned and
 *                  dst.flags['F_CONTIGUOUS']))):             # <<<<<<<<<<<<<<
 *             raise ValueError, "GpuArray and Numpy array do not match in contiguity or GpuArray is not aligned"
 *         if self.dtype != dst.dtype:
 */
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_dst), __pyx_n_s_flags); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1698, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_2 = PyObject_GetItem(__pyx_t_3, __pyx_n_s_F_CONTIGUOUS); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1698, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_4 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely(__pyx_t_4 < 0)) __PYX_ERR(0, 1698, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_1 = __pyx_t_4;
  __pyx_L5_bool_binop_done:;

  /* "pygpu/gpuarray.pyx":1695
 *         if not np.PyArray_ISBEHAVED(dst):
 *             raise ValueError, "Destination Numpy array is not well behaved: aligned and writeable"
 *         if (not ((self.flags.c_contiguous and self.flags.aligned and             # <<<<<<<<<<<<<<
 *                   dst.flags['C_CONTIGUOUS']) or
 *                 (self.flags.f_contiguous and self.flags.aligned and
 */
  __pyx_t_4 = ((!__pyx_t_1) != 0);
  if (__pyx_t_4) {

    /* "pygpu/gpuarray.pyx":1699
 *                 (self.flags.f_contiguous and self.flags.aligned and
 *                  dst.flags['F_CONTIGUOUS']))):
 *             raise ValueError, "GpuArray and Numpy array do not match in contiguity or GpuArray is not aligned"             # <<<<<<<<<<<<<<
 *         if self.dtype != dst.dtype:
 *             raise ValueError, "GpuArray and Numpy array do not have matching data types"
 */
    __Pyx_Raise(__pyx_builtin_ValueError, __pyx_kp_s_GpuArray_and_Numpy_array_do_not_3, 0, 0);
    __PYX_ERR(0, 1699, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":1695
 *         if not np.PyArray_ISBEHAVED(dst):
 *             raise ValueError, "Destination Numpy array is not well behaved: aligned and writeable"
 *         if (not ((self.flags.c_contiguous and self.flags.aligned and             # <<<<<<<<<<<<<<
 *                   dst.flags['C_CONTIGUOUS']) or
 *                 (self.flags.f_contiguous and self.flags.aligned and
 */
  }

  /* "pygpu/gpuarray.pyx":1700
 *                  dst.flags['F_CONTIGUOUS']))):
 *             raise ValueError, "GpuArray and Numpy array do not match in contiguity or GpuArray is not aligned"
 *         if self.dtype != dst.dtype:             # <<<<<<<<<<<<<<
 *             raise ValueError, "GpuArray and Numpy array do not have matching data types"
 *         cdef size_t npsz = np.PyArray_NBYTES(dst)
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_dtype); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1700, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_dst), __pyx_n_s_dtype); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1700, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_5 = PyObject_RichCompare(__pyx_t_2, __pyx_t_3, Py_NE); __Pyx_XGOTREF(__pyx_t_5); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 1700, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_4 = __Pyx_PyObject_IsTrue(__pyx_t_5); if (unlikely(__pyx_t_4 < 0)) __PYX_ERR(0, 1700, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  if (__pyx_t_4) {

    /* "pygpu/gpuarray.pyx":1701
 *             raise ValueError, "GpuArray and Numpy array do not match in contiguity or GpuArray is not aligned"
 *         if self.dtype != dst.dtype:
 *             raise ValueError, "GpuArray and Numpy array do not have matching data types"             # <<<<<<<<<<<<<<
 *         cdef size_t npsz = np.PyArray_NBYTES(dst)
 *         cdef size_t sz = gpuarray_get_elsize(self.ga.typecode)
 */
    __Pyx_Raise(__pyx_builtin_ValueError, __pyx_kp_s_GpuArray_and_Numpy_array_do_not, 0, 0);
    __PYX_ERR(0, 1701, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":1700
 *                  dst.flags['F_CONTIGUOUS']))):
 *             raise ValueError, "GpuArray and Numpy array do not match in contiguity or GpuArray is not aligned"
 *         if self.dtype != dst.dtype:             # <<<<<<<<<<<<<<
 *             raise ValueError, "GpuArray and Numpy array do not have matching data types"
 *         cdef size_t npsz = np.PyArray_NBYTES(dst)
 */
  }

  /* "pygpu/gpuarray.pyx":1702
 *         if self.dtype != dst.dtype:
 *             raise ValueError, "GpuArray and Numpy array do not have matching data types"
 *         cdef size_t npsz = np.PyArray_NBYTES(dst)             # <<<<<<<<<<<<<<
 *         cdef size_t sz = gpuarray_get_elsize(self.ga.typecode)
 *         cdef unsigned i
 */
  __pyx_v_npsz = PyArray_NBYTES(__pyx_v_dst);

  /* "pygpu/gpuarray.pyx":1703
 *             raise ValueError, "GpuArray and Numpy array do not have matching data types"
 *         cdef size_t npsz = np.PyArray_NBYTES(dst)
 *         cdef size_t sz = gpuarray_get_elsize(self.ga.typecode)             # <<<<<<<<<<<<<<
 *         cdef unsigned i
 *         for i in range(self.ga.nd):
 */
  __pyx_v_sz = gpuarray_get_elsize(__pyx_v_self->ga.typecode);

  /* "pygpu/gpuarray.pyx":1705
 *         cdef size_t sz = gpuarray_get_elsize(self.ga.typecode)
 *         cdef unsigned i
 *         for i in range(self.ga.nd):             # <<<<<<<<<<<<<<
 *             sz *= self.ga.dimensions[i]
 *         if sz != npsz:
 */
  __pyx_t_6 = __pyx_v_self->ga.nd;
  for (__pyx_t_7 = 0; __pyx_t_7 < __pyx_t_6; __pyx_t_7+=1) {
    __pyx_v_i = __pyx_t_7;

    /* "pygpu/gpuarray.pyx":1706
 *         cdef unsigned i
 *         for i in range(self.ga.nd):
 *             sz *= self.ga.dimensions[i]             # <<<<<<<<<<<<<<
 *         if sz != npsz:
 *             raise ValueError, "GpuArray and Numpy array do not have the same size in bytes"
 */
    __pyx_v_sz = (__pyx_v_sz * (__pyx_v_self->ga.dimensions[__pyx_v_i]));
  }

  /* "pygpu/gpuarray.pyx":1707
 *         for i in range(self.ga.nd):
 *             sz *= self.ga.dimensions[i]
 *         if sz != npsz:             # <<<<<<<<<<<<<<
 *             raise ValueError, "GpuArray and Numpy array do not have the same size in bytes"
 *         array_read(np.PyArray_DATA(dst), sz, self)
 */
  __pyx_t_4 = ((__pyx_v_sz != __pyx_v_npsz) != 0);
  if (__pyx_t_4) {

    /* "pygpu/gpuarray.pyx":1708
 *             sz *= self.ga.dimensions[i]
 *         if sz != npsz:
 *             raise ValueError, "GpuArray and Numpy array do not have the same size in bytes"             # <<<<<<<<<<<<<<
 *         array_read(np.PyArray_DATA(dst), sz, self)
 * 
 */
    __Pyx_Raise(__pyx_builtin_ValueError, __pyx_kp_s_GpuArray_and_Numpy_array_do_not_2, 0, 0);
    __PYX_ERR(0, 1708, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":1707
 *         for i in range(self.ga.nd):
 *             sz *= self.ga.dimensions[i]
 *         if sz != npsz:             # <<<<<<<<<<<<<<
 *             raise ValueError, "GpuArray and Numpy array do not have the same size in bytes"
 *         array_read(np.PyArray_DATA(dst), sz, self)
 */
  }

  /* "pygpu/gpuarray.pyx":1709
 *         if sz != npsz:
 *             raise ValueError, "GpuArray and Numpy array do not have the same size in bytes"
 *         array_read(np.PyArray_DATA(dst), sz, self)             # <<<<<<<<<<<<<<
 * 
 *     def get_ipc_handle(self):
 */
  __pyx_t_8 = __pyx_f_5pygpu_8gpuarray_array_read(PyArray_DATA(__pyx_v_dst), __pyx_v_sz, __pyx_v_self); if (unlikely(__pyx_t_8 == ((int)-1))) __PYX_ERR(0, 1709, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":1665
 *         array_write(self, np.PyArray_DATA(src), sz)
 * 
 *     def read(self, np.ndarray dst not None):             # <<<<<<<<<<<<<<
 *         """
 *         read(dst)
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("pygpu.gpuarray.GpuArray.read", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":1711
 *         array_read(np.PyArray_DATA(dst), sz, self)
 * 
 *     def get_ipc_handle(self):             # <<<<<<<<<<<<<<
 *         """
 *         get_ipc_handle()
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_8GpuArray_13get_ipc_handle(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static char __pyx_doc_5pygpu_8gpuarray_8GpuArray_12get_ipc_handle[] = "\n        get_ipc_handle()\n        ";
static PyObject *__pyx_pw_5pygpu_8gpuarray_8GpuArray_13get_ipc_handle(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("get_ipc_handle (wrapper)", 0);
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_8GpuArray_12get_ipc_handle(((struct PyGpuArrayObject *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_8GpuArray_12get_ipc_handle(struct PyGpuArrayObject *__pyx_v_self) {
  GpuArrayIpcMemHandle __pyx_v_h;
  int __pyx_v_err;
  PyObject *__pyx_v_res = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_t_2;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  __Pyx_RefNannySetupContext("get_ipc_handle", 0);

  /* "pygpu/gpuarray.pyx":1717
 *         cdef GpuArrayIpcMemHandle h
 *         cdef int err
 *         if cuda_get_ipc_handle is NULL:             # <<<<<<<<<<<<<<
 *             raise SystemError, "Could not get necessary extension"
 *         if self.context.kind != b'cuda':
 */
  __pyx_t_1 = ((__pyx_v_5pygpu_8gpuarray_cuda_get_ipc_handle == NULL) != 0);
  if (__pyx_t_1) {

    /* "pygpu/gpuarray.pyx":1718
 *         cdef int err
 *         if cuda_get_ipc_handle is NULL:
 *             raise SystemError, "Could not get necessary extension"             # <<<<<<<<<<<<<<
 *         if self.context.kind != b'cuda':
 *             raise ValueError, "Only works for cuda contexts"
 */
    __Pyx_Raise(__pyx_builtin_SystemError, __pyx_kp_s_Could_not_get_necessary_extensio, 0, 0);
    __PYX_ERR(0, 1718, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":1717
 *         cdef GpuArrayIpcMemHandle h
 *         cdef int err
 *         if cuda_get_ipc_handle is NULL:             # <<<<<<<<<<<<<<
 *             raise SystemError, "Could not get necessary extension"
 *         if self.context.kind != b'cuda':
 */
  }

  /* "pygpu/gpuarray.pyx":1719
 *         if cuda_get_ipc_handle is NULL:
 *             raise SystemError, "Could not get necessary extension"
 *         if self.context.kind != b'cuda':             # <<<<<<<<<<<<<<
 *             raise ValueError, "Only works for cuda contexts"
 *         err = cuda_get_ipc_handle(self.ga.data, &h)
 */
  __pyx_t_1 = (__Pyx_PyBytes_Equals(__pyx_v_self->context->kind, __pyx_n_b_cuda, Py_NE)); if (unlikely(__pyx_t_1 < 0)) __PYX_ERR(0, 1719, __pyx_L1_error)
  __pyx_t_2 = (__pyx_t_1 != 0);
  if (__pyx_t_2) {

    /* "pygpu/gpuarray.pyx":1720
 *             raise SystemError, "Could not get necessary extension"
 *         if self.context.kind != b'cuda':
 *             raise ValueError, "Only works for cuda contexts"             # <<<<<<<<<<<<<<
 *         err = cuda_get_ipc_handle(self.ga.data, &h)
 *         if err != GA_NO_ERROR:
 */
    __Pyx_Raise(__pyx_builtin_ValueError, __pyx_kp_s_Only_works_for_cuda_contexts, 0, 0);
    __PYX_ERR(0, 1720, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":1719
 *         if cuda_get_ipc_handle is NULL:
 *             raise SystemError, "Could not get necessary extension"
 *         if self.context.kind != b'cuda':             # <<<<<<<<<<<<<<
 *             raise ValueError, "Only works for cuda contexts"
 *         err = cuda_get_ipc_handle(self.ga.data, &h)
 */
  }

  /* "pygpu/gpuarray.pyx":1721
 *         if self.context.kind != b'cuda':
 *             raise ValueError, "Only works for cuda contexts"
 *         err = cuda_get_ipc_handle(self.ga.data, &h)             # <<<<<<<<<<<<<<
 *         if err != GA_NO_ERROR:
 *             raise get_exc(err), GpuArray_error(&self.ga, err)
 */
  __pyx_v_err = __pyx_v_5pygpu_8gpuarray_cuda_get_ipc_handle(__pyx_v_self->ga.data, (&__pyx_v_h));

  /* "pygpu/gpuarray.pyx":1722
 *             raise ValueError, "Only works for cuda contexts"
 *         err = cuda_get_ipc_handle(self.ga.data, &h)
 *         if err != GA_NO_ERROR:             # <<<<<<<<<<<<<<
 *             raise get_exc(err), GpuArray_error(&self.ga, err)
 *         res = <bytes>(<char *>&h)[:sizeof(h)]
 */
  __pyx_t_2 = ((__pyx_v_err != GA_NO_ERROR) != 0);
  if (__pyx_t_2) {

    /* "pygpu/gpuarray.pyx":1723
 *         err = cuda_get_ipc_handle(self.ga.data, &h)
 *         if err != GA_NO_ERROR:
 *             raise get_exc(err), GpuArray_error(&self.ga, err)             # <<<<<<<<<<<<<<
 *         res = <bytes>(<char *>&h)[:sizeof(h)]
 *         return res
 */
    __pyx_t_3 = ((PyObject *)__pyx_f_5pygpu_8gpuarray_get_exc(__pyx_v_err)); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1723, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_4 = __Pyx_PyBytes_FromString(GpuArray_error((&__pyx_v_self->ga), __pyx_v_err)); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1723, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_Raise(__pyx_t_3, __pyx_t_4, 0, 0);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __PYX_ERR(0, 1723, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":1722
 *             raise ValueError, "Only works for cuda contexts"
 *         err = cuda_get_ipc_handle(self.ga.data, &h)
 *         if err != GA_NO_ERROR:             # <<<<<<<<<<<<<<
 *             raise get_exc(err), GpuArray_error(&self.ga, err)
 *         res = <bytes>(<char *>&h)[:sizeof(h)]
 */
  }

  /* "pygpu/gpuarray.pyx":1724
 *         if err != GA_NO_ERROR:
 *             raise get_exc(err), GpuArray_error(&self.ga, err)
 *         res = <bytes>(<char *>&h)[:sizeof(h)]             # <<<<<<<<<<<<<<
 *         return res
 * 
 */
  __pyx_t_4 = __Pyx_PyBytes_FromStringAndSize(((char *)(&__pyx_v_h)) + 0, (sizeof(__pyx_v_h)) - 0); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1724, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_3 = __pyx_t_4;
  __Pyx_INCREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_v_res = ((PyObject*)__pyx_t_3);
  __pyx_t_3 = 0;

  /* "pygpu/gpuarray.pyx":1725
 *             raise get_exc(err), GpuArray_error(&self.ga, err)
 *         res = <bytes>(<char *>&h)[:sizeof(h)]
 *         return res             # <<<<<<<<<<<<<<
 * 
 *     def __array__(self, ldtype=None):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_res);
  __pyx_r = __pyx_v_res;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":1711
 *         array_read(np.PyArray_DATA(dst), sz, self)
 * 
 *     def get_ipc_handle(self):             # <<<<<<<<<<<<<<
 *         """
 *         get_ipc_handle()
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_AddTraceback("pygpu.gpuarray.GpuArray.get_ipc_handle", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_res);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":1727
 *         return res
 * 
 *     def __array__(self, ldtype=None):             # <<<<<<<<<<<<<<
 *         """
 *         __array__(ldtype=None)
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_8GpuArray_15__array__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static char __pyx_doc_5pygpu_8gpuarray_8GpuArray_14__array__[] = "\n        __array__(ldtype=None)\n\n        Return a :class:`numpy.ndarray` with the same content.\n\n        Automatically used by :meth:`numpy.asarray`.\n        ";
static PyObject *__pyx_pw_5pygpu_8gpuarray_8GpuArray_15__array__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_ldtype = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__array__ (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_ldtype,0};
    PyObject* values[1] = {0};
    values[0] = ((PyObject *)Py_None);
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_ldtype);
          if (value) { values[0] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "__array__") < 0)) __PYX_ERR(0, 1727, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    __pyx_v_ldtype = values[0];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("__array__", 0, 0, 1, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 1727, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("pygpu.gpuarray.GpuArray.__array__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_8GpuArray_14__array__(((struct PyGpuArrayObject *)__pyx_v_self), __pyx_v_ldtype);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_8GpuArray_14__array__(struct PyGpuArrayObject *__pyx_v_self, PyObject *__pyx_v_ldtype) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("__array__", 0);

  /* "pygpu/gpuarray.pyx":1735
 *         Automatically used by :meth:`numpy.asarray`.
 *         """
 *         return _pygpu_as_ndarray(self, ldtype)             # <<<<<<<<<<<<<<
 * 
 *     def __bool__(self):
 */
  __Pyx_XDECREF(__pyx_r);
  if (!(likely(((__pyx_v_ldtype) == Py_None) || likely(__Pyx_TypeTest(__pyx_v_ldtype, __pyx_ptype_5numpy_dtype))))) __PYX_ERR(0, 1735, __pyx_L1_error)
  __pyx_t_1 = ((PyObject *)__pyx_f_5pygpu_8gpuarray__pygpu_as_ndarray(__pyx_v_self, ((PyArray_Descr *)__pyx_v_ldtype))); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1735, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":1727
 *         return res
 * 
 *     def __array__(self, ldtype=None):             # <<<<<<<<<<<<<<
 *         """
 *         __array__(ldtype=None)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("pygpu.gpuarray.GpuArray.__array__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":1737
 *         return _pygpu_as_ndarray(self, ldtype)
 * 
 *     def __bool__(self):             # <<<<<<<<<<<<<<
 *         """
 *         __bool__()
 */

/* Python wrapper */
static int __pyx_pw_5pygpu_8gpuarray_8GpuArray_17__bool__(PyObject *__pyx_v_self); /*proto*/
static int __pyx_pw_5pygpu_8gpuarray_8GpuArray_17__bool__(PyObject *__pyx_v_self) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__bool__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_8GpuArray_16__bool__(((struct PyGpuArrayObject *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_5pygpu_8gpuarray_8GpuArray_16__bool__(struct PyGpuArrayObject *__pyx_v_self) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  int __pyx_t_3;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  __Pyx_RefNannySetupContext("__bool__", 0);

  /* "pygpu/gpuarray.pyx":1741
 *         __bool__()
 *         """
 *         if self.size == 0:             # <<<<<<<<<<<<<<
 *             return False
 *         elif self.size == 1:
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_size); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1741, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyInt_EqObjC(__pyx_t_1, __pyx_int_0, 0, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1741, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_3 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely(__pyx_t_3 < 0)) __PYX_ERR(0, 1741, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (__pyx_t_3) {

    /* "pygpu/gpuarray.pyx":1742
 *         """
 *         if self.size == 0:
 *             return False             # <<<<<<<<<<<<<<
 *         elif self.size == 1:
 *             return bool(numpy.asarray(self))
 */
    __pyx_r = 0;
    goto __pyx_L0;

    /* "pygpu/gpuarray.pyx":1741
 *         __bool__()
 *         """
 *         if self.size == 0:             # <<<<<<<<<<<<<<
 *             return False
 *         elif self.size == 1:
 */
  }

  /* "pygpu/gpuarray.pyx":1743
 *         if self.size == 0:
 *             return False
 *         elif self.size == 1:             # <<<<<<<<<<<<<<
 *             return bool(numpy.asarray(self))
 *         else:
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_size); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1743, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = __Pyx_PyInt_EqObjC(__pyx_t_2, __pyx_int_1, 1, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1743, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_3 = __Pyx_PyObject_IsTrue(__pyx_t_1); if (unlikely(__pyx_t_3 < 0)) __PYX_ERR(0, 1743, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  if (__pyx_t_3) {

    /* "pygpu/gpuarray.pyx":1744
 *             return False
 *         elif self.size == 1:
 *             return bool(numpy.asarray(self))             # <<<<<<<<<<<<<<
 *         else:
 *             raise ValueError('The truth value of a multi-element array is ambiguous')
 */
    __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_numpy); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1744, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_asarray); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1744, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_2 = NULL;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_4))) {
      __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_4);
      if (likely(__pyx_t_2)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_4);
        __Pyx_INCREF(__pyx_t_2);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_4, function);
      }
    }
    if (!__pyx_t_2) {
      __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_4, ((PyObject *)__pyx_v_self)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1744, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
    } else {
      #if CYTHON_FAST_PYCALL
      if (PyFunction_Check(__pyx_t_4)) {
        PyObject *__pyx_temp[2] = {__pyx_t_2, ((PyObject *)__pyx_v_self)};
        __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_4, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1744, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
        __Pyx_GOTREF(__pyx_t_1);
      } else
      #endif
      #if CYTHON_FAST_PYCCALL
      if (__Pyx_PyFastCFunction_Check(__pyx_t_4)) {
        PyObject *__pyx_temp[2] = {__pyx_t_2, ((PyObject *)__pyx_v_self)};
        __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_4, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1744, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
        __Pyx_GOTREF(__pyx_t_1);
      } else
      #endif
      {
        __pyx_t_5 = PyTuple_New(1+1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 1744, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_5);
        __Pyx_GIVEREF(__pyx_t_2); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_2); __pyx_t_2 = NULL;
        __Pyx_INCREF(((PyObject *)__pyx_v_self));
        __Pyx_GIVEREF(((PyObject *)__pyx_v_self));
        PyTuple_SET_ITEM(__pyx_t_5, 0+1, ((PyObject *)__pyx_v_self));
        __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_4, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1744, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      }
    }
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_t_3 = __Pyx_PyObject_IsTrue(__pyx_t_1); if (unlikely(__pyx_t_3 < 0)) __PYX_ERR(0, 1744, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_r = (!(!__pyx_t_3));
    goto __pyx_L0;

    /* "pygpu/gpuarray.pyx":1743
 *         if self.size == 0:
 *             return False
 *         elif self.size == 1:             # <<<<<<<<<<<<<<
 *             return bool(numpy.asarray(self))
 *         else:
 */
  }

  /* "pygpu/gpuarray.pyx":1746
 *             return bool(numpy.asarray(self))
 *         else:
 *             raise ValueError('The truth value of a multi-element array is ambiguous')             # <<<<<<<<<<<<<<
 * 
 *     def _empty_like_me(self, dtype=None, order='C'):
 */
  /*else*/ {
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__23, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1746, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_Raise(__pyx_t_1, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __PYX_ERR(0, 1746, __pyx_L1_error)
  }

  /* "pygpu/gpuarray.pyx":1737
 *         return _pygpu_as_ndarray(self, ldtype)
 * 
 *     def __bool__(self):             # <<<<<<<<<<<<<<
 *         """
 *         __bool__()
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("pygpu.gpuarray.GpuArray.__bool__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":1748
 *             raise ValueError('The truth value of a multi-element array is ambiguous')
 * 
 *     def _empty_like_me(self, dtype=None, order='C'):             # <<<<<<<<<<<<<<
 *         """
 *         _empty_like_me(dtype=None, order='C')
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_8GpuArray_19_empty_like_me(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static char __pyx_doc_5pygpu_8gpuarray_8GpuArray_18_empty_like_me[] = "\n        _empty_like_me(dtype=None, order='C')\n\n        Returns an empty (uninitialized) GpuArray with the same\n        properties except if overridden by parameters.\n        ";
static PyObject *__pyx_pw_5pygpu_8gpuarray_8GpuArray_19_empty_like_me(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_dtype = 0;
  PyObject *__pyx_v_order = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("_empty_like_me (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_dtype,&__pyx_n_s_order,0};
    PyObject* values[2] = {0,0};
    values[0] = ((PyObject *)Py_None);
    values[1] = ((PyObject *)__pyx_n_s_C);
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_dtype);
          if (value) { values[0] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  1:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_order);
          if (value) { values[1] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "_empty_like_me") < 0)) __PYX_ERR(0, 1748, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    __pyx_v_dtype = values[0];
    __pyx_v_order = values[1];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("_empty_like_me", 0, 0, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 1748, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("pygpu.gpuarray.GpuArray._empty_like_me", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_8GpuArray_18_empty_like_me(((struct PyGpuArrayObject *)__pyx_v_self), __pyx_v_dtype, __pyx_v_order);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_8GpuArray_18_empty_like_me(struct PyGpuArrayObject *__pyx_v_self, PyObject *__pyx_v_dtype, PyObject *__pyx_v_order) {
  int __pyx_v_typecode;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_t_2;
  int __pyx_t_3;
  ga_order __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  __Pyx_RefNannySetupContext("_empty_like_me", 0);

  /* "pygpu/gpuarray.pyx":1758
 *         cdef GpuArray res
 * 
 *         if dtype is None:             # <<<<<<<<<<<<<<
 *             typecode = -1
 *         else:
 */
  __pyx_t_1 = (__pyx_v_dtype == Py_None);
  __pyx_t_2 = (__pyx_t_1 != 0);
  if (__pyx_t_2) {

    /* "pygpu/gpuarray.pyx":1759
 * 
 *         if dtype is None:
 *             typecode = -1             # <<<<<<<<<<<<<<
 *         else:
 *             typecode = dtype_to_typecode(dtype)
 */
    __pyx_v_typecode = -1;

    /* "pygpu/gpuarray.pyx":1758
 *         cdef GpuArray res
 * 
 *         if dtype is None:             # <<<<<<<<<<<<<<
 *             typecode = -1
 *         else:
 */
    goto __pyx_L3;
  }

  /* "pygpu/gpuarray.pyx":1761
 *             typecode = -1
 *         else:
 *             typecode = dtype_to_typecode(dtype)             # <<<<<<<<<<<<<<
 * 
 *         return pygpu_empty_like(self, to_ga_order(order), typecode)
 */
  /*else*/ {
    __pyx_t_3 = __pyx_f_5pygpu_8gpuarray_dtype_to_typecode(__pyx_v_dtype, 0); if (unlikely(__pyx_t_3 == ((int)-1))) __PYX_ERR(0, 1761, __pyx_L1_error)
    __pyx_v_typecode = __pyx_t_3;
  }
  __pyx_L3:;

  /* "pygpu/gpuarray.pyx":1763
 *             typecode = dtype_to_typecode(dtype)
 * 
 *         return pygpu_empty_like(self, to_ga_order(order), typecode)             # <<<<<<<<<<<<<<
 * 
 *     def copy(self, order='C'):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_4 = __pyx_f_5pygpu_8gpuarray_to_ga_order(__pyx_v_order); if (unlikely(__pyx_t_4 == ((ga_order)((ga_order)-2L)))) __PYX_ERR(0, 1763, __pyx_L1_error)
  __pyx_t_5 = ((PyObject *)__pyx_f_5pygpu_8gpuarray_pygpu_empty_like(__pyx_v_self, __pyx_t_4, __pyx_v_typecode)); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 1763, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_r = __pyx_t_5;
  __pyx_t_5 = 0;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":1748
 *             raise ValueError('The truth value of a multi-element array is ambiguous')
 * 
 *     def _empty_like_me(self, dtype=None, order='C'):             # <<<<<<<<<<<<<<
 *         """
 *         _empty_like_me(dtype=None, order='C')
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("pygpu.gpuarray.GpuArray._empty_like_me", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":1765
 *         return pygpu_empty_like(self, to_ga_order(order), typecode)
 * 
 *     def copy(self, order='C'):             # <<<<<<<<<<<<<<
 *         """
 *         copy(order='C')
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_8GpuArray_21copy(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static char __pyx_doc_5pygpu_8gpuarray_8GpuArray_20copy[] = "\n        copy(order='C')\n\n        Return a copy if this array.\n\n        Parameters\n        ----------\n        order: {'C', 'A', 'F'}\n            memory layout of the copy\n\n        ";
static PyObject *__pyx_pw_5pygpu_8gpuarray_8GpuArray_21copy(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_order = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("copy (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_order,0};
    PyObject* values[1] = {0};
    values[0] = ((PyObject *)__pyx_n_s_C);
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_order);
          if (value) { values[0] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "copy") < 0)) __PYX_ERR(0, 1765, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    __pyx_v_order = values[0];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("copy", 0, 0, 1, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 1765, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("pygpu.gpuarray.GpuArray.copy", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_8GpuArray_20copy(((struct PyGpuArrayObject *)__pyx_v_self), __pyx_v_order);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_8GpuArray_20copy(struct PyGpuArrayObject *__pyx_v_self, PyObject *__pyx_v_order) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  ga_order __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  __Pyx_RefNannySetupContext("copy", 0);

  /* "pygpu/gpuarray.pyx":1777
 * 
 *         """
 *         return pygpu_copy(self, to_ga_order(order))             # <<<<<<<<<<<<<<
 * 
 *     def transfer(self, GpuContext new_ctx):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __pyx_f_5pygpu_8gpuarray_to_ga_order(__pyx_v_order); if (unlikely(__pyx_t_1 == ((ga_order)((ga_order)-2L)))) __PYX_ERR(0, 1777, __pyx_L1_error)
  __pyx_t_2 = ((PyObject *)__pyx_f_5pygpu_8gpuarray_pygpu_copy(__pyx_v_self, __pyx_t_1)); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1777, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_r = __pyx_t_2;
  __pyx_t_2 = 0;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":1765
 *         return pygpu_empty_like(self, to_ga_order(order), typecode)
 * 
 *     def copy(self, order='C'):             # <<<<<<<<<<<<<<
 *         """
 *         copy(order='C')
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("pygpu.gpuarray.GpuArray.copy", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":1779
 *         return pygpu_copy(self, to_ga_order(order))
 * 
 *     def transfer(self, GpuContext new_ctx):             # <<<<<<<<<<<<<<
 *         """
 *         transfer(new_ctx)
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_8GpuArray_23transfer(PyObject *__pyx_v_self, PyObject *__pyx_v_new_ctx); /*proto*/
static char __pyx_doc_5pygpu_8gpuarray_8GpuArray_22transfer[] = "\n        transfer(new_ctx)\n        ";
static PyObject *__pyx_pw_5pygpu_8gpuarray_8GpuArray_23transfer(PyObject *__pyx_v_self, PyObject *__pyx_v_new_ctx) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("transfer (wrapper)", 0);
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_new_ctx), __pyx_ptype_5pygpu_8gpuarray_GpuContext, 1, "new_ctx", 0))) __PYX_ERR(0, 1779, __pyx_L1_error)
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_8GpuArray_22transfer(((struct PyGpuArrayObject *)__pyx_v_self), ((struct PyGpuContextObject *)__pyx_v_new_ctx));

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_8GpuArray_22transfer(struct PyGpuArrayObject *__pyx_v_self, struct PyGpuContextObject *__pyx_v_new_ctx) {
  struct PyGpuArrayObject *__pyx_v_r = 0;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  ga_order __pyx_t_3;
  int __pyx_t_4;
  __Pyx_RefNannySetupContext("transfer", 0);

  /* "pygpu/gpuarray.pyx":1784
 *         """
 *         cdef GpuArray r
 *         if not GpuArray_ISONESEGMENT(&self.ga):             # <<<<<<<<<<<<<<
 *             # For now raise an error, may make it work later
 *             raise ValueError("transfer() only works for contigous source")
 */
  __pyx_t_1 = ((!(GpuArray_ISONESEGMENT((&__pyx_v_self->ga)) != 0)) != 0);
  if (__pyx_t_1) {

    /* "pygpu/gpuarray.pyx":1786
 *         if not GpuArray_ISONESEGMENT(&self.ga):
 *             # For now raise an error, may make it work later
 *             raise ValueError("transfer() only works for contigous source")             # <<<<<<<<<<<<<<
 *         r = pygpu_empty(self.ga.nd, self.ga.dimensions, self.ga.typecode,
 *                         GA_C_ORDER if GpuArray_IS_C_CONTIGUOUS(&self.ga) else GA_F_ORDER,
 */
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__24, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1786, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(0, 1786, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":1784
 *         """
 *         cdef GpuArray r
 *         if not GpuArray_ISONESEGMENT(&self.ga):             # <<<<<<<<<<<<<<
 *             # For now raise an error, may make it work later
 *             raise ValueError("transfer() only works for contigous source")
 */
  }

  /* "pygpu/gpuarray.pyx":1788
 *             raise ValueError("transfer() only works for contigous source")
 *         r = pygpu_empty(self.ga.nd, self.ga.dimensions, self.ga.typecode,
 *                         GA_C_ORDER if GpuArray_IS_C_CONTIGUOUS(&self.ga) else GA_F_ORDER,             # <<<<<<<<<<<<<<
 *                         new_ctx, None)
 *         pygpu_transfer(r, self)  # Will raise an error if needed
 */
  if ((GpuArray_IS_C_CONTIGUOUS((&__pyx_v_self->ga)) != 0)) {
    __pyx_t_3 = GA_C_ORDER;
  } else {
    __pyx_t_3 = GA_F_ORDER;
  }

  /* "pygpu/gpuarray.pyx":1787
 *             # For now raise an error, may make it work later
 *             raise ValueError("transfer() only works for contigous source")
 *         r = pygpu_empty(self.ga.nd, self.ga.dimensions, self.ga.typecode,             # <<<<<<<<<<<<<<
 *                         GA_C_ORDER if GpuArray_IS_C_CONTIGUOUS(&self.ga) else GA_F_ORDER,
 *                         new_ctx, None)
 */
  __pyx_t_2 = ((PyObject *)__pyx_f_5pygpu_8gpuarray_pygpu_empty(__pyx_v_self->ga.nd, __pyx_v_self->ga.dimensions, __pyx_v_self->ga.typecode, __pyx_t_3, __pyx_v_new_ctx, Py_None)); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1787, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_v_r = ((struct PyGpuArrayObject *)__pyx_t_2);
  __pyx_t_2 = 0;

  /* "pygpu/gpuarray.pyx":1790
 *                         GA_C_ORDER if GpuArray_IS_C_CONTIGUOUS(&self.ga) else GA_F_ORDER,
 *                         new_ctx, None)
 *         pygpu_transfer(r, self)  # Will raise an error if needed             # <<<<<<<<<<<<<<
 *         return r
 * 
 */
  __pyx_t_4 = __pyx_f_5pygpu_8gpuarray_pygpu_transfer(__pyx_v_r, __pyx_v_self); if (unlikely(__pyx_t_4 == ((int)-1))) __PYX_ERR(0, 1790, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":1791
 *                         new_ctx, None)
 *         pygpu_transfer(r, self)  # Will raise an error if needed
 *         return r             # <<<<<<<<<<<<<<
 * 
 *     def __copy__(self):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_r));
  __pyx_r = ((PyObject *)__pyx_v_r);
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":1779
 *         return pygpu_copy(self, to_ga_order(order))
 * 
 *     def transfer(self, GpuContext new_ctx):             # <<<<<<<<<<<<<<
 *         """
 *         transfer(new_ctx)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("pygpu.gpuarray.GpuArray.transfer", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_r);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":1793
 *         return r
 * 
 *     def __copy__(self):             # <<<<<<<<<<<<<<
 *         return pygpu_copy(self, GA_C_ORDER)
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_8GpuArray_25__copy__(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_pw_5pygpu_8gpuarray_8GpuArray_25__copy__(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__copy__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_8GpuArray_24__copy__(((struct PyGpuArrayObject *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_8GpuArray_24__copy__(struct PyGpuArrayObject *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("__copy__", 0);

  /* "pygpu/gpuarray.pyx":1794
 * 
 *     def __copy__(self):
 *         return pygpu_copy(self, GA_C_ORDER)             # <<<<<<<<<<<<<<
 * 
 *     def __deepcopy__(self, memo):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = ((PyObject *)__pyx_f_5pygpu_8gpuarray_pygpu_copy(__pyx_v_self, GA_C_ORDER)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1794, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":1793
 *         return r
 * 
 *     def __copy__(self):             # <<<<<<<<<<<<<<
 *         return pygpu_copy(self, GA_C_ORDER)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("pygpu.gpuarray.GpuArray.__copy__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":1796
 *         return pygpu_copy(self, GA_C_ORDER)
 * 
 *     def __deepcopy__(self, memo):             # <<<<<<<<<<<<<<
 *         if id(self) in memo:
 *             return memo[id(self)]
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_8GpuArray_27__deepcopy__(PyObject *__pyx_v_self, PyObject *__pyx_v_memo); /*proto*/
static PyObject *__pyx_pw_5pygpu_8gpuarray_8GpuArray_27__deepcopy__(PyObject *__pyx_v_self, PyObject *__pyx_v_memo) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__deepcopy__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_8GpuArray_26__deepcopy__(((struct PyGpuArrayObject *)__pyx_v_self), ((PyObject *)__pyx_v_memo));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_8GpuArray_26__deepcopy__(struct PyGpuArrayObject *__pyx_v_self, PyObject *__pyx_v_memo) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  int __pyx_t_3;
  int __pyx_t_4;
  __Pyx_RefNannySetupContext("__deepcopy__", 0);

  /* "pygpu/gpuarray.pyx":1797
 * 
 *     def __deepcopy__(self, memo):
 *         if id(self) in memo:             # <<<<<<<<<<<<<<
 *             return memo[id(self)]
 *         else:
 */
  __pyx_t_1 = PyTuple_New(1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1797, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __Pyx_GIVEREF(((PyObject *)__pyx_v_self));
  PyTuple_SET_ITEM(__pyx_t_1, 0, ((PyObject *)__pyx_v_self));
  __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_id, __pyx_t_1, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1797, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_3 = (__Pyx_PySequence_ContainsTF(__pyx_t_2, __pyx_v_memo, Py_EQ)); if (unlikely(__pyx_t_3 < 0)) __PYX_ERR(0, 1797, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_4 = (__pyx_t_3 != 0);
  if (__pyx_t_4) {

    /* "pygpu/gpuarray.pyx":1798
 *     def __deepcopy__(self, memo):
 *         if id(self) in memo:
 *             return memo[id(self)]             # <<<<<<<<<<<<<<
 *         else:
 *             return pygpu_copy(self, GA_C_ORDER)
 */
    __Pyx_XDECREF(__pyx_r);
    __pyx_t_2 = PyTuple_New(1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1798, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_INCREF(((PyObject *)__pyx_v_self));
    __Pyx_GIVEREF(((PyObject *)__pyx_v_self));
    PyTuple_SET_ITEM(__pyx_t_2, 0, ((PyObject *)__pyx_v_self));
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_builtin_id, __pyx_t_2, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1798, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_2 = PyObject_GetItem(__pyx_v_memo, __pyx_t_1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1798, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_r = __pyx_t_2;
    __pyx_t_2 = 0;
    goto __pyx_L0;

    /* "pygpu/gpuarray.pyx":1797
 * 
 *     def __deepcopy__(self, memo):
 *         if id(self) in memo:             # <<<<<<<<<<<<<<
 *             return memo[id(self)]
 *         else:
 */
  }

  /* "pygpu/gpuarray.pyx":1800
 *             return memo[id(self)]
 *         else:
 *             return pygpu_copy(self, GA_C_ORDER)             # <<<<<<<<<<<<<<
 * 
 *     def sync(self):
 */
  /*else*/ {
    __Pyx_XDECREF(__pyx_r);
    __pyx_t_2 = ((PyObject *)__pyx_f_5pygpu_8gpuarray_pygpu_copy(__pyx_v_self, GA_C_ORDER)); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1800, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_r = __pyx_t_2;
    __pyx_t_2 = 0;
    goto __pyx_L0;
  }

  /* "pygpu/gpuarray.pyx":1796
 *         return pygpu_copy(self, GA_C_ORDER)
 * 
 *     def __deepcopy__(self, memo):             # <<<<<<<<<<<<<<
 *         if id(self) in memo:
 *             return memo[id(self)]
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("pygpu.gpuarray.GpuArray.__deepcopy__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":1802
 *             return pygpu_copy(self, GA_C_ORDER)
 * 
 *     def sync(self):             # <<<<<<<<<<<<<<
 *         """
 *         sync()
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_8GpuArray_29sync(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static char __pyx_doc_5pygpu_8gpuarray_8GpuArray_28sync[] = "\n        sync()\n\n        Wait for all pending operations on this array.\n\n        This is done automatically when reading or writing from it,\n        but can be useful as a separate operation for timings.\n        ";
static PyObject *__pyx_pw_5pygpu_8gpuarray_8GpuArray_29sync(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("sync (wrapper)", 0);
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_8GpuArray_28sync(((struct PyGpuArrayObject *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_8GpuArray_28sync(struct PyGpuArrayObject *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  __Pyx_RefNannySetupContext("sync", 0);

  /* "pygpu/gpuarray.pyx":1811
 *         but can be useful as a separate operation for timings.
 *         """
 *         pygpu_sync(self)             # <<<<<<<<<<<<<<
 * 
 *     def view(self, object cls=GpuArray):
 */
  __pyx_t_1 = __pyx_f_5pygpu_8gpuarray_pygpu_sync(__pyx_v_self); if (unlikely(__pyx_t_1 == ((int)-1))) __PYX_ERR(0, 1811, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":1802
 *             return pygpu_copy(self, GA_C_ORDER)
 * 
 *     def sync(self):             # <<<<<<<<<<<<<<
 *         """
 *         sync()
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_AddTraceback("pygpu.gpuarray.GpuArray.sync", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":1813
 *         pygpu_sync(self)
 * 
 *     def view(self, object cls=GpuArray):             # <<<<<<<<<<<<<<
 *         """
 *         view(cls=GpuArray)
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_8GpuArray_31view(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static char __pyx_doc_5pygpu_8gpuarray_8GpuArray_30view[] = "\n        view(cls=GpuArray)\n\n        Return a view of this array.\n\n        The returned array shares device data with this one and both\n        will reflect changes made to the other.\n\n        Parameters\n        ----------\n        cls: type\n            class of the view (must inherit from GpuArray)\n\n        ";
static PyObject *__pyx_pw_5pygpu_8gpuarray_8GpuArray_31view(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_cls = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("view (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_cls,0};
    PyObject* values[1] = {0};
    values[0] = __pyx_k__25;
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_cls);
          if (value) { values[0] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "view") < 0)) __PYX_ERR(0, 1813, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    __pyx_v_cls = values[0];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("view", 0, 0, 1, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 1813, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("pygpu.gpuarray.GpuArray.view", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_8GpuArray_30view(((struct PyGpuArrayObject *)__pyx_v_self), __pyx_v_cls);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_8GpuArray_30view(struct PyGpuArrayObject *__pyx_v_self, PyObject *__pyx_v_cls) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("view", 0);

  /* "pygpu/gpuarray.pyx":1828
 * 
 *         """
 *         return pygpu_view(self, cls)             # <<<<<<<<<<<<<<
 * 
 *     def astype(self, dtype, order='A', copy=True):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = ((PyObject *)__pyx_f_5pygpu_8gpuarray_pygpu_view(__pyx_v_self, __pyx_v_cls)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1828, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":1813
 *         pygpu_sync(self)
 * 
 *     def view(self, object cls=GpuArray):             # <<<<<<<<<<<<<<
 *         """
 *         view(cls=GpuArray)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("pygpu.gpuarray.GpuArray.view", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":1830
 *         return pygpu_view(self, cls)
 * 
 *     def astype(self, dtype, order='A', copy=True):             # <<<<<<<<<<<<<<
 *         """
 *         astype(dtype, order='A', copy=True)
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_8GpuArray_33astype(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static char __pyx_doc_5pygpu_8gpuarray_8GpuArray_32astype[] = "\n        astype(dtype, order='A', copy=True)\n\n        Cast the elements of this array to a new type.\n\n        This function returns a new array will all elements cast to\n        the supplied `dtype`, but otherwise unchanged.\n\n        If `copy` is False and the type and order match `self` is\n        returned.\n\n        Parameters\n        ----------\n        dtype: str or numpy.dtype or int\n            type of the elements of the result\n        order: {'A', 'C', 'F'}\n            memory layout of the result\n        copy: bool\n            Always return a copy?\n\n        ";
static PyObject *__pyx_pw_5pygpu_8gpuarray_8GpuArray_33astype(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_dtype = 0;
  PyObject *__pyx_v_order = 0;
  PyObject *__pyx_v_copy = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("astype (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_dtype,&__pyx_n_s_order,&__pyx_n_s_copy,0};
    PyObject* values[3] = {0,0,0};
    values[1] = ((PyObject *)__pyx_n_s_A);
    values[2] = ((PyObject *)Py_True);
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_dtype)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_order);
          if (value) { values[1] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_copy);
          if (value) { values[2] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "astype") < 0)) __PYX_ERR(0, 1830, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    __pyx_v_dtype = values[0];
    __pyx_v_order = values[1];
    __pyx_v_copy = values[2];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("astype", 0, 1, 3, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 1830, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("pygpu.gpuarray.GpuArray.astype", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_8GpuArray_32astype(((struct PyGpuArrayObject *)__pyx_v_self), __pyx_v_dtype, __pyx_v_order, __pyx_v_copy);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_8GpuArray_32astype(struct PyGpuArrayObject *__pyx_v_self, PyObject *__pyx_v_dtype, PyObject *__pyx_v_order, PyObject *__pyx_v_copy) {
  struct PyGpuArrayObject *__pyx_v_res = 0;
  int __pyx_v_typecode;
  ga_order __pyx_v_ord;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  ga_order __pyx_t_2;
  int __pyx_t_3;
  int __pyx_t_4;
  int __pyx_t_5;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  PyObject *__pyx_t_8 = NULL;
  __Pyx_RefNannySetupContext("astype", 0);

  /* "pygpu/gpuarray.pyx":1853
 *         """
 *         cdef GpuArray res
 *         cdef int typecode = dtype_to_typecode(dtype)             # <<<<<<<<<<<<<<
 *         cdef ga_order ord = to_ga_order(order)
 * 
 */
  __pyx_t_1 = __pyx_f_5pygpu_8gpuarray_dtype_to_typecode(__pyx_v_dtype, 0); if (unlikely(__pyx_t_1 == ((int)-1))) __PYX_ERR(0, 1853, __pyx_L1_error)
  __pyx_v_typecode = __pyx_t_1;

  /* "pygpu/gpuarray.pyx":1854
 *         cdef GpuArray res
 *         cdef int typecode = dtype_to_typecode(dtype)
 *         cdef ga_order ord = to_ga_order(order)             # <<<<<<<<<<<<<<
 * 
 *         if (not copy and typecode == self.ga.typecode and
 */
  __pyx_t_2 = __pyx_f_5pygpu_8gpuarray_to_ga_order(__pyx_v_order); if (unlikely(__pyx_t_2 == ((ga_order)((ga_order)-2L)))) __PYX_ERR(0, 1854, __pyx_L1_error)
  __pyx_v_ord = __pyx_t_2;

  /* "pygpu/gpuarray.pyx":1856
 *         cdef ga_order ord = to_ga_order(order)
 * 
 *         if (not copy and typecode == self.ga.typecode and             # <<<<<<<<<<<<<<
 *             ((py_CHKFLAGS(self, GA_F_CONTIGUOUS) and ord == GA_F_ORDER) or
 *              (py_CHKFLAGS(self, GA_C_CONTIGUOUS) and ord == GA_C_ORDER))):
 */
  __pyx_t_4 = __Pyx_PyObject_IsTrue(__pyx_v_copy); if (unlikely(__pyx_t_4 < 0)) __PYX_ERR(0, 1856, __pyx_L1_error)
  __pyx_t_5 = ((!__pyx_t_4) != 0);
  if (__pyx_t_5) {
  } else {
    __pyx_t_3 = __pyx_t_5;
    goto __pyx_L4_bool_binop_done;
  }
  __pyx_t_5 = ((__pyx_v_typecode == __pyx_v_self->ga.typecode) != 0);
  if (__pyx_t_5) {
  } else {
    __pyx_t_3 = __pyx_t_5;
    goto __pyx_L4_bool_binop_done;
  }

  /* "pygpu/gpuarray.pyx":1857
 * 
 *         if (not copy and typecode == self.ga.typecode and
 *             ((py_CHKFLAGS(self, GA_F_CONTIGUOUS) and ord == GA_F_ORDER) or             # <<<<<<<<<<<<<<
 *              (py_CHKFLAGS(self, GA_C_CONTIGUOUS) and ord == GA_C_ORDER))):
 *             return self
 */
  __pyx_t_5 = (__pyx_f_5pygpu_8gpuarray_py_CHKFLAGS(__pyx_v_self, GA_F_CONTIGUOUS) != 0);
  if (!__pyx_t_5) {
    goto __pyx_L7_next_or;
  } else {
  }
  __pyx_t_5 = ((__pyx_v_ord == GA_F_ORDER) != 0);
  if (!__pyx_t_5) {
  } else {
    __pyx_t_3 = __pyx_t_5;
    goto __pyx_L4_bool_binop_done;
  }
  __pyx_L7_next_or:;

  /* "pygpu/gpuarray.pyx":1858
 *         if (not copy and typecode == self.ga.typecode and
 *             ((py_CHKFLAGS(self, GA_F_CONTIGUOUS) and ord == GA_F_ORDER) or
 *              (py_CHKFLAGS(self, GA_C_CONTIGUOUS) and ord == GA_C_ORDER))):             # <<<<<<<<<<<<<<
 *             return self
 * 
 */
  __pyx_t_5 = (__pyx_f_5pygpu_8gpuarray_py_CHKFLAGS(__pyx_v_self, GA_C_CONTIGUOUS) != 0);
  if (__pyx_t_5) {
  } else {
    __pyx_t_3 = __pyx_t_5;
    goto __pyx_L4_bool_binop_done;
  }
  __pyx_t_5 = ((__pyx_v_ord == GA_C_ORDER) != 0);
  __pyx_t_3 = __pyx_t_5;
  __pyx_L4_bool_binop_done:;

  /* "pygpu/gpuarray.pyx":1856
 *         cdef ga_order ord = to_ga_order(order)
 * 
 *         if (not copy and typecode == self.ga.typecode and             # <<<<<<<<<<<<<<
 *             ((py_CHKFLAGS(self, GA_F_CONTIGUOUS) and ord == GA_F_ORDER) or
 *              (py_CHKFLAGS(self, GA_C_CONTIGUOUS) and ord == GA_C_ORDER))):
 */
  if (__pyx_t_3) {

    /* "pygpu/gpuarray.pyx":1859
 *             ((py_CHKFLAGS(self, GA_F_CONTIGUOUS) and ord == GA_F_ORDER) or
 *              (py_CHKFLAGS(self, GA_C_CONTIGUOUS) and ord == GA_C_ORDER))):
 *             return self             # <<<<<<<<<<<<<<
 * 
 *         res = self._empty_like_me(dtype=typecode, order=order)
 */
    __Pyx_XDECREF(__pyx_r);
    __Pyx_INCREF(((PyObject *)__pyx_v_self));
    __pyx_r = ((PyObject *)__pyx_v_self);
    goto __pyx_L0;

    /* "pygpu/gpuarray.pyx":1856
 *         cdef ga_order ord = to_ga_order(order)
 * 
 *         if (not copy and typecode == self.ga.typecode and             # <<<<<<<<<<<<<<
 *             ((py_CHKFLAGS(self, GA_F_CONTIGUOUS) and ord == GA_F_ORDER) or
 *              (py_CHKFLAGS(self, GA_C_CONTIGUOUS) and ord == GA_C_ORDER))):
 */
  }

  /* "pygpu/gpuarray.pyx":1861
 *             return self
 * 
 *         res = self._empty_like_me(dtype=typecode, order=order)             # <<<<<<<<<<<<<<
 *         array_move(res, self)
 *         return res
 */
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_empty_like_me); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1861, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __pyx_t_7 = __Pyx_PyDict_NewPresized(2); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 1861, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __pyx_t_8 = __Pyx_PyInt_From_int(__pyx_v_typecode); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1861, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  if (PyDict_SetItem(__pyx_t_7, __pyx_n_s_dtype, __pyx_t_8) < 0) __PYX_ERR(0, 1861, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  if (PyDict_SetItem(__pyx_t_7, __pyx_n_s_order, __pyx_v_order) < 0) __PYX_ERR(0, 1861, __pyx_L1_error)
  __pyx_t_8 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_empty_tuple, __pyx_t_7); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1861, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  if (!(likely(((__pyx_t_8) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_8, __pyx_ptype_5pygpu_8gpuarray_GpuArray))))) __PYX_ERR(0, 1861, __pyx_L1_error)
  __pyx_v_res = ((struct PyGpuArrayObject *)__pyx_t_8);
  __pyx_t_8 = 0;

  /* "pygpu/gpuarray.pyx":1862
 * 
 *         res = self._empty_like_me(dtype=typecode, order=order)
 *         array_move(res, self)             # <<<<<<<<<<<<<<
 *         return res
 * 
 */
  __pyx_t_1 = __pyx_f_5pygpu_8gpuarray_array_move(__pyx_v_res, __pyx_v_self); if (unlikely(__pyx_t_1 == ((int)-1))) __PYX_ERR(0, 1862, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":1863
 *         res = self._empty_like_me(dtype=typecode, order=order)
 *         array_move(res, self)
 *         return res             # <<<<<<<<<<<<<<
 * 
 *     def reshape(self, shape, order='C'):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_res));
  __pyx_r = ((PyObject *)__pyx_v_res);
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":1830
 *         return pygpu_view(self, cls)
 * 
 *     def astype(self, dtype, order='A', copy=True):             # <<<<<<<<<<<<<<
 *         """
 *         astype(dtype, order='A', copy=True)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_AddTraceback("pygpu.gpuarray.GpuArray.astype", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_res);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":1865
 *         return res
 * 
 *     def reshape(self, shape, order='C'):             # <<<<<<<<<<<<<<
 *         """
 *         reshape(shape, order='C')
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_8GpuArray_35reshape(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static char __pyx_doc_5pygpu_8gpuarray_8GpuArray_34reshape[] = "\n        reshape(shape, order='C')\n\n        Returns a new array with the given shape and order.\n\n        The new shape must have the same size (total number of\n        elements) as the current one.\n        ";
static PyObject *__pyx_pw_5pygpu_8gpuarray_8GpuArray_35reshape(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_shape = 0;
  PyObject *__pyx_v_order = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("reshape (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_shape,&__pyx_n_s_order,0};
    PyObject* values[2] = {0,0};
    values[1] = ((PyObject *)__pyx_n_s_C);
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_shape)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_order);
          if (value) { values[1] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "reshape") < 0)) __PYX_ERR(0, 1865, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    __pyx_v_shape = values[0];
    __pyx_v_order = values[1];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("reshape", 0, 1, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 1865, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("pygpu.gpuarray.GpuArray.reshape", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_8GpuArray_34reshape(((struct PyGpuArrayObject *)__pyx_v_self), __pyx_v_shape, __pyx_v_order);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_8GpuArray_34reshape(struct PyGpuArrayObject *__pyx_v_self, PyObject *__pyx_v_shape, PyObject *__pyx_v_order) {
  size_t *__pyx_v_newdims;
  unsigned int __pyx_v_nd;
  unsigned int __pyx_v_i;
  int __pyx_v_compute_axis;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  Py_ssize_t __pyx_t_4;
  int __pyx_t_5;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  PyObject *__pyx_t_8 = NULL;
  PyObject *__pyx_t_9 = NULL;
  int __pyx_t_10;
  unsigned int __pyx_t_11;
  unsigned int __pyx_t_12;
  size_t __pyx_t_13;
  ga_order __pyx_t_14;
  int __pyx_t_15;
  char const *__pyx_t_16;
  PyObject *__pyx_t_17 = NULL;
  PyObject *__pyx_t_18 = NULL;
  PyObject *__pyx_t_19 = NULL;
  __Pyx_RefNannySetupContext("reshape", 0);
  __Pyx_INCREF(__pyx_v_shape);

  /* "pygpu/gpuarray.pyx":1879
 *         cdef int compute_axis
 * 
 *         try:             # <<<<<<<<<<<<<<
 *             nd = <unsigned int>len(shape)
 *         except TypeError:
 */
  {
    __Pyx_PyThreadState_declare
    __Pyx_PyThreadState_assign
    __Pyx_ExceptionSave(&__pyx_t_1, &__pyx_t_2, &__pyx_t_3);
    __Pyx_XGOTREF(__pyx_t_1);
    __Pyx_XGOTREF(__pyx_t_2);
    __Pyx_XGOTREF(__pyx_t_3);
    /*try:*/ {

      /* "pygpu/gpuarray.pyx":1880
 * 
 *         try:
 *             nd = <unsigned int>len(shape)             # <<<<<<<<<<<<<<
 *         except TypeError:
 *             nd = 1
 */
      __pyx_t_4 = PyObject_Length(__pyx_v_shape); if (unlikely(__pyx_t_4 == ((Py_ssize_t)-1))) __PYX_ERR(0, 1880, __pyx_L3_error)
      __pyx_v_nd = ((unsigned int)__pyx_t_4);

      /* "pygpu/gpuarray.pyx":1879
 *         cdef int compute_axis
 * 
 *         try:             # <<<<<<<<<<<<<<
 *             nd = <unsigned int>len(shape)
 *         except TypeError:
 */
    }
    __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
    goto __pyx_L8_try_end;
    __pyx_L3_error:;

    /* "pygpu/gpuarray.pyx":1881
 *         try:
 *             nd = <unsigned int>len(shape)
 *         except TypeError:             # <<<<<<<<<<<<<<
 *             nd = 1
 *             shape = [shape]
 */
    __pyx_t_5 = __Pyx_PyErr_ExceptionMatches(__pyx_builtin_TypeError);
    if (__pyx_t_5) {
      __Pyx_AddTraceback("pygpu.gpuarray.GpuArray.reshape", __pyx_clineno, __pyx_lineno, __pyx_filename);
      if (__Pyx_GetException(&__pyx_t_6, &__pyx_t_7, &__pyx_t_8) < 0) __PYX_ERR(0, 1881, __pyx_L5_except_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_GOTREF(__pyx_t_7);
      __Pyx_GOTREF(__pyx_t_8);

      /* "pygpu/gpuarray.pyx":1882
 *             nd = <unsigned int>len(shape)
 *         except TypeError:
 *             nd = 1             # <<<<<<<<<<<<<<
 *             shape = [shape]
 * 
 */
      __pyx_v_nd = 1;

      /* "pygpu/gpuarray.pyx":1883
 *         except TypeError:
 *             nd = 1
 *             shape = [shape]             # <<<<<<<<<<<<<<
 * 
 *         newdims = <size_t *>calloc(nd, sizeof(size_t))
 */
      __pyx_t_9 = PyList_New(1); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 1883, __pyx_L5_except_error)
      __Pyx_GOTREF(__pyx_t_9);
      __Pyx_INCREF(__pyx_v_shape);
      __Pyx_GIVEREF(__pyx_v_shape);
      PyList_SET_ITEM(__pyx_t_9, 0, __pyx_v_shape);
      __Pyx_DECREF_SET(__pyx_v_shape, __pyx_t_9);
      __pyx_t_9 = 0;
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      goto __pyx_L4_exception_handled;
    }
    goto __pyx_L5_except_error;
    __pyx_L5_except_error:;

    /* "pygpu/gpuarray.pyx":1879
 *         cdef int compute_axis
 * 
 *         try:             # <<<<<<<<<<<<<<
 *             nd = <unsigned int>len(shape)
 *         except TypeError:
 */
    __Pyx_XGIVEREF(__pyx_t_1);
    __Pyx_XGIVEREF(__pyx_t_2);
    __Pyx_XGIVEREF(__pyx_t_3);
    __Pyx_ExceptionReset(__pyx_t_1, __pyx_t_2, __pyx_t_3);
    goto __pyx_L1_error;
    __pyx_L4_exception_handled:;
    __Pyx_XGIVEREF(__pyx_t_1);
    __Pyx_XGIVEREF(__pyx_t_2);
    __Pyx_XGIVEREF(__pyx_t_3);
    __Pyx_ExceptionReset(__pyx_t_1, __pyx_t_2, __pyx_t_3);
    __pyx_L8_try_end:;
  }

  /* "pygpu/gpuarray.pyx":1885
 *             shape = [shape]
 * 
 *         newdims = <size_t *>calloc(nd, sizeof(size_t))             # <<<<<<<<<<<<<<
 *         if newdims == NULL:
 *             raise MemoryError, "calloc"
 */
  __pyx_v_newdims = ((size_t *)calloc(__pyx_v_nd, (sizeof(size_t))));

  /* "pygpu/gpuarray.pyx":1886
 * 
 *         newdims = <size_t *>calloc(nd, sizeof(size_t))
 *         if newdims == NULL:             # <<<<<<<<<<<<<<
 *             raise MemoryError, "calloc"
 *         compute_axis = -1
 */
  __pyx_t_10 = ((__pyx_v_newdims == NULL) != 0);
  if (__pyx_t_10) {

    /* "pygpu/gpuarray.pyx":1887
 *         newdims = <size_t *>calloc(nd, sizeof(size_t))
 *         if newdims == NULL:
 *             raise MemoryError, "calloc"             # <<<<<<<<<<<<<<
 *         compute_axis = -1
 *         try:
 */
    __Pyx_Raise(__pyx_builtin_MemoryError, __pyx_n_s_calloc, 0, 0);
    __PYX_ERR(0, 1887, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":1886
 * 
 *         newdims = <size_t *>calloc(nd, sizeof(size_t))
 *         if newdims == NULL:             # <<<<<<<<<<<<<<
 *             raise MemoryError, "calloc"
 *         compute_axis = -1
 */
  }

  /* "pygpu/gpuarray.pyx":1888
 *         if newdims == NULL:
 *             raise MemoryError, "calloc"
 *         compute_axis = -1             # <<<<<<<<<<<<<<
 *         try:
 *             for i in range(nd):
 */
  __pyx_v_compute_axis = -1;

  /* "pygpu/gpuarray.pyx":1889
 *             raise MemoryError, "calloc"
 *         compute_axis = -1
 *         try:             # <<<<<<<<<<<<<<
 *             for i in range(nd):
 *                 if shape[i] == -1:
 */
  /*try:*/ {

    /* "pygpu/gpuarray.pyx":1890
 *         compute_axis = -1
 *         try:
 *             for i in range(nd):             # <<<<<<<<<<<<<<
 *                 if shape[i] == -1:
 *                     assert compute_axis == -1
 */
    __pyx_t_11 = __pyx_v_nd;
    for (__pyx_t_12 = 0; __pyx_t_12 < __pyx_t_11; __pyx_t_12+=1) {
      __pyx_v_i = __pyx_t_12;

      /* "pygpu/gpuarray.pyx":1891
 *         try:
 *             for i in range(nd):
 *                 if shape[i] == -1:             # <<<<<<<<<<<<<<
 *                     assert compute_axis == -1
 *                     compute_axis = i
 */
      __pyx_t_8 = __Pyx_GetItemInt(__pyx_v_shape, __pyx_v_i, unsigned int, 0, __Pyx_PyInt_From_unsigned_int, 0, 0, 1); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 1891, __pyx_L13_error)
      __Pyx_GOTREF(__pyx_t_8);
      __pyx_t_7 = __Pyx_PyInt_EqObjC(__pyx_t_8, __pyx_int_neg_1, -1L, 0); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 1891, __pyx_L13_error)
      __Pyx_GOTREF(__pyx_t_7);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __pyx_t_10 = __Pyx_PyObject_IsTrue(__pyx_t_7); if (unlikely(__pyx_t_10 < 0)) __PYX_ERR(0, 1891, __pyx_L13_error)
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      if (__pyx_t_10) {

        /* "pygpu/gpuarray.pyx":1892
 *             for i in range(nd):
 *                 if shape[i] == -1:
 *                     assert compute_axis == -1             # <<<<<<<<<<<<<<
 *                     compute_axis = i
 *                     newdims[i] = 1
 */
        #ifndef CYTHON_WITHOUT_ASSERTIONS
        if (unlikely(!Py_OptimizeFlag)) {
          if (unlikely(!((__pyx_v_compute_axis == -1L) != 0))) {
            PyErr_SetNone(PyExc_AssertionError);
            __PYX_ERR(0, 1892, __pyx_L13_error)
          }
        }
        #endif

        /* "pygpu/gpuarray.pyx":1893
 *                 if shape[i] == -1:
 *                     assert compute_axis == -1
 *                     compute_axis = i             # <<<<<<<<<<<<<<
 *                     newdims[i] = 1
 *                 else:
 */
        __pyx_v_compute_axis = __pyx_v_i;

        /* "pygpu/gpuarray.pyx":1894
 *                     assert compute_axis == -1
 *                     compute_axis = i
 *                     newdims[i] = 1             # <<<<<<<<<<<<<<
 *                 else:
 *                     newdims[i] = shape[i]
 */
        (__pyx_v_newdims[__pyx_v_i]) = 1;

        /* "pygpu/gpuarray.pyx":1891
 *         try:
 *             for i in range(nd):
 *                 if shape[i] == -1:             # <<<<<<<<<<<<<<
 *                     assert compute_axis == -1
 *                     compute_axis = i
 */
        goto __pyx_L17;
      }

      /* "pygpu/gpuarray.pyx":1896
 *                     newdims[i] = 1
 *                 else:
 *                     newdims[i] = shape[i]             # <<<<<<<<<<<<<<
 *             return pygpu_reshape(self, nd, newdims, to_ga_order(order), 0, compute_axis)
 *         finally:
 */
      /*else*/ {
        __pyx_t_7 = __Pyx_GetItemInt(__pyx_v_shape, __pyx_v_i, unsigned int, 0, __Pyx_PyInt_From_unsigned_int, 0, 0, 1); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 1896, __pyx_L13_error)
        __Pyx_GOTREF(__pyx_t_7);
        __pyx_t_13 = __Pyx_PyInt_As_size_t(__pyx_t_7); if (unlikely((__pyx_t_13 == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 1896, __pyx_L13_error)
        __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
        (__pyx_v_newdims[__pyx_v_i]) = __pyx_t_13;
      }
      __pyx_L17:;
    }

    /* "pygpu/gpuarray.pyx":1897
 *                 else:
 *                     newdims[i] = shape[i]
 *             return pygpu_reshape(self, nd, newdims, to_ga_order(order), 0, compute_axis)             # <<<<<<<<<<<<<<
 *         finally:
 *             free(newdims)
 */
    __Pyx_XDECREF(__pyx_r);
    __pyx_t_14 = __pyx_f_5pygpu_8gpuarray_to_ga_order(__pyx_v_order); if (unlikely(__pyx_t_14 == ((ga_order)((ga_order)-2L)))) __PYX_ERR(0, 1897, __pyx_L13_error)
    __pyx_t_7 = ((PyObject *)__pyx_f_5pygpu_8gpuarray_pygpu_reshape(__pyx_v_self, __pyx_v_nd, __pyx_v_newdims, __pyx_t_14, 0, __pyx_v_compute_axis)); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 1897, __pyx_L13_error)
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_r = __pyx_t_7;
    __pyx_t_7 = 0;
    goto __pyx_L12_return;
  }

  /* "pygpu/gpuarray.pyx":1899
 *             return pygpu_reshape(self, nd, newdims, to_ga_order(order), 0, compute_axis)
 *         finally:
 *             free(newdims)             # <<<<<<<<<<<<<<
 * 
 *     def transpose(self, *params):
 */
  /*finally:*/ {
    __pyx_L13_error:;
    /*exception exit:*/{
      __Pyx_PyThreadState_declare
      __Pyx_PyThreadState_assign
      __pyx_t_3 = 0; __pyx_t_2 = 0; __pyx_t_1 = 0; __pyx_t_17 = 0; __pyx_t_18 = 0; __pyx_t_19 = 0;
      __Pyx_XDECREF(__pyx_t_9); __pyx_t_9 = 0;
      __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
      __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
      __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
      if (PY_MAJOR_VERSION >= 3) __Pyx_ExceptionSwap(&__pyx_t_17, &__pyx_t_18, &__pyx_t_19);
      if ((PY_MAJOR_VERSION < 3) || unlikely(__Pyx_GetException(&__pyx_t_3, &__pyx_t_2, &__pyx_t_1) < 0)) __Pyx_ErrFetch(&__pyx_t_3, &__pyx_t_2, &__pyx_t_1);
      __Pyx_XGOTREF(__pyx_t_3);
      __Pyx_XGOTREF(__pyx_t_2);
      __Pyx_XGOTREF(__pyx_t_1);
      __Pyx_XGOTREF(__pyx_t_17);
      __Pyx_XGOTREF(__pyx_t_18);
      __Pyx_XGOTREF(__pyx_t_19);
      __pyx_t_5 = __pyx_lineno; __pyx_t_15 = __pyx_clineno; __pyx_t_16 = __pyx_filename;
      {
        free(__pyx_v_newdims);
      }
      if (PY_MAJOR_VERSION >= 3) {
        __Pyx_XGIVEREF(__pyx_t_17);
        __Pyx_XGIVEREF(__pyx_t_18);
        __Pyx_XGIVEREF(__pyx_t_19);
        __Pyx_ExceptionReset(__pyx_t_17, __pyx_t_18, __pyx_t_19);
      }
      __Pyx_XGIVEREF(__pyx_t_3);
      __Pyx_XGIVEREF(__pyx_t_2);
      __Pyx_XGIVEREF(__pyx_t_1);
      __Pyx_ErrRestore(__pyx_t_3, __pyx_t_2, __pyx_t_1);
      __pyx_t_3 = 0; __pyx_t_2 = 0; __pyx_t_1 = 0; __pyx_t_17 = 0; __pyx_t_18 = 0; __pyx_t_19 = 0;
      __pyx_lineno = __pyx_t_5; __pyx_clineno = __pyx_t_15; __pyx_filename = __pyx_t_16;
      goto __pyx_L1_error;
    }
    __pyx_L12_return: {
      __pyx_t_19 = __pyx_r;
      __pyx_r = 0;
      free(__pyx_v_newdims);
      __pyx_r = __pyx_t_19;
      __pyx_t_19 = 0;
      goto __pyx_L0;
    }
  }

  /* "pygpu/gpuarray.pyx":1865
 *         return res
 * 
 *     def reshape(self, shape, order='C'):             # <<<<<<<<<<<<<<
 *         """
 *         reshape(shape, order='C')
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_XDECREF(__pyx_t_9);
  __Pyx_AddTraceback("pygpu.gpuarray.GpuArray.reshape", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_shape);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":1901
 *             free(newdims)
 * 
 *     def transpose(self, *params):             # <<<<<<<<<<<<<<
 *         """
 *         transpose(*params)
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_8GpuArray_37transpose(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static char __pyx_doc_5pygpu_8gpuarray_8GpuArray_36transpose[] = "\n        transpose(*params)\n        ";
static PyObject *__pyx_pw_5pygpu_8gpuarray_8GpuArray_37transpose(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_params = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("transpose (wrapper)", 0);
  if (unlikely(__pyx_kwds) && unlikely(PyDict_Size(__pyx_kwds) > 0) && unlikely(!__Pyx_CheckKeywordStrings(__pyx_kwds, "transpose", 0))) return NULL;
  __Pyx_INCREF(__pyx_args);
  __pyx_v_params = __pyx_args;
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_8GpuArray_36transpose(((struct PyGpuArrayObject *)__pyx_v_self), __pyx_v_params);

  /* function exit code */
  __Pyx_XDECREF(__pyx_v_params);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_8GpuArray_36transpose(struct PyGpuArrayObject *__pyx_v_self, PyObject *__pyx_v_params) {
  unsigned int *__pyx_v_new_axes;
  unsigned int __pyx_v_i;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  Py_ssize_t __pyx_t_2;
  int __pyx_t_3;
  PyObject *__pyx_t_4 = NULL;
  int __pyx_t_5;
  int __pyx_t_6;
  PyObject *__pyx_t_7 = NULL;
  unsigned int __pyx_t_8;
  unsigned int __pyx_t_9;
  unsigned int __pyx_t_10;
  int __pyx_t_11;
  int __pyx_t_12;
  char const *__pyx_t_13;
  PyObject *__pyx_t_14 = NULL;
  PyObject *__pyx_t_15 = NULL;
  PyObject *__pyx_t_16 = NULL;
  PyObject *__pyx_t_17 = NULL;
  PyObject *__pyx_t_18 = NULL;
  PyObject *__pyx_t_19 = NULL;
  __Pyx_RefNannySetupContext("transpose", 0);
  __Pyx_INCREF(__pyx_v_params);

  /* "pygpu/gpuarray.pyx":1907
 *         cdef unsigned int *new_axes
 *         cdef unsigned int i
 *         if len(params) is 1 and isinstance(params[0], (tuple, list)):             # <<<<<<<<<<<<<<
 *             params = params[0]
 *         if params is () or params == (None,):
 */
  __pyx_t_2 = PyObject_Length(__pyx_v_params); if (unlikely(__pyx_t_2 == ((Py_ssize_t)-1))) __PYX_ERR(0, 1907, __pyx_L1_error)
  __pyx_t_3 = ((__pyx_t_2 == 1) != 0);
  if (__pyx_t_3) {
  } else {
    __pyx_t_1 = __pyx_t_3;
    goto __pyx_L4_bool_binop_done;
  }
  __pyx_t_4 = __Pyx_GetItemInt(__pyx_v_params, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1907, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_5 = PyTuple_Check(__pyx_t_4); 
  __pyx_t_6 = (__pyx_t_5 != 0);
  if (!__pyx_t_6) {
  } else {
    __pyx_t_3 = __pyx_t_6;
    goto __pyx_L6_bool_binop_done;
  }
  __pyx_t_6 = PyList_Check(__pyx_t_4); 
  __pyx_t_5 = (__pyx_t_6 != 0);
  __pyx_t_3 = __pyx_t_5;
  __pyx_L6_bool_binop_done:;
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_5 = (__pyx_t_3 != 0);
  __pyx_t_1 = __pyx_t_5;
  __pyx_L4_bool_binop_done:;
  if (__pyx_t_1) {

    /* "pygpu/gpuarray.pyx":1908
 *         cdef unsigned int i
 *         if len(params) is 1 and isinstance(params[0], (tuple, list)):
 *             params = params[0]             # <<<<<<<<<<<<<<
 *         if params is () or params == (None,):
 *             return pygpu_transpose(self, NULL)
 */
    __pyx_t_4 = __Pyx_GetItemInt_Tuple(__pyx_v_params, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1908, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF_SET(__pyx_v_params, __pyx_t_4);
    __pyx_t_4 = 0;

    /* "pygpu/gpuarray.pyx":1907
 *         cdef unsigned int *new_axes
 *         cdef unsigned int i
 *         if len(params) is 1 and isinstance(params[0], (tuple, list)):             # <<<<<<<<<<<<<<
 *             params = params[0]
 *         if params is () or params == (None,):
 */
  }

  /* "pygpu/gpuarray.pyx":1909
 *         if len(params) is 1 and isinstance(params[0], (tuple, list)):
 *             params = params[0]
 *         if params is () or params == (None,):             # <<<<<<<<<<<<<<
 *             return pygpu_transpose(self, NULL)
 *         else:
 */
  __pyx_t_5 = (__pyx_v_params == __pyx_empty_tuple);
  __pyx_t_3 = (__pyx_t_5 != 0);
  if (!__pyx_t_3) {
  } else {
    __pyx_t_1 = __pyx_t_3;
    goto __pyx_L9_bool_binop_done;
  }
  __pyx_t_4 = PyObject_RichCompare(__pyx_v_params, __pyx_tuple__26, Py_EQ); __Pyx_XGOTREF(__pyx_t_4); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1909, __pyx_L1_error)
  __pyx_t_3 = __Pyx_PyObject_IsTrue(__pyx_t_4); if (unlikely(__pyx_t_3 < 0)) __PYX_ERR(0, 1909, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_1 = __pyx_t_3;
  __pyx_L9_bool_binop_done:;
  if (__pyx_t_1) {

    /* "pygpu/gpuarray.pyx":1910
 *             params = params[0]
 *         if params is () or params == (None,):
 *             return pygpu_transpose(self, NULL)             # <<<<<<<<<<<<<<
 *         else:
 *             if len(params) != self.ga.nd:
 */
    __Pyx_XDECREF(__pyx_r);
    __pyx_t_4 = ((PyObject *)__pyx_f_5pygpu_8gpuarray_pygpu_transpose(__pyx_v_self, NULL)); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1910, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_r = __pyx_t_4;
    __pyx_t_4 = 0;
    goto __pyx_L0;

    /* "pygpu/gpuarray.pyx":1909
 *         if len(params) is 1 and isinstance(params[0], (tuple, list)):
 *             params = params[0]
 *         if params is () or params == (None,):             # <<<<<<<<<<<<<<
 *             return pygpu_transpose(self, NULL)
 *         else:
 */
  }

  /* "pygpu/gpuarray.pyx":1912
 *             return pygpu_transpose(self, NULL)
 *         else:
 *             if len(params) != self.ga.nd:             # <<<<<<<<<<<<<<
 *                 raise ValueError("axes don't match: " + str(params))
 *             new_axes = <unsigned int *>calloc(self.ga.nd, sizeof(unsigned int))
 */
  /*else*/ {
    __pyx_t_2 = PyObject_Length(__pyx_v_params); if (unlikely(__pyx_t_2 == ((Py_ssize_t)-1))) __PYX_ERR(0, 1912, __pyx_L1_error)
    __pyx_t_1 = ((__pyx_t_2 != __pyx_v_self->ga.nd) != 0);
    if (__pyx_t_1) {

      /* "pygpu/gpuarray.pyx":1913
 *         else:
 *             if len(params) != self.ga.nd:
 *                 raise ValueError("axes don't match: " + str(params))             # <<<<<<<<<<<<<<
 *             new_axes = <unsigned int *>calloc(self.ga.nd, sizeof(unsigned int))
 *             try:
 */
      __pyx_t_4 = PyTuple_New(1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1913, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_INCREF(__pyx_v_params);
      __Pyx_GIVEREF(__pyx_v_params);
      PyTuple_SET_ITEM(__pyx_t_4, 0, __pyx_v_params);
      __pyx_t_7 = __Pyx_PyObject_Call(((PyObject *)(&PyString_Type)), __pyx_t_4, NULL); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 1913, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __pyx_t_4 = PyNumber_Add(__pyx_kp_s_axes_don_t_match, __pyx_t_7); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1913, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      __pyx_t_7 = PyTuple_New(1); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 1913, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      __Pyx_GIVEREF(__pyx_t_4);
      PyTuple_SET_ITEM(__pyx_t_7, 0, __pyx_t_4);
      __pyx_t_4 = 0;
      __pyx_t_4 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_t_7, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1913, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      __Pyx_Raise(__pyx_t_4, 0, 0, 0);
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __PYX_ERR(0, 1913, __pyx_L1_error)

      /* "pygpu/gpuarray.pyx":1912
 *             return pygpu_transpose(self, NULL)
 *         else:
 *             if len(params) != self.ga.nd:             # <<<<<<<<<<<<<<
 *                 raise ValueError("axes don't match: " + str(params))
 *             new_axes = <unsigned int *>calloc(self.ga.nd, sizeof(unsigned int))
 */
    }

    /* "pygpu/gpuarray.pyx":1914
 *             if len(params) != self.ga.nd:
 *                 raise ValueError("axes don't match: " + str(params))
 *             new_axes = <unsigned int *>calloc(self.ga.nd, sizeof(unsigned int))             # <<<<<<<<<<<<<<
 *             try:
 *                 for i in range(self.ga.nd):
 */
    __pyx_v_new_axes = ((unsigned int *)calloc(__pyx_v_self->ga.nd, (sizeof(unsigned int))));

    /* "pygpu/gpuarray.pyx":1915
 *                 raise ValueError("axes don't match: " + str(params))
 *             new_axes = <unsigned int *>calloc(self.ga.nd, sizeof(unsigned int))
 *             try:             # <<<<<<<<<<<<<<
 *                 for i in range(self.ga.nd):
 *                     new_axes[i] = params[i]
 */
    /*try:*/ {

      /* "pygpu/gpuarray.pyx":1916
 *             new_axes = <unsigned int *>calloc(self.ga.nd, sizeof(unsigned int))
 *             try:
 *                 for i in range(self.ga.nd):             # <<<<<<<<<<<<<<
 *                     new_axes[i] = params[i]
 *                 return pygpu_transpose(self, new_axes)
 */
      __pyx_t_8 = __pyx_v_self->ga.nd;
      for (__pyx_t_9 = 0; __pyx_t_9 < __pyx_t_8; __pyx_t_9+=1) {
        __pyx_v_i = __pyx_t_9;

        /* "pygpu/gpuarray.pyx":1917
 *             try:
 *                 for i in range(self.ga.nd):
 *                     new_axes[i] = params[i]             # <<<<<<<<<<<<<<
 *                 return pygpu_transpose(self, new_axes)
 *             finally:
 */
        __pyx_t_4 = __Pyx_GetItemInt(__pyx_v_params, __pyx_v_i, unsigned int, 0, __Pyx_PyInt_From_unsigned_int, 0, 0, 1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1917, __pyx_L13_error)
        __Pyx_GOTREF(__pyx_t_4);
        __pyx_t_10 = __Pyx_PyInt_As_unsigned_int(__pyx_t_4); if (unlikely((__pyx_t_10 == (unsigned int)-1) && PyErr_Occurred())) __PYX_ERR(0, 1917, __pyx_L13_error)
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
        (__pyx_v_new_axes[__pyx_v_i]) = __pyx_t_10;
      }

      /* "pygpu/gpuarray.pyx":1918
 *                 for i in range(self.ga.nd):
 *                     new_axes[i] = params[i]
 *                 return pygpu_transpose(self, new_axes)             # <<<<<<<<<<<<<<
 *             finally:
 *                 free(new_axes)
 */
      __Pyx_XDECREF(__pyx_r);
      __pyx_t_4 = ((PyObject *)__pyx_f_5pygpu_8gpuarray_pygpu_transpose(__pyx_v_self, __pyx_v_new_axes)); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1918, __pyx_L13_error)
      __Pyx_GOTREF(__pyx_t_4);
      __pyx_r = __pyx_t_4;
      __pyx_t_4 = 0;
      goto __pyx_L12_return;
    }

    /* "pygpu/gpuarray.pyx":1920
 *                 return pygpu_transpose(self, new_axes)
 *             finally:
 *                 free(new_axes)             # <<<<<<<<<<<<<<
 * 
 *     def __len__(self):
 */
    /*finally:*/ {
      __pyx_L13_error:;
      /*exception exit:*/{
        __Pyx_PyThreadState_declare
        __Pyx_PyThreadState_assign
        __pyx_t_14 = 0; __pyx_t_15 = 0; __pyx_t_16 = 0; __pyx_t_17 = 0; __pyx_t_18 = 0; __pyx_t_19 = 0;
        __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
        __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
        if (PY_MAJOR_VERSION >= 3) __Pyx_ExceptionSwap(&__pyx_t_17, &__pyx_t_18, &__pyx_t_19);
        if ((PY_MAJOR_VERSION < 3) || unlikely(__Pyx_GetException(&__pyx_t_14, &__pyx_t_15, &__pyx_t_16) < 0)) __Pyx_ErrFetch(&__pyx_t_14, &__pyx_t_15, &__pyx_t_16);
        __Pyx_XGOTREF(__pyx_t_14);
        __Pyx_XGOTREF(__pyx_t_15);
        __Pyx_XGOTREF(__pyx_t_16);
        __Pyx_XGOTREF(__pyx_t_17);
        __Pyx_XGOTREF(__pyx_t_18);
        __Pyx_XGOTREF(__pyx_t_19);
        __pyx_t_11 = __pyx_lineno; __pyx_t_12 = __pyx_clineno; __pyx_t_13 = __pyx_filename;
        {
          free(__pyx_v_new_axes);
        }
        if (PY_MAJOR_VERSION >= 3) {
          __Pyx_XGIVEREF(__pyx_t_17);
          __Pyx_XGIVEREF(__pyx_t_18);
          __Pyx_XGIVEREF(__pyx_t_19);
          __Pyx_ExceptionReset(__pyx_t_17, __pyx_t_18, __pyx_t_19);
        }
        __Pyx_XGIVEREF(__pyx_t_14);
        __Pyx_XGIVEREF(__pyx_t_15);
        __Pyx_XGIVEREF(__pyx_t_16);
        __Pyx_ErrRestore(__pyx_t_14, __pyx_t_15, __pyx_t_16);
        __pyx_t_14 = 0; __pyx_t_15 = 0; __pyx_t_16 = 0; __pyx_t_17 = 0; __pyx_t_18 = 0; __pyx_t_19 = 0;
        __pyx_lineno = __pyx_t_11; __pyx_clineno = __pyx_t_12; __pyx_filename = __pyx_t_13;
        goto __pyx_L1_error;
      }
      __pyx_L12_return: {
        __pyx_t_19 = __pyx_r;
        __pyx_r = 0;
        free(__pyx_v_new_axes);
        __pyx_r = __pyx_t_19;
        __pyx_t_19 = 0;
        goto __pyx_L0;
      }
    }
  }

  /* "pygpu/gpuarray.pyx":1901
 *             free(newdims)
 * 
 *     def transpose(self, *params):             # <<<<<<<<<<<<<<
 *         """
 *         transpose(*params)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_AddTraceback("pygpu.gpuarray.GpuArray.transpose", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_params);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":1922
 *                 free(new_axes)
 * 
 *     def __len__(self):             # <<<<<<<<<<<<<<
 *         if self.ga.nd > 0:
 *             return self.ga.dimensions[0]
 */

/* Python wrapper */
static Py_ssize_t __pyx_pw_5pygpu_8gpuarray_8GpuArray_39__len__(PyObject *__pyx_v_self); /*proto*/
static Py_ssize_t __pyx_pw_5pygpu_8gpuarray_8GpuArray_39__len__(PyObject *__pyx_v_self) {
  Py_ssize_t __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__len__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_8GpuArray_38__len__(((struct PyGpuArrayObject *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static Py_ssize_t __pyx_pf_5pygpu_8gpuarray_8GpuArray_38__len__(struct PyGpuArrayObject *__pyx_v_self) {
  Py_ssize_t __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  __Pyx_RefNannySetupContext("__len__", 0);

  /* "pygpu/gpuarray.pyx":1923
 * 
 *     def __len__(self):
 *         if self.ga.nd > 0:             # <<<<<<<<<<<<<<
 *             return self.ga.dimensions[0]
 *         else:
 */
  __pyx_t_1 = ((__pyx_v_self->ga.nd > 0) != 0);
  if (__pyx_t_1) {

    /* "pygpu/gpuarray.pyx":1924
 *     def __len__(self):
 *         if self.ga.nd > 0:
 *             return self.ga.dimensions[0]             # <<<<<<<<<<<<<<
 *         else:
 *             raise TypeError, "len() of unsized object"
 */
    __pyx_r = (__pyx_v_self->ga.dimensions[0]);
    goto __pyx_L0;

    /* "pygpu/gpuarray.pyx":1923
 * 
 *     def __len__(self):
 *         if self.ga.nd > 0:             # <<<<<<<<<<<<<<
 *             return self.ga.dimensions[0]
 *         else:
 */
  }

  /* "pygpu/gpuarray.pyx":1926
 *             return self.ga.dimensions[0]
 *         else:
 *             raise TypeError, "len() of unsized object"             # <<<<<<<<<<<<<<
 * 
 *     def __getitem__(self, key):
 */
  /*else*/ {
    __Pyx_Raise(__pyx_builtin_TypeError, __pyx_kp_s_len_of_unsized_object, 0, 0);
    __PYX_ERR(0, 1926, __pyx_L1_error)
  }

  /* "pygpu/gpuarray.pyx":1922
 *                 free(new_axes)
 * 
 *     def __len__(self):             # <<<<<<<<<<<<<<
 *         if self.ga.nd > 0:
 *             return self.ga.dimensions[0]
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_AddTraceback("pygpu.gpuarray.GpuArray.__len__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":1928
 *             raise TypeError, "len() of unsized object"
 * 
 *     def __getitem__(self, key):             # <<<<<<<<<<<<<<
 *         cdef unsigned int i
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_8GpuArray_41__getitem__(PyObject *__pyx_v_self, PyObject *__pyx_v_key); /*proto*/
static PyObject *__pyx_pw_5pygpu_8gpuarray_8GpuArray_41__getitem__(PyObject *__pyx_v_self, PyObject *__pyx_v_key) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__getitem__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_8GpuArray_40__getitem__(((struct PyGpuArrayObject *)__pyx_v_self), ((PyObject *)__pyx_v_key));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}
static PyObject *__pyx_gb_5pygpu_8gpuarray_8GpuArray_11__getitem___2generator2(__pyx_CoroutineObject *__pyx_generator, CYTHON_UNUSED PyThreadState *__pyx_tstate, PyObject *__pyx_sent_value); /* proto */

/* "pygpu/gpuarray.pyx":1939
 *         # the same as a tuple.
 *         if isinstance(key, list):
 *             if any(isinstance(k, slice) or k is Ellipsis for k in key):             # <<<<<<<<<<<<<<
 *                 return self.__getitem__(tuple(key))
 *             else:
 */

static PyObject *__pyx_pf_5pygpu_8gpuarray_8GpuArray_11__getitem___genexpr(PyObject *__pyx_self) {
  struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_4_genexpr *__pyx_cur_scope;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("genexpr", 0);
  __pyx_cur_scope = (struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_4_genexpr *)__pyx_tp_new_5pygpu_8gpuarray___pyx_scope_struct_4_genexpr(__pyx_ptype_5pygpu_8gpuarray___pyx_scope_struct_4_genexpr, __pyx_empty_tuple, NULL);
  if (unlikely(!__pyx_cur_scope)) {
    __pyx_cur_scope = ((struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_4_genexpr *)Py_None);
    __Pyx_INCREF(Py_None);
    __PYX_ERR(0, 1939, __pyx_L1_error)
  } else {
    __Pyx_GOTREF(__pyx_cur_scope);
  }
  __pyx_cur_scope->__pyx_outer_scope = (struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_3___getitem__ *) __pyx_self;
  __Pyx_INCREF(((PyObject *)__pyx_cur_scope->__pyx_outer_scope));
  __Pyx_GIVEREF(__pyx_cur_scope->__pyx_outer_scope);
  {
    __pyx_CoroutineObject *gen = __Pyx_Generator_New((__pyx_coroutine_body_t) __pyx_gb_5pygpu_8gpuarray_8GpuArray_11__getitem___2generator2, (PyObject *) __pyx_cur_scope, __pyx_n_s_genexpr, __pyx_n_s_getitem___locals_genexpr, __pyx_n_s_pygpu_gpuarray); if (unlikely(!gen)) __PYX_ERR(0, 1939, __pyx_L1_error)
    __Pyx_DECREF(__pyx_cur_scope);
    __Pyx_RefNannyFinishContext();
    return (PyObject *) gen;
  }

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_AddTraceback("pygpu.gpuarray.GpuArray.__getitem__.genexpr", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __Pyx_DECREF(((PyObject *)__pyx_cur_scope));
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_gb_5pygpu_8gpuarray_8GpuArray_11__getitem___2generator2(__pyx_CoroutineObject *__pyx_generator, CYTHON_UNUSED PyThreadState *__pyx_tstate, PyObject *__pyx_sent_value) /* generator body */
{
  struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_4_genexpr *__pyx_cur_scope = ((struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_4_genexpr *)__pyx_generator->closure);
  PyObject *__pyx_r = NULL;
  PyObject *__pyx_t_1 = NULL;
  Py_ssize_t __pyx_t_2;
  PyObject *(*__pyx_t_3)(PyObject *);
  PyObject *__pyx_t_4 = NULL;
  int __pyx_t_5;
  int __pyx_t_6;
  int __pyx_t_7;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("genexpr", 0);
  switch (__pyx_generator->resume_label) {
    case 0: goto __pyx_L3_first_run;
    default: /* CPython raises the right error here */
    __Pyx_RefNannyFinishContext();
    return NULL;
  }
  __pyx_L3_first_run:;
  if (unlikely(!__pyx_sent_value)) __PYX_ERR(0, 1939, __pyx_L1_error)
  if (unlikely(!__pyx_cur_scope->__pyx_outer_scope->__pyx_v_key)) { __Pyx_RaiseClosureNameError("key"); __PYX_ERR(0, 1939, __pyx_L1_error) }
  if (likely(PyList_CheckExact(__pyx_cur_scope->__pyx_outer_scope->__pyx_v_key)) || PyTuple_CheckExact(__pyx_cur_scope->__pyx_outer_scope->__pyx_v_key)) {
    __pyx_t_1 = __pyx_cur_scope->__pyx_outer_scope->__pyx_v_key; __Pyx_INCREF(__pyx_t_1); __pyx_t_2 = 0;
    __pyx_t_3 = NULL;
  } else {
    __pyx_t_2 = -1; __pyx_t_1 = PyObject_GetIter(__pyx_cur_scope->__pyx_outer_scope->__pyx_v_key); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1939, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_3 = Py_TYPE(__pyx_t_1)->tp_iternext; if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1939, __pyx_L1_error)
  }
  for (;;) {
    if (likely(!__pyx_t_3)) {
      if (likely(PyList_CheckExact(__pyx_t_1))) {
        if (__pyx_t_2 >= PyList_GET_SIZE(__pyx_t_1)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_4 = PyList_GET_ITEM(__pyx_t_1, __pyx_t_2); __Pyx_INCREF(__pyx_t_4); __pyx_t_2++; if (unlikely(0 < 0)) __PYX_ERR(0, 1939, __pyx_L1_error)
        #else
        __pyx_t_4 = PySequence_ITEM(__pyx_t_1, __pyx_t_2); __pyx_t_2++; if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1939, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_4);
        #endif
      } else {
        if (__pyx_t_2 >= PyTuple_GET_SIZE(__pyx_t_1)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_4 = PyTuple_GET_ITEM(__pyx_t_1, __pyx_t_2); __Pyx_INCREF(__pyx_t_4); __pyx_t_2++; if (unlikely(0 < 0)) __PYX_ERR(0, 1939, __pyx_L1_error)
        #else
        __pyx_t_4 = PySequence_ITEM(__pyx_t_1, __pyx_t_2); __pyx_t_2++; if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1939, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_4);
        #endif
      }
    } else {
      __pyx_t_4 = __pyx_t_3(__pyx_t_1);
      if (unlikely(!__pyx_t_4)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
          else __PYX_ERR(0, 1939, __pyx_L1_error)
        }
        break;
      }
      __Pyx_GOTREF(__pyx_t_4);
    }
    __Pyx_XGOTREF(__pyx_cur_scope->__pyx_v_k);
    __Pyx_XDECREF_SET(__pyx_cur_scope->__pyx_v_k, __pyx_t_4);
    __Pyx_GIVEREF(__pyx_t_4);
    __pyx_t_4 = 0;
    __pyx_t_6 = PySlice_Check(__pyx_cur_scope->__pyx_v_k); 
    __pyx_t_7 = (__pyx_t_6 != 0);
    if (!__pyx_t_7) {
    } else {
      __pyx_t_5 = __pyx_t_7;
      goto __pyx_L7_bool_binop_done;
    }
    __pyx_t_7 = (__pyx_cur_scope->__pyx_v_k == __pyx_builtin_Ellipsis);
    __pyx_t_6 = (__pyx_t_7 != 0);
    __pyx_t_5 = __pyx_t_6;
    __pyx_L7_bool_binop_done:;
    if (__pyx_t_5) {
      __Pyx_XDECREF(__pyx_r);
      __Pyx_INCREF(Py_True);
      __pyx_r = Py_True;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      goto __pyx_L0;
    }
  }
  /*else*/ {
    __Pyx_XDECREF(__pyx_r);
    __Pyx_INCREF(Py_False);
    __pyx_r = Py_False;
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    goto __pyx_L0;
  }
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  CYTHON_MAYBE_UNUSED_VAR(__pyx_cur_scope);

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_AddTraceback("genexpr", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_Coroutine_ResetAndClearException(__pyx_generator);
  __pyx_generator->resume_label = -1;
  __Pyx_Coroutine_clear((PyObject*)__pyx_generator);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}
static PyObject *__pyx_gb_5pygpu_8gpuarray_8GpuArray_11__getitem___5generator3(__pyx_CoroutineObject *__pyx_generator, CYTHON_UNUSED PyThreadState *__pyx_tstate, PyObject *__pyx_sent_value); /* proto */

/* "pygpu/gpuarray.pyx":1949
 *             key = (key,)
 *         else:
 *             if all(isinstance(k, list) for k in key):             # <<<<<<<<<<<<<<
 *                 raise NotImplementedError, "fancy indexing not supported"
 * 
 */

static PyObject *__pyx_pf_5pygpu_8gpuarray_8GpuArray_11__getitem___3genexpr(PyObject *__pyx_self) {
  struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_5_genexpr *__pyx_cur_scope;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("genexpr", 0);
  __pyx_cur_scope = (struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_5_genexpr *)__pyx_tp_new_5pygpu_8gpuarray___pyx_scope_struct_5_genexpr(__pyx_ptype_5pygpu_8gpuarray___pyx_scope_struct_5_genexpr, __pyx_empty_tuple, NULL);
  if (unlikely(!__pyx_cur_scope)) {
    __pyx_cur_scope = ((struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_5_genexpr *)Py_None);
    __Pyx_INCREF(Py_None);
    __PYX_ERR(0, 1949, __pyx_L1_error)
  } else {
    __Pyx_GOTREF(__pyx_cur_scope);
  }
  __pyx_cur_scope->__pyx_outer_scope = (struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_3___getitem__ *) __pyx_self;
  __Pyx_INCREF(((PyObject *)__pyx_cur_scope->__pyx_outer_scope));
  __Pyx_GIVEREF(__pyx_cur_scope->__pyx_outer_scope);
  {
    __pyx_CoroutineObject *gen = __Pyx_Generator_New((__pyx_coroutine_body_t) __pyx_gb_5pygpu_8gpuarray_8GpuArray_11__getitem___5generator3, (PyObject *) __pyx_cur_scope, __pyx_n_s_genexpr, __pyx_n_s_getitem___locals_genexpr, __pyx_n_s_pygpu_gpuarray); if (unlikely(!gen)) __PYX_ERR(0, 1949, __pyx_L1_error)
    __Pyx_DECREF(__pyx_cur_scope);
    __Pyx_RefNannyFinishContext();
    return (PyObject *) gen;
  }

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_AddTraceback("pygpu.gpuarray.GpuArray.__getitem__.genexpr", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __Pyx_DECREF(((PyObject *)__pyx_cur_scope));
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_gb_5pygpu_8gpuarray_8GpuArray_11__getitem___5generator3(__pyx_CoroutineObject *__pyx_generator, CYTHON_UNUSED PyThreadState *__pyx_tstate, PyObject *__pyx_sent_value) /* generator body */
{
  struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_5_genexpr *__pyx_cur_scope = ((struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_5_genexpr *)__pyx_generator->closure);
  PyObject *__pyx_r = NULL;
  PyObject *__pyx_t_1 = NULL;
  Py_ssize_t __pyx_t_2;
  PyObject *(*__pyx_t_3)(PyObject *);
  PyObject *__pyx_t_4 = NULL;
  int __pyx_t_5;
  int __pyx_t_6;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("genexpr", 0);
  switch (__pyx_generator->resume_label) {
    case 0: goto __pyx_L3_first_run;
    default: /* CPython raises the right error here */
    __Pyx_RefNannyFinishContext();
    return NULL;
  }
  __pyx_L3_first_run:;
  if (unlikely(!__pyx_sent_value)) __PYX_ERR(0, 1949, __pyx_L1_error)
  if (unlikely(!__pyx_cur_scope->__pyx_outer_scope->__pyx_v_key)) { __Pyx_RaiseClosureNameError("key"); __PYX_ERR(0, 1949, __pyx_L1_error) }
  if (likely(PyList_CheckExact(__pyx_cur_scope->__pyx_outer_scope->__pyx_v_key)) || PyTuple_CheckExact(__pyx_cur_scope->__pyx_outer_scope->__pyx_v_key)) {
    __pyx_t_1 = __pyx_cur_scope->__pyx_outer_scope->__pyx_v_key; __Pyx_INCREF(__pyx_t_1); __pyx_t_2 = 0;
    __pyx_t_3 = NULL;
  } else {
    __pyx_t_2 = -1; __pyx_t_1 = PyObject_GetIter(__pyx_cur_scope->__pyx_outer_scope->__pyx_v_key); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1949, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_3 = Py_TYPE(__pyx_t_1)->tp_iternext; if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1949, __pyx_L1_error)
  }
  for (;;) {
    if (likely(!__pyx_t_3)) {
      if (likely(PyList_CheckExact(__pyx_t_1))) {
        if (__pyx_t_2 >= PyList_GET_SIZE(__pyx_t_1)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_4 = PyList_GET_ITEM(__pyx_t_1, __pyx_t_2); __Pyx_INCREF(__pyx_t_4); __pyx_t_2++; if (unlikely(0 < 0)) __PYX_ERR(0, 1949, __pyx_L1_error)
        #else
        __pyx_t_4 = PySequence_ITEM(__pyx_t_1, __pyx_t_2); __pyx_t_2++; if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1949, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_4);
        #endif
      } else {
        if (__pyx_t_2 >= PyTuple_GET_SIZE(__pyx_t_1)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_4 = PyTuple_GET_ITEM(__pyx_t_1, __pyx_t_2); __Pyx_INCREF(__pyx_t_4); __pyx_t_2++; if (unlikely(0 < 0)) __PYX_ERR(0, 1949, __pyx_L1_error)
        #else
        __pyx_t_4 = PySequence_ITEM(__pyx_t_1, __pyx_t_2); __pyx_t_2++; if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1949, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_4);
        #endif
      }
    } else {
      __pyx_t_4 = __pyx_t_3(__pyx_t_1);
      if (unlikely(!__pyx_t_4)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
          else __PYX_ERR(0, 1949, __pyx_L1_error)
        }
        break;
      }
      __Pyx_GOTREF(__pyx_t_4);
    }
    __Pyx_XGOTREF(__pyx_cur_scope->__pyx_v_k);
    __Pyx_XDECREF_SET(__pyx_cur_scope->__pyx_v_k, __pyx_t_4);
    __Pyx_GIVEREF(__pyx_t_4);
    __pyx_t_4 = 0;
    __pyx_t_5 = PyList_Check(__pyx_cur_scope->__pyx_v_k); 
    __pyx_t_6 = ((!(__pyx_t_5 != 0)) != 0);
    if (__pyx_t_6) {
      __Pyx_XDECREF(__pyx_r);
      __Pyx_INCREF(Py_False);
      __pyx_r = Py_False;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      goto __pyx_L0;
    }
  }
  /*else*/ {
    __Pyx_XDECREF(__pyx_r);
    __Pyx_INCREF(Py_True);
    __pyx_r = Py_True;
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    goto __pyx_L0;
  }
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  CYTHON_MAYBE_UNUSED_VAR(__pyx_cur_scope);

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_AddTraceback("genexpr", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_Coroutine_ResetAndClearException(__pyx_generator);
  __pyx_generator->resume_label = -1;
  __Pyx_Coroutine_clear((PyObject*)__pyx_generator);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}
static PyObject *__pyx_gb_5pygpu_8gpuarray_8GpuArray_11__getitem___8generator4(__pyx_CoroutineObject *__pyx_generator, CYTHON_UNUSED PyThreadState *__pyx_tstate, PyObject *__pyx_sent_value); /* proto */

/* "pygpu/gpuarray.pyx":1975
 * 
 *         # Remove the None entries for indexing
 *         getitem_idcs = tuple(k for k in key if k is not None)             # <<<<<<<<<<<<<<
 * 
 *         # For less than 1 index, fill up with slice(None) to the right.
 */

static PyObject *__pyx_pf_5pygpu_8gpuarray_8GpuArray_11__getitem___6genexpr(PyObject *__pyx_self) {
  struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_6_genexpr *__pyx_cur_scope;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("genexpr", 0);
  __pyx_cur_scope = (struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_6_genexpr *)__pyx_tp_new_5pygpu_8gpuarray___pyx_scope_struct_6_genexpr(__pyx_ptype_5pygpu_8gpuarray___pyx_scope_struct_6_genexpr, __pyx_empty_tuple, NULL);
  if (unlikely(!__pyx_cur_scope)) {
    __pyx_cur_scope = ((struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_6_genexpr *)Py_None);
    __Pyx_INCREF(Py_None);
    __PYX_ERR(0, 1975, __pyx_L1_error)
  } else {
    __Pyx_GOTREF(__pyx_cur_scope);
  }
  __pyx_cur_scope->__pyx_outer_scope = (struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_3___getitem__ *) __pyx_self;
  __Pyx_INCREF(((PyObject *)__pyx_cur_scope->__pyx_outer_scope));
  __Pyx_GIVEREF(__pyx_cur_scope->__pyx_outer_scope);
  {
    __pyx_CoroutineObject *gen = __Pyx_Generator_New((__pyx_coroutine_body_t) __pyx_gb_5pygpu_8gpuarray_8GpuArray_11__getitem___8generator4, (PyObject *) __pyx_cur_scope, __pyx_n_s_genexpr, __pyx_n_s_getitem___locals_genexpr, __pyx_n_s_pygpu_gpuarray); if (unlikely(!gen)) __PYX_ERR(0, 1975, __pyx_L1_error)
    __Pyx_DECREF(__pyx_cur_scope);
    __Pyx_RefNannyFinishContext();
    return (PyObject *) gen;
  }

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_AddTraceback("pygpu.gpuarray.GpuArray.__getitem__.genexpr", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __Pyx_DECREF(((PyObject *)__pyx_cur_scope));
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_gb_5pygpu_8gpuarray_8GpuArray_11__getitem___8generator4(__pyx_CoroutineObject *__pyx_generator, CYTHON_UNUSED PyThreadState *__pyx_tstate, PyObject *__pyx_sent_value) /* generator body */
{
  struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_6_genexpr *__pyx_cur_scope = ((struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_6_genexpr *)__pyx_generator->closure);
  PyObject *__pyx_r = NULL;
  PyObject *__pyx_t_1 = NULL;
  Py_ssize_t __pyx_t_2;
  PyObject *(*__pyx_t_3)(PyObject *);
  PyObject *__pyx_t_4 = NULL;
  int __pyx_t_5;
  int __pyx_t_6;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("genexpr", 0);
  switch (__pyx_generator->resume_label) {
    case 0: goto __pyx_L3_first_run;
    case 1: goto __pyx_L7_resume_from_yield;
    default: /* CPython raises the right error here */
    __Pyx_RefNannyFinishContext();
    return NULL;
  }
  __pyx_L3_first_run:;
  if (unlikely(!__pyx_sent_value)) __PYX_ERR(0, 1975, __pyx_L1_error)
  if (unlikely(!__pyx_cur_scope->__pyx_outer_scope->__pyx_v_key)) { __Pyx_RaiseClosureNameError("key"); __PYX_ERR(0, 1975, __pyx_L1_error) }
  if (likely(PyList_CheckExact(__pyx_cur_scope->__pyx_outer_scope->__pyx_v_key)) || PyTuple_CheckExact(__pyx_cur_scope->__pyx_outer_scope->__pyx_v_key)) {
    __pyx_t_1 = __pyx_cur_scope->__pyx_outer_scope->__pyx_v_key; __Pyx_INCREF(__pyx_t_1); __pyx_t_2 = 0;
    __pyx_t_3 = NULL;
  } else {
    __pyx_t_2 = -1; __pyx_t_1 = PyObject_GetIter(__pyx_cur_scope->__pyx_outer_scope->__pyx_v_key); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1975, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_3 = Py_TYPE(__pyx_t_1)->tp_iternext; if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1975, __pyx_L1_error)
  }
  for (;;) {
    if (likely(!__pyx_t_3)) {
      if (likely(PyList_CheckExact(__pyx_t_1))) {
        if (__pyx_t_2 >= PyList_GET_SIZE(__pyx_t_1)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_4 = PyList_GET_ITEM(__pyx_t_1, __pyx_t_2); __Pyx_INCREF(__pyx_t_4); __pyx_t_2++; if (unlikely(0 < 0)) __PYX_ERR(0, 1975, __pyx_L1_error)
        #else
        __pyx_t_4 = PySequence_ITEM(__pyx_t_1, __pyx_t_2); __pyx_t_2++; if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1975, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_4);
        #endif
      } else {
        if (__pyx_t_2 >= PyTuple_GET_SIZE(__pyx_t_1)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_4 = PyTuple_GET_ITEM(__pyx_t_1, __pyx_t_2); __Pyx_INCREF(__pyx_t_4); __pyx_t_2++; if (unlikely(0 < 0)) __PYX_ERR(0, 1975, __pyx_L1_error)
        #else
        __pyx_t_4 = PySequence_ITEM(__pyx_t_1, __pyx_t_2); __pyx_t_2++; if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1975, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_4);
        #endif
      }
    } else {
      __pyx_t_4 = __pyx_t_3(__pyx_t_1);
      if (unlikely(!__pyx_t_4)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
          else __PYX_ERR(0, 1975, __pyx_L1_error)
        }
        break;
      }
      __Pyx_GOTREF(__pyx_t_4);
    }
    __Pyx_XGOTREF(__pyx_cur_scope->__pyx_v_k);
    __Pyx_XDECREF_SET(__pyx_cur_scope->__pyx_v_k, __pyx_t_4);
    __Pyx_GIVEREF(__pyx_t_4);
    __pyx_t_4 = 0;
    __pyx_t_5 = (__pyx_cur_scope->__pyx_v_k != Py_None);
    __pyx_t_6 = (__pyx_t_5 != 0);
    if (__pyx_t_6) {
      __Pyx_INCREF(__pyx_cur_scope->__pyx_v_k);
      __pyx_r = __pyx_cur_scope->__pyx_v_k;
      __Pyx_XGIVEREF(__pyx_t_1);
      __pyx_cur_scope->__pyx_t_0 = __pyx_t_1;
      __pyx_cur_scope->__pyx_t_1 = __pyx_t_2;
      __pyx_cur_scope->__pyx_t_2 = __pyx_t_3;
      __Pyx_XGIVEREF(__pyx_r);
      __Pyx_RefNannyFinishContext();
      __Pyx_Coroutine_ResetAndClearException(__pyx_generator);
      /* return from generator, yielding value */
      __pyx_generator->resume_label = 1;
      return __pyx_r;
      __pyx_L7_resume_from_yield:;
      __pyx_t_1 = __pyx_cur_scope->__pyx_t_0;
      __pyx_cur_scope->__pyx_t_0 = 0;
      __Pyx_XGOTREF(__pyx_t_1);
      __pyx_t_2 = __pyx_cur_scope->__pyx_t_1;
      __pyx_t_3 = __pyx_cur_scope->__pyx_t_2;
      if (unlikely(!__pyx_sent_value)) __PYX_ERR(0, 1975, __pyx_L1_error)
    }
  }
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  CYTHON_MAYBE_UNUSED_VAR(__pyx_cur_scope);

  /* function exit code */
  PyErr_SetNone(PyExc_StopIteration);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_AddTraceback("genexpr", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_r); __pyx_r = 0;
  __Pyx_Coroutine_ResetAndClearException(__pyx_generator);
  __pyx_generator->resume_label = -1;
  __Pyx_Coroutine_clear((PyObject*)__pyx_generator);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":1928
 *             raise TypeError, "len() of unsized object"
 * 
 *     def __getitem__(self, key):             # <<<<<<<<<<<<<<
 *         cdef unsigned int i
 * 
 */

static PyObject *__pyx_pf_5pygpu_8gpuarray_8GpuArray_40__getitem__(struct PyGpuArrayObject *__pyx_v_self, PyObject *__pyx_v_key) {
  struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_3___getitem__ *__pyx_cur_scope;
  unsigned int __pyx_v_i;
  PyObject *__pyx_v_ell_idx = NULL;
  size_t __pyx_v_num_slcs;
  PyObject *__pyx_v_fill_slices = NULL;
  PyObject *__pyx_v_getitem_idcs = NULL;
  PyObject *__pyx_v_sliced = NULL;
  PyObject *__pyx_v_new_shape = NULL;
  PyObject *__pyx_v_k = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_t_2;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  PyObject *__pyx_t_8 = NULL;
  PyObject *__pyx_t_9 = NULL;
  PyObject *__pyx_t_10 = NULL;
  int __pyx_t_11;
  Py_ssize_t __pyx_t_12;
  PyObject *(*__pyx_t_13)(PyObject *);
  int __pyx_t_14;
  __Pyx_RefNannySetupContext("__getitem__", 0);
  __pyx_cur_scope = (struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_3___getitem__ *)__pyx_tp_new_5pygpu_8gpuarray___pyx_scope_struct_3___getitem__(__pyx_ptype_5pygpu_8gpuarray___pyx_scope_struct_3___getitem__, __pyx_empty_tuple, NULL);
  if (unlikely(!__pyx_cur_scope)) {
    __pyx_cur_scope = ((struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_3___getitem__ *)Py_None);
    __Pyx_INCREF(Py_None);
    __PYX_ERR(0, 1928, __pyx_L1_error)
  } else {
    __Pyx_GOTREF(__pyx_cur_scope);
  }
  __pyx_cur_scope->__pyx_v_key = __pyx_v_key;
  __Pyx_INCREF(__pyx_cur_scope->__pyx_v_key);
  __Pyx_GIVEREF(__pyx_cur_scope->__pyx_v_key);

  /* "pygpu/gpuarray.pyx":1931
 *         cdef unsigned int i
 * 
 *         if key is Ellipsis:             # <<<<<<<<<<<<<<
 *             return self.__cgetitem__(key)
 * 
 */
  __pyx_t_1 = (__pyx_cur_scope->__pyx_v_key == __pyx_builtin_Ellipsis);
  __pyx_t_2 = (__pyx_t_1 != 0);
  if (__pyx_t_2) {

    /* "pygpu/gpuarray.pyx":1932
 * 
 *         if key is Ellipsis:
 *             return self.__cgetitem__(key)             # <<<<<<<<<<<<<<
 * 
 *         # A list or a sequence of list should trigger "fancy" indexing.
 */
    __Pyx_XDECREF(__pyx_r);
    __pyx_t_3 = __pyx_cur_scope->__pyx_v_key;
    __Pyx_INCREF(__pyx_t_3);
    __pyx_t_4 = ((struct __pyx_vtabstruct_5pygpu_8gpuarray_GpuArray *)__pyx_v_self->__pyx_vtab)->__pyx___cgetitem__(__pyx_v_self, __pyx_t_3); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1932, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_r = __pyx_t_4;
    __pyx_t_4 = 0;
    goto __pyx_L0;

    /* "pygpu/gpuarray.pyx":1931
 *         cdef unsigned int i
 * 
 *         if key is Ellipsis:             # <<<<<<<<<<<<<<
 *             return self.__cgetitem__(key)
 * 
 */
  }

  /* "pygpu/gpuarray.pyx":1938
 *         # Conversely, if a list contains slice or Ellipsis objects, it behaves
 *         # the same as a tuple.
 *         if isinstance(key, list):             # <<<<<<<<<<<<<<
 *             if any(isinstance(k, slice) or k is Ellipsis for k in key):
 *                 return self.__getitem__(tuple(key))
 */
  __pyx_t_4 = __pyx_cur_scope->__pyx_v_key;
  __Pyx_INCREF(__pyx_t_4);
  __pyx_t_2 = PyList_Check(__pyx_t_4); 
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_1 = (__pyx_t_2 != 0);
  if (__pyx_t_1) {

    /* "pygpu/gpuarray.pyx":1939
 *         # the same as a tuple.
 *         if isinstance(key, list):
 *             if any(isinstance(k, slice) or k is Ellipsis for k in key):             # <<<<<<<<<<<<<<
 *                 return self.__getitem__(tuple(key))
 *             else:
 */
    __pyx_t_4 = __pyx_pf_5pygpu_8gpuarray_8GpuArray_11__getitem___genexpr(((PyObject*)__pyx_cur_scope)); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1939, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_3 = __Pyx_Generator_Next(__pyx_t_4); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1939, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_t_1 = __Pyx_PyObject_IsTrue(__pyx_t_3); if (unlikely(__pyx_t_1 < 0)) __PYX_ERR(0, 1939, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    if (__pyx_t_1) {

      /* "pygpu/gpuarray.pyx":1940
 *         if isinstance(key, list):
 *             if any(isinstance(k, slice) or k is Ellipsis for k in key):
 *                 return self.__getitem__(tuple(key))             # <<<<<<<<<<<<<<
 *             else:
 *                 raise NotImplementedError, "fancy indexing not supported"
 */
      __Pyx_XDECREF(__pyx_r);
      __pyx_t_4 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_getitem); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1940, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __pyx_t_5 = __Pyx_PySequence_Tuple(__pyx_cur_scope->__pyx_v_key); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 1940, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_5);
      __pyx_t_6 = NULL;
      if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_4))) {
        __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_4);
        if (likely(__pyx_t_6)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_4);
          __Pyx_INCREF(__pyx_t_6);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_4, function);
        }
      }
      if (!__pyx_t_6) {
        __pyx_t_3 = __Pyx_PyObject_CallOneArg(__pyx_t_4, __pyx_t_5); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1940, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
        __Pyx_GOTREF(__pyx_t_3);
      } else {
        #if CYTHON_FAST_PYCALL
        if (PyFunction_Check(__pyx_t_4)) {
          PyObject *__pyx_temp[2] = {__pyx_t_6, __pyx_t_5};
          __pyx_t_3 = __Pyx_PyFunction_FastCall(__pyx_t_4, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1940, __pyx_L1_error)
          __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
          __Pyx_GOTREF(__pyx_t_3);
          __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
        } else
        #endif
        #if CYTHON_FAST_PYCCALL
        if (__Pyx_PyFastCFunction_Check(__pyx_t_4)) {
          PyObject *__pyx_temp[2] = {__pyx_t_6, __pyx_t_5};
          __pyx_t_3 = __Pyx_PyCFunction_FastCall(__pyx_t_4, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1940, __pyx_L1_error)
          __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
          __Pyx_GOTREF(__pyx_t_3);
          __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
        } else
        #endif
        {
          __pyx_t_7 = PyTuple_New(1+1); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 1940, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_7);
          __Pyx_GIVEREF(__pyx_t_6); PyTuple_SET_ITEM(__pyx_t_7, 0, __pyx_t_6); __pyx_t_6 = NULL;
          __Pyx_GIVEREF(__pyx_t_5);
          PyTuple_SET_ITEM(__pyx_t_7, 0+1, __pyx_t_5);
          __pyx_t_5 = 0;
          __pyx_t_3 = __Pyx_PyObject_Call(__pyx_t_4, __pyx_t_7, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1940, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_3);
          __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
        }
      }
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __pyx_r = __pyx_t_3;
      __pyx_t_3 = 0;
      goto __pyx_L0;

      /* "pygpu/gpuarray.pyx":1939
 *         # the same as a tuple.
 *         if isinstance(key, list):
 *             if any(isinstance(k, slice) or k is Ellipsis for k in key):             # <<<<<<<<<<<<<<
 *                 return self.__getitem__(tuple(key))
 *             else:
 */
    }

    /* "pygpu/gpuarray.pyx":1942
 *                 return self.__getitem__(tuple(key))
 *             else:
 *                 raise NotImplementedError, "fancy indexing not supported"             # <<<<<<<<<<<<<<
 * 
 *         try:
 */
    /*else*/ {
      __Pyx_Raise(__pyx_builtin_NotImplementedError, __pyx_kp_s_fancy_indexing_not_supported, 0, 0);
      __PYX_ERR(0, 1942, __pyx_L1_error)
    }

    /* "pygpu/gpuarray.pyx":1938
 *         # Conversely, if a list contains slice or Ellipsis objects, it behaves
 *         # the same as a tuple.
 *         if isinstance(key, list):             # <<<<<<<<<<<<<<
 *             if any(isinstance(k, slice) or k is Ellipsis for k in key):
 *                 return self.__getitem__(tuple(key))
 */
  }

  /* "pygpu/gpuarray.pyx":1944
 *                 raise NotImplementedError, "fancy indexing not supported"
 * 
 *         try:             # <<<<<<<<<<<<<<
 *             iter(key)
 *         except TypeError:
 */
  {
    __Pyx_PyThreadState_declare
    __Pyx_PyThreadState_assign
    __Pyx_ExceptionSave(&__pyx_t_8, &__pyx_t_9, &__pyx_t_10);
    __Pyx_XGOTREF(__pyx_t_8);
    __Pyx_XGOTREF(__pyx_t_9);
    __Pyx_XGOTREF(__pyx_t_10);
    /*try:*/ {

      /* "pygpu/gpuarray.pyx":1945
 * 
 *         try:
 *             iter(key)             # <<<<<<<<<<<<<<
 *         except TypeError:
 *             key = (key,)
 */
      __pyx_t_3 = __pyx_cur_scope->__pyx_v_key;
      __Pyx_INCREF(__pyx_t_3);
      __pyx_t_4 = PyObject_GetIter(__pyx_t_3); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1945, __pyx_L6_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;

      /* "pygpu/gpuarray.pyx":1944
 *                 raise NotImplementedError, "fancy indexing not supported"
 * 
 *         try:             # <<<<<<<<<<<<<<
 *             iter(key)
 *         except TypeError:
 */
    }

    /* "pygpu/gpuarray.pyx":1949
 *             key = (key,)
 *         else:
 *             if all(isinstance(k, list) for k in key):             # <<<<<<<<<<<<<<
 *                 raise NotImplementedError, "fancy indexing not supported"
 * 
 */
    /*else:*/ {
      __pyx_t_4 = __pyx_pf_5pygpu_8gpuarray_8GpuArray_11__getitem___3genexpr(((PyObject*)__pyx_cur_scope)); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1949, __pyx_L8_except_error)
      __Pyx_GOTREF(__pyx_t_4);
      __pyx_t_3 = __Pyx_Generator_Next(__pyx_t_4); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1949, __pyx_L8_except_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __pyx_t_1 = __Pyx_PyObject_IsTrue(__pyx_t_3); if (unlikely(__pyx_t_1 < 0)) __PYX_ERR(0, 1949, __pyx_L8_except_error)
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      if (__pyx_t_1) {

        /* "pygpu/gpuarray.pyx":1950
 *         else:
 *             if all(isinstance(k, list) for k in key):
 *                 raise NotImplementedError, "fancy indexing not supported"             # <<<<<<<<<<<<<<
 * 
 *             key = tuple(key)
 */
        __Pyx_Raise(__pyx_builtin_NotImplementedError, __pyx_kp_s_fancy_indexing_not_supported, 0, 0);
        __PYX_ERR(0, 1950, __pyx_L8_except_error)

        /* "pygpu/gpuarray.pyx":1949
 *             key = (key,)
 *         else:
 *             if all(isinstance(k, list) for k in key):             # <<<<<<<<<<<<<<
 *                 raise NotImplementedError, "fancy indexing not supported"
 * 
 */
      }

      /* "pygpu/gpuarray.pyx":1952
 *                 raise NotImplementedError, "fancy indexing not supported"
 * 
 *             key = tuple(key)             # <<<<<<<<<<<<<<
 * 
 *         # Need to massage Ellipsis here, to avoid packing it into a tuple.
 */
      __pyx_t_3 = __Pyx_PySequence_Tuple(__pyx_cur_scope->__pyx_v_key); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1952, __pyx_L8_except_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_GOTREF(__pyx_cur_scope->__pyx_v_key);
      __Pyx_DECREF_SET(__pyx_cur_scope->__pyx_v_key, __pyx_t_3);
      __Pyx_GIVEREF(__pyx_t_3);
      __pyx_t_3 = 0;
    }
    __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
    __Pyx_XDECREF(__pyx_t_9); __pyx_t_9 = 0;
    __Pyx_XDECREF(__pyx_t_10); __pyx_t_10 = 0;
    goto __pyx_L11_try_end;
    __pyx_L6_error:;
    __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
    __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
    __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;

    /* "pygpu/gpuarray.pyx":1946
 *         try:
 *             iter(key)
 *         except TypeError:             # <<<<<<<<<<<<<<
 *             key = (key,)
 *         else:
 */
    __pyx_t_11 = __Pyx_PyErr_ExceptionMatches(__pyx_builtin_TypeError);
    if (__pyx_t_11) {
      __Pyx_AddTraceback("pygpu.gpuarray.GpuArray.__getitem__", __pyx_clineno, __pyx_lineno, __pyx_filename);
      if (__Pyx_GetException(&__pyx_t_3, &__pyx_t_4, &__pyx_t_7) < 0) __PYX_ERR(0, 1946, __pyx_L8_except_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_GOTREF(__pyx_t_7);

      /* "pygpu/gpuarray.pyx":1947
 *             iter(key)
 *         except TypeError:
 *             key = (key,)             # <<<<<<<<<<<<<<
 *         else:
 *             if all(isinstance(k, list) for k in key):
 */
      __pyx_t_5 = PyTuple_New(1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 1947, __pyx_L8_except_error)
      __Pyx_GOTREF(__pyx_t_5);
      __Pyx_INCREF(__pyx_cur_scope->__pyx_v_key);
      __Pyx_GIVEREF(__pyx_cur_scope->__pyx_v_key);
      PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_cur_scope->__pyx_v_key);
      __Pyx_GOTREF(__pyx_cur_scope->__pyx_v_key);
      __Pyx_DECREF_SET(__pyx_cur_scope->__pyx_v_key, __pyx_t_5);
      __Pyx_GIVEREF(__pyx_t_5);
      __pyx_t_5 = 0;
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      goto __pyx_L7_exception_handled;
    }
    goto __pyx_L8_except_error;
    __pyx_L8_except_error:;

    /* "pygpu/gpuarray.pyx":1944
 *                 raise NotImplementedError, "fancy indexing not supported"
 * 
 *         try:             # <<<<<<<<<<<<<<
 *             iter(key)
 *         except TypeError:
 */
    __Pyx_XGIVEREF(__pyx_t_8);
    __Pyx_XGIVEREF(__pyx_t_9);
    __Pyx_XGIVEREF(__pyx_t_10);
    __Pyx_ExceptionReset(__pyx_t_8, __pyx_t_9, __pyx_t_10);
    goto __pyx_L1_error;
    __pyx_L7_exception_handled:;
    __Pyx_XGIVEREF(__pyx_t_8);
    __Pyx_XGIVEREF(__pyx_t_9);
    __Pyx_XGIVEREF(__pyx_t_10);
    __Pyx_ExceptionReset(__pyx_t_8, __pyx_t_9, __pyx_t_10);
    __pyx_L11_try_end:;
  }

  /* "pygpu/gpuarray.pyx":1955
 * 
 *         # Need to massage Ellipsis here, to avoid packing it into a tuple.
 *         if countis(key, Ellipsis) > 1:             # <<<<<<<<<<<<<<
 *             raise IndexError, "cannot use more than one Ellipsis"
 * 
 */
  __pyx_t_7 = __pyx_cur_scope->__pyx_v_key;
  __Pyx_INCREF(__pyx_t_7);
  __pyx_t_1 = ((__pyx_f_5pygpu_8gpuarray_countis(__pyx_t_7, __pyx_builtin_Ellipsis) > 1) != 0);
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  if (__pyx_t_1) {

    /* "pygpu/gpuarray.pyx":1956
 *         # Need to massage Ellipsis here, to avoid packing it into a tuple.
 *         if countis(key, Ellipsis) > 1:
 *             raise IndexError, "cannot use more than one Ellipsis"             # <<<<<<<<<<<<<<
 * 
 *         # The following code replaces an Ellipsis found in the key by
 */
    __Pyx_Raise(__pyx_builtin_IndexError, __pyx_kp_s_cannot_use_more_than_one_Ellipsi, 0, 0);
    __PYX_ERR(0, 1956, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":1955
 * 
 *         # Need to massage Ellipsis here, to avoid packing it into a tuple.
 *         if countis(key, Ellipsis) > 1:             # <<<<<<<<<<<<<<
 *             raise IndexError, "cannot use more than one Ellipsis"
 * 
 */
  }

  /* "pygpu/gpuarray.pyx":1963
 *         # dimension with a[..., 1:] on any array (including 1-dim).  This
 *         # is also required for numpy compat.
 *         try:             # <<<<<<<<<<<<<<
 *             ell_idx = key.index(Ellipsis)
 *         except ValueError:
 */
  {
    __Pyx_PyThreadState_declare
    __Pyx_PyThreadState_assign
    __Pyx_ExceptionSave(&__pyx_t_10, &__pyx_t_9, &__pyx_t_8);
    __Pyx_XGOTREF(__pyx_t_10);
    __Pyx_XGOTREF(__pyx_t_9);
    __Pyx_XGOTREF(__pyx_t_8);
    /*try:*/ {

      /* "pygpu/gpuarray.pyx":1964
 *         # is also required for numpy compat.
 *         try:
 *             ell_idx = key.index(Ellipsis)             # <<<<<<<<<<<<<<
 *         except ValueError:
 *             pass
 */
      __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_cur_scope->__pyx_v_key, __pyx_n_s_index); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 1964, __pyx_L16_error)
      __Pyx_GOTREF(__pyx_t_7);
      __pyx_t_4 = __Pyx_PyObject_Call(__pyx_t_7, __pyx_tuple__27, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1964, __pyx_L16_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      __pyx_v_ell_idx = __pyx_t_4;
      __pyx_t_4 = 0;

      /* "pygpu/gpuarray.pyx":1963
 *         # dimension with a[..., 1:] on any array (including 1-dim).  This
 *         # is also required for numpy compat.
 *         try:             # <<<<<<<<<<<<<<
 *             ell_idx = key.index(Ellipsis)
 *         except ValueError:
 */
    }

    /* "pygpu/gpuarray.pyx":1970
 *             # Need number of axes minus missing dimensions extra slice(None)
 *             # objects, not counting None entries and the Ellipsis itself
 *             num_slcs = self.ga.nd - (len(key) - countis(key, None) - 1)             # <<<<<<<<<<<<<<
 *             fill_slices = (slice(None),) * num_slcs
 *             key = key[:ell_idx] + fill_slices + key[ell_idx + 1:]
 */
    /*else:*/ {
      __pyx_t_4 = __pyx_cur_scope->__pyx_v_key;
      __Pyx_INCREF(__pyx_t_4);
      __pyx_t_12 = PyObject_Length(__pyx_t_4); if (unlikely(__pyx_t_12 == ((Py_ssize_t)-1))) __PYX_ERR(0, 1970, __pyx_L18_except_error)
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __pyx_t_4 = __pyx_cur_scope->__pyx_v_key;
      __Pyx_INCREF(__pyx_t_4);
      __pyx_v_num_slcs = (__pyx_v_self->ga.nd - ((__pyx_t_12 - __pyx_f_5pygpu_8gpuarray_countis(__pyx_t_4, Py_None)) - 1));
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;

      /* "pygpu/gpuarray.pyx":1971
 *             # objects, not counting None entries and the Ellipsis itself
 *             num_slcs = self.ga.nd - (len(key) - countis(key, None) - 1)
 *             fill_slices = (slice(None),) * num_slcs             # <<<<<<<<<<<<<<
 *             key = key[:ell_idx] + fill_slices + key[ell_idx + 1:]
 * 
 */
      __pyx_t_4 = __Pyx_PyInt_FromSize_t(__pyx_v_num_slcs); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1971, __pyx_L18_except_error)
      __Pyx_GOTREF(__pyx_t_4);
      __pyx_t_7 = PyNumber_Multiply(__pyx_tuple__29, __pyx_t_4); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 1971, __pyx_L18_except_error)
      __Pyx_GOTREF(__pyx_t_7);
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __pyx_v_fill_slices = ((PyObject*)__pyx_t_7);
      __pyx_t_7 = 0;

      /* "pygpu/gpuarray.pyx":1972
 *             num_slcs = self.ga.nd - (len(key) - countis(key, None) - 1)
 *             fill_slices = (slice(None),) * num_slcs
 *             key = key[:ell_idx] + fill_slices + key[ell_idx + 1:]             # <<<<<<<<<<<<<<
 * 
 *         # Remove the None entries for indexing
 */
      __pyx_t_7 = __Pyx_PyObject_GetSlice(__pyx_cur_scope->__pyx_v_key, 0, 0, NULL, &__pyx_v_ell_idx, NULL, 0, 0, 1); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 1972, __pyx_L18_except_error)
      __Pyx_GOTREF(__pyx_t_7);
      __pyx_t_4 = PyNumber_Add(__pyx_t_7, __pyx_v_fill_slices); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1972, __pyx_L18_except_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      __pyx_t_7 = __Pyx_PyInt_AddObjC(__pyx_v_ell_idx, __pyx_int_1, 1, 0); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 1972, __pyx_L18_except_error)
      __Pyx_GOTREF(__pyx_t_7);
      __pyx_t_3 = __Pyx_PyObject_GetSlice(__pyx_cur_scope->__pyx_v_key, 0, 0, &__pyx_t_7, NULL, NULL, 0, 0, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1972, __pyx_L18_except_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      __pyx_t_7 = PyNumber_Add(__pyx_t_4, __pyx_t_3); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 1972, __pyx_L18_except_error)
      __Pyx_GOTREF(__pyx_t_7);
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __Pyx_GOTREF(__pyx_cur_scope->__pyx_v_key);
      __Pyx_DECREF_SET(__pyx_cur_scope->__pyx_v_key, __pyx_t_7);
      __Pyx_GIVEREF(__pyx_t_7);
      __pyx_t_7 = 0;
    }
    __Pyx_XDECREF(__pyx_t_10); __pyx_t_10 = 0;
    __Pyx_XDECREF(__pyx_t_9); __pyx_t_9 = 0;
    __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
    goto __pyx_L21_try_end;
    __pyx_L16_error:;
    __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
    __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;

    /* "pygpu/gpuarray.pyx":1965
 *         try:
 *             ell_idx = key.index(Ellipsis)
 *         except ValueError:             # <<<<<<<<<<<<<<
 *             pass
 *         else:
 */
    __pyx_t_11 = __Pyx_PyErr_ExceptionMatches(__pyx_builtin_ValueError);
    if (__pyx_t_11) {
      __Pyx_ErrRestore(0,0,0);
      goto __pyx_L17_exception_handled;
    }
    goto __pyx_L18_except_error;
    __pyx_L18_except_error:;

    /* "pygpu/gpuarray.pyx":1963
 *         # dimension with a[..., 1:] on any array (including 1-dim).  This
 *         # is also required for numpy compat.
 *         try:             # <<<<<<<<<<<<<<
 *             ell_idx = key.index(Ellipsis)
 *         except ValueError:
 */
    __Pyx_XGIVEREF(__pyx_t_10);
    __Pyx_XGIVEREF(__pyx_t_9);
    __Pyx_XGIVEREF(__pyx_t_8);
    __Pyx_ExceptionReset(__pyx_t_10, __pyx_t_9, __pyx_t_8);
    goto __pyx_L1_error;
    __pyx_L17_exception_handled:;
    __Pyx_XGIVEREF(__pyx_t_10);
    __Pyx_XGIVEREF(__pyx_t_9);
    __Pyx_XGIVEREF(__pyx_t_8);
    __Pyx_ExceptionReset(__pyx_t_10, __pyx_t_9, __pyx_t_8);
    __pyx_L21_try_end:;
  }

  /* "pygpu/gpuarray.pyx":1975
 * 
 *         # Remove the None entries for indexing
 *         getitem_idcs = tuple(k for k in key if k is not None)             # <<<<<<<<<<<<<<
 * 
 *         # For less than 1 index, fill up with slice(None) to the right.
 */
  __pyx_t_7 = __pyx_pf_5pygpu_8gpuarray_8GpuArray_11__getitem___6genexpr(((PyObject*)__pyx_cur_scope)); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 1975, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __pyx_t_3 = __Pyx_PySequence_Tuple(__pyx_t_7); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1975, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __pyx_v_getitem_idcs = ((PyObject*)__pyx_t_3);
  __pyx_t_3 = 0;

  /* "pygpu/gpuarray.pyx":1981
 *         # slice is applied along the first axis only. It also allows
 *         # a[()], which simply is a view in Numpy.
 *         if len(getitem_idcs) <= 1:             # <<<<<<<<<<<<<<
 *             getitem_idcs = (getitem_idcs +
 *                             (slice(None),) * (self.ga.nd - len(getitem_idcs)))
 */
  __pyx_t_12 = PyTuple_GET_SIZE(__pyx_v_getitem_idcs); if (unlikely(__pyx_t_12 == ((Py_ssize_t)-1))) __PYX_ERR(0, 1981, __pyx_L1_error)
  __pyx_t_1 = ((__pyx_t_12 <= 1) != 0);
  if (__pyx_t_1) {

    /* "pygpu/gpuarray.pyx":1983
 *         if len(getitem_idcs) <= 1:
 *             getitem_idcs = (getitem_idcs +
 *                             (slice(None),) * (self.ga.nd - len(getitem_idcs)))             # <<<<<<<<<<<<<<
 * 
 *         # Slice into array, then reshape, accommodating for None entries in key
 */
    __pyx_t_12 = PyTuple_GET_SIZE(__pyx_v_getitem_idcs); if (unlikely(__pyx_t_12 == ((Py_ssize_t)-1))) __PYX_ERR(0, 1983, __pyx_L1_error)
    __pyx_t_3 = PyInt_FromSsize_t((__pyx_v_self->ga.nd - __pyx_t_12)); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1983, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_7 = PyNumber_Multiply(__pyx_tuple__31, __pyx_t_3); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 1983, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

    /* "pygpu/gpuarray.pyx":1982
 *         # a[()], which simply is a view in Numpy.
 *         if len(getitem_idcs) <= 1:
 *             getitem_idcs = (getitem_idcs +             # <<<<<<<<<<<<<<
 *                             (slice(None),) * (self.ga.nd - len(getitem_idcs)))
 * 
 */
    __pyx_t_3 = PyNumber_Add(__pyx_v_getitem_idcs, __pyx_t_7); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1982, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __Pyx_DECREF_SET(__pyx_v_getitem_idcs, ((PyObject*)__pyx_t_3));
    __pyx_t_3 = 0;

    /* "pygpu/gpuarray.pyx":1981
 *         # slice is applied along the first axis only. It also allows
 *         # a[()], which simply is a view in Numpy.
 *         if len(getitem_idcs) <= 1:             # <<<<<<<<<<<<<<
 *             getitem_idcs = (getitem_idcs +
 *                             (slice(None),) * (self.ga.nd - len(getitem_idcs)))
 */
  }

  /* "pygpu/gpuarray.pyx":1986
 * 
 *         # Slice into array, then reshape, accommodating for None entries in key
 *         sliced = self.__cgetitem__(getitem_idcs)             # <<<<<<<<<<<<<<
 *         if countis(key, None) == 0:
 *             # Avoid unnecessary reshaping if there was no None
 */
  __pyx_t_3 = ((struct __pyx_vtabstruct_5pygpu_8gpuarray_GpuArray *)__pyx_v_self->__pyx_vtab)->__pyx___cgetitem__(__pyx_v_self, __pyx_v_getitem_idcs); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1986, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_v_sliced = __pyx_t_3;
  __pyx_t_3 = 0;

  /* "pygpu/gpuarray.pyx":1987
 *         # Slice into array, then reshape, accommodating for None entries in key
 *         sliced = self.__cgetitem__(getitem_idcs)
 *         if countis(key, None) == 0:             # <<<<<<<<<<<<<<
 *             # Avoid unnecessary reshaping if there was no None
 *             return sliced
 */
  __pyx_t_3 = __pyx_cur_scope->__pyx_v_key;
  __Pyx_INCREF(__pyx_t_3);
  __pyx_t_1 = ((__pyx_f_5pygpu_8gpuarray_countis(__pyx_t_3, Py_None) == 0) != 0);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (__pyx_t_1) {

    /* "pygpu/gpuarray.pyx":1989
 *         if countis(key, None) == 0:
 *             # Avoid unnecessary reshaping if there was no None
 *             return sliced             # <<<<<<<<<<<<<<
 *         else:
 *             new_shape = []
 */
    __Pyx_XDECREF(__pyx_r);
    __Pyx_INCREF(__pyx_v_sliced);
    __pyx_r = __pyx_v_sliced;
    goto __pyx_L0;

    /* "pygpu/gpuarray.pyx":1987
 *         # Slice into array, then reshape, accommodating for None entries in key
 *         sliced = self.__cgetitem__(getitem_idcs)
 *         if countis(key, None) == 0:             # <<<<<<<<<<<<<<
 *             # Avoid unnecessary reshaping if there was no None
 *             return sliced
 */
  }

  /* "pygpu/gpuarray.pyx":1991
 *             return sliced
 *         else:
 *             new_shape = []             # <<<<<<<<<<<<<<
 *             i = 0
 *             if sliced.shape:
 */
  /*else*/ {
    __pyx_t_3 = PyList_New(0); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1991, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_v_new_shape = ((PyObject*)__pyx_t_3);
    __pyx_t_3 = 0;

    /* "pygpu/gpuarray.pyx":1992
 *         else:
 *             new_shape = []
 *             i = 0             # <<<<<<<<<<<<<<
 *             if sliced.shape:
 *                 for k in key:
 */
    __pyx_v_i = 0;

    /* "pygpu/gpuarray.pyx":1993
 *             new_shape = []
 *             i = 0
 *             if sliced.shape:             # <<<<<<<<<<<<<<
 *                 for k in key:
 *                     if isinstance(k, int):
 */
    __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_sliced, __pyx_n_s_shape); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1993, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_1 = __Pyx_PyObject_IsTrue(__pyx_t_3); if (unlikely(__pyx_t_1 < 0)) __PYX_ERR(0, 1993, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    if (__pyx_t_1) {

      /* "pygpu/gpuarray.pyx":1994
 *             i = 0
 *             if sliced.shape:
 *                 for k in key:             # <<<<<<<<<<<<<<
 *                     if isinstance(k, int):
 *                         continue
 */
      if (likely(PyList_CheckExact(__pyx_cur_scope->__pyx_v_key)) || PyTuple_CheckExact(__pyx_cur_scope->__pyx_v_key)) {
        __pyx_t_3 = __pyx_cur_scope->__pyx_v_key; __Pyx_INCREF(__pyx_t_3); __pyx_t_12 = 0;
        __pyx_t_13 = NULL;
      } else {
        __pyx_t_12 = -1; __pyx_t_3 = PyObject_GetIter(__pyx_cur_scope->__pyx_v_key); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1994, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
        __pyx_t_13 = Py_TYPE(__pyx_t_3)->tp_iternext; if (unlikely(!__pyx_t_13)) __PYX_ERR(0, 1994, __pyx_L1_error)
      }
      for (;;) {
        if (likely(!__pyx_t_13)) {
          if (likely(PyList_CheckExact(__pyx_t_3))) {
            if (__pyx_t_12 >= PyList_GET_SIZE(__pyx_t_3)) break;
            #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
            __pyx_t_7 = PyList_GET_ITEM(__pyx_t_3, __pyx_t_12); __Pyx_INCREF(__pyx_t_7); __pyx_t_12++; if (unlikely(0 < 0)) __PYX_ERR(0, 1994, __pyx_L1_error)
            #else
            __pyx_t_7 = PySequence_ITEM(__pyx_t_3, __pyx_t_12); __pyx_t_12++; if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 1994, __pyx_L1_error)
            __Pyx_GOTREF(__pyx_t_7);
            #endif
          } else {
            if (__pyx_t_12 >= PyTuple_GET_SIZE(__pyx_t_3)) break;
            #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
            __pyx_t_7 = PyTuple_GET_ITEM(__pyx_t_3, __pyx_t_12); __Pyx_INCREF(__pyx_t_7); __pyx_t_12++; if (unlikely(0 < 0)) __PYX_ERR(0, 1994, __pyx_L1_error)
            #else
            __pyx_t_7 = PySequence_ITEM(__pyx_t_3, __pyx_t_12); __pyx_t_12++; if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 1994, __pyx_L1_error)
            __Pyx_GOTREF(__pyx_t_7);
            #endif
          }
        } else {
          __pyx_t_7 = __pyx_t_13(__pyx_t_3);
          if (unlikely(!__pyx_t_7)) {
            PyObject* exc_type = PyErr_Occurred();
            if (exc_type) {
              if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
              else __PYX_ERR(0, 1994, __pyx_L1_error)
            }
            break;
          }
          __Pyx_GOTREF(__pyx_t_7);
        }
        __Pyx_XDECREF_SET(__pyx_v_k, __pyx_t_7);
        __pyx_t_7 = 0;

        /* "pygpu/gpuarray.pyx":1995
 *             if sliced.shape:
 *                 for k in key:
 *                     if isinstance(k, int):             # <<<<<<<<<<<<<<
 *                         continue
 *                     elif k is None:
 */
        __pyx_t_1 = PyInt_Check(__pyx_v_k); 
        __pyx_t_2 = (__pyx_t_1 != 0);
        if (__pyx_t_2) {

          /* "pygpu/gpuarray.pyx":1996
 *                 for k in key:
 *                     if isinstance(k, int):
 *                         continue             # <<<<<<<<<<<<<<
 *                     elif k is None:
 *                         new_shape.append(1)
 */
          goto __pyx_L25_continue;

          /* "pygpu/gpuarray.pyx":1995
 *             if sliced.shape:
 *                 for k in key:
 *                     if isinstance(k, int):             # <<<<<<<<<<<<<<
 *                         continue
 *                     elif k is None:
 */
        }

        /* "pygpu/gpuarray.pyx":1997
 *                     if isinstance(k, int):
 *                         continue
 *                     elif k is None:             # <<<<<<<<<<<<<<
 *                         new_shape.append(1)
 *                     else:
 */
        __pyx_t_2 = (__pyx_v_k == Py_None);
        __pyx_t_1 = (__pyx_t_2 != 0);
        if (__pyx_t_1) {

          /* "pygpu/gpuarray.pyx":1998
 *                         continue
 *                     elif k is None:
 *                         new_shape.append(1)             # <<<<<<<<<<<<<<
 *                     else:
 *                         new_shape.append(sliced.shape[i])
 */
          __pyx_t_14 = __Pyx_PyList_Append(__pyx_v_new_shape, __pyx_int_1); if (unlikely(__pyx_t_14 == ((int)-1))) __PYX_ERR(0, 1998, __pyx_L1_error)

          /* "pygpu/gpuarray.pyx":1997
 *                     if isinstance(k, int):
 *                         continue
 *                     elif k is None:             # <<<<<<<<<<<<<<
 *                         new_shape.append(1)
 *                     else:
 */
          goto __pyx_L27;
        }

        /* "pygpu/gpuarray.pyx":2000
 *                         new_shape.append(1)
 *                     else:
 *                         new_shape.append(sliced.shape[i])             # <<<<<<<<<<<<<<
 *                         i += 1
 *             # Add remaining entries from sliced.shape if existing (happens
 */
        /*else*/ {
          __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_v_sliced, __pyx_n_s_shape); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 2000, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_7);
          __pyx_t_4 = __Pyx_GetItemInt(__pyx_t_7, __pyx_v_i, unsigned int, 0, __Pyx_PyInt_From_unsigned_int, 0, 0, 1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2000, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_4);
          __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
          __pyx_t_14 = __Pyx_PyList_Append(__pyx_v_new_shape, __pyx_t_4); if (unlikely(__pyx_t_14 == ((int)-1))) __PYX_ERR(0, 2000, __pyx_L1_error)
          __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;

          /* "pygpu/gpuarray.pyx":2001
 *                     else:
 *                         new_shape.append(sliced.shape[i])
 *                         i += 1             # <<<<<<<<<<<<<<
 *             # Add remaining entries from sliced.shape if existing (happens
 *             # for 1 index or less if ndim >= 2).
 */
          __pyx_v_i = (__pyx_v_i + 1);
        }
        __pyx_L27:;

        /* "pygpu/gpuarray.pyx":1994
 *             i = 0
 *             if sliced.shape:
 *                 for k in key:             # <<<<<<<<<<<<<<
 *                     if isinstance(k, int):
 *                         continue
 */
        __pyx_L25_continue:;
      }
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

      /* "pygpu/gpuarray.pyx":1993
 *             new_shape = []
 *             i = 0
 *             if sliced.shape:             # <<<<<<<<<<<<<<
 *                 for k in key:
 *                     if isinstance(k, int):
 */
    }

    /* "pygpu/gpuarray.pyx":2004
 *             # Add remaining entries from sliced.shape if existing (happens
 *             # for 1 index or less if ndim >= 2).
 *             new_shape.extend(sliced.shape[i:])             # <<<<<<<<<<<<<<
 *             return sliced.reshape(new_shape)
 * 
 */
    __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_sliced, __pyx_n_s_shape); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 2004, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_4 = __Pyx_PyObject_GetSlice(__pyx_t_3, __pyx_v_i, 0, NULL, NULL, NULL, 1, 0, 1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2004, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_14 = __Pyx_PyList_Extend(__pyx_v_new_shape, __pyx_t_4); if (unlikely(__pyx_t_14 == ((int)-1))) __PYX_ERR(0, 2004, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;

    /* "pygpu/gpuarray.pyx":2005
 *             # for 1 index or less if ndim >= 2).
 *             new_shape.extend(sliced.shape[i:])
 *             return sliced.reshape(new_shape)             # <<<<<<<<<<<<<<
 * 
 *     cdef __cgetitem__(self, key):
 */
    __Pyx_XDECREF(__pyx_r);
    __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_sliced, __pyx_n_s_reshape); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 2005, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_7 = NULL;
    if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_3))) {
      __pyx_t_7 = PyMethod_GET_SELF(__pyx_t_3);
      if (likely(__pyx_t_7)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
        __Pyx_INCREF(__pyx_t_7);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_3, function);
      }
    }
    if (!__pyx_t_7) {
      __pyx_t_4 = __Pyx_PyObject_CallOneArg(__pyx_t_3, __pyx_v_new_shape); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2005, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
    } else {
      #if CYTHON_FAST_PYCALL
      if (PyFunction_Check(__pyx_t_3)) {
        PyObject *__pyx_temp[2] = {__pyx_t_7, __pyx_v_new_shape};
        __pyx_t_4 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2005, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
        __Pyx_GOTREF(__pyx_t_4);
      } else
      #endif
      #if CYTHON_FAST_PYCCALL
      if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
        PyObject *__pyx_temp[2] = {__pyx_t_7, __pyx_v_new_shape};
        __pyx_t_4 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2005, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
        __Pyx_GOTREF(__pyx_t_4);
      } else
      #endif
      {
        __pyx_t_5 = PyTuple_New(1+1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 2005, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_5);
        __Pyx_GIVEREF(__pyx_t_7); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_7); __pyx_t_7 = NULL;
        __Pyx_INCREF(__pyx_v_new_shape);
        __Pyx_GIVEREF(__pyx_v_new_shape);
        PyTuple_SET_ITEM(__pyx_t_5, 0+1, __pyx_v_new_shape);
        __pyx_t_4 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_5, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2005, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_4);
        __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      }
    }
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_r = __pyx_t_4;
    __pyx_t_4 = 0;
    goto __pyx_L0;
  }

  /* "pygpu/gpuarray.pyx":1928
 *             raise TypeError, "len() of unsized object"
 * 
 *     def __getitem__(self, key):             # <<<<<<<<<<<<<<
 *         cdef unsigned int i
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_AddTraceback("pygpu.gpuarray.GpuArray.__getitem__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_ell_idx);
  __Pyx_XDECREF(__pyx_v_fill_slices);
  __Pyx_XDECREF(__pyx_v_getitem_idcs);
  __Pyx_XDECREF(__pyx_v_sliced);
  __Pyx_XDECREF(__pyx_v_new_shape);
  __Pyx_XDECREF(__pyx_v_k);
  __Pyx_DECREF(((PyObject *)__pyx_cur_scope));
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":2007
 *             return sliced.reshape(new_shape)
 * 
 *     cdef __cgetitem__(self, key):             # <<<<<<<<<<<<<<
 *         cdef ssize_t *starts
 *         cdef ssize_t *stops
 */

static PyObject *__pyx_f_5pygpu_8gpuarray_8GpuArray___cgetitem__(struct PyGpuArrayObject *__pyx_v_self, PyObject *__pyx_v_key) {
  Py_ssize_t *__pyx_v_starts;
  Py_ssize_t *__pyx_v_stops;
  Py_ssize_t *__pyx_v_steps;
  unsigned int __pyx_v_i;
  unsigned int __pyx_v_d;
  unsigned int __pyx_v_el;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_t_2;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  Py_ssize_t __pyx_t_5;
  PyObject *__pyx_t_6 = NULL;
  unsigned int __pyx_t_7;
  PyObject *__pyx_t_8 = NULL;
  unsigned int __pyx_t_9;
  int __pyx_t_10;
  int __pyx_t_11;
  char const *__pyx_t_12;
  PyObject *__pyx_t_13 = NULL;
  PyObject *__pyx_t_14 = NULL;
  PyObject *__pyx_t_15 = NULL;
  PyObject *__pyx_t_16 = NULL;
  PyObject *__pyx_t_17 = NULL;
  PyObject *__pyx_t_18 = NULL;
  __Pyx_RefNannySetupContext("__cgetitem__", 0);
  __Pyx_INCREF(__pyx_v_key);

  /* "pygpu/gpuarray.pyx":2015
 *         cdef unsigned int el
 * 
 *         if key is Ellipsis:             # <<<<<<<<<<<<<<
 *             return pygpu_view(self, None)
 *         elif self.ga.nd == 0:
 */
  __pyx_t_1 = (__pyx_v_key == __pyx_builtin_Ellipsis);
  __pyx_t_2 = (__pyx_t_1 != 0);
  if (__pyx_t_2) {

    /* "pygpu/gpuarray.pyx":2016
 * 
 *         if key is Ellipsis:
 *             return pygpu_view(self, None)             # <<<<<<<<<<<<<<
 *         elif self.ga.nd == 0:
 *             if isinstance(key, tuple) and len(key) == 0:
 */
    __Pyx_XDECREF(__pyx_r);
    __pyx_t_3 = ((PyObject *)__pyx_f_5pygpu_8gpuarray_pygpu_view(__pyx_v_self, Py_None)); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 2016, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_r = __pyx_t_3;
    __pyx_t_3 = 0;
    goto __pyx_L0;

    /* "pygpu/gpuarray.pyx":2015
 *         cdef unsigned int el
 * 
 *         if key is Ellipsis:             # <<<<<<<<<<<<<<
 *             return pygpu_view(self, None)
 *         elif self.ga.nd == 0:
 */
  }

  /* "pygpu/gpuarray.pyx":2017
 *         if key is Ellipsis:
 *             return pygpu_view(self, None)
 *         elif self.ga.nd == 0:             # <<<<<<<<<<<<<<
 *             if isinstance(key, tuple) and len(key) == 0:
 *                 return self
 */
  __pyx_t_2 = ((__pyx_v_self->ga.nd == 0) != 0);
  if (__pyx_t_2) {

    /* "pygpu/gpuarray.pyx":2018
 *             return pygpu_view(self, None)
 *         elif self.ga.nd == 0:
 *             if isinstance(key, tuple) and len(key) == 0:             # <<<<<<<<<<<<<<
 *                 return self
 *             else:
 */
    __pyx_t_1 = PyTuple_Check(__pyx_v_key); 
    __pyx_t_4 = (__pyx_t_1 != 0);
    if (__pyx_t_4) {
    } else {
      __pyx_t_2 = __pyx_t_4;
      goto __pyx_L5_bool_binop_done;
    }
    __pyx_t_5 = PyObject_Length(__pyx_v_key); if (unlikely(__pyx_t_5 == ((Py_ssize_t)-1))) __PYX_ERR(0, 2018, __pyx_L1_error)
    __pyx_t_4 = ((__pyx_t_5 == 0) != 0);
    __pyx_t_2 = __pyx_t_4;
    __pyx_L5_bool_binop_done:;
    if (__pyx_t_2) {

      /* "pygpu/gpuarray.pyx":2019
 *         elif self.ga.nd == 0:
 *             if isinstance(key, tuple) and len(key) == 0:
 *                 return self             # <<<<<<<<<<<<<<
 *             else:
 *                 raise IndexError, "0-d arrays can't be indexed"
 */
      __Pyx_XDECREF(__pyx_r);
      __Pyx_INCREF(((PyObject *)__pyx_v_self));
      __pyx_r = ((PyObject *)__pyx_v_self);
      goto __pyx_L0;

      /* "pygpu/gpuarray.pyx":2018
 *             return pygpu_view(self, None)
 *         elif self.ga.nd == 0:
 *             if isinstance(key, tuple) and len(key) == 0:             # <<<<<<<<<<<<<<
 *                 return self
 *             else:
 */
    }

    /* "pygpu/gpuarray.pyx":2021
 *                 return self
 *             else:
 *                 raise IndexError, "0-d arrays can't be indexed"             # <<<<<<<<<<<<<<
 * 
 *         starts = <ssize_t *>calloc(self.ga.nd, sizeof(ssize_t))
 */
    /*else*/ {
      __Pyx_Raise(__pyx_builtin_IndexError, __pyx_kp_s_0_d_arrays_can_t_be_indexed, 0, 0);
      __PYX_ERR(0, 2021, __pyx_L1_error)
    }

    /* "pygpu/gpuarray.pyx":2017
 *         if key is Ellipsis:
 *             return pygpu_view(self, None)
 *         elif self.ga.nd == 0:             # <<<<<<<<<<<<<<
 *             if isinstance(key, tuple) and len(key) == 0:
 *                 return self
 */
  }

  /* "pygpu/gpuarray.pyx":2023
 *                 raise IndexError, "0-d arrays can't be indexed"
 * 
 *         starts = <ssize_t *>calloc(self.ga.nd, sizeof(ssize_t))             # <<<<<<<<<<<<<<
 *         stops = <ssize_t *>calloc(self.ga.nd, sizeof(ssize_t))
 *         steps = <ssize_t *>calloc(self.ga.nd, sizeof(ssize_t))
 */
  __pyx_v_starts = ((Py_ssize_t *)calloc(__pyx_v_self->ga.nd, (sizeof(Py_ssize_t))));

  /* "pygpu/gpuarray.pyx":2024
 * 
 *         starts = <ssize_t *>calloc(self.ga.nd, sizeof(ssize_t))
 *         stops = <ssize_t *>calloc(self.ga.nd, sizeof(ssize_t))             # <<<<<<<<<<<<<<
 *         steps = <ssize_t *>calloc(self.ga.nd, sizeof(ssize_t))
 *         try:
 */
  __pyx_v_stops = ((Py_ssize_t *)calloc(__pyx_v_self->ga.nd, (sizeof(Py_ssize_t))));

  /* "pygpu/gpuarray.pyx":2025
 *         starts = <ssize_t *>calloc(self.ga.nd, sizeof(ssize_t))
 *         stops = <ssize_t *>calloc(self.ga.nd, sizeof(ssize_t))
 *         steps = <ssize_t *>calloc(self.ga.nd, sizeof(ssize_t))             # <<<<<<<<<<<<<<
 *         try:
 *             if starts == NULL or stops == NULL or steps == NULL:
 */
  __pyx_v_steps = ((Py_ssize_t *)calloc(__pyx_v_self->ga.nd, (sizeof(Py_ssize_t))));

  /* "pygpu/gpuarray.pyx":2026
 *         stops = <ssize_t *>calloc(self.ga.nd, sizeof(ssize_t))
 *         steps = <ssize_t *>calloc(self.ga.nd, sizeof(ssize_t))
 *         try:             # <<<<<<<<<<<<<<
 *             if starts == NULL or stops == NULL or steps == NULL:
 *                 raise MemoryError
 */
  /*try:*/ {

    /* "pygpu/gpuarray.pyx":2027
 *         steps = <ssize_t *>calloc(self.ga.nd, sizeof(ssize_t))
 *         try:
 *             if starts == NULL or stops == NULL or steps == NULL:             # <<<<<<<<<<<<<<
 *                 raise MemoryError
 * 
 */
    __pyx_t_4 = ((__pyx_v_starts == NULL) != 0);
    if (!__pyx_t_4) {
    } else {
      __pyx_t_2 = __pyx_t_4;
      goto __pyx_L11_bool_binop_done;
    }
    __pyx_t_4 = ((__pyx_v_stops == NULL) != 0);
    if (!__pyx_t_4) {
    } else {
      __pyx_t_2 = __pyx_t_4;
      goto __pyx_L11_bool_binop_done;
    }
    __pyx_t_4 = ((__pyx_v_steps == NULL) != 0);
    __pyx_t_2 = __pyx_t_4;
    __pyx_L11_bool_binop_done:;
    if (__pyx_t_2) {

      /* "pygpu/gpuarray.pyx":2028
 *         try:
 *             if starts == NULL or stops == NULL or steps == NULL:
 *                 raise MemoryError             # <<<<<<<<<<<<<<
 * 
 *             d = 0
 */
      PyErr_NoMemory(); __PYX_ERR(0, 2028, __pyx_L8_error)

      /* "pygpu/gpuarray.pyx":2027
 *         steps = <ssize_t *>calloc(self.ga.nd, sizeof(ssize_t))
 *         try:
 *             if starts == NULL or stops == NULL or steps == NULL:             # <<<<<<<<<<<<<<
 *                 raise MemoryError
 * 
 */
    }

    /* "pygpu/gpuarray.pyx":2030
 *                 raise MemoryError
 * 
 *             d = 0             # <<<<<<<<<<<<<<
 * 
 *             if isinstance(key, (tuple, list)):
 */
    __pyx_v_d = 0;

    /* "pygpu/gpuarray.pyx":2032
 *             d = 0
 * 
 *             if isinstance(key, (tuple, list)):             # <<<<<<<<<<<<<<
 *                 if Ellipsis in key:
 *                     # The following code replaces the first Ellipsis
 */
    __pyx_t_4 = PyTuple_Check(__pyx_v_key); 
    __pyx_t_1 = (__pyx_t_4 != 0);
    if (!__pyx_t_1) {
    } else {
      __pyx_t_2 = __pyx_t_1;
      goto __pyx_L15_bool_binop_done;
    }
    __pyx_t_1 = PyList_Check(__pyx_v_key); 
    __pyx_t_4 = (__pyx_t_1 != 0);
    __pyx_t_2 = __pyx_t_4;
    __pyx_L15_bool_binop_done:;
    __pyx_t_4 = (__pyx_t_2 != 0);
    if (__pyx_t_4) {

      /* "pygpu/gpuarray.pyx":2033
 * 
 *             if isinstance(key, (tuple, list)):
 *                 if Ellipsis in key:             # <<<<<<<<<<<<<<
 *                     # The following code replaces the first Ellipsis
 *                     # found in the key by a bunch of them depending on
 */
      __pyx_t_4 = (__Pyx_PySequence_ContainsTF(__pyx_builtin_Ellipsis, __pyx_v_key, Py_EQ)); if (unlikely(__pyx_t_4 < 0)) __PYX_ERR(0, 2033, __pyx_L8_error)
      __pyx_t_2 = (__pyx_t_4 != 0);
      if (__pyx_t_2) {

        /* "pygpu/gpuarray.pyx":2040
 *                     # a[..., 1:] on any array (including 1-dim).  This
 *                     # is also required for numpy compat.
 *                     el = key.index(Ellipsis)             # <<<<<<<<<<<<<<
 *                     if isinstance(key, tuple):
 *                         key = (key[:el] +
 */
        __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_key, __pyx_n_s_index); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 2040, __pyx_L8_error)
        __Pyx_GOTREF(__pyx_t_3);
        __pyx_t_6 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_tuple__32, NULL); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 2040, __pyx_L8_error)
        __Pyx_GOTREF(__pyx_t_6);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
        __pyx_t_7 = __Pyx_PyInt_As_unsigned_int(__pyx_t_6); if (unlikely((__pyx_t_7 == (unsigned int)-1) && PyErr_Occurred())) __PYX_ERR(0, 2040, __pyx_L8_error)
        __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
        __pyx_v_el = __pyx_t_7;

        /* "pygpu/gpuarray.pyx":2041
 *                     # is also required for numpy compat.
 *                     el = key.index(Ellipsis)
 *                     if isinstance(key, tuple):             # <<<<<<<<<<<<<<
 *                         key = (key[:el] +
 *                                (Ellipsis,)*(self.ga.nd - (len(key) - 1)) +
 */
        __pyx_t_2 = PyTuple_Check(__pyx_v_key); 
        __pyx_t_4 = (__pyx_t_2 != 0);
        if (__pyx_t_4) {

          /* "pygpu/gpuarray.pyx":2042
 *                     el = key.index(Ellipsis)
 *                     if isinstance(key, tuple):
 *                         key = (key[:el] +             # <<<<<<<<<<<<<<
 *                                (Ellipsis,)*(self.ga.nd - (len(key) - 1)) +
 *                                key[el+1:])
 */
          __pyx_t_6 = __Pyx_PyObject_GetSlice(__pyx_v_key, 0, __pyx_v_el, NULL, NULL, NULL, 0, 1, 1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 2042, __pyx_L8_error)
          __Pyx_GOTREF(__pyx_t_6);

          /* "pygpu/gpuarray.pyx":2043
 *                     if isinstance(key, tuple):
 *                         key = (key[:el] +
 *                                (Ellipsis,)*(self.ga.nd - (len(key) - 1)) +             # <<<<<<<<<<<<<<
 *                                key[el+1:])
 *                     else:
 */
          __pyx_t_5 = PyObject_Length(__pyx_v_key); if (unlikely(__pyx_t_5 == ((Py_ssize_t)-1))) __PYX_ERR(0, 2043, __pyx_L8_error)
          __pyx_t_3 = PyInt_FromSsize_t((__pyx_v_self->ga.nd - (__pyx_t_5 - 1))); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 2043, __pyx_L8_error)
          __Pyx_GOTREF(__pyx_t_3);
          __pyx_t_8 = PyNumber_Multiply(__pyx_tuple__33, __pyx_t_3); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 2043, __pyx_L8_error)
          __Pyx_GOTREF(__pyx_t_8);
          __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

          /* "pygpu/gpuarray.pyx":2042
 *                     el = key.index(Ellipsis)
 *                     if isinstance(key, tuple):
 *                         key = (key[:el] +             # <<<<<<<<<<<<<<
 *                                (Ellipsis,)*(self.ga.nd - (len(key) - 1)) +
 *                                key[el+1:])
 */
          __pyx_t_3 = PyNumber_Add(__pyx_t_6, __pyx_t_8); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 2042, __pyx_L8_error)
          __Pyx_GOTREF(__pyx_t_3);
          __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
          __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;

          /* "pygpu/gpuarray.pyx":2044
 *                         key = (key[:el] +
 *                                (Ellipsis,)*(self.ga.nd - (len(key) - 1)) +
 *                                key[el+1:])             # <<<<<<<<<<<<<<
 *                     else:
 *                         key = (key[:el] +
 */
          __pyx_t_8 = __Pyx_PyObject_GetSlice(__pyx_v_key, (__pyx_v_el + 1), 0, NULL, NULL, NULL, 1, 0, 1); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 2044, __pyx_L8_error)
          __Pyx_GOTREF(__pyx_t_8);

          /* "pygpu/gpuarray.pyx":2043
 *                     if isinstance(key, tuple):
 *                         key = (key[:el] +
 *                                (Ellipsis,)*(self.ga.nd - (len(key) - 1)) +             # <<<<<<<<<<<<<<
 *                                key[el+1:])
 *                     else:
 */
          __pyx_t_6 = PyNumber_Add(__pyx_t_3, __pyx_t_8); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 2043, __pyx_L8_error)
          __Pyx_GOTREF(__pyx_t_6);
          __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
          __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
          __Pyx_DECREF_SET(__pyx_v_key, __pyx_t_6);
          __pyx_t_6 = 0;

          /* "pygpu/gpuarray.pyx":2041
 *                     # is also required for numpy compat.
 *                     el = key.index(Ellipsis)
 *                     if isinstance(key, tuple):             # <<<<<<<<<<<<<<
 *                         key = (key[:el] +
 *                                (Ellipsis,)*(self.ga.nd - (len(key) - 1)) +
 */
          goto __pyx_L18;
        }

        /* "pygpu/gpuarray.pyx":2047
 *                     else:
 *                         key = (key[:el] +
 *                                [Ellipsis,]*(self.ga.nd - (len(key) - 1)) +             # <<<<<<<<<<<<<<
 *                                key[el+1:])
 *                 if len(key) > self.ga.nd:
 */
        /*else*/ {

          /* "pygpu/gpuarray.pyx":2046
 *                                key[el+1:])
 *                     else:
 *                         key = (key[:el] +             # <<<<<<<<<<<<<<
 *                                [Ellipsis,]*(self.ga.nd - (len(key) - 1)) +
 *                                key[el+1:])
 */
          __pyx_t_6 = __Pyx_PyObject_GetSlice(__pyx_v_key, 0, __pyx_v_el, NULL, NULL, NULL, 0, 1, 1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 2046, __pyx_L8_error)
          __Pyx_GOTREF(__pyx_t_6);

          /* "pygpu/gpuarray.pyx":2047
 *                     else:
 *                         key = (key[:el] +
 *                                [Ellipsis,]*(self.ga.nd - (len(key) - 1)) +             # <<<<<<<<<<<<<<
 *                                key[el+1:])
 *                 if len(key) > self.ga.nd:
 */
          __pyx_t_5 = PyObject_Length(__pyx_v_key); if (unlikely(__pyx_t_5 == ((Py_ssize_t)-1))) __PYX_ERR(0, 2047, __pyx_L8_error)
          __pyx_t_8 = PyList_New(1 * (((__pyx_v_self->ga.nd - (__pyx_t_5 - 1))<0) ? 0:(__pyx_v_self->ga.nd - (__pyx_t_5 - 1)))); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 2047, __pyx_L8_error)
          __Pyx_GOTREF(__pyx_t_8);
          { Py_ssize_t __pyx_temp;
            for (__pyx_temp=0; __pyx_temp < (__pyx_v_self->ga.nd - (__pyx_t_5 - 1)); __pyx_temp++) {
              __Pyx_INCREF(__pyx_builtin_Ellipsis);
              __Pyx_GIVEREF(__pyx_builtin_Ellipsis);
              PyList_SET_ITEM(__pyx_t_8, __pyx_temp, __pyx_builtin_Ellipsis);
            }
          }

          /* "pygpu/gpuarray.pyx":2046
 *                                key[el+1:])
 *                     else:
 *                         key = (key[:el] +             # <<<<<<<<<<<<<<
 *                                [Ellipsis,]*(self.ga.nd - (len(key) - 1)) +
 *                                key[el+1:])
 */
          __pyx_t_3 = PyNumber_Add(__pyx_t_6, __pyx_t_8); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 2046, __pyx_L8_error)
          __Pyx_GOTREF(__pyx_t_3);
          __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
          __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;

          /* "pygpu/gpuarray.pyx":2048
 *                         key = (key[:el] +
 *                                [Ellipsis,]*(self.ga.nd - (len(key) - 1)) +
 *                                key[el+1:])             # <<<<<<<<<<<<<<
 *                 if len(key) > self.ga.nd:
 *                     raise IndexError, "too many indices"
 */
          __pyx_t_8 = __Pyx_PyObject_GetSlice(__pyx_v_key, (__pyx_v_el + 1), 0, NULL, NULL, NULL, 1, 0, 1); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 2048, __pyx_L8_error)
          __Pyx_GOTREF(__pyx_t_8);

          /* "pygpu/gpuarray.pyx":2047
 *                     else:
 *                         key = (key[:el] +
 *                                [Ellipsis,]*(self.ga.nd - (len(key) - 1)) +             # <<<<<<<<<<<<<<
 *                                key[el+1:])
 *                 if len(key) > self.ga.nd:
 */
          __pyx_t_6 = PyNumber_Add(__pyx_t_3, __pyx_t_8); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 2047, __pyx_L8_error)
          __Pyx_GOTREF(__pyx_t_6);
          __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
          __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
          __Pyx_DECREF_SET(__pyx_v_key, __pyx_t_6);
          __pyx_t_6 = 0;
        }
        __pyx_L18:;

        /* "pygpu/gpuarray.pyx":2033
 * 
 *             if isinstance(key, (tuple, list)):
 *                 if Ellipsis in key:             # <<<<<<<<<<<<<<
 *                     # The following code replaces the first Ellipsis
 *                     # found in the key by a bunch of them depending on
 */
      }

      /* "pygpu/gpuarray.pyx":2049
 *                                [Ellipsis,]*(self.ga.nd - (len(key) - 1)) +
 *                                key[el+1:])
 *                 if len(key) > self.ga.nd:             # <<<<<<<<<<<<<<
 *                     raise IndexError, "too many indices"
 *                 for i in range(0, len(key)):
 */
      __pyx_t_5 = PyObject_Length(__pyx_v_key); if (unlikely(__pyx_t_5 == ((Py_ssize_t)-1))) __PYX_ERR(0, 2049, __pyx_L8_error)
      __pyx_t_4 = ((__pyx_t_5 > __pyx_v_self->ga.nd) != 0);
      if (__pyx_t_4) {

        /* "pygpu/gpuarray.pyx":2050
 *                                key[el+1:])
 *                 if len(key) > self.ga.nd:
 *                     raise IndexError, "too many indices"             # <<<<<<<<<<<<<<
 *                 for i in range(0, len(key)):
 *                     self.__index_helper(key[i], i, &starts[i], &stops[i],
 */
        __Pyx_Raise(__pyx_builtin_IndexError, __pyx_kp_s_too_many_indices, 0, 0);
        __PYX_ERR(0, 2050, __pyx_L8_error)

        /* "pygpu/gpuarray.pyx":2049
 *                                [Ellipsis,]*(self.ga.nd - (len(key) - 1)) +
 *                                key[el+1:])
 *                 if len(key) > self.ga.nd:             # <<<<<<<<<<<<<<
 *                     raise IndexError, "too many indices"
 *                 for i in range(0, len(key)):
 */
      }

      /* "pygpu/gpuarray.pyx":2051
 *                 if len(key) > self.ga.nd:
 *                     raise IndexError, "too many indices"
 *                 for i in range(0, len(key)):             # <<<<<<<<<<<<<<
 *                     self.__index_helper(key[i], i, &starts[i], &stops[i],
 *                                         &steps[i])
 */
      __pyx_t_5 = PyObject_Length(__pyx_v_key); if (unlikely(__pyx_t_5 == ((Py_ssize_t)-1))) __PYX_ERR(0, 2051, __pyx_L8_error)
      for (__pyx_t_7 = 0; __pyx_t_7 < __pyx_t_5; __pyx_t_7+=1) {
        __pyx_v_i = __pyx_t_7;

        /* "pygpu/gpuarray.pyx":2052
 *                     raise IndexError, "too many indices"
 *                 for i in range(0, len(key)):
 *                     self.__index_helper(key[i], i, &starts[i], &stops[i],             # <<<<<<<<<<<<<<
 *                                         &steps[i])
 *                 d += <unsigned int>len(key)
 */
        __pyx_t_6 = __Pyx_GetItemInt(__pyx_v_key, __pyx_v_i, unsigned int, 0, __Pyx_PyInt_From_unsigned_int, 0, 0, 1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 2052, __pyx_L8_error)
        __Pyx_GOTREF(__pyx_t_6);

        /* "pygpu/gpuarray.pyx":2053
 *                 for i in range(0, len(key)):
 *                     self.__index_helper(key[i], i, &starts[i], &stops[i],
 *                                         &steps[i])             # <<<<<<<<<<<<<<
 *                 d += <unsigned int>len(key)
 *             else:
 */
        __pyx_t_8 = ((struct __pyx_vtabstruct_5pygpu_8gpuarray_GpuArray *)__pyx_v_self->__pyx_vtab)->__pyx___index_helper(__pyx_v_self, __pyx_t_6, __pyx_v_i, (&(__pyx_v_starts[__pyx_v_i])), (&(__pyx_v_stops[__pyx_v_i])), (&(__pyx_v_steps[__pyx_v_i]))); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 2052, __pyx_L8_error)
        __Pyx_GOTREF(__pyx_t_8);
        __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
        __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      }

      /* "pygpu/gpuarray.pyx":2054
 *                     self.__index_helper(key[i], i, &starts[i], &stops[i],
 *                                         &steps[i])
 *                 d += <unsigned int>len(key)             # <<<<<<<<<<<<<<
 *             else:
 *                 self.__index_helper(key, 0, starts, stops, steps)
 */
      __pyx_t_5 = PyObject_Length(__pyx_v_key); if (unlikely(__pyx_t_5 == ((Py_ssize_t)-1))) __PYX_ERR(0, 2054, __pyx_L8_error)
      __pyx_v_d = (__pyx_v_d + ((unsigned int)__pyx_t_5));

      /* "pygpu/gpuarray.pyx":2032
 *             d = 0
 * 
 *             if isinstance(key, (tuple, list)):             # <<<<<<<<<<<<<<
 *                 if Ellipsis in key:
 *                     # The following code replaces the first Ellipsis
 */
      goto __pyx_L14;
    }

    /* "pygpu/gpuarray.pyx":2056
 *                 d += <unsigned int>len(key)
 *             else:
 *                 self.__index_helper(key, 0, starts, stops, steps)             # <<<<<<<<<<<<<<
 *                 d += 1
 * 
 */
    /*else*/ {
      __pyx_t_8 = ((struct __pyx_vtabstruct_5pygpu_8gpuarray_GpuArray *)__pyx_v_self->__pyx_vtab)->__pyx___index_helper(__pyx_v_self, __pyx_v_key, 0, __pyx_v_starts, __pyx_v_stops, __pyx_v_steps); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 2056, __pyx_L8_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;

      /* "pygpu/gpuarray.pyx":2057
 *             else:
 *                 self.__index_helper(key, 0, starts, stops, steps)
 *                 d += 1             # <<<<<<<<<<<<<<
 * 
 *             for i in range(d, self.ga.nd):
 */
      __pyx_v_d = (__pyx_v_d + 1);
    }
    __pyx_L14:;

    /* "pygpu/gpuarray.pyx":2059
 *                 d += 1
 * 
 *             for i in range(d, self.ga.nd):             # <<<<<<<<<<<<<<
 *                 starts[i] = 0
 *                 stops[i] = self.ga.dimensions[i]
 */
    __pyx_t_7 = __pyx_v_self->ga.nd;
    for (__pyx_t_9 = __pyx_v_d; __pyx_t_9 < __pyx_t_7; __pyx_t_9+=1) {
      __pyx_v_i = __pyx_t_9;

      /* "pygpu/gpuarray.pyx":2060
 * 
 *             for i in range(d, self.ga.nd):
 *                 starts[i] = 0             # <<<<<<<<<<<<<<
 *                 stops[i] = self.ga.dimensions[i]
 *                 steps[i] = 1
 */
      (__pyx_v_starts[__pyx_v_i]) = 0;

      /* "pygpu/gpuarray.pyx":2061
 *             for i in range(d, self.ga.nd):
 *                 starts[i] = 0
 *                 stops[i] = self.ga.dimensions[i]             # <<<<<<<<<<<<<<
 *                 steps[i] = 1
 * 
 */
      (__pyx_v_stops[__pyx_v_i]) = (__pyx_v_self->ga.dimensions[__pyx_v_i]);

      /* "pygpu/gpuarray.pyx":2062
 *                 starts[i] = 0
 *                 stops[i] = self.ga.dimensions[i]
 *                 steps[i] = 1             # <<<<<<<<<<<<<<
 * 
 *             return pygpu_index(self, starts, stops, steps)
 */
      (__pyx_v_steps[__pyx_v_i]) = 1;
    }

    /* "pygpu/gpuarray.pyx":2064
 *                 steps[i] = 1
 * 
 *             return pygpu_index(self, starts, stops, steps)             # <<<<<<<<<<<<<<
 * 
 *         finally:
 */
    __Pyx_XDECREF(__pyx_r);
    __pyx_t_8 = ((PyObject *)__pyx_f_5pygpu_8gpuarray_pygpu_index(__pyx_v_self, __pyx_v_starts, __pyx_v_stops, __pyx_v_steps)); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 2064, __pyx_L8_error)
    __Pyx_GOTREF(__pyx_t_8);
    __pyx_r = __pyx_t_8;
    __pyx_t_8 = 0;
    goto __pyx_L7_return;
  }

  /* "pygpu/gpuarray.pyx":2067
 * 
 *         finally:
 *             free(starts)             # <<<<<<<<<<<<<<
 *             free(stops)
 *             free(steps)
 */
  /*finally:*/ {
    __pyx_L8_error:;
    /*exception exit:*/{
      __Pyx_PyThreadState_declare
      __Pyx_PyThreadState_assign
      __pyx_t_13 = 0; __pyx_t_14 = 0; __pyx_t_15 = 0; __pyx_t_16 = 0; __pyx_t_17 = 0; __pyx_t_18 = 0;
      __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
      __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
      __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
      if (PY_MAJOR_VERSION >= 3) __Pyx_ExceptionSwap(&__pyx_t_16, &__pyx_t_17, &__pyx_t_18);
      if ((PY_MAJOR_VERSION < 3) || unlikely(__Pyx_GetException(&__pyx_t_13, &__pyx_t_14, &__pyx_t_15) < 0)) __Pyx_ErrFetch(&__pyx_t_13, &__pyx_t_14, &__pyx_t_15);
      __Pyx_XGOTREF(__pyx_t_13);
      __Pyx_XGOTREF(__pyx_t_14);
      __Pyx_XGOTREF(__pyx_t_15);
      __Pyx_XGOTREF(__pyx_t_16);
      __Pyx_XGOTREF(__pyx_t_17);
      __Pyx_XGOTREF(__pyx_t_18);
      __pyx_t_10 = __pyx_lineno; __pyx_t_11 = __pyx_clineno; __pyx_t_12 = __pyx_filename;
      {
        free(__pyx_v_starts);

        /* "pygpu/gpuarray.pyx":2068
 *         finally:
 *             free(starts)
 *             free(stops)             # <<<<<<<<<<<<<<
 *             free(steps)
 * 
 */
        free(__pyx_v_stops);

        /* "pygpu/gpuarray.pyx":2069
 *             free(starts)
 *             free(stops)
 *             free(steps)             # <<<<<<<<<<<<<<
 * 
 *     def __setitem__(self, idx, v):
 */
        free(__pyx_v_steps);
      }
      if (PY_MAJOR_VERSION >= 3) {
        __Pyx_XGIVEREF(__pyx_t_16);
        __Pyx_XGIVEREF(__pyx_t_17);
        __Pyx_XGIVEREF(__pyx_t_18);
        __Pyx_ExceptionReset(__pyx_t_16, __pyx_t_17, __pyx_t_18);
      }
      __Pyx_XGIVEREF(__pyx_t_13);
      __Pyx_XGIVEREF(__pyx_t_14);
      __Pyx_XGIVEREF(__pyx_t_15);
      __Pyx_ErrRestore(__pyx_t_13, __pyx_t_14, __pyx_t_15);
      __pyx_t_13 = 0; __pyx_t_14 = 0; __pyx_t_15 = 0; __pyx_t_16 = 0; __pyx_t_17 = 0; __pyx_t_18 = 0;
      __pyx_lineno = __pyx_t_10; __pyx_clineno = __pyx_t_11; __pyx_filename = __pyx_t_12;
      goto __pyx_L1_error;
    }
    __pyx_L7_return: {
      __pyx_t_18 = __pyx_r;
      __pyx_r = 0;

      /* "pygpu/gpuarray.pyx":2067
 * 
 *         finally:
 *             free(starts)             # <<<<<<<<<<<<<<
 *             free(stops)
 *             free(steps)
 */
      free(__pyx_v_starts);

      /* "pygpu/gpuarray.pyx":2068
 *         finally:
 *             free(starts)
 *             free(stops)             # <<<<<<<<<<<<<<
 *             free(steps)
 * 
 */
      free(__pyx_v_stops);

      /* "pygpu/gpuarray.pyx":2069
 *             free(starts)
 *             free(stops)
 *             free(steps)             # <<<<<<<<<<<<<<
 * 
 *     def __setitem__(self, idx, v):
 */
      free(__pyx_v_steps);
      __pyx_r = __pyx_t_18;
      __pyx_t_18 = 0;
      goto __pyx_L0;
    }
  }

  /* "pygpu/gpuarray.pyx":2007
 *             return sliced.reshape(new_shape)
 * 
 *     cdef __cgetitem__(self, key):             # <<<<<<<<<<<<<<
 *         cdef ssize_t *starts
 *         cdef ssize_t *stops
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_AddTraceback("pygpu.gpuarray.GpuArray.__cgetitem__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_key);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":2071
 *             free(steps)
 * 
 *     def __setitem__(self, idx, v):             # <<<<<<<<<<<<<<
 *         cdef GpuArray tmp, gv
 * 
 */

/* Python wrapper */
static int __pyx_pw_5pygpu_8gpuarray_8GpuArray_43__setitem__(PyObject *__pyx_v_self, PyObject *__pyx_v_idx, PyObject *__pyx_v_v); /*proto*/
static int __pyx_pw_5pygpu_8gpuarray_8GpuArray_43__setitem__(PyObject *__pyx_v_self, PyObject *__pyx_v_idx, PyObject *__pyx_v_v) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__setitem__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_8GpuArray_42__setitem__(((struct PyGpuArrayObject *)__pyx_v_self), ((PyObject *)__pyx_v_idx), ((PyObject *)__pyx_v_v));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}
static PyObject *__pyx_gb_5pygpu_8gpuarray_8GpuArray_11__setitem___2generator5(__pyx_CoroutineObject *__pyx_generator, CYTHON_UNUSED PyThreadState *__pyx_tstate, PyObject *__pyx_sent_value); /* proto */

/* "pygpu/gpuarray.pyx":2075
 * 
 *         if isinstance(idx, list):
 *             if any(isinstance(i, slice) or i is Ellipsis for i in idx):             # <<<<<<<<<<<<<<
 *                 self.__setitem__(tuple(idx), v)
 *             else:
 */

static PyObject *__pyx_pf_5pygpu_8gpuarray_8GpuArray_11__setitem___genexpr(PyObject *__pyx_self) {
  struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_8_genexpr *__pyx_cur_scope;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("genexpr", 0);
  __pyx_cur_scope = (struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_8_genexpr *)__pyx_tp_new_5pygpu_8gpuarray___pyx_scope_struct_8_genexpr(__pyx_ptype_5pygpu_8gpuarray___pyx_scope_struct_8_genexpr, __pyx_empty_tuple, NULL);
  if (unlikely(!__pyx_cur_scope)) {
    __pyx_cur_scope = ((struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_8_genexpr *)Py_None);
    __Pyx_INCREF(Py_None);
    __PYX_ERR(0, 2075, __pyx_L1_error)
  } else {
    __Pyx_GOTREF(__pyx_cur_scope);
  }
  __pyx_cur_scope->__pyx_outer_scope = (struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_7___setitem__ *) __pyx_self;
  __Pyx_INCREF(((PyObject *)__pyx_cur_scope->__pyx_outer_scope));
  __Pyx_GIVEREF(__pyx_cur_scope->__pyx_outer_scope);
  {
    __pyx_CoroutineObject *gen = __Pyx_Generator_New((__pyx_coroutine_body_t) __pyx_gb_5pygpu_8gpuarray_8GpuArray_11__setitem___2generator5, (PyObject *) __pyx_cur_scope, __pyx_n_s_genexpr, __pyx_n_s_setitem___locals_genexpr, __pyx_n_s_pygpu_gpuarray); if (unlikely(!gen)) __PYX_ERR(0, 2075, __pyx_L1_error)
    __Pyx_DECREF(__pyx_cur_scope);
    __Pyx_RefNannyFinishContext();
    return (PyObject *) gen;
  }

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_AddTraceback("pygpu.gpuarray.GpuArray.__setitem__.genexpr", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __Pyx_DECREF(((PyObject *)__pyx_cur_scope));
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_gb_5pygpu_8gpuarray_8GpuArray_11__setitem___2generator5(__pyx_CoroutineObject *__pyx_generator, CYTHON_UNUSED PyThreadState *__pyx_tstate, PyObject *__pyx_sent_value) /* generator body */
{
  struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_8_genexpr *__pyx_cur_scope = ((struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_8_genexpr *)__pyx_generator->closure);
  PyObject *__pyx_r = NULL;
  PyObject *__pyx_t_1 = NULL;
  Py_ssize_t __pyx_t_2;
  PyObject *(*__pyx_t_3)(PyObject *);
  PyObject *__pyx_t_4 = NULL;
  int __pyx_t_5;
  int __pyx_t_6;
  int __pyx_t_7;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("genexpr", 0);
  switch (__pyx_generator->resume_label) {
    case 0: goto __pyx_L3_first_run;
    default: /* CPython raises the right error here */
    __Pyx_RefNannyFinishContext();
    return NULL;
  }
  __pyx_L3_first_run:;
  if (unlikely(!__pyx_sent_value)) __PYX_ERR(0, 2075, __pyx_L1_error)
  if (unlikely(!__pyx_cur_scope->__pyx_outer_scope->__pyx_v_idx)) { __Pyx_RaiseClosureNameError("idx"); __PYX_ERR(0, 2075, __pyx_L1_error) }
  if (likely(PyList_CheckExact(__pyx_cur_scope->__pyx_outer_scope->__pyx_v_idx)) || PyTuple_CheckExact(__pyx_cur_scope->__pyx_outer_scope->__pyx_v_idx)) {
    __pyx_t_1 = __pyx_cur_scope->__pyx_outer_scope->__pyx_v_idx; __Pyx_INCREF(__pyx_t_1); __pyx_t_2 = 0;
    __pyx_t_3 = NULL;
  } else {
    __pyx_t_2 = -1; __pyx_t_1 = PyObject_GetIter(__pyx_cur_scope->__pyx_outer_scope->__pyx_v_idx); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2075, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_3 = Py_TYPE(__pyx_t_1)->tp_iternext; if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 2075, __pyx_L1_error)
  }
  for (;;) {
    if (likely(!__pyx_t_3)) {
      if (likely(PyList_CheckExact(__pyx_t_1))) {
        if (__pyx_t_2 >= PyList_GET_SIZE(__pyx_t_1)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_4 = PyList_GET_ITEM(__pyx_t_1, __pyx_t_2); __Pyx_INCREF(__pyx_t_4); __pyx_t_2++; if (unlikely(0 < 0)) __PYX_ERR(0, 2075, __pyx_L1_error)
        #else
        __pyx_t_4 = PySequence_ITEM(__pyx_t_1, __pyx_t_2); __pyx_t_2++; if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2075, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_4);
        #endif
      } else {
        if (__pyx_t_2 >= PyTuple_GET_SIZE(__pyx_t_1)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_4 = PyTuple_GET_ITEM(__pyx_t_1, __pyx_t_2); __Pyx_INCREF(__pyx_t_4); __pyx_t_2++; if (unlikely(0 < 0)) __PYX_ERR(0, 2075, __pyx_L1_error)
        #else
        __pyx_t_4 = PySequence_ITEM(__pyx_t_1, __pyx_t_2); __pyx_t_2++; if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2075, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_4);
        #endif
      }
    } else {
      __pyx_t_4 = __pyx_t_3(__pyx_t_1);
      if (unlikely(!__pyx_t_4)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
          else __PYX_ERR(0, 2075, __pyx_L1_error)
        }
        break;
      }
      __Pyx_GOTREF(__pyx_t_4);
    }
    __Pyx_XGOTREF(__pyx_cur_scope->__pyx_v_i);
    __Pyx_XDECREF_SET(__pyx_cur_scope->__pyx_v_i, __pyx_t_4);
    __Pyx_GIVEREF(__pyx_t_4);
    __pyx_t_4 = 0;
    __pyx_t_6 = PySlice_Check(__pyx_cur_scope->__pyx_v_i); 
    __pyx_t_7 = (__pyx_t_6 != 0);
    if (!__pyx_t_7) {
    } else {
      __pyx_t_5 = __pyx_t_7;
      goto __pyx_L7_bool_binop_done;
    }
    __pyx_t_7 = (__pyx_cur_scope->__pyx_v_i == __pyx_builtin_Ellipsis);
    __pyx_t_6 = (__pyx_t_7 != 0);
    __pyx_t_5 = __pyx_t_6;
    __pyx_L7_bool_binop_done:;
    if (__pyx_t_5) {
      __Pyx_XDECREF(__pyx_r);
      __Pyx_INCREF(Py_True);
      __pyx_r = Py_True;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      goto __pyx_L0;
    }
  }
  /*else*/ {
    __Pyx_XDECREF(__pyx_r);
    __Pyx_INCREF(Py_False);
    __pyx_r = Py_False;
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    goto __pyx_L0;
  }
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  CYTHON_MAYBE_UNUSED_VAR(__pyx_cur_scope);

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_AddTraceback("genexpr", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_Coroutine_ResetAndClearException(__pyx_generator);
  __pyx_generator->resume_label = -1;
  __Pyx_Coroutine_clear((PyObject*)__pyx_generator);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}
static PyObject *__pyx_gb_5pygpu_8gpuarray_8GpuArray_11__setitem___5generator6(__pyx_CoroutineObject *__pyx_generator, CYTHON_UNUSED PyThreadState *__pyx_tstate, PyObject *__pyx_sent_value); /* proto */

/* "pygpu/gpuarray.pyx":2084
 *             idx = (idx,)
 *         else:
 *             if all(isinstance(i, list) for i in idx):             # <<<<<<<<<<<<<<
 *                 raise NotImplementedError, "fancy indexing not supported"
 * 
 */

static PyObject *__pyx_pf_5pygpu_8gpuarray_8GpuArray_11__setitem___3genexpr(PyObject *__pyx_self) {
  struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_9_genexpr *__pyx_cur_scope;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("genexpr", 0);
  __pyx_cur_scope = (struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_9_genexpr *)__pyx_tp_new_5pygpu_8gpuarray___pyx_scope_struct_9_genexpr(__pyx_ptype_5pygpu_8gpuarray___pyx_scope_struct_9_genexpr, __pyx_empty_tuple, NULL);
  if (unlikely(!__pyx_cur_scope)) {
    __pyx_cur_scope = ((struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_9_genexpr *)Py_None);
    __Pyx_INCREF(Py_None);
    __PYX_ERR(0, 2084, __pyx_L1_error)
  } else {
    __Pyx_GOTREF(__pyx_cur_scope);
  }
  __pyx_cur_scope->__pyx_outer_scope = (struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_7___setitem__ *) __pyx_self;
  __Pyx_INCREF(((PyObject *)__pyx_cur_scope->__pyx_outer_scope));
  __Pyx_GIVEREF(__pyx_cur_scope->__pyx_outer_scope);
  {
    __pyx_CoroutineObject *gen = __Pyx_Generator_New((__pyx_coroutine_body_t) __pyx_gb_5pygpu_8gpuarray_8GpuArray_11__setitem___5generator6, (PyObject *) __pyx_cur_scope, __pyx_n_s_genexpr, __pyx_n_s_setitem___locals_genexpr, __pyx_n_s_pygpu_gpuarray); if (unlikely(!gen)) __PYX_ERR(0, 2084, __pyx_L1_error)
    __Pyx_DECREF(__pyx_cur_scope);
    __Pyx_RefNannyFinishContext();
    return (PyObject *) gen;
  }

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_AddTraceback("pygpu.gpuarray.GpuArray.__setitem__.genexpr", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __Pyx_DECREF(((PyObject *)__pyx_cur_scope));
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_gb_5pygpu_8gpuarray_8GpuArray_11__setitem___5generator6(__pyx_CoroutineObject *__pyx_generator, CYTHON_UNUSED PyThreadState *__pyx_tstate, PyObject *__pyx_sent_value) /* generator body */
{
  struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_9_genexpr *__pyx_cur_scope = ((struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_9_genexpr *)__pyx_generator->closure);
  PyObject *__pyx_r = NULL;
  PyObject *__pyx_t_1 = NULL;
  Py_ssize_t __pyx_t_2;
  PyObject *(*__pyx_t_3)(PyObject *);
  PyObject *__pyx_t_4 = NULL;
  int __pyx_t_5;
  int __pyx_t_6;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("genexpr", 0);
  switch (__pyx_generator->resume_label) {
    case 0: goto __pyx_L3_first_run;
    default: /* CPython raises the right error here */
    __Pyx_RefNannyFinishContext();
    return NULL;
  }
  __pyx_L3_first_run:;
  if (unlikely(!__pyx_sent_value)) __PYX_ERR(0, 2084, __pyx_L1_error)
  if (unlikely(!__pyx_cur_scope->__pyx_outer_scope->__pyx_v_idx)) { __Pyx_RaiseClosureNameError("idx"); __PYX_ERR(0, 2084, __pyx_L1_error) }
  if (likely(PyList_CheckExact(__pyx_cur_scope->__pyx_outer_scope->__pyx_v_idx)) || PyTuple_CheckExact(__pyx_cur_scope->__pyx_outer_scope->__pyx_v_idx)) {
    __pyx_t_1 = __pyx_cur_scope->__pyx_outer_scope->__pyx_v_idx; __Pyx_INCREF(__pyx_t_1); __pyx_t_2 = 0;
    __pyx_t_3 = NULL;
  } else {
    __pyx_t_2 = -1; __pyx_t_1 = PyObject_GetIter(__pyx_cur_scope->__pyx_outer_scope->__pyx_v_idx); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2084, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_3 = Py_TYPE(__pyx_t_1)->tp_iternext; if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 2084, __pyx_L1_error)
  }
  for (;;) {
    if (likely(!__pyx_t_3)) {
      if (likely(PyList_CheckExact(__pyx_t_1))) {
        if (__pyx_t_2 >= PyList_GET_SIZE(__pyx_t_1)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_4 = PyList_GET_ITEM(__pyx_t_1, __pyx_t_2); __Pyx_INCREF(__pyx_t_4); __pyx_t_2++; if (unlikely(0 < 0)) __PYX_ERR(0, 2084, __pyx_L1_error)
        #else
        __pyx_t_4 = PySequence_ITEM(__pyx_t_1, __pyx_t_2); __pyx_t_2++; if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2084, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_4);
        #endif
      } else {
        if (__pyx_t_2 >= PyTuple_GET_SIZE(__pyx_t_1)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_4 = PyTuple_GET_ITEM(__pyx_t_1, __pyx_t_2); __Pyx_INCREF(__pyx_t_4); __pyx_t_2++; if (unlikely(0 < 0)) __PYX_ERR(0, 2084, __pyx_L1_error)
        #else
        __pyx_t_4 = PySequence_ITEM(__pyx_t_1, __pyx_t_2); __pyx_t_2++; if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2084, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_4);
        #endif
      }
    } else {
      __pyx_t_4 = __pyx_t_3(__pyx_t_1);
      if (unlikely(!__pyx_t_4)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
          else __PYX_ERR(0, 2084, __pyx_L1_error)
        }
        break;
      }
      __Pyx_GOTREF(__pyx_t_4);
    }
    __Pyx_XGOTREF(__pyx_cur_scope->__pyx_v_i);
    __Pyx_XDECREF_SET(__pyx_cur_scope->__pyx_v_i, __pyx_t_4);
    __Pyx_GIVEREF(__pyx_t_4);
    __pyx_t_4 = 0;
    __pyx_t_5 = PyList_Check(__pyx_cur_scope->__pyx_v_i); 
    __pyx_t_6 = ((!(__pyx_t_5 != 0)) != 0);
    if (__pyx_t_6) {
      __Pyx_XDECREF(__pyx_r);
      __Pyx_INCREF(Py_False);
      __pyx_r = Py_False;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      goto __pyx_L0;
    }
  }
  /*else*/ {
    __Pyx_XDECREF(__pyx_r);
    __Pyx_INCREF(Py_True);
    __pyx_r = Py_True;
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    goto __pyx_L0;
  }
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  CYTHON_MAYBE_UNUSED_VAR(__pyx_cur_scope);

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_AddTraceback("genexpr", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_Coroutine_ResetAndClearException(__pyx_generator);
  __pyx_generator->resume_label = -1;
  __Pyx_Coroutine_clear((PyObject*)__pyx_generator);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}
static PyObject *__pyx_gb_5pygpu_8gpuarray_8GpuArray_11__setitem___8generator7(__pyx_CoroutineObject *__pyx_generator, CYTHON_UNUSED PyThreadState *__pyx_tstate, PyObject *__pyx_sent_value); /* proto */

/* "pygpu/gpuarray.pyx":2093
 * 
 *         # Remove None entries, they should be ignored (as in Numpy)
 *         idx = tuple(i for i in idx if i is not None)             # <<<<<<<<<<<<<<
 *         tmp = self.__cgetitem__(idx)
 *         gv = carray(v, self.ga.typecode, False, 'A', 0, self.context, GpuArray)
 */

static PyObject *__pyx_pf_5pygpu_8gpuarray_8GpuArray_11__setitem___6genexpr(PyObject *__pyx_self) {
  struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_10_genexpr *__pyx_cur_scope;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("genexpr", 0);
  __pyx_cur_scope = (struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_10_genexpr *)__pyx_tp_new_5pygpu_8gpuarray___pyx_scope_struct_10_genexpr(__pyx_ptype_5pygpu_8gpuarray___pyx_scope_struct_10_genexpr, __pyx_empty_tuple, NULL);
  if (unlikely(!__pyx_cur_scope)) {
    __pyx_cur_scope = ((struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_10_genexpr *)Py_None);
    __Pyx_INCREF(Py_None);
    __PYX_ERR(0, 2093, __pyx_L1_error)
  } else {
    __Pyx_GOTREF(__pyx_cur_scope);
  }
  __pyx_cur_scope->__pyx_outer_scope = (struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_7___setitem__ *) __pyx_self;
  __Pyx_INCREF(((PyObject *)__pyx_cur_scope->__pyx_outer_scope));
  __Pyx_GIVEREF(__pyx_cur_scope->__pyx_outer_scope);
  {
    __pyx_CoroutineObject *gen = __Pyx_Generator_New((__pyx_coroutine_body_t) __pyx_gb_5pygpu_8gpuarray_8GpuArray_11__setitem___8generator7, (PyObject *) __pyx_cur_scope, __pyx_n_s_genexpr, __pyx_n_s_setitem___locals_genexpr, __pyx_n_s_pygpu_gpuarray); if (unlikely(!gen)) __PYX_ERR(0, 2093, __pyx_L1_error)
    __Pyx_DECREF(__pyx_cur_scope);
    __Pyx_RefNannyFinishContext();
    return (PyObject *) gen;
  }

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_AddTraceback("pygpu.gpuarray.GpuArray.__setitem__.genexpr", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __Pyx_DECREF(((PyObject *)__pyx_cur_scope));
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_gb_5pygpu_8gpuarray_8GpuArray_11__setitem___8generator7(__pyx_CoroutineObject *__pyx_generator, CYTHON_UNUSED PyThreadState *__pyx_tstate, PyObject *__pyx_sent_value) /* generator body */
{
  struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_10_genexpr *__pyx_cur_scope = ((struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_10_genexpr *)__pyx_generator->closure);
  PyObject *__pyx_r = NULL;
  PyObject *__pyx_t_1 = NULL;
  Py_ssize_t __pyx_t_2;
  PyObject *(*__pyx_t_3)(PyObject *);
  PyObject *__pyx_t_4 = NULL;
  int __pyx_t_5;
  int __pyx_t_6;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("genexpr", 0);
  switch (__pyx_generator->resume_label) {
    case 0: goto __pyx_L3_first_run;
    case 1: goto __pyx_L7_resume_from_yield;
    default: /* CPython raises the right error here */
    __Pyx_RefNannyFinishContext();
    return NULL;
  }
  __pyx_L3_first_run:;
  if (unlikely(!__pyx_sent_value)) __PYX_ERR(0, 2093, __pyx_L1_error)
  if (unlikely(!__pyx_cur_scope->__pyx_outer_scope->__pyx_v_idx)) { __Pyx_RaiseClosureNameError("idx"); __PYX_ERR(0, 2093, __pyx_L1_error) }
  if (likely(PyList_CheckExact(__pyx_cur_scope->__pyx_outer_scope->__pyx_v_idx)) || PyTuple_CheckExact(__pyx_cur_scope->__pyx_outer_scope->__pyx_v_idx)) {
    __pyx_t_1 = __pyx_cur_scope->__pyx_outer_scope->__pyx_v_idx; __Pyx_INCREF(__pyx_t_1); __pyx_t_2 = 0;
    __pyx_t_3 = NULL;
  } else {
    __pyx_t_2 = -1; __pyx_t_1 = PyObject_GetIter(__pyx_cur_scope->__pyx_outer_scope->__pyx_v_idx); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2093, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_3 = Py_TYPE(__pyx_t_1)->tp_iternext; if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 2093, __pyx_L1_error)
  }
  for (;;) {
    if (likely(!__pyx_t_3)) {
      if (likely(PyList_CheckExact(__pyx_t_1))) {
        if (__pyx_t_2 >= PyList_GET_SIZE(__pyx_t_1)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_4 = PyList_GET_ITEM(__pyx_t_1, __pyx_t_2); __Pyx_INCREF(__pyx_t_4); __pyx_t_2++; if (unlikely(0 < 0)) __PYX_ERR(0, 2093, __pyx_L1_error)
        #else
        __pyx_t_4 = PySequence_ITEM(__pyx_t_1, __pyx_t_2); __pyx_t_2++; if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2093, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_4);
        #endif
      } else {
        if (__pyx_t_2 >= PyTuple_GET_SIZE(__pyx_t_1)) break;
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_4 = PyTuple_GET_ITEM(__pyx_t_1, __pyx_t_2); __Pyx_INCREF(__pyx_t_4); __pyx_t_2++; if (unlikely(0 < 0)) __PYX_ERR(0, 2093, __pyx_L1_error)
        #else
        __pyx_t_4 = PySequence_ITEM(__pyx_t_1, __pyx_t_2); __pyx_t_2++; if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2093, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_4);
        #endif
      }
    } else {
      __pyx_t_4 = __pyx_t_3(__pyx_t_1);
      if (unlikely(!__pyx_t_4)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) PyErr_Clear();
          else __PYX_ERR(0, 2093, __pyx_L1_error)
        }
        break;
      }
      __Pyx_GOTREF(__pyx_t_4);
    }
    __Pyx_XGOTREF(__pyx_cur_scope->__pyx_v_i);
    __Pyx_XDECREF_SET(__pyx_cur_scope->__pyx_v_i, __pyx_t_4);
    __Pyx_GIVEREF(__pyx_t_4);
    __pyx_t_4 = 0;
    __pyx_t_5 = (__pyx_cur_scope->__pyx_v_i != Py_None);
    __pyx_t_6 = (__pyx_t_5 != 0);
    if (__pyx_t_6) {
      __Pyx_INCREF(__pyx_cur_scope->__pyx_v_i);
      __pyx_r = __pyx_cur_scope->__pyx_v_i;
      __Pyx_XGIVEREF(__pyx_t_1);
      __pyx_cur_scope->__pyx_t_0 = __pyx_t_1;
      __pyx_cur_scope->__pyx_t_1 = __pyx_t_2;
      __pyx_cur_scope->__pyx_t_2 = __pyx_t_3;
      __Pyx_XGIVEREF(__pyx_r);
      __Pyx_RefNannyFinishContext();
      __Pyx_Coroutine_ResetAndClearException(__pyx_generator);
      /* return from generator, yielding value */
      __pyx_generator->resume_label = 1;
      return __pyx_r;
      __pyx_L7_resume_from_yield:;
      __pyx_t_1 = __pyx_cur_scope->__pyx_t_0;
      __pyx_cur_scope->__pyx_t_0 = 0;
      __Pyx_XGOTREF(__pyx_t_1);
      __pyx_t_2 = __pyx_cur_scope->__pyx_t_1;
      __pyx_t_3 = __pyx_cur_scope->__pyx_t_2;
      if (unlikely(!__pyx_sent_value)) __PYX_ERR(0, 2093, __pyx_L1_error)
    }
  }
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  CYTHON_MAYBE_UNUSED_VAR(__pyx_cur_scope);

  /* function exit code */
  PyErr_SetNone(PyExc_StopIteration);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_AddTraceback("genexpr", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_r); __pyx_r = 0;
  __Pyx_Coroutine_ResetAndClearException(__pyx_generator);
  __pyx_generator->resume_label = -1;
  __Pyx_Coroutine_clear((PyObject*)__pyx_generator);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":2071
 *             free(steps)
 * 
 *     def __setitem__(self, idx, v):             # <<<<<<<<<<<<<<
 *         cdef GpuArray tmp, gv
 * 
 */

static int __pyx_pf_5pygpu_8gpuarray_8GpuArray_42__setitem__(struct PyGpuArrayObject *__pyx_v_self, PyObject *__pyx_v_idx, PyObject *__pyx_v_v) {
  struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_7___setitem__ *__pyx_cur_scope;
  struct PyGpuArrayObject *__pyx_v_tmp = 0;
  struct PyGpuArrayObject *__pyx_v_gv = 0;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_t_2;
  int __pyx_t_3;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  int __pyx_t_7;
  PyObject *__pyx_t_8 = NULL;
  PyObject *__pyx_t_9 = NULL;
  PyObject *__pyx_t_10 = NULL;
  PyObject *__pyx_t_11 = NULL;
  __Pyx_RefNannySetupContext("__setitem__", 0);
  __pyx_cur_scope = (struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_7___setitem__ *)__pyx_tp_new_5pygpu_8gpuarray___pyx_scope_struct_7___setitem__(__pyx_ptype_5pygpu_8gpuarray___pyx_scope_struct_7___setitem__, __pyx_empty_tuple, NULL);
  if (unlikely(!__pyx_cur_scope)) {
    __pyx_cur_scope = ((struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_7___setitem__ *)Py_None);
    __Pyx_INCREF(Py_None);
    __PYX_ERR(0, 2071, __pyx_L1_error)
  } else {
    __Pyx_GOTREF(__pyx_cur_scope);
  }
  __pyx_cur_scope->__pyx_v_idx = __pyx_v_idx;
  __Pyx_INCREF(__pyx_cur_scope->__pyx_v_idx);
  __Pyx_GIVEREF(__pyx_cur_scope->__pyx_v_idx);

  /* "pygpu/gpuarray.pyx":2074
 *         cdef GpuArray tmp, gv
 * 
 *         if isinstance(idx, list):             # <<<<<<<<<<<<<<
 *             if any(isinstance(i, slice) or i is Ellipsis for i in idx):
 *                 self.__setitem__(tuple(idx), v)
 */
  __pyx_t_1 = __pyx_cur_scope->__pyx_v_idx;
  __Pyx_INCREF(__pyx_t_1);
  __pyx_t_2 = PyList_Check(__pyx_t_1); 
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_3 = (__pyx_t_2 != 0);
  if (__pyx_t_3) {

    /* "pygpu/gpuarray.pyx":2075
 * 
 *         if isinstance(idx, list):
 *             if any(isinstance(i, slice) or i is Ellipsis for i in idx):             # <<<<<<<<<<<<<<
 *                 self.__setitem__(tuple(idx), v)
 *             else:
 */
    __pyx_t_1 = __pyx_pf_5pygpu_8gpuarray_8GpuArray_11__setitem___genexpr(((PyObject*)__pyx_cur_scope)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2075, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_4 = __Pyx_Generator_Next(__pyx_t_1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2075, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_3 = __Pyx_PyObject_IsTrue(__pyx_t_4); if (unlikely(__pyx_t_3 < 0)) __PYX_ERR(0, 2075, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    if (__pyx_t_3) {

      /* "pygpu/gpuarray.pyx":2076
 *         if isinstance(idx, list):
 *             if any(isinstance(i, slice) or i is Ellipsis for i in idx):
 *                 self.__setitem__(tuple(idx), v)             # <<<<<<<<<<<<<<
 *             else:
 *                 raise NotImplementedError, "fancy indexing not supported"
 */
      __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_setitem); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2076, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __pyx_t_5 = __Pyx_PySequence_Tuple(__pyx_cur_scope->__pyx_v_idx); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 2076, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_5);
      __pyx_t_6 = NULL;
      __pyx_t_7 = 0;
      if (CYTHON_UNPACK_METHODS && likely(PyMethod_Check(__pyx_t_1))) {
        __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_1);
        if (likely(__pyx_t_6)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_1);
          __Pyx_INCREF(__pyx_t_6);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_1, function);
          __pyx_t_7 = 1;
        }
      }
      #if CYTHON_FAST_PYCALL
      if (PyFunction_Check(__pyx_t_1)) {
        PyObject *__pyx_temp[3] = {__pyx_t_6, __pyx_t_5, __pyx_v_v};
        __pyx_t_4 = __Pyx_PyFunction_FastCall(__pyx_t_1, __pyx_temp+1-__pyx_t_7, 2+__pyx_t_7); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2076, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
        __Pyx_GOTREF(__pyx_t_4);
        __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      } else
      #endif
      #if CYTHON_FAST_PYCCALL
      if (__Pyx_PyFastCFunction_Check(__pyx_t_1)) {
        PyObject *__pyx_temp[3] = {__pyx_t_6, __pyx_t_5, __pyx_v_v};
        __pyx_t_4 = __Pyx_PyCFunction_FastCall(__pyx_t_1, __pyx_temp+1-__pyx_t_7, 2+__pyx_t_7); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2076, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
        __Pyx_GOTREF(__pyx_t_4);
        __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      } else
      #endif
      {
        __pyx_t_8 = PyTuple_New(2+__pyx_t_7); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 2076, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_8);
        if (__pyx_t_6) {
          __Pyx_GIVEREF(__pyx_t_6); PyTuple_SET_ITEM(__pyx_t_8, 0, __pyx_t_6); __pyx_t_6 = NULL;
        }
        __Pyx_GIVEREF(__pyx_t_5);
        PyTuple_SET_ITEM(__pyx_t_8, 0+__pyx_t_7, __pyx_t_5);
        __Pyx_INCREF(__pyx_v_v);
        __Pyx_GIVEREF(__pyx_v_v);
        PyTuple_SET_ITEM(__pyx_t_8, 1+__pyx_t_7, __pyx_v_v);
        __pyx_t_5 = 0;
        __pyx_t_4 = __Pyx_PyObject_Call(__pyx_t_1, __pyx_t_8, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2076, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_4);
        __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      }
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;

      /* "pygpu/gpuarray.pyx":2075
 * 
 *         if isinstance(idx, list):
 *             if any(isinstance(i, slice) or i is Ellipsis for i in idx):             # <<<<<<<<<<<<<<
 *                 self.__setitem__(tuple(idx), v)
 *             else:
 */
      goto __pyx_L4;
    }

    /* "pygpu/gpuarray.pyx":2078
 *                 self.__setitem__(tuple(idx), v)
 *             else:
 *                 raise NotImplementedError, "fancy indexing not supported"             # <<<<<<<<<<<<<<
 *         try:
 *             iter(idx)
 */
    /*else*/ {
      __Pyx_Raise(__pyx_builtin_NotImplementedError, __pyx_kp_s_fancy_indexing_not_supported, 0, 0);
      __PYX_ERR(0, 2078, __pyx_L1_error)
    }
    __pyx_L4:;

    /* "pygpu/gpuarray.pyx":2074
 *         cdef GpuArray tmp, gv
 * 
 *         if isinstance(idx, list):             # <<<<<<<<<<<<<<
 *             if any(isinstance(i, slice) or i is Ellipsis for i in idx):
 *                 self.__setitem__(tuple(idx), v)
 */
  }

  /* "pygpu/gpuarray.pyx":2079
 *             else:
 *                 raise NotImplementedError, "fancy indexing not supported"
 *         try:             # <<<<<<<<<<<<<<
 *             iter(idx)
 *         except TypeError:
 */
  {
    __Pyx_PyThreadState_declare
    __Pyx_PyThreadState_assign
    __Pyx_ExceptionSave(&__pyx_t_9, &__pyx_t_10, &__pyx_t_11);
    __Pyx_XGOTREF(__pyx_t_9);
    __Pyx_XGOTREF(__pyx_t_10);
    __Pyx_XGOTREF(__pyx_t_11);
    /*try:*/ {

      /* "pygpu/gpuarray.pyx":2080
 *                 raise NotImplementedError, "fancy indexing not supported"
 *         try:
 *             iter(idx)             # <<<<<<<<<<<<<<
 *         except TypeError:
 *             idx = (idx,)
 */
      __pyx_t_4 = __pyx_cur_scope->__pyx_v_idx;
      __Pyx_INCREF(__pyx_t_4);
      __pyx_t_1 = PyObject_GetIter(__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2080, __pyx_L5_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

      /* "pygpu/gpuarray.pyx":2079
 *             else:
 *                 raise NotImplementedError, "fancy indexing not supported"
 *         try:             # <<<<<<<<<<<<<<
 *             iter(idx)
 *         except TypeError:
 */
    }

    /* "pygpu/gpuarray.pyx":2084
 *             idx = (idx,)
 *         else:
 *             if all(isinstance(i, list) for i in idx):             # <<<<<<<<<<<<<<
 *                 raise NotImplementedError, "fancy indexing not supported"
 * 
 */
    /*else:*/ {
      __pyx_t_1 = __pyx_pf_5pygpu_8gpuarray_8GpuArray_11__setitem___3genexpr(((PyObject*)__pyx_cur_scope)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2084, __pyx_L7_except_error)
      __Pyx_GOTREF(__pyx_t_1);
      __pyx_t_4 = __Pyx_Generator_Next(__pyx_t_1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2084, __pyx_L7_except_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __pyx_t_3 = __Pyx_PyObject_IsTrue(__pyx_t_4); if (unlikely(__pyx_t_3 < 0)) __PYX_ERR(0, 2084, __pyx_L7_except_error)
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      if (__pyx_t_3) {

        /* "pygpu/gpuarray.pyx":2085
 *         else:
 *             if all(isinstance(i, list) for i in idx):
 *                 raise NotImplementedError, "fancy indexing not supported"             # <<<<<<<<<<<<<<
 * 
 *             idx = tuple(idx)
 */
        __Pyx_Raise(__pyx_builtin_NotImplementedError, __pyx_kp_s_fancy_indexing_not_supported, 0, 0);
        __PYX_ERR(0, 2085, __pyx_L7_except_error)

        /* "pygpu/gpuarray.pyx":2084
 *             idx = (idx,)
 *         else:
 *             if all(isinstance(i, list) for i in idx):             # <<<<<<<<<<<<<<
 *                 raise NotImplementedError, "fancy indexing not supported"
 * 
 */
      }

      /* "pygpu/gpuarray.pyx":2087
 *                 raise NotImplementedError, "fancy indexing not supported"
 * 
 *             idx = tuple(idx)             # <<<<<<<<<<<<<<
 * 
 *         if countis(idx, Ellipsis) > 1:
 */
      __pyx_t_4 = __Pyx_PySequence_Tuple(__pyx_cur_scope->__pyx_v_idx); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2087, __pyx_L7_except_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_GOTREF(__pyx_cur_scope->__pyx_v_idx);
      __Pyx_DECREF_SET(__pyx_cur_scope->__pyx_v_idx, __pyx_t_4);
      __Pyx_GIVEREF(__pyx_t_4);
      __pyx_t_4 = 0;
    }
    __Pyx_XDECREF(__pyx_t_9); __pyx_t_9 = 0;
    __Pyx_XDECREF(__pyx_t_10); __pyx_t_10 = 0;
    __Pyx_XDECREF(__pyx_t_11); __pyx_t_11 = 0;
    goto __pyx_L10_try_end;
    __pyx_L5_error:;
    __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
    __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;

    /* "pygpu/gpuarray.pyx":2081
 *         try:
 *             iter(idx)
 *         except TypeError:             # <<<<<<<<<<<<<<
 *             idx = (idx,)
 *         else:
 */
    __pyx_t_7 = __Pyx_PyErr_ExceptionMatches(__pyx_builtin_TypeError);
    if (__pyx_t_7) {
      __Pyx_AddTraceback("pygpu.gpuarray.GpuArray.__setitem__", __pyx_clineno, __pyx_lineno, __pyx_filename);
      if (__Pyx_GetException(&__pyx_t_4, &__pyx_t_1, &__pyx_t_8) < 0) __PYX_ERR(0, 2081, __pyx_L7_except_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_GOTREF(__pyx_t_8);

      /* "pygpu/gpuarray.pyx":2082
 *             iter(idx)
 *         except TypeError:
 *             idx = (idx,)             # <<<<<<<<<<<<<<
 *         else:
 *             if all(isinstance(i, list) for i in idx):
 */
      __pyx_t_5 = PyTuple_New(1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 2082, __pyx_L7_except_error)
      __Pyx_GOTREF(__pyx_t_5);
      __Pyx_INCREF(__pyx_cur_scope->__pyx_v_idx);
      __Pyx_GIVEREF(__pyx_cur_scope->__pyx_v_idx);
      PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_cur_scope->__pyx_v_idx);
      __Pyx_GOTREF(__pyx_cur_scope->__pyx_v_idx);
      __Pyx_DECREF_SET(__pyx_cur_scope->__pyx_v_idx, __pyx_t_5);
      __Pyx_GIVEREF(__pyx_t_5);
      __pyx_t_5 = 0;
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      goto __pyx_L6_exception_handled;
    }
    goto __pyx_L7_except_error;
    __pyx_L7_except_error:;

    /* "pygpu/gpuarray.pyx":2079
 *             else:
 *                 raise NotImplementedError, "fancy indexing not supported"
 *         try:             # <<<<<<<<<<<<<<
 *             iter(idx)
 *         except TypeError:
 */
    __Pyx_XGIVEREF(__pyx_t_9);
    __Pyx_XGIVEREF(__pyx_t_10);
    __Pyx_XGIVEREF(__pyx_t_11);
    __Pyx_ExceptionReset(__pyx_t_9, __pyx_t_10, __pyx_t_11);
    goto __pyx_L1_error;
    __pyx_L6_exception_handled:;
    __Pyx_XGIVEREF(__pyx_t_9);
    __Pyx_XGIVEREF(__pyx_t_10);
    __Pyx_XGIVEREF(__pyx_t_11);
    __Pyx_ExceptionReset(__pyx_t_9, __pyx_t_10, __pyx_t_11);
    __pyx_L10_try_end:;
  }

  /* "pygpu/gpuarray.pyx":2089
 *             idx = tuple(idx)
 * 
 *         if countis(idx, Ellipsis) > 1:             # <<<<<<<<<<<<<<
 *             raise IndexError, "cannot use more than one Ellipsis"
 * 
 */
  __pyx_t_8 = __pyx_cur_scope->__pyx_v_idx;
  __Pyx_INCREF(__pyx_t_8);
  __pyx_t_3 = ((__pyx_f_5pygpu_8gpuarray_countis(__pyx_t_8, __pyx_builtin_Ellipsis) > 1) != 0);
  __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  if (__pyx_t_3) {

    /* "pygpu/gpuarray.pyx":2090
 * 
 *         if countis(idx, Ellipsis) > 1:
 *             raise IndexError, "cannot use more than one Ellipsis"             # <<<<<<<<<<<<<<
 * 
 *         # Remove None entries, they should be ignored (as in Numpy)
 */
    __Pyx_Raise(__pyx_builtin_IndexError, __pyx_kp_s_cannot_use_more_than_one_Ellipsi, 0, 0);
    __PYX_ERR(0, 2090, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":2089
 *             idx = tuple(idx)
 * 
 *         if countis(idx, Ellipsis) > 1:             # <<<<<<<<<<<<<<
 *             raise IndexError, "cannot use more than one Ellipsis"
 * 
 */
  }

  /* "pygpu/gpuarray.pyx":2093
 * 
 *         # Remove None entries, they should be ignored (as in Numpy)
 *         idx = tuple(i for i in idx if i is not None)             # <<<<<<<<<<<<<<
 *         tmp = self.__cgetitem__(idx)
 *         gv = carray(v, self.ga.typecode, False, 'A', 0, self.context, GpuArray)
 */
  __pyx_t_8 = __pyx_pf_5pygpu_8gpuarray_8GpuArray_11__setitem___6genexpr(((PyObject*)__pyx_cur_scope)); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 2093, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __pyx_t_1 = __Pyx_PySequence_Tuple(__pyx_t_8); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2093, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  __Pyx_GOTREF(__pyx_cur_scope->__pyx_v_idx);
  __Pyx_DECREF_SET(__pyx_cur_scope->__pyx_v_idx, __pyx_t_1);
  __Pyx_GIVEREF(__pyx_t_1);
  __pyx_t_1 = 0;

  /* "pygpu/gpuarray.pyx":2094
 *         # Remove None entries, they should be ignored (as in Numpy)
 *         idx = tuple(i for i in idx if i is not None)
 *         tmp = self.__cgetitem__(idx)             # <<<<<<<<<<<<<<
 *         gv = carray(v, self.ga.typecode, False, 'A', 0, self.context, GpuArray)
 *         array_setarray(tmp, gv)
 */
  __pyx_t_1 = __pyx_cur_scope->__pyx_v_idx;
  __Pyx_INCREF(__pyx_t_1);
  __pyx_t_8 = ((struct __pyx_vtabstruct_5pygpu_8gpuarray_GpuArray *)__pyx_v_self->__pyx_vtab)->__pyx___cgetitem__(__pyx_v_self, __pyx_t_1); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 2094, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  if (!(likely(((__pyx_t_8) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_8, __pyx_ptype_5pygpu_8gpuarray_GpuArray))))) __PYX_ERR(0, 2094, __pyx_L1_error)
  __pyx_v_tmp = ((struct PyGpuArrayObject *)__pyx_t_8);
  __pyx_t_8 = 0;

  /* "pygpu/gpuarray.pyx":2095
 *         idx = tuple(i for i in idx if i is not None)
 *         tmp = self.__cgetitem__(idx)
 *         gv = carray(v, self.ga.typecode, False, 'A', 0, self.context, GpuArray)             # <<<<<<<<<<<<<<
 *         array_setarray(tmp, gv)
 * 
 */
  __pyx_t_8 = __Pyx_PyInt_From_int(__pyx_v_self->ga.typecode); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 2095, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __pyx_t_1 = ((PyObject *)__pyx_v_self->context);
  __Pyx_INCREF(__pyx_t_1);
  __pyx_t_4 = __pyx_f_5pygpu_8gpuarray_carray(__pyx_v_v, __pyx_t_8, Py_False, __pyx_n_s_A, 0, ((struct PyGpuContextObject *)__pyx_t_1), ((PyObject *)__pyx_ptype_5pygpu_8gpuarray_GpuArray)); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2095, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  if (!(likely(((__pyx_t_4) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_4, __pyx_ptype_5pygpu_8gpuarray_GpuArray))))) __PYX_ERR(0, 2095, __pyx_L1_error)
  __pyx_v_gv = ((struct PyGpuArrayObject *)__pyx_t_4);
  __pyx_t_4 = 0;

  /* "pygpu/gpuarray.pyx":2096
 *         tmp = self.__cgetitem__(idx)
 *         gv = carray(v, self.ga.typecode, False, 'A', 0, self.context, GpuArray)
 *         array_setarray(tmp, gv)             # <<<<<<<<<<<<<<
 * 
 *     def take1(self, GpuArray idx):
 */
  __pyx_t_7 = __pyx_f_5pygpu_8gpuarray_array_setarray(__pyx_v_tmp, __pyx_v_gv); if (unlikely(__pyx_t_7 == ((int)-1))) __PYX_ERR(0, 2096, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":2071
 *             free(steps)
 * 
 *     def __setitem__(self, idx, v):             # <<<<<<<<<<<<<<
 *         cdef GpuArray tmp, gv
 * 
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_AddTraceback("pygpu.gpuarray.GpuArray.__setitem__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_tmp);
  __Pyx_XDECREF((PyObject *)__pyx_v_gv);
  __Pyx_DECREF(((PyObject *)__pyx_cur_scope));
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":2098
 *         array_setarray(tmp, gv)
 * 
 *     def take1(self, GpuArray idx):             # <<<<<<<<<<<<<<
 *         """
 *         take1(idx)
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_8GpuArray_45take1(PyObject *__pyx_v_self, PyObject *__pyx_v_idx); /*proto*/
static char __pyx_doc_5pygpu_8gpuarray_8GpuArray_44take1[] = "\n        take1(idx)\n        ";
static PyObject *__pyx_pw_5pygpu_8gpuarray_8GpuArray_45take1(PyObject *__pyx_v_self, PyObject *__pyx_v_idx) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("take1 (wrapper)", 0);
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_idx), __pyx_ptype_5pygpu_8gpuarray_GpuArray, 1, "idx", 0))) __PYX_ERR(0, 2098, __pyx_L1_error)
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_8GpuArray_44take1(((struct PyGpuArrayObject *)__pyx_v_self), ((struct PyGpuArrayObject *)__pyx_v_idx));

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_8GpuArray_44take1(struct PyGpuArrayObject *__pyx_v_self, struct PyGpuArrayObject *__pyx_v_idx) {
  struct PyGpuArrayObject *__pyx_v_res = 0;
  size_t __pyx_v_odim;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  int __pyx_t_3;
  int __pyx_t_4;
  char const *__pyx_t_5;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  PyObject *__pyx_t_8 = NULL;
  PyObject *__pyx_t_9 = NULL;
  PyObject *__pyx_t_10 = NULL;
  PyObject *__pyx_t_11 = NULL;
  __Pyx_RefNannySetupContext("take1", 0);

  /* "pygpu/gpuarray.pyx":2104
 *         cdef GpuArray res
 *         cdef size_t odim
 *         if idx.ga.nd != 1:             # <<<<<<<<<<<<<<
 *             raise ValueError, "Expected index with nd=1"
 *         odim = self.ga.dimensions[0]
 */
  __pyx_t_1 = ((__pyx_v_idx->ga.nd != 1) != 0);
  if (__pyx_t_1) {

    /* "pygpu/gpuarray.pyx":2105
 *         cdef size_t odim
 *         if idx.ga.nd != 1:
 *             raise ValueError, "Expected index with nd=1"             # <<<<<<<<<<<<<<
 *         odim = self.ga.dimensions[0]
 *         try:
 */
    __Pyx_Raise(__pyx_builtin_ValueError, __pyx_kp_s_Expected_index_with_nd_1, 0, 0);
    __PYX_ERR(0, 2105, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":2104
 *         cdef GpuArray res
 *         cdef size_t odim
 *         if idx.ga.nd != 1:             # <<<<<<<<<<<<<<
 *             raise ValueError, "Expected index with nd=1"
 *         odim = self.ga.dimensions[0]
 */
  }

  /* "pygpu/gpuarray.pyx":2106
 *         if idx.ga.nd != 1:
 *             raise ValueError, "Expected index with nd=1"
 *         odim = self.ga.dimensions[0]             # <<<<<<<<<<<<<<
 *         try:
 *             self.ga.dimensions[0] = idx.ga.dimensions[0]
 */
  __pyx_v_odim = (__pyx_v_self->ga.dimensions[0]);

  /* "pygpu/gpuarray.pyx":2107
 *             raise ValueError, "Expected index with nd=1"
 *         odim = self.ga.dimensions[0]
 *         try:             # <<<<<<<<<<<<<<
 *             self.ga.dimensions[0] = idx.ga.dimensions[0]
 *             res = pygpu_empty_like(self, GA_C_ORDER, -1)
 */
  /*try:*/ {

    /* "pygpu/gpuarray.pyx":2108
 *         odim = self.ga.dimensions[0]
 *         try:
 *             self.ga.dimensions[0] = idx.ga.dimensions[0]             # <<<<<<<<<<<<<<
 *             res = pygpu_empty_like(self, GA_C_ORDER, -1)
 *         finally:
 */
    (__pyx_v_self->ga.dimensions[0]) = (__pyx_v_idx->ga.dimensions[0]);

    /* "pygpu/gpuarray.pyx":2109
 *         try:
 *             self.ga.dimensions[0] = idx.ga.dimensions[0]
 *             res = pygpu_empty_like(self, GA_C_ORDER, -1)             # <<<<<<<<<<<<<<
 *         finally:
 *             self.ga.dimensions[0] = odim
 */
    __pyx_t_2 = ((PyObject *)__pyx_f_5pygpu_8gpuarray_pygpu_empty_like(__pyx_v_self, GA_C_ORDER, -1)); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2109, __pyx_L5_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_v_res = ((struct PyGpuArrayObject *)__pyx_t_2);
    __pyx_t_2 = 0;
  }

  /* "pygpu/gpuarray.pyx":2111
 *             res = pygpu_empty_like(self, GA_C_ORDER, -1)
 *         finally:
 *             self.ga.dimensions[0] = odim             # <<<<<<<<<<<<<<
 *         array_take1(res, self, idx, 1)
 *         return res
 */
  /*finally:*/ {
    /*normal exit:*/{
      (__pyx_v_self->ga.dimensions[0]) = __pyx_v_odim;
      goto __pyx_L6;
    }
    __pyx_L5_error:;
    /*exception exit:*/{
      __Pyx_PyThreadState_declare
      __Pyx_PyThreadState_assign
      __pyx_t_6 = 0; __pyx_t_7 = 0; __pyx_t_8 = 0; __pyx_t_9 = 0; __pyx_t_10 = 0; __pyx_t_11 = 0;
      __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
      if (PY_MAJOR_VERSION >= 3) __Pyx_ExceptionSwap(&__pyx_t_9, &__pyx_t_10, &__pyx_t_11);
      if ((PY_MAJOR_VERSION < 3) || unlikely(__Pyx_GetException(&__pyx_t_6, &__pyx_t_7, &__pyx_t_8) < 0)) __Pyx_ErrFetch(&__pyx_t_6, &__pyx_t_7, &__pyx_t_8);
      __Pyx_XGOTREF(__pyx_t_6);
      __Pyx_XGOTREF(__pyx_t_7);
      __Pyx_XGOTREF(__pyx_t_8);
      __Pyx_XGOTREF(__pyx_t_9);
      __Pyx_XGOTREF(__pyx_t_10);
      __Pyx_XGOTREF(__pyx_t_11);
      __pyx_t_3 = __pyx_lineno; __pyx_t_4 = __pyx_clineno; __pyx_t_5 = __pyx_filename;
      {
        (__pyx_v_self->ga.dimensions[0]) = __pyx_v_odim;
      }
      if (PY_MAJOR_VERSION >= 3) {
        __Pyx_XGIVEREF(__pyx_t_9);
        __Pyx_XGIVEREF(__pyx_t_10);
        __Pyx_XGIVEREF(__pyx_t_11);
        __Pyx_ExceptionReset(__pyx_t_9, __pyx_t_10, __pyx_t_11);
      }
      __Pyx_XGIVEREF(__pyx_t_6);
      __Pyx_XGIVEREF(__pyx_t_7);
      __Pyx_XGIVEREF(__pyx_t_8);
      __Pyx_ErrRestore(__pyx_t_6, __pyx_t_7, __pyx_t_8);
      __pyx_t_6 = 0; __pyx_t_7 = 0; __pyx_t_8 = 0; __pyx_t_9 = 0; __pyx_t_10 = 0; __pyx_t_11 = 0;
      __pyx_lineno = __pyx_t_3; __pyx_clineno = __pyx_t_4; __pyx_filename = __pyx_t_5;
      goto __pyx_L1_error;
    }
    __pyx_L6:;
  }

  /* "pygpu/gpuarray.pyx":2112
 *         finally:
 *             self.ga.dimensions[0] = odim
 *         array_take1(res, self, idx, 1)             # <<<<<<<<<<<<<<
 *         return res
 * 
 */
  __pyx_t_4 = __pyx_f_5pygpu_8gpuarray_array_take1(__pyx_v_res, __pyx_v_self, __pyx_v_idx, 1); if (unlikely(__pyx_t_4 == ((int)-1))) __PYX_ERR(0, 2112, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":2113
 *             self.ga.dimensions[0] = odim
 *         array_take1(res, self, idx, 1)
 *         return res             # <<<<<<<<<<<<<<
 * 
 *     def __hash__(self):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_res));
  __pyx_r = ((PyObject *)__pyx_v_res);
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":2098
 *         array_setarray(tmp, gv)
 * 
 *     def take1(self, GpuArray idx):             # <<<<<<<<<<<<<<
 *         """
 *         take1(idx)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("pygpu.gpuarray.GpuArray.take1", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_res);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":2115
 *         return res
 * 
 *     def __hash__(self):             # <<<<<<<<<<<<<<
 *         raise TypeError, "unhashable type '%s'" % (self.__class__,)
 * 
 */

/* Python wrapper */
static Py_hash_t __pyx_pw_5pygpu_8gpuarray_8GpuArray_47__hash__(PyObject *__pyx_v_self); /*proto*/
static Py_hash_t __pyx_pw_5pygpu_8gpuarray_8GpuArray_47__hash__(PyObject *__pyx_v_self) {
  Py_hash_t __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__hash__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_8GpuArray_46__hash__(((struct PyGpuArrayObject *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static Py_hash_t __pyx_pf_5pygpu_8gpuarray_8GpuArray_46__hash__(struct PyGpuArrayObject *__pyx_v_self) {
  Py_hash_t __pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  __Pyx_RefNannySetupContext("__hash__", 0);

  /* "pygpu/gpuarray.pyx":2116
 * 
 *     def __hash__(self):
 *         raise TypeError, "unhashable type '%s'" % (self.__class__,)             # <<<<<<<<<<<<<<
 * 
 *     def __nonzero__(self):
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_class); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2116, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = PyTuple_New(1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2116, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_GIVEREF(__pyx_t_1);
  PyTuple_SET_ITEM(__pyx_t_2, 0, __pyx_t_1);
  __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyString_Format(__pyx_kp_s_unhashable_type_s, __pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2116, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_Raise(__pyx_builtin_TypeError, __pyx_t_1, 0, 0);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __PYX_ERR(0, 2116, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":2115
 *         return res
 * 
 *     def __hash__(self):             # <<<<<<<<<<<<<<
 *         raise TypeError, "unhashable type '%s'" % (self.__class__,)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("pygpu.gpuarray.GpuArray.__hash__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  if (unlikely(__pyx_r == -1) && !PyErr_Occurred()) __pyx_r = -2;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":2118
 *         raise TypeError, "unhashable type '%s'" % (self.__class__,)
 * 
 *     def __nonzero__(self):             # <<<<<<<<<<<<<<
 *         cdef int sz = self.size
 *         if sz == 0:
 */

/* Python wrapper */
static int __pyx_pw_5pygpu_8gpuarray_8GpuArray_49__nonzero__(PyObject *__pyx_v_self); /*proto*/
static int __pyx_pw_5pygpu_8gpuarray_8GpuArray_49__nonzero__(PyObject *__pyx_v_self) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__nonzero__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_8GpuArray_48__nonzero__(((struct PyGpuArrayObject *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_5pygpu_8gpuarray_8GpuArray_48__nonzero__(struct PyGpuArrayObject *__pyx_v_self) {
  int __pyx_v_sz;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_t_2;
  int __pyx_t_3;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  __Pyx_RefNannySetupContext("__nonzero__", 0);

  /* "pygpu/gpuarray.pyx":2119
 * 
 *     def __nonzero__(self):
 *         cdef int sz = self.size             # <<<<<<<<<<<<<<
 *         if sz == 0:
 *             return False
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_size); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2119, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_2 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 2119, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_sz = __pyx_t_2;

  /* "pygpu/gpuarray.pyx":2120
 *     def __nonzero__(self):
 *         cdef int sz = self.size
 *         if sz == 0:             # <<<<<<<<<<<<<<
 *             return False
 *         if sz == 1:
 */
  __pyx_t_3 = ((__pyx_v_sz == 0) != 0);
  if (__pyx_t_3) {

    /* "pygpu/gpuarray.pyx":2121
 *         cdef int sz = self.size
 *         if sz == 0:
 *             return False             # <<<<<<<<<<<<<<
 *         if sz == 1:
 *             return bool(numpy.asarray(self))
 */
    __pyx_r = 0;
    goto __pyx_L0;

    /* "pygpu/gpuarray.pyx":2120
 *     def __nonzero__(self):
 *         cdef int sz = self.size
 *         if sz == 0:             # <<<<<<<<<<<<<<
 *             return False
 *         if sz == 1:
 */
  }

  /* "pygpu/gpuarray.pyx":2122
 *         if sz == 0:
 *             return False
 *         if sz == 1:             # <<<<<<<<<<<<<<
 *             return bool(numpy.asarray(self))
 *         else:
 */
  __pyx_t_3 = ((__pyx_v_sz == 1) != 0);
  if (__pyx_t_3) {

    /* "pygpu/gpuarray.pyx":2123
 *             return False
 *         if sz == 1:
 *             return bool(numpy.asarray(self))             # <<<<<<<<<<<<<<
 *         else:
 *             raise ValueError, "Truth value of array with more than one element is ambiguous"
 */
    __pyx_t_4 = __Pyx_GetModuleGlobalName(__pyx_n_s_numpy); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2123, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_4, __pyx_n_s_asarray); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 2123, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_t_4 = NULL;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_5))) {
      __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_5);
      if (likely(__pyx_t_4)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
        __Pyx_INCREF(__pyx_t_4);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_5, function);
      }
    }
    if (!__pyx_t_4) {
      __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_5, ((PyObject *)__pyx_v_self)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2123, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
    } else {
      #if CYTHON_FAST_PYCALL
      if (PyFunction_Check(__pyx_t_5)) {
        PyObject *__pyx_temp[2] = {__pyx_t_4, ((PyObject *)__pyx_v_self)};
        __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_5, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2123, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
        __Pyx_GOTREF(__pyx_t_1);
      } else
      #endif
      #if CYTHON_FAST_PYCCALL
      if (__Pyx_PyFastCFunction_Check(__pyx_t_5)) {
        PyObject *__pyx_temp[2] = {__pyx_t_4, ((PyObject *)__pyx_v_self)};
        __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_5, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2123, __pyx_L1_error)
        __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
        __Pyx_GOTREF(__pyx_t_1);
      } else
      #endif
      {
        __pyx_t_6 = PyTuple_New(1+1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 2123, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_6);
        __Pyx_GIVEREF(__pyx_t_4); PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_t_4); __pyx_t_4 = NULL;
        __Pyx_INCREF(((PyObject *)__pyx_v_self));
        __Pyx_GIVEREF(((PyObject *)__pyx_v_self));
        PyTuple_SET_ITEM(__pyx_t_6, 0+1, ((PyObject *)__pyx_v_self));
        __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_5, __pyx_t_6, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2123, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      }
    }
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_3 = __Pyx_PyObject_IsTrue(__pyx_t_1); if (unlikely(__pyx_t_3 < 0)) __PYX_ERR(0, 2123, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_r = (!(!__pyx_t_3));
    goto __pyx_L0;

    /* "pygpu/gpuarray.pyx":2122
 *         if sz == 0:
 *             return False
 *         if sz == 1:             # <<<<<<<<<<<<<<
 *             return bool(numpy.asarray(self))
 *         else:
 */
  }

  /* "pygpu/gpuarray.pyx":2125
 *             return bool(numpy.asarray(self))
 *         else:
 *             raise ValueError, "Truth value of array with more than one element is ambiguous"             # <<<<<<<<<<<<<<
 * 
 *     property shape:
 */
  /*else*/ {
    __Pyx_Raise(__pyx_builtin_ValueError, __pyx_kp_s_Truth_value_of_array_with_more_t, 0, 0);
    __PYX_ERR(0, 2125, __pyx_L1_error)
  }

  /* "pygpu/gpuarray.pyx":2118
 *         raise TypeError, "unhashable type '%s'" % (self.__class__,)
 * 
 *     def __nonzero__(self):             # <<<<<<<<<<<<<<
 *         cdef int sz = self.size
 *         if sz == 0:
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_AddTraceback("pygpu.gpuarray.GpuArray.__nonzero__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":2129
 *     property shape:
 *         "shape of this ndarray (tuple)"
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             cdef unsigned int i
 *             res = [None] * self.ga.nd
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_8GpuArray_5shape_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_5pygpu_8gpuarray_8GpuArray_5shape_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_8GpuArray_5shape___get__(((struct PyGpuArrayObject *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_8GpuArray_5shape___get__(struct PyGpuArrayObject *__pyx_v_self) {
  unsigned int __pyx_v_i;
  PyObject *__pyx_v_res = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  unsigned int __pyx_t_2;
  unsigned int __pyx_t_3;
  __Pyx_RefNannySetupContext("__get__", 0);

  /* "pygpu/gpuarray.pyx":2131
 *         def __get__(self):
 *             cdef unsigned int i
 *             res = [None] * self.ga.nd             # <<<<<<<<<<<<<<
 *             for i in range(self.ga.nd):
 *                 res[i] = self.ga.dimensions[i]
 */
  __pyx_t_1 = PyList_New(1 * (__pyx_v_self->ga.nd)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2131, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  { Py_ssize_t __pyx_temp;
    for (__pyx_temp=0; __pyx_temp < __pyx_v_self->ga.nd; __pyx_temp++) {
      __Pyx_INCREF(Py_None);
      __Pyx_GIVEREF(Py_None);
      PyList_SET_ITEM(__pyx_t_1, __pyx_temp, Py_None);
    }
  }
  __pyx_v_res = ((PyObject*)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "pygpu/gpuarray.pyx":2132
 *             cdef unsigned int i
 *             res = [None] * self.ga.nd
 *             for i in range(self.ga.nd):             # <<<<<<<<<<<<<<
 *                 res[i] = self.ga.dimensions[i]
 *             return tuple(res)
 */
  __pyx_t_2 = __pyx_v_self->ga.nd;
  for (__pyx_t_3 = 0; __pyx_t_3 < __pyx_t_2; __pyx_t_3+=1) {
    __pyx_v_i = __pyx_t_3;

    /* "pygpu/gpuarray.pyx":2133
 *             res = [None] * self.ga.nd
 *             for i in range(self.ga.nd):
 *                 res[i] = self.ga.dimensions[i]             # <<<<<<<<<<<<<<
 *             return tuple(res)
 * 
 */
    __pyx_t_1 = __Pyx_PyInt_FromSize_t((__pyx_v_self->ga.dimensions[__pyx_v_i])); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2133, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    if (unlikely(__Pyx_SetItemInt(__pyx_v_res, __pyx_v_i, __pyx_t_1, unsigned int, 0, __Pyx_PyInt_From_unsigned_int, 1, 0, 1) < 0)) __PYX_ERR(0, 2133, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  }

  /* "pygpu/gpuarray.pyx":2134
 *             for i in range(self.ga.nd):
 *                 res[i] = self.ga.dimensions[i]
 *             return tuple(res)             # <<<<<<<<<<<<<<
 * 
 *         def __set__(self, newshape):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = PyList_AsTuple(__pyx_v_res); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2134, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":2129
 *     property shape:
 *         "shape of this ndarray (tuple)"
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             cdef unsigned int i
 *             res = [None] * self.ga.nd
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("pygpu.gpuarray.GpuArray.shape.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_res);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":2136
 *             return tuple(res)
 * 
 *         def __set__(self, newshape):             # <<<<<<<<<<<<<<
 *             # We support -1 only in a call to reshape
 *             cdef size_t *newdims
 */

/* Python wrapper */
static int __pyx_pw_5pygpu_8gpuarray_8GpuArray_5shape_3__set__(PyObject *__pyx_v_self, PyObject *__pyx_v_newshape); /*proto*/
static int __pyx_pw_5pygpu_8gpuarray_8GpuArray_5shape_3__set__(PyObject *__pyx_v_self, PyObject *__pyx_v_newshape) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__set__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_8GpuArray_5shape_2__set__(((struct PyGpuArrayObject *)__pyx_v_self), ((PyObject *)__pyx_v_newshape));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_5pygpu_8gpuarray_8GpuArray_5shape_2__set__(struct PyGpuArrayObject *__pyx_v_self, PyObject *__pyx_v_newshape) {
  size_t *__pyx_v_newdims;
  unsigned int __pyx_v_nd;
  unsigned int __pyx_v_i;
  int __pyx_v_err;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  Py_ssize_t __pyx_t_1;
  int __pyx_t_2;
  unsigned int __pyx_t_3;
  unsigned int __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  size_t __pyx_t_6;
  PyObject *__pyx_t_7 = NULL;
  int __pyx_t_8;
  int __pyx_t_9;
  char const *__pyx_t_10;
  PyObject *__pyx_t_11 = NULL;
  PyObject *__pyx_t_12 = NULL;
  PyObject *__pyx_t_13 = NULL;
  PyObject *__pyx_t_14 = NULL;
  PyObject *__pyx_t_15 = NULL;
  PyObject *__pyx_t_16 = NULL;
  __Pyx_RefNannySetupContext("__set__", 0);

  /* "pygpu/gpuarray.pyx":2142
 *             cdef unsigned int i
 *             cdef int err
 *             nd = <unsigned int>len(newshape)             # <<<<<<<<<<<<<<
 *             newdims = <size_t *>calloc(nd, sizeof(size_t))
 *             if newdims == NULL:
 */
  __pyx_t_1 = PyObject_Length(__pyx_v_newshape); if (unlikely(__pyx_t_1 == ((Py_ssize_t)-1))) __PYX_ERR(0, 2142, __pyx_L1_error)
  __pyx_v_nd = ((unsigned int)__pyx_t_1);

  /* "pygpu/gpuarray.pyx":2143
 *             cdef int err
 *             nd = <unsigned int>len(newshape)
 *             newdims = <size_t *>calloc(nd, sizeof(size_t))             # <<<<<<<<<<<<<<
 *             if newdims == NULL:
 *                 raise MemoryError, "calloc"
 */
  __pyx_v_newdims = ((size_t *)calloc(__pyx_v_nd, (sizeof(size_t))));

  /* "pygpu/gpuarray.pyx":2144
 *             nd = <unsigned int>len(newshape)
 *             newdims = <size_t *>calloc(nd, sizeof(size_t))
 *             if newdims == NULL:             # <<<<<<<<<<<<<<
 *                 raise MemoryError, "calloc"
 *             try:
 */
  __pyx_t_2 = ((__pyx_v_newdims == NULL) != 0);
  if (__pyx_t_2) {

    /* "pygpu/gpuarray.pyx":2145
 *             newdims = <size_t *>calloc(nd, sizeof(size_t))
 *             if newdims == NULL:
 *                 raise MemoryError, "calloc"             # <<<<<<<<<<<<<<
 *             try:
 *                 for i in range(nd):
 */
    __Pyx_Raise(__pyx_builtin_MemoryError, __pyx_n_s_calloc, 0, 0);
    __PYX_ERR(0, 2145, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":2144
 *             nd = <unsigned int>len(newshape)
 *             newdims = <size_t *>calloc(nd, sizeof(size_t))
 *             if newdims == NULL:             # <<<<<<<<<<<<<<
 *                 raise MemoryError, "calloc"
 *             try:
 */
  }

  /* "pygpu/gpuarray.pyx":2146
 *             if newdims == NULL:
 *                 raise MemoryError, "calloc"
 *             try:             # <<<<<<<<<<<<<<
 *                 for i in range(nd):
 *                     newdims[i] = newshape[i]
 */
  /*try:*/ {

    /* "pygpu/gpuarray.pyx":2147
 *                 raise MemoryError, "calloc"
 *             try:
 *                 for i in range(nd):             # <<<<<<<<<<<<<<
 *                     newdims[i] = newshape[i]
 *                 err = GpuArray_reshape_inplace(&self.ga, nd, newdims, GA_C_ORDER)
 */
    __pyx_t_3 = __pyx_v_nd;
    for (__pyx_t_4 = 0; __pyx_t_4 < __pyx_t_3; __pyx_t_4+=1) {
      __pyx_v_i = __pyx_t_4;

      /* "pygpu/gpuarray.pyx":2148
 *             try:
 *                 for i in range(nd):
 *                     newdims[i] = newshape[i]             # <<<<<<<<<<<<<<
 *                 err = GpuArray_reshape_inplace(&self.ga, nd, newdims, GA_C_ORDER)
 *                 if err != GA_NO_ERROR:
 */
      __pyx_t_5 = __Pyx_GetItemInt(__pyx_v_newshape, __pyx_v_i, unsigned int, 0, __Pyx_PyInt_From_unsigned_int, 0, 0, 1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 2148, __pyx_L5_error)
      __Pyx_GOTREF(__pyx_t_5);
      __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_5); if (unlikely((__pyx_t_6 == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 2148, __pyx_L5_error)
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      (__pyx_v_newdims[__pyx_v_i]) = __pyx_t_6;
    }

    /* "pygpu/gpuarray.pyx":2149
 *                 for i in range(nd):
 *                     newdims[i] = newshape[i]
 *                 err = GpuArray_reshape_inplace(&self.ga, nd, newdims, GA_C_ORDER)             # <<<<<<<<<<<<<<
 *                 if err != GA_NO_ERROR:
 *                     raise get_exc(err), GpuArray_error(&self.ga, err)
 */
    __pyx_v_err = GpuArray_reshape_inplace((&__pyx_v_self->ga), __pyx_v_nd, __pyx_v_newdims, GA_C_ORDER);

    /* "pygpu/gpuarray.pyx":2150
 *                     newdims[i] = newshape[i]
 *                 err = GpuArray_reshape_inplace(&self.ga, nd, newdims, GA_C_ORDER)
 *                 if err != GA_NO_ERROR:             # <<<<<<<<<<<<<<
 *                     raise get_exc(err), GpuArray_error(&self.ga, err)
 *             finally:
 */
    __pyx_t_2 = ((__pyx_v_err != GA_NO_ERROR) != 0);
    if (__pyx_t_2) {

      /* "pygpu/gpuarray.pyx":2151
 *                 err = GpuArray_reshape_inplace(&self.ga, nd, newdims, GA_C_ORDER)
 *                 if err != GA_NO_ERROR:
 *                     raise get_exc(err), GpuArray_error(&self.ga, err)             # <<<<<<<<<<<<<<
 *             finally:
 *                 free(newdims)
 */
      __pyx_t_5 = ((PyObject *)__pyx_f_5pygpu_8gpuarray_get_exc(__pyx_v_err)); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 2151, __pyx_L5_error)
      __Pyx_GOTREF(__pyx_t_5);
      __pyx_t_7 = __Pyx_PyBytes_FromString(GpuArray_error((&__pyx_v_self->ga), __pyx_v_err)); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 2151, __pyx_L5_error)
      __Pyx_GOTREF(__pyx_t_7);
      __Pyx_Raise(__pyx_t_5, __pyx_t_7, 0, 0);
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      __PYX_ERR(0, 2151, __pyx_L5_error)

      /* "pygpu/gpuarray.pyx":2150
 *                     newdims[i] = newshape[i]
 *                 err = GpuArray_reshape_inplace(&self.ga, nd, newdims, GA_C_ORDER)
 *                 if err != GA_NO_ERROR:             # <<<<<<<<<<<<<<
 *                     raise get_exc(err), GpuArray_error(&self.ga, err)
 *             finally:
 */
    }
  }

  /* "pygpu/gpuarray.pyx":2153
 *                     raise get_exc(err), GpuArray_error(&self.ga, err)
 *             finally:
 *                 free(newdims)             # <<<<<<<<<<<<<<
 * 
 *     property T:
 */
  /*finally:*/ {
    /*normal exit:*/{
      free(__pyx_v_newdims);
      goto __pyx_L6;
    }
    __pyx_L5_error:;
    /*exception exit:*/{
      __Pyx_PyThreadState_declare
      __Pyx_PyThreadState_assign
      __pyx_t_11 = 0; __pyx_t_12 = 0; __pyx_t_13 = 0; __pyx_t_14 = 0; __pyx_t_15 = 0; __pyx_t_16 = 0;
      __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
      __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
      if (PY_MAJOR_VERSION >= 3) __Pyx_ExceptionSwap(&__pyx_t_14, &__pyx_t_15, &__pyx_t_16);
      if ((PY_MAJOR_VERSION < 3) || unlikely(__Pyx_GetException(&__pyx_t_11, &__pyx_t_12, &__pyx_t_13) < 0)) __Pyx_ErrFetch(&__pyx_t_11, &__pyx_t_12, &__pyx_t_13);
      __Pyx_XGOTREF(__pyx_t_11);
      __Pyx_XGOTREF(__pyx_t_12);
      __Pyx_XGOTREF(__pyx_t_13);
      __Pyx_XGOTREF(__pyx_t_14);
      __Pyx_XGOTREF(__pyx_t_15);
      __Pyx_XGOTREF(__pyx_t_16);
      __pyx_t_8 = __pyx_lineno; __pyx_t_9 = __pyx_clineno; __pyx_t_10 = __pyx_filename;
      {
        free(__pyx_v_newdims);
      }
      if (PY_MAJOR_VERSION >= 3) {
        __Pyx_XGIVEREF(__pyx_t_14);
        __Pyx_XGIVEREF(__pyx_t_15);
        __Pyx_XGIVEREF(__pyx_t_16);
        __Pyx_ExceptionReset(__pyx_t_14, __pyx_t_15, __pyx_t_16);
      }
      __Pyx_XGIVEREF(__pyx_t_11);
      __Pyx_XGIVEREF(__pyx_t_12);
      __Pyx_XGIVEREF(__pyx_t_13);
      __Pyx_ErrRestore(__pyx_t_11, __pyx_t_12, __pyx_t_13);
      __pyx_t_11 = 0; __pyx_t_12 = 0; __pyx_t_13 = 0; __pyx_t_14 = 0; __pyx_t_15 = 0; __pyx_t_16 = 0;
      __pyx_lineno = __pyx_t_8; __pyx_clineno = __pyx_t_9; __pyx_filename = __pyx_t_10;
      goto __pyx_L1_error;
    }
    __pyx_L6:;
  }

  /* "pygpu/gpuarray.pyx":2136
 *             return tuple(res)
 * 
 *         def __set__(self, newshape):             # <<<<<<<<<<<<<<
 *             # We support -1 only in a call to reshape
 *             cdef size_t *newdims
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_AddTraceback("pygpu.gpuarray.GpuArray.shape.__set__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":2156
 * 
 *     property T:
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             return pygpu_transpose(self, NULL)
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_8GpuArray_1T_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_5pygpu_8gpuarray_8GpuArray_1T_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_8GpuArray_1T___get__(((struct PyGpuArrayObject *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_8GpuArray_1T___get__(struct PyGpuArrayObject *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("__get__", 0);

  /* "pygpu/gpuarray.pyx":2157
 *     property T:
 *         def __get__(self):
 *             return pygpu_transpose(self, NULL)             # <<<<<<<<<<<<<<
 * 
 *     property size:
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = ((PyObject *)__pyx_f_5pygpu_8gpuarray_pygpu_transpose(__pyx_v_self, NULL)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2157, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":2156
 * 
 *     property T:
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             return pygpu_transpose(self, NULL)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("pygpu.gpuarray.GpuArray.T.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":2161
 *     property size:
 *         "The number of elements in this object."
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             cdef size_t res = 1
 *             cdef unsigned int i
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_8GpuArray_4size_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_5pygpu_8gpuarray_8GpuArray_4size_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_8GpuArray_4size___get__(((struct PyGpuArrayObject *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_8GpuArray_4size___get__(struct PyGpuArrayObject *__pyx_v_self) {
  size_t __pyx_v_res;
  unsigned int __pyx_v_i;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  unsigned int __pyx_t_1;
  unsigned int __pyx_t_2;
  PyObject *__pyx_t_3 = NULL;
  __Pyx_RefNannySetupContext("__get__", 0);

  /* "pygpu/gpuarray.pyx":2162
 *         "The number of elements in this object."
 *         def __get__(self):
 *             cdef size_t res = 1             # <<<<<<<<<<<<<<
 *             cdef unsigned int i
 *             for i in range(self.ga.nd):
 */
  __pyx_v_res = 1;

  /* "pygpu/gpuarray.pyx":2164
 *             cdef size_t res = 1
 *             cdef unsigned int i
 *             for i in range(self.ga.nd):             # <<<<<<<<<<<<<<
 *                 res *= self.ga.dimensions[i]
 *             return res
 */
  __pyx_t_1 = __pyx_v_self->ga.nd;
  for (__pyx_t_2 = 0; __pyx_t_2 < __pyx_t_1; __pyx_t_2+=1) {
    __pyx_v_i = __pyx_t_2;

    /* "pygpu/gpuarray.pyx":2165
 *             cdef unsigned int i
 *             for i in range(self.ga.nd):
 *                 res *= self.ga.dimensions[i]             # <<<<<<<<<<<<<<
 *             return res
 * 
 */
    __pyx_v_res = (__pyx_v_res * (__pyx_v_self->ga.dimensions[__pyx_v_i]));
  }

  /* "pygpu/gpuarray.pyx":2166
 *             for i in range(self.ga.nd):
 *                 res *= self.ga.dimensions[i]
 *             return res             # <<<<<<<<<<<<<<
 * 
 *     property strides:
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_3 = __Pyx_PyInt_FromSize_t(__pyx_v_res); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 2166, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_r = __pyx_t_3;
  __pyx_t_3 = 0;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":2161
 *     property size:
 *         "The number of elements in this object."
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             cdef size_t res = 1
 *             cdef unsigned int i
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("pygpu.gpuarray.GpuArray.size.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":2170
 *     property strides:
 *         "data pointer strides (in bytes)"
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             cdef unsigned int i
 *             res = [None] * self.ga.nd
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_8GpuArray_7strides_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_5pygpu_8gpuarray_8GpuArray_7strides_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_8GpuArray_7strides___get__(((struct PyGpuArrayObject *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_8GpuArray_7strides___get__(struct PyGpuArrayObject *__pyx_v_self) {
  unsigned int __pyx_v_i;
  PyObject *__pyx_v_res = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  unsigned int __pyx_t_2;
  unsigned int __pyx_t_3;
  __Pyx_RefNannySetupContext("__get__", 0);

  /* "pygpu/gpuarray.pyx":2172
 *         def __get__(self):
 *             cdef unsigned int i
 *             res = [None] * self.ga.nd             # <<<<<<<<<<<<<<
 *             for i in range(self.ga.nd):
 *                 res[i] = self.ga.strides[i]
 */
  __pyx_t_1 = PyList_New(1 * (__pyx_v_self->ga.nd)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2172, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  { Py_ssize_t __pyx_temp;
    for (__pyx_temp=0; __pyx_temp < __pyx_v_self->ga.nd; __pyx_temp++) {
      __Pyx_INCREF(Py_None);
      __Pyx_GIVEREF(Py_None);
      PyList_SET_ITEM(__pyx_t_1, __pyx_temp, Py_None);
    }
  }
  __pyx_v_res = ((PyObject*)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "pygpu/gpuarray.pyx":2173
 *             cdef unsigned int i
 *             res = [None] * self.ga.nd
 *             for i in range(self.ga.nd):             # <<<<<<<<<<<<<<
 *                 res[i] = self.ga.strides[i]
 *             return tuple(res)
 */
  __pyx_t_2 = __pyx_v_self->ga.nd;
  for (__pyx_t_3 = 0; __pyx_t_3 < __pyx_t_2; __pyx_t_3+=1) {
    __pyx_v_i = __pyx_t_3;

    /* "pygpu/gpuarray.pyx":2174
 *             res = [None] * self.ga.nd
 *             for i in range(self.ga.nd):
 *                 res[i] = self.ga.strides[i]             # <<<<<<<<<<<<<<
 *             return tuple(res)
 * 
 */
    __pyx_t_1 = PyInt_FromSsize_t((__pyx_v_self->ga.strides[__pyx_v_i])); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2174, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    if (unlikely(__Pyx_SetItemInt(__pyx_v_res, __pyx_v_i, __pyx_t_1, unsigned int, 0, __Pyx_PyInt_From_unsigned_int, 1, 0, 1) < 0)) __PYX_ERR(0, 2174, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  }

  /* "pygpu/gpuarray.pyx":2175
 *             for i in range(self.ga.nd):
 *                 res[i] = self.ga.strides[i]
 *             return tuple(res)             # <<<<<<<<<<<<<<
 * 
 *         def __set__(self, newstrides):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = PyList_AsTuple(__pyx_v_res); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2175, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":2170
 *     property strides:
 *         "data pointer strides (in bytes)"
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             cdef unsigned int i
 *             res = [None] * self.ga.nd
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("pygpu.gpuarray.GpuArray.strides.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_res);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":2177
 *             return tuple(res)
 * 
 *         def __set__(self, newstrides):             # <<<<<<<<<<<<<<
 *             cdef unsigned int i
 *             if len(newstrides) != self.ga.nd:
 */

/* Python wrapper */
static int __pyx_pw_5pygpu_8gpuarray_8GpuArray_7strides_3__set__(PyObject *__pyx_v_self, PyObject *__pyx_v_newstrides); /*proto*/
static int __pyx_pw_5pygpu_8gpuarray_8GpuArray_7strides_3__set__(PyObject *__pyx_v_self, PyObject *__pyx_v_newstrides) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__set__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_8GpuArray_7strides_2__set__(((struct PyGpuArrayObject *)__pyx_v_self), ((PyObject *)__pyx_v_newstrides));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_5pygpu_8gpuarray_8GpuArray_7strides_2__set__(struct PyGpuArrayObject *__pyx_v_self, PyObject *__pyx_v_newstrides) {
  unsigned int __pyx_v_i;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  Py_ssize_t __pyx_t_1;
  int __pyx_t_2;
  PyObject *__pyx_t_3 = NULL;
  unsigned int __pyx_t_4;
  unsigned int __pyx_t_5;
  Py_ssize_t __pyx_t_6;
  __Pyx_RefNannySetupContext("__set__", 0);

  /* "pygpu/gpuarray.pyx":2179
 *         def __set__(self, newstrides):
 *             cdef unsigned int i
 *             if len(newstrides) != self.ga.nd:             # <<<<<<<<<<<<<<
 *                 raise ValueError("new strides are the wrong length")
 *             if not strides_ok(self,  newstrides):
 */
  __pyx_t_1 = PyObject_Length(__pyx_v_newstrides); if (unlikely(__pyx_t_1 == ((Py_ssize_t)-1))) __PYX_ERR(0, 2179, __pyx_L1_error)
  __pyx_t_2 = ((__pyx_t_1 != __pyx_v_self->ga.nd) != 0);
  if (__pyx_t_2) {

    /* "pygpu/gpuarray.pyx":2180
 *             cdef unsigned int i
 *             if len(newstrides) != self.ga.nd:
 *                 raise ValueError("new strides are the wrong length")             # <<<<<<<<<<<<<<
 *             if not strides_ok(self,  newstrides):
 *                 raise ValueError("new strides go outside of allocated memory")
 */
    __pyx_t_3 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__34, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 2180, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_Raise(__pyx_t_3, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __PYX_ERR(0, 2180, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":2179
 *         def __set__(self, newstrides):
 *             cdef unsigned int i
 *             if len(newstrides) != self.ga.nd:             # <<<<<<<<<<<<<<
 *                 raise ValueError("new strides are the wrong length")
 *             if not strides_ok(self,  newstrides):
 */
  }

  /* "pygpu/gpuarray.pyx":2181
 *             if len(newstrides) != self.ga.nd:
 *                 raise ValueError("new strides are the wrong length")
 *             if not strides_ok(self,  newstrides):             # <<<<<<<<<<<<<<
 *                 raise ValueError("new strides go outside of allocated memory")
 *             for i in range(self.ga.nd):
 */
  __pyx_t_2 = ((!(__pyx_f_5pygpu_8gpuarray_strides_ok(__pyx_v_self, __pyx_v_newstrides) != 0)) != 0);
  if (__pyx_t_2) {

    /* "pygpu/gpuarray.pyx":2182
 *                 raise ValueError("new strides are the wrong length")
 *             if not strides_ok(self,  newstrides):
 *                 raise ValueError("new strides go outside of allocated memory")             # <<<<<<<<<<<<<<
 *             for i in range(self.ga.nd):
 *                 self.ga.strides[i] = newstrides[i]
 */
    __pyx_t_3 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__35, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 2182, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_Raise(__pyx_t_3, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __PYX_ERR(0, 2182, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":2181
 *             if len(newstrides) != self.ga.nd:
 *                 raise ValueError("new strides are the wrong length")
 *             if not strides_ok(self,  newstrides):             # <<<<<<<<<<<<<<
 *                 raise ValueError("new strides go outside of allocated memory")
 *             for i in range(self.ga.nd):
 */
  }

  /* "pygpu/gpuarray.pyx":2183
 *             if not strides_ok(self,  newstrides):
 *                 raise ValueError("new strides go outside of allocated memory")
 *             for i in range(self.ga.nd):             # <<<<<<<<<<<<<<
 *                 self.ga.strides[i] = newstrides[i]
 *             array_fix_flags(self)
 */
  __pyx_t_4 = __pyx_v_self->ga.nd;
  for (__pyx_t_5 = 0; __pyx_t_5 < __pyx_t_4; __pyx_t_5+=1) {
    __pyx_v_i = __pyx_t_5;

    /* "pygpu/gpuarray.pyx":2184
 *                 raise ValueError("new strides go outside of allocated memory")
 *             for i in range(self.ga.nd):
 *                 self.ga.strides[i] = newstrides[i]             # <<<<<<<<<<<<<<
 *             array_fix_flags(self)
 * 
 */
    __pyx_t_3 = __Pyx_GetItemInt(__pyx_v_newstrides, __pyx_v_i, unsigned int, 0, __Pyx_PyInt_From_unsigned_int, 0, 0, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 2184, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_6 = PyInt_AsSsize_t(__pyx_t_3); if (unlikely((__pyx_t_6 == (Py_ssize_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 2184, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    (__pyx_v_self->ga.strides[__pyx_v_i]) = __pyx_t_6;
  }

  /* "pygpu/gpuarray.pyx":2185
 *             for i in range(self.ga.nd):
 *                 self.ga.strides[i] = newstrides[i]
 *             array_fix_flags(self)             # <<<<<<<<<<<<<<
 * 
 *     property ndim:
 */
  __pyx_f_5pygpu_8gpuarray_array_fix_flags(__pyx_v_self);

  /* "pygpu/gpuarray.pyx":2177
 *             return tuple(res)
 * 
 *         def __set__(self, newstrides):             # <<<<<<<<<<<<<<
 *             cdef unsigned int i
 *             if len(newstrides) != self.ga.nd:
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("pygpu.gpuarray.GpuArray.strides.__set__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":2189
 *     property ndim:
 *         "The number of dimensions in this object"
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             return self.ga.nd
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_8GpuArray_4ndim_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_5pygpu_8gpuarray_8GpuArray_4ndim_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_8GpuArray_4ndim___get__(((struct PyGpuArrayObject *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_8GpuArray_4ndim___get__(struct PyGpuArrayObject *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("__get__", 0);

  /* "pygpu/gpuarray.pyx":2190
 *         "The number of dimensions in this object"
 *         def __get__(self):
 *             return self.ga.nd             # <<<<<<<<<<<<<<
 * 
 *     property dtype:
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyInt_From_unsigned_int(__pyx_v_self->ga.nd); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2190, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":2189
 *     property ndim:
 *         "The number of dimensions in this object"
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             return self.ga.nd
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("pygpu.gpuarray.GpuArray.ndim.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":2194
 *     property dtype:
 *         "The dtype of the element"
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             return typecode_to_dtype(self.ga.typecode)
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_8GpuArray_5dtype_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_5pygpu_8gpuarray_8GpuArray_5dtype_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_8GpuArray_5dtype___get__(((struct PyGpuArrayObject *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_8GpuArray_5dtype___get__(struct PyGpuArrayObject *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("__get__", 0);

  /* "pygpu/gpuarray.pyx":2195
 *         "The dtype of the element"
 *         def __get__(self):
 *             return typecode_to_dtype(self.ga.typecode)             # <<<<<<<<<<<<<<
 * 
 *     property typecode:
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = ((PyObject *)__pyx_f_5pygpu_8gpuarray_typecode_to_dtype(__pyx_v_self->ga.typecode)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2195, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":2194
 *     property dtype:
 *         "The dtype of the element"
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             return typecode_to_dtype(self.ga.typecode)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("pygpu.gpuarray.GpuArray.dtype.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":2199
 *     property typecode:
 *         "The gpuarray typecode for the data type of the array"
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             return self.ga.typecode
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_8GpuArray_8typecode_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_5pygpu_8gpuarray_8GpuArray_8typecode_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_8GpuArray_8typecode___get__(((struct PyGpuArrayObject *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_8GpuArray_8typecode___get__(struct PyGpuArrayObject *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("__get__", 0);

  /* "pygpu/gpuarray.pyx":2200
 *         "The gpuarray typecode for the data type of the array"
 *         def __get__(self):
 *             return self.ga.typecode             # <<<<<<<<<<<<<<
 * 
 *     property itemsize:
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyInt_From_int(__pyx_v_self->ga.typecode); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2200, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":2199
 *     property typecode:
 *         "The gpuarray typecode for the data type of the array"
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             return self.ga.typecode
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("pygpu.gpuarray.GpuArray.typecode.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":2204
 *     property itemsize:
 *         "The size of the base element."
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             return gpuarray_get_elsize(self.ga.typecode)
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_8GpuArray_8itemsize_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_5pygpu_8gpuarray_8GpuArray_8itemsize_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_8GpuArray_8itemsize___get__(((struct PyGpuArrayObject *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_8GpuArray_8itemsize___get__(struct PyGpuArrayObject *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("__get__", 0);

  /* "pygpu/gpuarray.pyx":2205
 *         "The size of the base element."
 *         def __get__(self):
 *             return gpuarray_get_elsize(self.ga.typecode)             # <<<<<<<<<<<<<<
 * 
 *     property flags:
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyInt_FromSize_t(gpuarray_get_elsize(__pyx_v_self->ga.typecode)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2205, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":2204
 *     property itemsize:
 *         "The size of the base element."
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             return gpuarray_get_elsize(self.ga.typecode)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("pygpu.gpuarray.GpuArray.itemsize.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":2215
 *           * UPDATEIFCOPY is not supported, therefore always False.
 *         """
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             return flags(self.ga.flags)
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_8GpuArray_5flags_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_5pygpu_8gpuarray_8GpuArray_5flags_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_8GpuArray_5flags___get__(((struct PyGpuArrayObject *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_8GpuArray_5flags___get__(struct PyGpuArrayObject *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  __Pyx_RefNannySetupContext("__get__", 0);

  /* "pygpu/gpuarray.pyx":2216
 *         """
 *         def __get__(self):
 *             return flags(self.ga.flags)             # <<<<<<<<<<<<<<
 * 
 *     property offset:
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyInt_From_int(__pyx_v_self->ga.flags); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2216, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = PyTuple_New(1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2216, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_GIVEREF(__pyx_t_1);
  PyTuple_SET_ITEM(__pyx_t_2, 0, __pyx_t_1);
  __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyObject_Call(((PyObject *)__pyx_ptype_5pygpu_8gpuarray_flags), __pyx_t_2, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2216, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":2215
 *           * UPDATEIFCOPY is not supported, therefore always False.
 *         """
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             return flags(self.ga.flags)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("pygpu.gpuarray.GpuArray.flags.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":2220
 *     property offset:
 *         "Return the offset into the gpudata pointer for this array."
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             return self.ga.offset
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_8GpuArray_6offset_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_5pygpu_8gpuarray_8GpuArray_6offset_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_8GpuArray_6offset___get__(((struct PyGpuArrayObject *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_8GpuArray_6offset___get__(struct PyGpuArrayObject *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("__get__", 0);

  /* "pygpu/gpuarray.pyx":2221
 *         "Return the offset into the gpudata pointer for this array."
 *         def __get__(self):
 *             return self.ga.offset             # <<<<<<<<<<<<<<
 * 
 *     property data:
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyInt_FromSize_t(__pyx_v_self->ga.offset); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2221, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":2220
 *     property offset:
 *         "Return the offset into the gpudata pointer for this array."
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             return self.ga.offset
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("pygpu.gpuarray.GpuArray.offset.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":2228
 *         This will fail for arrays that have an offset.
 *         """
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             if self.context.kind != b"opencl":
 *                 raise TypeError("This is for OpenCL arrays.")
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_8GpuArray_4data_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_5pygpu_8gpuarray_8GpuArray_4data_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_8GpuArray_4data___get__(((struct PyGpuArrayObject *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_8GpuArray_4data___get__(struct PyGpuArrayObject *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_t_2;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  __Pyx_RefNannySetupContext("__get__", 0);

  /* "pygpu/gpuarray.pyx":2229
 *         """
 *         def __get__(self):
 *             if self.context.kind != b"opencl":             # <<<<<<<<<<<<<<
 *                 raise TypeError("This is for OpenCL arrays.")
 *             if self.offset != 0:
 */
  __pyx_t_1 = (__Pyx_PyBytes_Equals(__pyx_v_self->context->kind, __pyx_n_b_opencl, Py_NE)); if (unlikely(__pyx_t_1 < 0)) __PYX_ERR(0, 2229, __pyx_L1_error)
  __pyx_t_2 = (__pyx_t_1 != 0);
  if (__pyx_t_2) {

    /* "pygpu/gpuarray.pyx":2230
 *         def __get__(self):
 *             if self.context.kind != b"opencl":
 *                 raise TypeError("This is for OpenCL arrays.")             # <<<<<<<<<<<<<<
 *             if self.offset != 0:
 *                 raise ValueError("This array has an offset.")
 */
    __pyx_t_3 = __Pyx_PyObject_Call(__pyx_builtin_TypeError, __pyx_tuple__36, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 2230, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_Raise(__pyx_t_3, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __PYX_ERR(0, 2230, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":2229
 *         """
 *         def __get__(self):
 *             if self.context.kind != b"opencl":             # <<<<<<<<<<<<<<
 *                 raise TypeError("This is for OpenCL arrays.")
 *             if self.offset != 0:
 */
  }

  /* "pygpu/gpuarray.pyx":2231
 *             if self.context.kind != b"opencl":
 *                 raise TypeError("This is for OpenCL arrays.")
 *             if self.offset != 0:             # <<<<<<<<<<<<<<
 *                 raise ValueError("This array has an offset.")
 *             # This wizadry grabs the actual backend pointer since it's
 */
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_offset); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 2231, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_4 = PyObject_RichCompare(__pyx_t_3, __pyx_int_0, Py_NE); __Pyx_XGOTREF(__pyx_t_4); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2231, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_2 = __Pyx_PyObject_IsTrue(__pyx_t_4); if (unlikely(__pyx_t_2 < 0)) __PYX_ERR(0, 2231, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  if (__pyx_t_2) {

    /* "pygpu/gpuarray.pyx":2232
 *                 raise TypeError("This is for OpenCL arrays.")
 *             if self.offset != 0:
 *                 raise ValueError("This array has an offset.")             # <<<<<<<<<<<<<<
 *             # This wizadry grabs the actual backend pointer since it's
 *             # guarenteed to be the first element of the gpudata
 */
    __pyx_t_4 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__37, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2232, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_Raise(__pyx_t_4, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __PYX_ERR(0, 2232, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":2231
 *             if self.context.kind != b"opencl":
 *                 raise TypeError("This is for OpenCL arrays.")
 *             if self.offset != 0:             # <<<<<<<<<<<<<<
 *                 raise ValueError("This array has an offset.")
 *             # This wizadry grabs the actual backend pointer since it's
 */
  }

  /* "pygpu/gpuarray.pyx":2236
 *             # guarenteed to be the first element of the gpudata
 *             # structure.
 *             return <size_t>((<void **>self.ga.data)[0])             # <<<<<<<<<<<<<<
 * 
 *     property base_data:
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_4 = __Pyx_PyInt_FromSize_t(((size_t)(((void **)__pyx_v_self->ga.data)[0]))); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2236, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_r = __pyx_t_4;
  __pyx_t_4 = 0;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":2228
 *         This will fail for arrays that have an offset.
 *         """
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             if self.context.kind != b"opencl":
 *                 raise TypeError("This is for OpenCL arrays.")
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_AddTraceback("pygpu.gpuarray.GpuArray.data.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":2240
 *     property base_data:
 *         "Return a pointer to the backing OpenCL object."
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             if self.context.kind != b"opencl":
 *                 raise TypeError("This is for OpenCL arrays.")
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_8GpuArray_9base_data_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_5pygpu_8gpuarray_8GpuArray_9base_data_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_8GpuArray_9base_data___get__(((struct PyGpuArrayObject *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_8GpuArray_9base_data___get__(struct PyGpuArrayObject *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_t_2;
  PyObject *__pyx_t_3 = NULL;
  __Pyx_RefNannySetupContext("__get__", 0);

  /* "pygpu/gpuarray.pyx":2241
 *         "Return a pointer to the backing OpenCL object."
 *         def __get__(self):
 *             if self.context.kind != b"opencl":             # <<<<<<<<<<<<<<
 *                 raise TypeError("This is for OpenCL arrays.")
 *             # This wizadry grabs the actual backend pointer since it's
 */
  __pyx_t_1 = (__Pyx_PyBytes_Equals(__pyx_v_self->context->kind, __pyx_n_b_opencl, Py_NE)); if (unlikely(__pyx_t_1 < 0)) __PYX_ERR(0, 2241, __pyx_L1_error)
  __pyx_t_2 = (__pyx_t_1 != 0);
  if (__pyx_t_2) {

    /* "pygpu/gpuarray.pyx":2242
 *         def __get__(self):
 *             if self.context.kind != b"opencl":
 *                 raise TypeError("This is for OpenCL arrays.")             # <<<<<<<<<<<<<<
 *             # This wizadry grabs the actual backend pointer since it's
 *             # guarenteed to be the first element of the gpudata
 */
    __pyx_t_3 = __Pyx_PyObject_Call(__pyx_builtin_TypeError, __pyx_tuple__38, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 2242, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_Raise(__pyx_t_3, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __PYX_ERR(0, 2242, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":2241
 *         "Return a pointer to the backing OpenCL object."
 *         def __get__(self):
 *             if self.context.kind != b"opencl":             # <<<<<<<<<<<<<<
 *                 raise TypeError("This is for OpenCL arrays.")
 *             # This wizadry grabs the actual backend pointer since it's
 */
  }

  /* "pygpu/gpuarray.pyx":2246
 *             # guarenteed to be the first element of the gpudata
 *             # structure.
 *             return <size_t>((<void **>self.ga.data)[0])             # <<<<<<<<<<<<<<
 * 
 *     property gpudata:
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_3 = __Pyx_PyInt_FromSize_t(((size_t)(((void **)__pyx_v_self->ga.data)[0]))); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 2246, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_r = __pyx_t_3;
  __pyx_t_3 = 0;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":2240
 *     property base_data:
 *         "Return a pointer to the backing OpenCL object."
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             if self.context.kind != b"opencl":
 *                 raise TypeError("This is for OpenCL arrays.")
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("pygpu.gpuarray.GpuArray.base_data.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":2250
 *     property gpudata:
 *         "Return a pointer to the raw backend object."
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             if self.context.kind != b"cuda":
 *                 raise TypeError("This is for CUDA arrays.")
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_8GpuArray_7gpudata_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_5pygpu_8gpuarray_8GpuArray_7gpudata_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_8GpuArray_7gpudata___get__(((struct PyGpuArrayObject *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_8GpuArray_7gpudata___get__(struct PyGpuArrayObject *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_t_2;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  __Pyx_RefNannySetupContext("__get__", 0);

  /* "pygpu/gpuarray.pyx":2251
 *         "Return a pointer to the raw backend object."
 *         def __get__(self):
 *             if self.context.kind != b"cuda":             # <<<<<<<<<<<<<<
 *                 raise TypeError("This is for CUDA arrays.")
 *             # This wizadry grabs the actual backend pointer since it's
 */
  __pyx_t_1 = (__Pyx_PyBytes_Equals(__pyx_v_self->context->kind, __pyx_n_b_cuda, Py_NE)); if (unlikely(__pyx_t_1 < 0)) __PYX_ERR(0, 2251, __pyx_L1_error)
  __pyx_t_2 = (__pyx_t_1 != 0);
  if (__pyx_t_2) {

    /* "pygpu/gpuarray.pyx":2252
 *         def __get__(self):
 *             if self.context.kind != b"cuda":
 *                 raise TypeError("This is for CUDA arrays.")             # <<<<<<<<<<<<<<
 *             # This wizadry grabs the actual backend pointer since it's
 *             # guarenteed to be the first element of the gpudata
 */
    __pyx_t_3 = __Pyx_PyObject_Call(__pyx_builtin_TypeError, __pyx_tuple__39, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 2252, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_Raise(__pyx_t_3, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __PYX_ERR(0, 2252, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":2251
 *         "Return a pointer to the raw backend object."
 *         def __get__(self):
 *             if self.context.kind != b"cuda":             # <<<<<<<<<<<<<<
 *                 raise TypeError("This is for CUDA arrays.")
 *             # This wizadry grabs the actual backend pointer since it's
 */
  }

  /* "pygpu/gpuarray.pyx":2256
 *             # guarenteed to be the first element of the gpudata
 *             # structure.
 *             return <size_t>((<void **>self.ga.data)[0]) + self.offset             # <<<<<<<<<<<<<<
 * 
 *     def __str__(self):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_3 = __Pyx_PyInt_FromSize_t(((size_t)(((void **)__pyx_v_self->ga.data)[0]))); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 2256, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_4 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_offset); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2256, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_5 = PyNumber_Add(__pyx_t_3, __pyx_t_4); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 2256, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_r = __pyx_t_5;
  __pyx_t_5 = 0;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":2250
 *     property gpudata:
 *         "Return a pointer to the raw backend object."
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             if self.context.kind != b"cuda":
 *                 raise TypeError("This is for CUDA arrays.")
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("pygpu.gpuarray.GpuArray.gpudata.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":2258
 *             return <size_t>((<void **>self.ga.data)[0]) + self.offset
 * 
 *     def __str__(self):             # <<<<<<<<<<<<<<
 *         return str(numpy.asarray(self))
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_8GpuArray_51__str__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_5pygpu_8gpuarray_8GpuArray_51__str__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__str__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_8GpuArray_50__str__(((struct PyGpuArrayObject *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_8GpuArray_50__str__(struct PyGpuArrayObject *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  __Pyx_RefNannySetupContext("__str__", 0);

  /* "pygpu/gpuarray.pyx":2259
 * 
 *     def __str__(self):
 *         return str(numpy.asarray(self))             # <<<<<<<<<<<<<<
 * 
 *     def __repr__(self):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_numpy); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2259, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_asarray); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 2259, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = NULL;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_2)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
    }
  }
  if (!__pyx_t_2) {
    __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_3, ((PyObject *)__pyx_v_self)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2259, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
  } else {
    #if CYTHON_FAST_PYCALL
    if (PyFunction_Check(__pyx_t_3)) {
      PyObject *__pyx_temp[2] = {__pyx_t_2, ((PyObject *)__pyx_v_self)};
      __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2259, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
      __Pyx_GOTREF(__pyx_t_1);
    } else
    #endif
    #if CYTHON_FAST_PYCCALL
    if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
      PyObject *__pyx_temp[2] = {__pyx_t_2, ((PyObject *)__pyx_v_self)};
      __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2259, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
      __Pyx_GOTREF(__pyx_t_1);
    } else
    #endif
    {
      __pyx_t_4 = PyTuple_New(1+1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2259, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_GIVEREF(__pyx_t_2); PyTuple_SET_ITEM(__pyx_t_4, 0, __pyx_t_2); __pyx_t_2 = NULL;
      __Pyx_INCREF(((PyObject *)__pyx_v_self));
      __Pyx_GIVEREF(((PyObject *)__pyx_v_self));
      PyTuple_SET_ITEM(__pyx_t_4, 0+1, ((PyObject *)__pyx_v_self));
      __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_4, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2259, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    }
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 2259, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_GIVEREF(__pyx_t_1);
  PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_1);
  __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyObject_Call(((PyObject *)(&PyString_Type)), __pyx_t_3, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2259, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":2258
 *             return <size_t>((<void **>self.ga.data)[0]) + self.offset
 * 
 *     def __str__(self):             # <<<<<<<<<<<<<<
 *         return str(numpy.asarray(self))
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_AddTraceback("pygpu.gpuarray.GpuArray.__str__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":2261
 *         return str(numpy.asarray(self))
 * 
 *     def __repr__(self):             # <<<<<<<<<<<<<<
 *         try:
 *             return 'gpuarray.' + repr(numpy.asarray(self))
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_8GpuArray_53__repr__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_5pygpu_8gpuarray_8GpuArray_53__repr__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__repr__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_8GpuArray_52__repr__(((struct PyGpuArrayObject *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_8GpuArray_52__repr__(struct PyGpuArrayObject *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  int __pyx_t_8;
  __Pyx_RefNannySetupContext("__repr__", 0);

  /* "pygpu/gpuarray.pyx":2262
 * 
 *     def __repr__(self):
 *         try:             # <<<<<<<<<<<<<<
 *             return 'gpuarray.' + repr(numpy.asarray(self))
 *         except Exception:
 */
  {
    __Pyx_PyThreadState_declare
    __Pyx_PyThreadState_assign
    __Pyx_ExceptionSave(&__pyx_t_1, &__pyx_t_2, &__pyx_t_3);
    __Pyx_XGOTREF(__pyx_t_1);
    __Pyx_XGOTREF(__pyx_t_2);
    __Pyx_XGOTREF(__pyx_t_3);
    /*try:*/ {

      /* "pygpu/gpuarray.pyx":2263
 *     def __repr__(self):
 *         try:
 *             return 'gpuarray.' + repr(numpy.asarray(self))             # <<<<<<<<<<<<<<
 *         except Exception:
 *             return 'gpuarray.array(<content not available>)'
 */
      __Pyx_XDECREF(__pyx_r);
      __pyx_t_5 = __Pyx_GetModuleGlobalName(__pyx_n_s_numpy); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 2263, __pyx_L3_error)
      __Pyx_GOTREF(__pyx_t_5);
      __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_t_5, __pyx_n_s_asarray); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 2263, __pyx_L3_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      __pyx_t_5 = NULL;
      if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_6))) {
        __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_6);
        if (likely(__pyx_t_5)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_6);
          __Pyx_INCREF(__pyx_t_5);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_6, function);
        }
      }
      if (!__pyx_t_5) {
        __pyx_t_4 = __Pyx_PyObject_CallOneArg(__pyx_t_6, ((PyObject *)__pyx_v_self)); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2263, __pyx_L3_error)
        __Pyx_GOTREF(__pyx_t_4);
      } else {
        #if CYTHON_FAST_PYCALL
        if (PyFunction_Check(__pyx_t_6)) {
          PyObject *__pyx_temp[2] = {__pyx_t_5, ((PyObject *)__pyx_v_self)};
          __pyx_t_4 = __Pyx_PyFunction_FastCall(__pyx_t_6, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2263, __pyx_L3_error)
          __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
          __Pyx_GOTREF(__pyx_t_4);
        } else
        #endif
        #if CYTHON_FAST_PYCCALL
        if (__Pyx_PyFastCFunction_Check(__pyx_t_6)) {
          PyObject *__pyx_temp[2] = {__pyx_t_5, ((PyObject *)__pyx_v_self)};
          __pyx_t_4 = __Pyx_PyCFunction_FastCall(__pyx_t_6, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2263, __pyx_L3_error)
          __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
          __Pyx_GOTREF(__pyx_t_4);
        } else
        #endif
        {
          __pyx_t_7 = PyTuple_New(1+1); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 2263, __pyx_L3_error)
          __Pyx_GOTREF(__pyx_t_7);
          __Pyx_GIVEREF(__pyx_t_5); PyTuple_SET_ITEM(__pyx_t_7, 0, __pyx_t_5); __pyx_t_5 = NULL;
          __Pyx_INCREF(((PyObject *)__pyx_v_self));
          __Pyx_GIVEREF(((PyObject *)__pyx_v_self));
          PyTuple_SET_ITEM(__pyx_t_7, 0+1, ((PyObject *)__pyx_v_self));
          __pyx_t_4 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_t_7, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2263, __pyx_L3_error)
          __Pyx_GOTREF(__pyx_t_4);
          __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
        }
      }
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __pyx_t_6 = PyObject_Repr(__pyx_t_4); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 2263, __pyx_L3_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __pyx_t_4 = PyNumber_Add(__pyx_kp_s_gpuarray, __pyx_t_6); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 2263, __pyx_L3_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __pyx_r = __pyx_t_4;
      __pyx_t_4 = 0;
      goto __pyx_L7_try_return;

      /* "pygpu/gpuarray.pyx":2262
 * 
 *     def __repr__(self):
 *         try:             # <<<<<<<<<<<<<<
 *             return 'gpuarray.' + repr(numpy.asarray(self))
 *         except Exception:
 */
    }
    __pyx_L3_error:;
    __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
    __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;

    /* "pygpu/gpuarray.pyx":2264
 *         try:
 *             return 'gpuarray.' + repr(numpy.asarray(self))
 *         except Exception:             # <<<<<<<<<<<<<<
 *             return 'gpuarray.array(<content not available>)'
 * 
 */
    __pyx_t_8 = __Pyx_PyErr_ExceptionMatches(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])));
    if (__pyx_t_8) {
      __Pyx_AddTraceback("pygpu.gpuarray.GpuArray.__repr__", __pyx_clineno, __pyx_lineno, __pyx_filename);
      if (__Pyx_GetException(&__pyx_t_4, &__pyx_t_6, &__pyx_t_7) < 0) __PYX_ERR(0, 2264, __pyx_L5_except_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_GOTREF(__pyx_t_7);

      /* "pygpu/gpuarray.pyx":2265
 *             return 'gpuarray.' + repr(numpy.asarray(self))
 *         except Exception:
 *             return 'gpuarray.array(<content not available>)'             # <<<<<<<<<<<<<<
 * 
 * 
 */
      __Pyx_XDECREF(__pyx_r);
      __Pyx_INCREF(__pyx_kp_s_gpuarray_array_content_not_avail);
      __pyx_r = __pyx_kp_s_gpuarray_array_content_not_avail;
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      goto __pyx_L6_except_return;
    }
    goto __pyx_L5_except_error;
    __pyx_L5_except_error:;

    /* "pygpu/gpuarray.pyx":2262
 * 
 *     def __repr__(self):
 *         try:             # <<<<<<<<<<<<<<
 *             return 'gpuarray.' + repr(numpy.asarray(self))
 *         except Exception:
 */
    __Pyx_XGIVEREF(__pyx_t_1);
    __Pyx_XGIVEREF(__pyx_t_2);
    __Pyx_XGIVEREF(__pyx_t_3);
    __Pyx_ExceptionReset(__pyx_t_1, __pyx_t_2, __pyx_t_3);
    goto __pyx_L1_error;
    __pyx_L7_try_return:;
    __Pyx_XGIVEREF(__pyx_t_1);
    __Pyx_XGIVEREF(__pyx_t_2);
    __Pyx_XGIVEREF(__pyx_t_3);
    __Pyx_ExceptionReset(__pyx_t_1, __pyx_t_2, __pyx_t_3);
    goto __pyx_L0;
    __pyx_L6_except_return:;
    __Pyx_XGIVEREF(__pyx_t_1);
    __Pyx_XGIVEREF(__pyx_t_2);
    __Pyx_XGIVEREF(__pyx_t_3);
    __Pyx_ExceptionReset(__pyx_t_1, __pyx_t_2, __pyx_t_3);
    goto __pyx_L0;
  }

  /* "pygpu/gpuarray.pyx":2261
 *         return str(numpy.asarray(self))
 * 
 *     def __repr__(self):             # <<<<<<<<<<<<<<
 *         try:
 *             return 'gpuarray.' + repr(numpy.asarray(self))
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_AddTraceback("pygpu.gpuarray.GpuArray.__repr__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pxd":331
 * cdef api class GpuArray [type PyGpuArrayType, object PyGpuArrayObject]:
 *     cdef _GpuArray ga
 *     cdef readonly GpuContext context             # <<<<<<<<<<<<<<
 *     cdef readonly object base
 *     cdef object __weakref__
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_8GpuArray_7context_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_5pygpu_8gpuarray_8GpuArray_7context_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_8GpuArray_7context___get__(((struct PyGpuArrayObject *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_8GpuArray_7context___get__(struct PyGpuArrayObject *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__", 0);
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self->context));
  __pyx_r = ((PyObject *)__pyx_v_self->context);
  goto __pyx_L0;

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pxd":332
 *     cdef _GpuArray ga
 *     cdef readonly GpuContext context
 *     cdef readonly object base             # <<<<<<<<<<<<<<
 *     cdef object __weakref__
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_8GpuArray_4base_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_5pygpu_8gpuarray_8GpuArray_4base_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_8GpuArray_4base___get__(((struct PyGpuArrayObject *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_8GpuArray_4base___get__(struct PyGpuArrayObject *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__", 0);
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_self->base);
  __pyx_r = __pyx_v_self->base;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":2342
 * 
 *     """
 *     def __dealloc__(self):             # <<<<<<<<<<<<<<
 *         cdef unsigned int numargs
 *         cdef int *types
 */

/* Python wrapper */
static void __pyx_pw_5pygpu_8gpuarray_9GpuKernel_1__dealloc__(PyObject *__pyx_v_self); /*proto*/
static void __pyx_pw_5pygpu_8gpuarray_9GpuKernel_1__dealloc__(PyObject *__pyx_v_self) {
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__dealloc__ (wrapper)", 0);
  __pyx_pf_5pygpu_8gpuarray_9GpuKernel___dealloc__(((struct PyGpuKernelObject *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
}

static void __pyx_pf_5pygpu_8gpuarray_9GpuKernel___dealloc__(struct PyGpuKernelObject *__pyx_v_self) {
  unsigned int __pyx_v_numargs;
  int *__pyx_v_types;
  unsigned int __pyx_v_i;
  int __pyx_v_res;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  unsigned int __pyx_t_2;
  unsigned int __pyx_t_3;
  int __pyx_t_4;
  __Pyx_RefNannySetupContext("__dealloc__", 0);

  /* "pygpu/gpuarray.pyx":2349
 *         # We need to do all of this at the C level to avoid touching
 *         # python stuff that could be gone and to avoid exceptions
 *         if self.k.k is not NULL:             # <<<<<<<<<<<<<<
 *             res = gpukernel_property(self.k.k, GA_KERNEL_PROP_NUMARGS, &numargs)
 *             if res != GA_NO_ERROR:
 */
  __pyx_t_1 = ((__pyx_v_self->k.k != NULL) != 0);
  if (__pyx_t_1) {

    /* "pygpu/gpuarray.pyx":2350
 *         # python stuff that could be gone and to avoid exceptions
 *         if self.k.k is not NULL:
 *             res = gpukernel_property(self.k.k, GA_KERNEL_PROP_NUMARGS, &numargs)             # <<<<<<<<<<<<<<
 *             if res != GA_NO_ERROR:
 *                 return
 */
    __pyx_v_res = gpukernel_property(__pyx_v_self->k.k, GA_KERNEL_PROP_NUMARGS, (&__pyx_v_numargs));

    /* "pygpu/gpuarray.pyx":2351
 *         if self.k.k is not NULL:
 *             res = gpukernel_property(self.k.k, GA_KERNEL_PROP_NUMARGS, &numargs)
 *             if res != GA_NO_ERROR:             # <<<<<<<<<<<<<<
 *                 return
 *             res = gpukernel_property(self.k.k, GA_KERNEL_PROP_TYPES, &types)
 */
    __pyx_t_1 = ((__pyx_v_res != GA_NO_ERROR) != 0);
    if (__pyx_t_1) {

      /* "pygpu/gpuarray.pyx":2352
 *             res = gpukernel_property(self.k.k, GA_KERNEL_PROP_NUMARGS, &numargs)
 *             if res != GA_NO_ERROR:
 *                 return             # <<<<<<<<<<<<<<
 *             res = gpukernel_property(self.k.k, GA_KERNEL_PROP_TYPES, &types)
 *             if res != GA_NO_ERROR:
 */
      goto __pyx_L0;

      /* "pygpu/gpuarray.pyx":2351
 *         if self.k.k is not NULL:
 *             res = gpukernel_property(self.k.k, GA_KERNEL_PROP_NUMARGS, &numargs)
 *             if res != GA_NO_ERROR:             # <<<<<<<<<<<<<<
 *                 return
 *             res = gpukernel_property(self.k.k, GA_KERNEL_PROP_TYPES, &types)
 */
    }

    /* "pygpu/gpuarray.pyx":2353
 *             if res != GA_NO_ERROR:
 *                 return
 *             res = gpukernel_property(self.k.k, GA_KERNEL_PROP_TYPES, &types)             # <<<<<<<<<<<<<<
 *             if res != GA_NO_ERROR:
 *                 return
 */
    __pyx_v_res = gpukernel_property(__pyx_v_self->k.k, GA_KERNEL_PROP_TYPES, (&__pyx_v_types));

    /* "pygpu/gpuarray.pyx":2354
 *                 return
 *             res = gpukernel_property(self.k.k, GA_KERNEL_PROP_TYPES, &types)
 *             if res != GA_NO_ERROR:             # <<<<<<<<<<<<<<
 *                 return
 *             for i in range(numargs):
 */
    __pyx_t_1 = ((__pyx_v_res != GA_NO_ERROR) != 0);
    if (__pyx_t_1) {

      /* "pygpu/gpuarray.pyx":2355
 *             res = gpukernel_property(self.k.k, GA_KERNEL_PROP_TYPES, &types)
 *             if res != GA_NO_ERROR:
 *                 return             # <<<<<<<<<<<<<<
 *             for i in range(numargs):
 *                 if types[i] != GA_BUFFER:
 */
      goto __pyx_L0;

      /* "pygpu/gpuarray.pyx":2354
 *                 return
 *             res = gpukernel_property(self.k.k, GA_KERNEL_PROP_TYPES, &types)
 *             if res != GA_NO_ERROR:             # <<<<<<<<<<<<<<
 *                 return
 *             for i in range(numargs):
 */
    }

    /* "pygpu/gpuarray.pyx":2356
 *             if res != GA_NO_ERROR:
 *                 return
 *             for i in range(numargs):             # <<<<<<<<<<<<<<
 *                 if types[i] != GA_BUFFER:
 *                     free(self.callbuf[i])
 */
    __pyx_t_2 = __pyx_v_numargs;
    for (__pyx_t_3 = 0; __pyx_t_3 < __pyx_t_2; __pyx_t_3+=1) {
      __pyx_v_i = __pyx_t_3;

      /* "pygpu/gpuarray.pyx":2357
 *                 return
 *             for i in range(numargs):
 *                 if types[i] != GA_BUFFER:             # <<<<<<<<<<<<<<
 *                     free(self.callbuf[i])
 *             kernel_clear(self)
 */
      __pyx_t_1 = (((__pyx_v_types[__pyx_v_i]) != GA_BUFFER) != 0);
      if (__pyx_t_1) {

        /* "pygpu/gpuarray.pyx":2358
 *             for i in range(numargs):
 *                 if types[i] != GA_BUFFER:
 *                     free(self.callbuf[i])             # <<<<<<<<<<<<<<
 *             kernel_clear(self)
 *         free(self.callbuf)
 */
        free((__pyx_v_self->callbuf[__pyx_v_i]));

        /* "pygpu/gpuarray.pyx":2357
 *                 return
 *             for i in range(numargs):
 *                 if types[i] != GA_BUFFER:             # <<<<<<<<<<<<<<
 *                     free(self.callbuf[i])
 *             kernel_clear(self)
 */
      }
    }

    /* "pygpu/gpuarray.pyx":2359
 *                 if types[i] != GA_BUFFER:
 *                     free(self.callbuf[i])
 *             kernel_clear(self)             # <<<<<<<<<<<<<<
 *         free(self.callbuf)
 * 
 */
    __pyx_t_4 = __pyx_f_5pygpu_8gpuarray_kernel_clear(__pyx_v_self); if (unlikely(__pyx_t_4 == ((int)-1))) __PYX_ERR(0, 2359, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":2349
 *         # We need to do all of this at the C level to avoid touching
 *         # python stuff that could be gone and to avoid exceptions
 *         if self.k.k is not NULL:             # <<<<<<<<<<<<<<
 *             res = gpukernel_property(self.k.k, GA_KERNEL_PROP_NUMARGS, &numargs)
 *             if res != GA_NO_ERROR:
 */
  }

  /* "pygpu/gpuarray.pyx":2360
 *                     free(self.callbuf[i])
 *             kernel_clear(self)
 *         free(self.callbuf)             # <<<<<<<<<<<<<<
 * 
 *     def __reduce__(self):
 */
  free(__pyx_v_self->callbuf);

  /* "pygpu/gpuarray.pyx":2342
 * 
 *     """
 *     def __dealloc__(self):             # <<<<<<<<<<<<<<
 *         cdef unsigned int numargs
 *         cdef int *types
 */

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_WriteUnraisable("pygpu.gpuarray.GpuKernel.__dealloc__", __pyx_clineno, __pyx_lineno, __pyx_filename, 1, 0);
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
}

/* "pygpu/gpuarray.pyx":2362
 *         free(self.callbuf)
 * 
 *     def __reduce__(self):             # <<<<<<<<<<<<<<
 *         raise RuntimeError, "Cannot pickle GpuKernel object"
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_9GpuKernel_3__reduce__(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_pw_5pygpu_8gpuarray_9GpuKernel_3__reduce__(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__reduce__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_9GpuKernel_2__reduce__(((struct PyGpuKernelObject *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_9GpuKernel_2__reduce__(CYTHON_UNUSED struct PyGpuKernelObject *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__reduce__", 0);

  /* "pygpu/gpuarray.pyx":2363
 * 
 *     def __reduce__(self):
 *         raise RuntimeError, "Cannot pickle GpuKernel object"             # <<<<<<<<<<<<<<
 * 
 *     def __cinit__(self, source, name, types, GpuContext context=None,
 */
  __Pyx_Raise(__pyx_builtin_RuntimeError, __pyx_kp_s_Cannot_pickle_GpuKernel_object, 0, 0);
  __PYX_ERR(0, 2363, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":2362
 *         free(self.callbuf)
 * 
 *     def __reduce__(self):             # <<<<<<<<<<<<<<
 *         raise RuntimeError, "Cannot pickle GpuKernel object"
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_AddTraceback("pygpu.gpuarray.GpuKernel.__reduce__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":2365
 *         raise RuntimeError, "Cannot pickle GpuKernel object"
 * 
 *     def __cinit__(self, source, name, types, GpuContext context=None,             # <<<<<<<<<<<<<<
 *                   have_double=False, have_small=False, have_complex=False,
 *                   have_half=False, cuda=False, opencl=False, *a, **kwa):
 */

/* Python wrapper */
static int __pyx_pw_5pygpu_8gpuarray_9GpuKernel_5__cinit__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static int __pyx_pw_5pygpu_8gpuarray_9GpuKernel_5__cinit__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_source = 0;
  PyObject *__pyx_v_name = 0;
  PyObject *__pyx_v_types = 0;
  struct PyGpuContextObject *__pyx_v_context = 0;
  PyObject *__pyx_v_have_double = 0;
  PyObject *__pyx_v_have_small = 0;
  PyObject *__pyx_v_have_complex = 0;
  PyObject *__pyx_v_have_half = 0;
  PyObject *__pyx_v_cuda = 0;
  PyObject *__pyx_v_opencl = 0;
  CYTHON_UNUSED PyObject *__pyx_v_a = 0;
  CYTHON_UNUSED PyObject *__pyx_v_kwa = 0;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__cinit__ (wrapper)", 0);
  __pyx_v_kwa = PyDict_New(); if (unlikely(!__pyx_v_kwa)) return -1;
  __Pyx_GOTREF(__pyx_v_kwa);
  if (PyTuple_GET_SIZE(__pyx_args) > 10) {
    __pyx_v_a = PyTuple_GetSlice(__pyx_args, 10, PyTuple_GET_SIZE(__pyx_args));
    if (unlikely(!__pyx_v_a)) {
      __Pyx_DECREF(__pyx_v_kwa); __pyx_v_kwa = 0;
      __Pyx_RefNannyFinishContext();
      return -1;
    }
    __Pyx_GOTREF(__pyx_v_a);
  } else {
    __pyx_v_a = __pyx_empty_tuple; __Pyx_INCREF(__pyx_empty_tuple);
  }
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_source,&__pyx_n_s_name,&__pyx_n_s_types,&__pyx_n_s_context,&__pyx_n_s_have_double,&__pyx_n_s_have_small,&__pyx_n_s_have_complex,&__pyx_n_s_have_half,&__pyx_n_s_cuda,&__pyx_n_s_opencl,0};
    PyObject* values[10] = {0,0,0,0,0,0,0,0,0,0};
    values[3] = (PyObject *)((struct PyGpuContextObject *)Py_None);

    /* "pygpu/gpuarray.pyx":2366
 * 
 *     def __cinit__(self, source, name, types, GpuContext context=None,
 *                   have_double=False, have_small=False, have_complex=False,             # <<<<<<<<<<<<<<
 *                   have_half=False, cuda=False, opencl=False, *a, **kwa):
 *         cdef const char *s[1]
 */
    values[4] = ((PyObject *)Py_False);
    values[5] = ((PyObject *)Py_False);
    values[6] = ((PyObject *)Py_False);

    /* "pygpu/gpuarray.pyx":2367
 *     def __cinit__(self, source, name, types, GpuContext context=None,
 *                   have_double=False, have_small=False, have_complex=False,
 *                   have_half=False, cuda=False, opencl=False, *a, **kwa):             # <<<<<<<<<<<<<<
 *         cdef const char *s[1]
 *         cdef size_t l
 */
    values[7] = ((PyObject *)Py_False);
    values[8] = ((PyObject *)Py_False);
    values[9] = ((PyObject *)Py_False);
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        default:
        case 10: values[9] = PyTuple_GET_ITEM(__pyx_args, 9);
        CYTHON_FALLTHROUGH;
        case  9: values[8] = PyTuple_GET_ITEM(__pyx_args, 8);
        CYTHON_FALLTHROUGH;
        case  8: values[7] = PyTuple_GET_ITEM(__pyx_args, 7);
        CYTHON_FALLTHROUGH;
        case  7: values[6] = PyTuple_GET_ITEM(__pyx_args, 6);
        CYTHON_FALLTHROUGH;
        case  6: values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
        CYTHON_FALLTHROUGH;
        case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
        CYTHON_FALLTHROUGH;
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_source)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_name)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("__cinit__", 0, 3, 10, 1); __PYX_ERR(0, 2365, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_types)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("__cinit__", 0, 3, 10, 2); __PYX_ERR(0, 2365, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  3:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_context);
          if (value) { values[3] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  4:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_have_double);
          if (value) { values[4] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  5:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_have_small);
          if (value) { values[5] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  6:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_have_complex);
          if (value) { values[6] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  7:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_have_half);
          if (value) { values[7] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  8:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_cuda);
          if (value) { values[8] = value; kw_args--; }
        }
        CYTHON_FALLTHROUGH;
        case  9:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_opencl);
          if (value) { values[9] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        const Py_ssize_t used_pos_args = (pos_args < 10) ? pos_args : 10;
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, __pyx_v_kwa, values, used_pos_args, "__cinit__") < 0)) __PYX_ERR(0, 2365, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        default:
        case 10: values[9] = PyTuple_GET_ITEM(__pyx_args, 9);
        CYTHON_FALLTHROUGH;
        case  9: values[8] = PyTuple_GET_ITEM(__pyx_args, 8);
        CYTHON_FALLTHROUGH;
        case  8: values[7] = PyTuple_GET_ITEM(__pyx_args, 7);
        CYTHON_FALLTHROUGH;
        case  7: values[6] = PyTuple_GET_ITEM(__pyx_args, 6);
        CYTHON_FALLTHROUGH;
        case  6: values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
        CYTHON_FALLTHROUGH;
        case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
        CYTHON_FALLTHROUGH;
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        break;
        case  2:
        case  1:
        case  0:
        goto __pyx_L5_argtuple_error;
      }
    }
    __pyx_v_source = values[0];
    __pyx_v_name = values[1];
    __pyx_v_types = values[2];
    __pyx_v_context = ((struct PyGpuContextObject *)values[3]);
    __pyx_v_have_double = values[4];
    __pyx_v_have_small = values[5];
    __pyx_v_have_complex = values[6];
    __pyx_v_have_half = values[7];
    __pyx_v_cuda = values[8];
    __pyx_v_opencl = values[9];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("__cinit__", 0, 3, 10, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 2365, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_DECREF(__pyx_v_a); __pyx_v_a = 0;
  __Pyx_DECREF(__pyx_v_kwa); __pyx_v_kwa = 0;
  __Pyx_AddTraceback("pygpu.gpuarray.GpuKernel.__cinit__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return -1;
  __pyx_L4_argument_unpacking_done:;
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_context), __pyx_ptype_5pygpu_8gpuarray_GpuContext, 1, "context", 0))) __PYX_ERR(0, 2365, __pyx_L1_error)
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_9GpuKernel_4__cinit__(((struct PyGpuKernelObject *)__pyx_v_self), __pyx_v_source, __pyx_v_name, __pyx_v_types, __pyx_v_context, __pyx_v_have_double, __pyx_v_have_small, __pyx_v_have_complex, __pyx_v_have_half, __pyx_v_cuda, __pyx_v_opencl, __pyx_v_a, __pyx_v_kwa);

  /* "pygpu/gpuarray.pyx":2365
 *         raise RuntimeError, "Cannot pickle GpuKernel object"
 * 
 *     def __cinit__(self, source, name, types, GpuContext context=None,             # <<<<<<<<<<<<<<
 *                   have_double=False, have_small=False, have_complex=False,
 *                   have_half=False, cuda=False, opencl=False, *a, **kwa):
 */

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_a);
  __Pyx_XDECREF(__pyx_v_kwa);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_5pygpu_8gpuarray_9GpuKernel_4__cinit__(struct PyGpuKernelObject *__pyx_v_self, PyObject *__pyx_v_source, PyObject *__pyx_v_name, PyObject *__pyx_v_types, struct PyGpuContextObject *__pyx_v_context, PyObject *__pyx_v_have_double, PyObject *__pyx_v_have_small, PyObject *__pyx_v_have_complex, PyObject *__pyx_v_have_half, PyObject *__pyx_v_cuda, PyObject *__pyx_v_opencl, CYTHON_UNUSED PyObject *__pyx_v_a, CYTHON_UNUSED PyObject *__pyx_v_kwa) {
  char const *__pyx_v_s[1];
  size_t __pyx_v_l;
  unsigned int __pyx_v_numargs;
  unsigned int __pyx_v_i;
  int *__pyx_v__types;
  int __pyx_v_flags;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_t_2;
  char const *__pyx_t_3;
  Py_ssize_t __pyx_t_4;
  unsigned int __pyx_t_5;
  unsigned int __pyx_t_6;
  PyObject *__pyx_t_7 = NULL;
  int __pyx_t_8;
  char const *__pyx_t_9;
  int __pyx_t_10;
  char const *__pyx_t_11;
  PyObject *__pyx_t_12 = NULL;
  PyObject *__pyx_t_13 = NULL;
  PyObject *__pyx_t_14 = NULL;
  PyObject *__pyx_t_15 = NULL;
  PyObject *__pyx_t_16 = NULL;
  PyObject *__pyx_t_17 = NULL;
  __Pyx_RefNannySetupContext("__cinit__", 0);
  __Pyx_INCREF(__pyx_v_source);
  __Pyx_INCREF(__pyx_v_name);

  /* "pygpu/gpuarray.pyx":2373
 *         cdef unsigned int i
 *         cdef int *_types
 *         cdef int flags = 0             # <<<<<<<<<<<<<<
 * 
 *         source = _s(source)
 */
  __pyx_v_flags = 0;

  /* "pygpu/gpuarray.pyx":2375
 *         cdef int flags = 0
 * 
 *         source = _s(source)             # <<<<<<<<<<<<<<
 *         name = _s(name)
 * 
 */
  __pyx_t_1 = __pyx_f_5pygpu_8gpuarray__s(__pyx_v_source); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2375, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF_SET(__pyx_v_source, __pyx_t_1);
  __pyx_t_1 = 0;

  /* "pygpu/gpuarray.pyx":2376
 * 
 *         source = _s(source)
 *         name = _s(name)             # <<<<<<<<<<<<<<
 * 
 *         self.context = ensure_context(context)
 */
  __pyx_t_1 = __pyx_f_5pygpu_8gpuarray__s(__pyx_v_name); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2376, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF_SET(__pyx_v_name, __pyx_t_1);
  __pyx_t_1 = 0;

  /* "pygpu/gpuarray.pyx":2378
 *         name = _s(name)
 * 
 *         self.context = ensure_context(context)             # <<<<<<<<<<<<<<
 * 
 *         if have_double:
 */
  __pyx_t_1 = ((PyObject *)__pyx_f_5pygpu_8gpuarray_ensure_context(__pyx_v_context)); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2378, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_GIVEREF(__pyx_t_1);
  __Pyx_GOTREF(__pyx_v_self->context);
  __Pyx_DECREF(((PyObject *)__pyx_v_self->context));
  __pyx_v_self->context = ((struct PyGpuContextObject *)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "pygpu/gpuarray.pyx":2380
 *         self.context = ensure_context(context)
 * 
 *         if have_double:             # <<<<<<<<<<<<<<
 *             flags |= GA_USE_DOUBLE
 *         if have_small:
 */
  __pyx_t_2 = __Pyx_PyObject_IsTrue(__pyx_v_have_double); if (unlikely(__pyx_t_2 < 0)) __PYX_ERR(0, 2380, __pyx_L1_error)
  if (__pyx_t_2) {

    /* "pygpu/gpuarray.pyx":2381
 * 
 *         if have_double:
 *             flags |= GA_USE_DOUBLE             # <<<<<<<<<<<<<<
 *         if have_small:
 *             flags |= GA_USE_SMALL
 */
    __pyx_v_flags = (__pyx_v_flags | GA_USE_DOUBLE);

    /* "pygpu/gpuarray.pyx":2380
 *         self.context = ensure_context(context)
 * 
 *         if have_double:             # <<<<<<<<<<<<<<
 *             flags |= GA_USE_DOUBLE
 *         if have_small:
 */
  }

  /* "pygpu/gpuarray.pyx":2382
 *         if have_double:
 *             flags |= GA_USE_DOUBLE
 *         if have_small:             # <<<<<<<<<<<<<<
 *             flags |= GA_USE_SMALL
 *         if have_complex:
 */
  __pyx_t_2 = __Pyx_PyObject_IsTrue(__pyx_v_have_small); if (unlikely(__pyx_t_2 < 0)) __PYX_ERR(0, 2382, __pyx_L1_error)
  if (__pyx_t_2) {

    /* "pygpu/gpuarray.pyx":2383
 *             flags |= GA_USE_DOUBLE
 *         if have_small:
 *             flags |= GA_USE_SMALL             # <<<<<<<<<<<<<<
 *         if have_complex:
 *             flags |= GA_USE_COMPLEX
 */
    __pyx_v_flags = (__pyx_v_flags | GA_USE_SMALL);

    /* "pygpu/gpuarray.pyx":2382
 *         if have_double:
 *             flags |= GA_USE_DOUBLE
 *         if have_small:             # <<<<<<<<<<<<<<
 *             flags |= GA_USE_SMALL
 *         if have_complex:
 */
  }

  /* "pygpu/gpuarray.pyx":2384
 *         if have_small:
 *             flags |= GA_USE_SMALL
 *         if have_complex:             # <<<<<<<<<<<<<<
 *             flags |= GA_USE_COMPLEX
 *         if have_half:
 */
  __pyx_t_2 = __Pyx_PyObject_IsTrue(__pyx_v_have_complex); if (unlikely(__pyx_t_2 < 0)) __PYX_ERR(0, 2384, __pyx_L1_error)
  if (__pyx_t_2) {

    /* "pygpu/gpuarray.pyx":2385
 *             flags |= GA_USE_SMALL
 *         if have_complex:
 *             flags |= GA_USE_COMPLEX             # <<<<<<<<<<<<<<
 *         if have_half:
 *             flags |= GA_USE_HALF
 */
    __pyx_v_flags = (__pyx_v_flags | GA_USE_COMPLEX);

    /* "pygpu/gpuarray.pyx":2384
 *         if have_small:
 *             flags |= GA_USE_SMALL
 *         if have_complex:             # <<<<<<<<<<<<<<
 *             flags |= GA_USE_COMPLEX
 *         if have_half:
 */
  }

  /* "pygpu/gpuarray.pyx":2386
 *         if have_complex:
 *             flags |= GA_USE_COMPLEX
 *         if have_half:             # <<<<<<<<<<<<<<
 *             flags |= GA_USE_HALF
 *         if cuda:
 */
  __pyx_t_2 = __Pyx_PyObject_IsTrue(__pyx_v_have_half); if (unlikely(__pyx_t_2 < 0)) __PYX_ERR(0, 2386, __pyx_L1_error)
  if (__pyx_t_2) {

    /* "pygpu/gpuarray.pyx":2387
 *             flags |= GA_USE_COMPLEX
 *         if have_half:
 *             flags |= GA_USE_HALF             # <<<<<<<<<<<<<<
 *         if cuda:
 *             flags |= GA_USE_CUDA
 */
    __pyx_v_flags = (__pyx_v_flags | GA_USE_HALF);

    /* "pygpu/gpuarray.pyx":2386
 *         if have_complex:
 *             flags |= GA_USE_COMPLEX
 *         if have_half:             # <<<<<<<<<<<<<<
 *             flags |= GA_USE_HALF
 *         if cuda:
 */
  }

  /* "pygpu/gpuarray.pyx":2388
 *         if have_half:
 *             flags |= GA_USE_HALF
 *         if cuda:             # <<<<<<<<<<<<<<
 *             flags |= GA_USE_CUDA
 *         if opencl:
 */
  __pyx_t_2 = __Pyx_PyObject_IsTrue(__pyx_v_cuda); if (unlikely(__pyx_t_2 < 0)) __PYX_ERR(0, 2388, __pyx_L1_error)
  if (__pyx_t_2) {

    /* "pygpu/gpuarray.pyx":2389
 *             flags |= GA_USE_HALF
 *         if cuda:
 *             flags |= GA_USE_CUDA             # <<<<<<<<<<<<<<
 *         if opencl:
 *             flags |= GA_USE_OPENCL
 */
    __pyx_v_flags = (__pyx_v_flags | GA_USE_CUDA);

    /* "pygpu/gpuarray.pyx":2388
 *         if have_half:
 *             flags |= GA_USE_HALF
 *         if cuda:             # <<<<<<<<<<<<<<
 *             flags |= GA_USE_CUDA
 *         if opencl:
 */
  }

  /* "pygpu/gpuarray.pyx":2390
 *         if cuda:
 *             flags |= GA_USE_CUDA
 *         if opencl:             # <<<<<<<<<<<<<<
 *             flags |= GA_USE_OPENCL
 * 
 */
  __pyx_t_2 = __Pyx_PyObject_IsTrue(__pyx_v_opencl); if (unlikely(__pyx_t_2 < 0)) __PYX_ERR(0, 2390, __pyx_L1_error)
  if (__pyx_t_2) {

    /* "pygpu/gpuarray.pyx":2391
 *             flags |= GA_USE_CUDA
 *         if opencl:
 *             flags |= GA_USE_OPENCL             # <<<<<<<<<<<<<<
 * 
 *         s[0] = source
 */
    __pyx_v_flags = (__pyx_v_flags | GA_USE_OPENCL);

    /* "pygpu/gpuarray.pyx":2390
 *         if cuda:
 *             flags |= GA_USE_CUDA
 *         if opencl:             # <<<<<<<<<<<<<<
 *             flags |= GA_USE_OPENCL
 * 
 */
  }

  /* "pygpu/gpuarray.pyx":2393
 *             flags |= GA_USE_OPENCL
 * 
 *         s[0] = source             # <<<<<<<<<<<<<<
 *         l = len(source)
 *         numargs = <unsigned int>len(types)
 */
  __pyx_t_3 = __Pyx_PyObject_AsString(__pyx_v_source); if (unlikely((!__pyx_t_3) && PyErr_Occurred())) __PYX_ERR(0, 2393, __pyx_L1_error)
  (__pyx_v_s[0]) = __pyx_t_3;

  /* "pygpu/gpuarray.pyx":2394
 * 
 *         s[0] = source
 *         l = len(source)             # <<<<<<<<<<<<<<
 *         numargs = <unsigned int>len(types)
 *         self.callbuf = <void **>calloc(len(types), sizeof(void *))
 */
  __pyx_t_4 = PyObject_Length(__pyx_v_source); if (unlikely(__pyx_t_4 == ((Py_ssize_t)-1))) __PYX_ERR(0, 2394, __pyx_L1_error)
  __pyx_v_l = __pyx_t_4;

  /* "pygpu/gpuarray.pyx":2395
 *         s[0] = source
 *         l = len(source)
 *         numargs = <unsigned int>len(types)             # <<<<<<<<<<<<<<
 *         self.callbuf = <void **>calloc(len(types), sizeof(void *))
 *         if self.callbuf == NULL:
 */
  __pyx_t_4 = PyObject_Length(__pyx_v_types); if (unlikely(__pyx_t_4 == ((Py_ssize_t)-1))) __PYX_ERR(0, 2395, __pyx_L1_error)
  __pyx_v_numargs = ((unsigned int)__pyx_t_4);

  /* "pygpu/gpuarray.pyx":2396
 *         l = len(source)
 *         numargs = <unsigned int>len(types)
 *         self.callbuf = <void **>calloc(len(types), sizeof(void *))             # <<<<<<<<<<<<<<
 *         if self.callbuf == NULL:
 *             raise MemoryError
 */
  __pyx_t_4 = PyObject_Length(__pyx_v_types); if (unlikely(__pyx_t_4 == ((Py_ssize_t)-1))) __PYX_ERR(0, 2396, __pyx_L1_error)
  __pyx_v_self->callbuf = ((void **)calloc(__pyx_t_4, (sizeof(void *))));

  /* "pygpu/gpuarray.pyx":2397
 *         numargs = <unsigned int>len(types)
 *         self.callbuf = <void **>calloc(len(types), sizeof(void *))
 *         if self.callbuf == NULL:             # <<<<<<<<<<<<<<
 *             raise MemoryError
 *         _types = <int *>calloc(numargs, sizeof(int))
 */
  __pyx_t_2 = ((__pyx_v_self->callbuf == NULL) != 0);
  if (__pyx_t_2) {

    /* "pygpu/gpuarray.pyx":2398
 *         self.callbuf = <void **>calloc(len(types), sizeof(void *))
 *         if self.callbuf == NULL:
 *             raise MemoryError             # <<<<<<<<<<<<<<
 *         _types = <int *>calloc(numargs, sizeof(int))
 *         if _types == NULL:
 */
    PyErr_NoMemory(); __PYX_ERR(0, 2398, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":2397
 *         numargs = <unsigned int>len(types)
 *         self.callbuf = <void **>calloc(len(types), sizeof(void *))
 *         if self.callbuf == NULL:             # <<<<<<<<<<<<<<
 *             raise MemoryError
 *         _types = <int *>calloc(numargs, sizeof(int))
 */
  }

  /* "pygpu/gpuarray.pyx":2399
 *         if self.callbuf == NULL:
 *             raise MemoryError
 *         _types = <int *>calloc(numargs, sizeof(int))             # <<<<<<<<<<<<<<
 *         if _types == NULL:
 *             raise MemoryError
 */
  __pyx_v__types = ((int *)calloc(__pyx_v_numargs, (sizeof(int))));

  /* "pygpu/gpuarray.pyx":2400
 *             raise MemoryError
 *         _types = <int *>calloc(numargs, sizeof(int))
 *         if _types == NULL:             # <<<<<<<<<<<<<<
 *             raise MemoryError
 *         try:
 */
  __pyx_t_2 = ((__pyx_v__types == NULL) != 0);
  if (__pyx_t_2) {

    /* "pygpu/gpuarray.pyx":2401
 *         _types = <int *>calloc(numargs, sizeof(int))
 *         if _types == NULL:
 *             raise MemoryError             # <<<<<<<<<<<<<<
 *         try:
 *             for i in range(numargs):
 */
    PyErr_NoMemory(); __PYX_ERR(0, 2401, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":2400
 *             raise MemoryError
 *         _types = <int *>calloc(numargs, sizeof(int))
 *         if _types == NULL:             # <<<<<<<<<<<<<<
 *             raise MemoryError
 *         try:
 */
  }

  /* "pygpu/gpuarray.pyx":2402
 *         if _types == NULL:
 *             raise MemoryError
 *         try:             # <<<<<<<<<<<<<<
 *             for i in range(numargs):
 *                 if (types[i] == GpuArray):
 */
  /*try:*/ {

    /* "pygpu/gpuarray.pyx":2403
 *             raise MemoryError
 *         try:
 *             for i in range(numargs):             # <<<<<<<<<<<<<<
 *                 if (types[i] == GpuArray):
 *                     _types[i] = GA_BUFFER
 */
    __pyx_t_5 = __pyx_v_numargs;
    for (__pyx_t_6 = 0; __pyx_t_6 < __pyx_t_5; __pyx_t_6+=1) {
      __pyx_v_i = __pyx_t_6;

      /* "pygpu/gpuarray.pyx":2404
 *         try:
 *             for i in range(numargs):
 *                 if (types[i] == GpuArray):             # <<<<<<<<<<<<<<
 *                     _types[i] = GA_BUFFER
 *                 else:
 */
      __pyx_t_1 = __Pyx_GetItemInt(__pyx_v_types, __pyx_v_i, unsigned int, 0, __Pyx_PyInt_From_unsigned_int, 0, 0, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 2404, __pyx_L12_error)
      __Pyx_GOTREF(__pyx_t_1);
      __pyx_t_7 = PyObject_RichCompare(__pyx_t_1, ((PyObject *)__pyx_ptype_5pygpu_8gpuarray_GpuArray), Py_EQ); __Pyx_XGOTREF(__pyx_t_7); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 2404, __pyx_L12_error)
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __pyx_t_2 = __Pyx_PyObject_IsTrue(__pyx_t_7); if (unlikely(__pyx_t_2 < 0)) __PYX_ERR(0, 2404, __pyx_L12_error)
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      if (__pyx_t_2) {

        /* "pygpu/gpuarray.pyx":2405
 *             for i in range(numargs):
 *                 if (types[i] == GpuArray):
 *                     _types[i] = GA_BUFFER             # <<<<<<<<<<<<<<
 *                 else:
 *                     _types[i] = dtype_to_typecode(types[i])
 */
        (__pyx_v__types[__pyx_v_i]) = GA_BUFFER;

        /* "pygpu/gpuarray.pyx":2404
 *         try:
 *             for i in range(numargs):
 *                 if (types[i] == GpuArray):             # <<<<<<<<<<<<<<
 *                     _types[i] = GA_BUFFER
 *                 else:
 */
        goto __pyx_L16;
      }

      /* "pygpu/gpuarray.pyx":2407
 *                     _types[i] = GA_BUFFER
 *                 else:
 *                     _types[i] = dtype_to_typecode(types[i])             # <<<<<<<<<<<<<<
 *                     self.callbuf[i] = malloc(gpuarray_get_elsize(_types[i]))
 *                     if self.callbuf[i] == NULL:
 */
      /*else*/ {
        __pyx_t_7 = __Pyx_GetItemInt(__pyx_v_types, __pyx_v_i, unsigned int, 0, __Pyx_PyInt_From_unsigned_int, 0, 0, 1); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 2407, __pyx_L12_error)
        __Pyx_GOTREF(__pyx_t_7);
        __pyx_t_8 = __pyx_f_5pygpu_8gpuarray_dtype_to_typecode(__pyx_t_7, 0); if (unlikely(__pyx_t_8 == ((int)-1))) __PYX_ERR(0, 2407, __pyx_L12_error)
        __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
        (__pyx_v__types[__pyx_v_i]) = __pyx_t_8;

        /* "pygpu/gpuarray.pyx":2408
 *                 else:
 *                     _types[i] = dtype_to_typecode(types[i])
 *                     self.callbuf[i] = malloc(gpuarray_get_elsize(_types[i]))             # <<<<<<<<<<<<<<
 *                     if self.callbuf[i] == NULL:
 *                         raise MemoryError
 */
        (__pyx_v_self->callbuf[__pyx_v_i]) = malloc(gpuarray_get_elsize((__pyx_v__types[__pyx_v_i])));

        /* "pygpu/gpuarray.pyx":2409
 *                     _types[i] = dtype_to_typecode(types[i])
 *                     self.callbuf[i] = malloc(gpuarray_get_elsize(_types[i]))
 *                     if self.callbuf[i] == NULL:             # <<<<<<<<<<<<<<
 *                         raise MemoryError
 *             kernel_init(self, self.context.ctx, 1, s, &l,
 */
        __pyx_t_2 = (((__pyx_v_self->callbuf[__pyx_v_i]) == NULL) != 0);
        if (__pyx_t_2) {

          /* "pygpu/gpuarray.pyx":2410
 *                     self.callbuf[i] = malloc(gpuarray_get_elsize(_types[i]))
 *                     if self.callbuf[i] == NULL:
 *                         raise MemoryError             # <<<<<<<<<<<<<<
 *             kernel_init(self, self.context.ctx, 1, s, &l,
 *                         name, numargs, _types, flags)
 */
          PyErr_NoMemory(); __PYX_ERR(0, 2410, __pyx_L12_error)

          /* "pygpu/gpuarray.pyx":2409
 *                     _types[i] = dtype_to_typecode(types[i])
 *                     self.callbuf[i] = malloc(gpuarray_get_elsize(_types[i]))
 *                     if self.callbuf[i] == NULL:             # <<<<<<<<<<<<<<
 *                         raise MemoryError
 *             kernel_init(self, self.context.ctx, 1, s, &l,
 */
        }
      }
      __pyx_L16:;
    }

    /* "pygpu/gpuarray.pyx":2412
 *                         raise MemoryError
 *             kernel_init(self, self.context.ctx, 1, s, &l,
 *                         name, numargs, _types, flags)             # <<<<<<<<<<<<<<
 *         finally:
 *             free(_types)
 */
    __pyx_t_9 = __Pyx_PyObject_AsString(__pyx_v_name); if (unlikely((!__pyx_t_9) && PyErr_Occurred())) __PYX_ERR(0, 2412, __pyx_L12_error)

    /* "pygpu/gpuarray.pyx":2411
 *                     if self.callbuf[i] == NULL:
 *                         raise MemoryError
 *             kernel_init(self, self.context.ctx, 1, s, &l,             # <<<<<<<<<<<<<<
 *                         name, numargs, _types, flags)
 *         finally:
 */
    __pyx_t_8 = __pyx_f_5pygpu_8gpuarray_kernel_init(__pyx_v_self, __pyx_v_self->context->ctx, 1, __pyx_v_s, (&__pyx_v_l), __pyx_t_9, __pyx_v_numargs, __pyx_v__types, __pyx_v_flags); if (unlikely(__pyx_t_8 == ((int)-1))) __PYX_ERR(0, 2411, __pyx_L12_error)
  }

  /* "pygpu/gpuarray.pyx":2414
 *                         name, numargs, _types, flags)
 *         finally:
 *             free(_types)             # <<<<<<<<<<<<<<
 * 
 *     def __call__(self, *args, n=None, gs=None, ls=None, shared=0):
 */
  /*finally:*/ {
    /*normal exit:*/{
      free(__pyx_v__types);
      goto __pyx_L13;
    }
    __pyx_L12_error:;
    /*exception exit:*/{
      __Pyx_PyThreadState_declare
      __Pyx_PyThreadState_assign
      __pyx_t_12 = 0; __pyx_t_13 = 0; __pyx_t_14 = 0; __pyx_t_15 = 0; __pyx_t_16 = 0; __pyx_t_17 = 0;
      __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
      __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
      if (PY_MAJOR_VERSION >= 3) __Pyx_ExceptionSwap(&__pyx_t_15, &__pyx_t_16, &__pyx_t_17);
      if ((PY_MAJOR_VERSION < 3) || unlikely(__Pyx_GetException(&__pyx_t_12, &__pyx_t_13, &__pyx_t_14) < 0)) __Pyx_ErrFetch(&__pyx_t_12, &__pyx_t_13, &__pyx_t_14);
      __Pyx_XGOTREF(__pyx_t_12);
      __Pyx_XGOTREF(__pyx_t_13);
      __Pyx_XGOTREF(__pyx_t_14);
      __Pyx_XGOTREF(__pyx_t_15);
      __Pyx_XGOTREF(__pyx_t_16);
      __Pyx_XGOTREF(__pyx_t_17);
      __pyx_t_8 = __pyx_lineno; __pyx_t_10 = __pyx_clineno; __pyx_t_11 = __pyx_filename;
      {
        free(__pyx_v__types);
      }
      if (PY_MAJOR_VERSION >= 3) {
        __Pyx_XGIVEREF(__pyx_t_15);
        __Pyx_XGIVEREF(__pyx_t_16);
        __Pyx_XGIVEREF(__pyx_t_17);
        __Pyx_ExceptionReset(__pyx_t_15, __pyx_t_16, __pyx_t_17);
      }
      __Pyx_XGIVEREF(__pyx_t_12);
      __Pyx_XGIVEREF(__pyx_t_13);
      __Pyx_XGIVEREF(__pyx_t_14);
      __Pyx_ErrRestore(__pyx_t_12, __pyx_t_13, __pyx_t_14);
      __pyx_t_12 = 0; __pyx_t_13 = 0; __pyx_t_14 = 0; __pyx_t_15 = 0; __pyx_t_16 = 0; __pyx_t_17 = 0;
      __pyx_lineno = __pyx_t_8; __pyx_clineno = __pyx_t_10; __pyx_filename = __pyx_t_11;
      goto __pyx_L1_error;
    }
    __pyx_L13:;
  }

  /* "pygpu/gpuarray.pyx":2365
 *         raise RuntimeError, "Cannot pickle GpuKernel object"
 * 
 *     def __cinit__(self, source, name, types, GpuContext context=None,             # <<<<<<<<<<<<<<
 *                   have_double=False, have_small=False, have_complex=False,
 *                   have_half=False, cuda=False, opencl=False, *a, **kwa):
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_AddTraceback("pygpu.gpuarray.GpuKernel.__cinit__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_source);
  __Pyx_XDECREF(__pyx_v_name);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":2416
 *             free(_types)
 * 
 *     def __call__(self, *args, n=None, gs=None, ls=None, shared=0):             # <<<<<<<<<<<<<<
 *         """
 *         __call__(*args, n=None, gs=None, ls=None, shared=0)
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_9GpuKernel_7__call__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static char __pyx_doc_5pygpu_8gpuarray_9GpuKernel_6__call__[] = "\n        __call__(*args, n=None, gs=None, ls=None, shared=0)\n        ";
#if CYTHON_COMPILING_IN_CPYTHON
struct wrapperbase __pyx_wrapperbase_5pygpu_8gpuarray_9GpuKernel_6__call__;
#endif
static PyObject *__pyx_pw_5pygpu_8gpuarray_9GpuKernel_7__call__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_n = 0;
  PyObject *__pyx_v_gs = 0;
  PyObject *__pyx_v_ls = 0;
  PyObject *__pyx_v_shared = 0;
  PyObject *__pyx_v_args = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__call__ (wrapper)", 0);
  if (PyTuple_GET_SIZE(__pyx_args) > 0) {
    __pyx_v_args = PyTuple_GetSlice(__pyx_args, 0, PyTuple_GET_SIZE(__pyx_args));
    if (unlikely(!__pyx_v_args)) {
      __Pyx_RefNannyFinishContext();
      return NULL;
    }
    __Pyx_GOTREF(__pyx_v_args);
  } else {
    __pyx_v_args = __pyx_empty_tuple; __Pyx_INCREF(__pyx_empty_tuple);
  }
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_n,&__pyx_n_s_gs,&__pyx_n_s_ls,&__pyx_n_s_shared,0};
    PyObject* values[4] = {0,0,0,0};
    values[0] = ((PyObject *)Py_None);
    values[1] = ((PyObject *)Py_None);
    values[2] = ((PyObject *)Py_None);
    values[3] = ((PyObject *)__pyx_int_0);
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        default:
        case  0: break;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      if (kw_args > 0 && likely(kw_args <= 4)) {
        Py_ssize_t index;
        for (index = 0; index < 4 && kw_args > 0; index++) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, *__pyx_pyargnames[index]);
          if (value) { values[index] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, 0, "__call__") < 0)) __PYX_ERR(0, 2416, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) < 0) {
      goto __pyx_L5_argtuple_error;
    } else {
    }
    __pyx_v_n = values[0];
    __pyx_v_gs = values[1];
    __pyx_v_ls = values[2];
    __pyx_v_shared = values[3];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("__call__", 0, 0, 0, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 2416, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_DECREF(__pyx_v_args); __pyx_v_args = 0;
  __Pyx_AddTraceback("pygpu.gpuarray.GpuKernel.__call__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_9GpuKernel_6__call__(((struct PyGpuKernelObject *)__pyx_v_self), __pyx_v_n, __pyx_v_gs, __pyx_v_ls, __pyx_v_shared, __pyx_v_args);

  /* function exit code */
  __Pyx_XDECREF(__pyx_v_args);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_9GpuKernel_6__call__(struct PyGpuKernelObject *__pyx_v_self, PyObject *__pyx_v_n, PyObject *__pyx_v_gs, PyObject *__pyx_v_ls, PyObject *__pyx_v_shared, PyObject *__pyx_v_args) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_t_2;
  int __pyx_t_3;
  size_t __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  __Pyx_RefNannySetupContext("__call__", 0);

  /* "pygpu/gpuarray.pyx":2420
 *         __call__(*args, n=None, gs=None, ls=None, shared=0)
 *         """
 *         if n is None and (ls is None or gs is None):             # <<<<<<<<<<<<<<
 *             raise ValueError, "Must specify size (n) or both gs and ls"
 *         self.do_call(n, gs, ls, args, shared)
 */
  __pyx_t_2 = (__pyx_v_n == Py_None);
  __pyx_t_3 = (__pyx_t_2 != 0);
  if (__pyx_t_3) {
  } else {
    __pyx_t_1 = __pyx_t_3;
    goto __pyx_L4_bool_binop_done;
  }
  __pyx_t_3 = (__pyx_v_ls == Py_None);
  __pyx_t_2 = (__pyx_t_3 != 0);
  if (!__pyx_t_2) {
  } else {
    __pyx_t_1 = __pyx_t_2;
    goto __pyx_L4_bool_binop_done;
  }
  __pyx_t_2 = (__pyx_v_gs == Py_None);
  __pyx_t_3 = (__pyx_t_2 != 0);
  __pyx_t_1 = __pyx_t_3;
  __pyx_L4_bool_binop_done:;
  if (__pyx_t_1) {

    /* "pygpu/gpuarray.pyx":2421
 *         """
 *         if n is None and (ls is None or gs is None):
 *             raise ValueError, "Must specify size (n) or both gs and ls"             # <<<<<<<<<<<<<<
 *         self.do_call(n, gs, ls, args, shared)
 * 
 */
    __Pyx_Raise(__pyx_builtin_ValueError, __pyx_kp_s_Must_specify_size_n_or_both_gs_a, 0, 0);
    __PYX_ERR(0, 2421, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":2420
 *         __call__(*args, n=None, gs=None, ls=None, shared=0)
 *         """
 *         if n is None and (ls is None or gs is None):             # <<<<<<<<<<<<<<
 *             raise ValueError, "Must specify size (n) or both gs and ls"
 *         self.do_call(n, gs, ls, args, shared)
 */
  }

  /* "pygpu/gpuarray.pyx":2422
 *         if n is None and (ls is None or gs is None):
 *             raise ValueError, "Must specify size (n) or both gs and ls"
 *         self.do_call(n, gs, ls, args, shared)             # <<<<<<<<<<<<<<
 * 
 *     cdef do_call(self, py_n, py_gs, py_ls, py_args, size_t shared):
 */
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_v_shared); if (unlikely((__pyx_t_4 == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 2422, __pyx_L1_error)
  __pyx_t_5 = ((struct __pyx_vtabstruct_5pygpu_8gpuarray_GpuKernel *)__pyx_v_self->__pyx_vtab)->do_call(__pyx_v_self, __pyx_v_n, __pyx_v_gs, __pyx_v_ls, __pyx_v_args, __pyx_t_4); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 2422, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;

  /* "pygpu/gpuarray.pyx":2416
 *             free(_types)
 * 
 *     def __call__(self, *args, n=None, gs=None, ls=None, shared=0):             # <<<<<<<<<<<<<<
 *         """
 *         __call__(*args, n=None, gs=None, ls=None, shared=0)
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("pygpu.gpuarray.GpuKernel.__call__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":2424
 *         self.do_call(n, gs, ls, args, shared)
 * 
 *     cdef do_call(self, py_n, py_gs, py_ls, py_args, size_t shared):             # <<<<<<<<<<<<<<
 *         cdef size_t n
 *         cdef size_t gs[3]
 */

static PyObject *__pyx_f_5pygpu_8gpuarray_9GpuKernel_do_call(struct PyGpuKernelObject *__pyx_v_self, PyObject *__pyx_v_py_n, PyObject *__pyx_v_py_gs, PyObject *__pyx_v_py_ls, PyObject *__pyx_v_py_args, size_t __pyx_v_shared) {
  size_t __pyx_v_n;
  size_t __pyx_v_gs[3];
  size_t __pyx_v_ls[3];
  unsigned int __pyx_v_nd;
  int const *__pyx_v_types;
  unsigned int __pyx_v_numargs;
  unsigned int __pyx_v_i;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_t_2;
  size_t __pyx_t_3;
  int __pyx_t_4;
  Py_ssize_t __pyx_t_5;
  PyObject *__pyx_t_6 = NULL;
  unsigned int __pyx_t_7;
  PyObject *__pyx_t_8 = NULL;
  PyObject *__pyx_t_9 = NULL;
  int __pyx_t_10;
  unsigned int __pyx_t_11;
  __Pyx_RefNannySetupContext("do_call", 0);

  /* "pygpu/gpuarray.pyx":2434
 *         cdef unsigned int i
 * 
 *         nd = 0             # <<<<<<<<<<<<<<
 * 
 *         if py_ls is None:
 */
  __pyx_v_nd = 0;

  /* "pygpu/gpuarray.pyx":2436
 *         nd = 0
 * 
 *         if py_ls is None:             # <<<<<<<<<<<<<<
 *             ls[0] = 0
 *             nd = 1
 */
  __pyx_t_1 = (__pyx_v_py_ls == Py_None);
  __pyx_t_2 = (__pyx_t_1 != 0);
  if (__pyx_t_2) {

    /* "pygpu/gpuarray.pyx":2437
 * 
 *         if py_ls is None:
 *             ls[0] = 0             # <<<<<<<<<<<<<<
 *             nd = 1
 *         else:
 */
    (__pyx_v_ls[0]) = 0;

    /* "pygpu/gpuarray.pyx":2438
 *         if py_ls is None:
 *             ls[0] = 0
 *             nd = 1             # <<<<<<<<<<<<<<
 *         else:
 *             if isinstance(py_ls, int):
 */
    __pyx_v_nd = 1;

    /* "pygpu/gpuarray.pyx":2436
 *         nd = 0
 * 
 *         if py_ls is None:             # <<<<<<<<<<<<<<
 *             ls[0] = 0
 *             nd = 1
 */
    goto __pyx_L3;
  }

  /* "pygpu/gpuarray.pyx":2440
 *             nd = 1
 *         else:
 *             if isinstance(py_ls, int):             # <<<<<<<<<<<<<<
 *                 ls[0] = py_ls
 *                 nd = 1
 */
  /*else*/ {
    __pyx_t_2 = PyInt_Check(__pyx_v_py_ls); 
    __pyx_t_1 = (__pyx_t_2 != 0);
    if (__pyx_t_1) {

      /* "pygpu/gpuarray.pyx":2441
 *         else:
 *             if isinstance(py_ls, int):
 *                 ls[0] = py_ls             # <<<<<<<<<<<<<<
 *                 nd = 1
 *             elif isinstance(py_ls, (list, tuple)):
 */
      __pyx_t_3 = __Pyx_PyInt_As_size_t(__pyx_v_py_ls); if (unlikely((__pyx_t_3 == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 2441, __pyx_L1_error)
      (__pyx_v_ls[0]) = __pyx_t_3;

      /* "pygpu/gpuarray.pyx":2442
 *             if isinstance(py_ls, int):
 *                 ls[0] = py_ls
 *                 nd = 1             # <<<<<<<<<<<<<<
 *             elif isinstance(py_ls, (list, tuple)):
 *                 if len(py_ls) > 3:
 */
      __pyx_v_nd = 1;

      /* "pygpu/gpuarray.pyx":2440
 *             nd = 1
 *         else:
 *             if isinstance(py_ls, int):             # <<<<<<<<<<<<<<
 *                 ls[0] = py_ls
 *                 nd = 1
 */
      goto __pyx_L4;
    }

    /* "pygpu/gpuarray.pyx":2443
 *                 ls[0] = py_ls
 *                 nd = 1
 *             elif isinstance(py_ls, (list, tuple)):             # <<<<<<<<<<<<<<
 *                 if len(py_ls) > 3:
 *                     raise ValueError, "ls is not of length 3 or less"
 */
    __pyx_t_2 = PyList_Check(__pyx_v_py_ls); 
    __pyx_t_4 = (__pyx_t_2 != 0);
    if (!__pyx_t_4) {
    } else {
      __pyx_t_1 = __pyx_t_4;
      goto __pyx_L5_bool_binop_done;
    }
    __pyx_t_4 = PyTuple_Check(__pyx_v_py_ls); 
    __pyx_t_2 = (__pyx_t_4 != 0);
    __pyx_t_1 = __pyx_t_2;
    __pyx_L5_bool_binop_done:;
    __pyx_t_2 = (__pyx_t_1 != 0);
    if (__pyx_t_2) {

      /* "pygpu/gpuarray.pyx":2444
 *                 nd = 1
 *             elif isinstance(py_ls, (list, tuple)):
 *                 if len(py_ls) > 3:             # <<<<<<<<<<<<<<
 *                     raise ValueError, "ls is not of length 3 or less"
 *                 nd = len(py_ls)
 */
      __pyx_t_5 = PyObject_Length(__pyx_v_py_ls); if (unlikely(__pyx_t_5 == ((Py_ssize_t)-1))) __PYX_ERR(0, 2444, __pyx_L1_error)
      __pyx_t_2 = ((__pyx_t_5 > 3) != 0);
      if (__pyx_t_2) {

        /* "pygpu/gpuarray.pyx":2445
 *             elif isinstance(py_ls, (list, tuple)):
 *                 if len(py_ls) > 3:
 *                     raise ValueError, "ls is not of length 3 or less"             # <<<<<<<<<<<<<<
 *                 nd = len(py_ls)
 * 
 */
        __Pyx_Raise(__pyx_builtin_ValueError, __pyx_kp_s_ls_is_not_of_length_3_or_less, 0, 0);
        __PYX_ERR(0, 2445, __pyx_L1_error)

        /* "pygpu/gpuarray.pyx":2444
 *                 nd = 1
 *             elif isinstance(py_ls, (list, tuple)):
 *                 if len(py_ls) > 3:             # <<<<<<<<<<<<<<
 *                     raise ValueError, "ls is not of length 3 or less"
 *                 nd = len(py_ls)
 */
      }

      /* "pygpu/gpuarray.pyx":2446
 *                 if len(py_ls) > 3:
 *                     raise ValueError, "ls is not of length 3 or less"
 *                 nd = len(py_ls)             # <<<<<<<<<<<<<<
 * 
 *                 if nd >= 3:
 */
      __pyx_t_5 = PyObject_Length(__pyx_v_py_ls); if (unlikely(__pyx_t_5 == ((Py_ssize_t)-1))) __PYX_ERR(0, 2446, __pyx_L1_error)
      __pyx_v_nd = __pyx_t_5;

      /* "pygpu/gpuarray.pyx":2448
 *                 nd = len(py_ls)
 * 
 *                 if nd >= 3:             # <<<<<<<<<<<<<<
 *                     ls[2] = py_ls[2]
 *                 if nd >= 2:
 */
      __pyx_t_2 = ((__pyx_v_nd >= 3) != 0);
      if (__pyx_t_2) {

        /* "pygpu/gpuarray.pyx":2449
 * 
 *                 if nd >= 3:
 *                     ls[2] = py_ls[2]             # <<<<<<<<<<<<<<
 *                 if nd >= 2:
 *                     ls[1] = py_ls[1]
 */
        __pyx_t_6 = __Pyx_GetItemInt(__pyx_v_py_ls, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 2449, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_6);
        __pyx_t_3 = __Pyx_PyInt_As_size_t(__pyx_t_6); if (unlikely((__pyx_t_3 == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 2449, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
        (__pyx_v_ls[2]) = __pyx_t_3;

        /* "pygpu/gpuarray.pyx":2448
 *                 nd = len(py_ls)
 * 
 *                 if nd >= 3:             # <<<<<<<<<<<<<<
 *                     ls[2] = py_ls[2]
 *                 if nd >= 2:
 */
      }

      /* "pygpu/gpuarray.pyx":2450
 *                 if nd >= 3:
 *                     ls[2] = py_ls[2]
 *                 if nd >= 2:             # <<<<<<<<<<<<<<
 *                     ls[1] = py_ls[1]
 *                 if nd >= 1:
 */
      __pyx_t_2 = ((__pyx_v_nd >= 2) != 0);
      if (__pyx_t_2) {

        /* "pygpu/gpuarray.pyx":2451
 *                     ls[2] = py_ls[2]
 *                 if nd >= 2:
 *                     ls[1] = py_ls[1]             # <<<<<<<<<<<<<<
 *                 if nd >= 1:
 *                     ls[0] = py_ls[0]
 */
        __pyx_t_6 = __Pyx_GetItemInt(__pyx_v_py_ls, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 2451, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_6);
        __pyx_t_3 = __Pyx_PyInt_As_size_t(__pyx_t_6); if (unlikely((__pyx_t_3 == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 2451, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
        (__pyx_v_ls[1]) = __pyx_t_3;

        /* "pygpu/gpuarray.pyx":2450
 *                 if nd >= 3:
 *                     ls[2] = py_ls[2]
 *                 if nd >= 2:             # <<<<<<<<<<<<<<
 *                     ls[1] = py_ls[1]
 *                 if nd >= 1:
 */
      }

      /* "pygpu/gpuarray.pyx":2452
 *                 if nd >= 2:
 *                     ls[1] = py_ls[1]
 *                 if nd >= 1:             # <<<<<<<<<<<<<<
 *                     ls[0] = py_ls[0]
 *             else:
 */
      __pyx_t_2 = ((__pyx_v_nd >= 1) != 0);
      if (__pyx_t_2) {

        /* "pygpu/gpuarray.pyx":2453
 *                     ls[1] = py_ls[1]
 *                 if nd >= 1:
 *                     ls[0] = py_ls[0]             # <<<<<<<<<<<<<<
 *             else:
 *                 raise TypeError, "ls is not int or list"
 */
        __pyx_t_6 = __Pyx_GetItemInt(__pyx_v_py_ls, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 2453, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_6);
        __pyx_t_3 = __Pyx_PyInt_As_size_t(__pyx_t_6); if (unlikely((__pyx_t_3 == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 2453, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
        (__pyx_v_ls[0]) = __pyx_t_3;

        /* "pygpu/gpuarray.pyx":2452
 *                 if nd >= 2:
 *                     ls[1] = py_ls[1]
 *                 if nd >= 1:             # <<<<<<<<<<<<<<
 *                     ls[0] = py_ls[0]
 *             else:
 */
      }

      /* "pygpu/gpuarray.pyx":2443
 *                 ls[0] = py_ls
 *                 nd = 1
 *             elif isinstance(py_ls, (list, tuple)):             # <<<<<<<<<<<<<<
 *                 if len(py_ls) > 3:
 *                     raise ValueError, "ls is not of length 3 or less"
 */
      goto __pyx_L4;
    }

    /* "pygpu/gpuarray.pyx":2455
 *                     ls[0] = py_ls[0]
 *             else:
 *                 raise TypeError, "ls is not int or list"             # <<<<<<<<<<<<<<
 * 
 *         if py_gs is None:
 */
    /*else*/ {
      __Pyx_Raise(__pyx_builtin_TypeError, __pyx_kp_s_ls_is_not_int_or_list, 0, 0);
      __PYX_ERR(0, 2455, __pyx_L1_error)
    }
    __pyx_L4:;
  }
  __pyx_L3:;

  /* "pygpu/gpuarray.pyx":2457
 *                 raise TypeError, "ls is not int or list"
 * 
 *         if py_gs is None:             # <<<<<<<<<<<<<<
 *             if nd != 1:
 *                 raise ValueError, "nd mismatch for gs (None)"
 */
  __pyx_t_2 = (__pyx_v_py_gs == Py_None);
  __pyx_t_1 = (__pyx_t_2 != 0);
  if (__pyx_t_1) {

    /* "pygpu/gpuarray.pyx":2458
 * 
 *         if py_gs is None:
 *             if nd != 1:             # <<<<<<<<<<<<<<
 *                 raise ValueError, "nd mismatch for gs (None)"
 *             gs[0] = 0
 */
    __pyx_t_1 = ((__pyx_v_nd != 1) != 0);
    if (__pyx_t_1) {

      /* "pygpu/gpuarray.pyx":2459
 *         if py_gs is None:
 *             if nd != 1:
 *                 raise ValueError, "nd mismatch for gs (None)"             # <<<<<<<<<<<<<<
 *             gs[0] = 0
 *         else:
 */
      __Pyx_Raise(__pyx_builtin_ValueError, __pyx_kp_s_nd_mismatch_for_gs_None, 0, 0);
      __PYX_ERR(0, 2459, __pyx_L1_error)

      /* "pygpu/gpuarray.pyx":2458
 * 
 *         if py_gs is None:
 *             if nd != 1:             # <<<<<<<<<<<<<<
 *                 raise ValueError, "nd mismatch for gs (None)"
 *             gs[0] = 0
 */
    }

    /* "pygpu/gpuarray.pyx":2460
 *             if nd != 1:
 *                 raise ValueError, "nd mismatch for gs (None)"
 *             gs[0] = 0             # <<<<<<<<<<<<<<
 *         else:
 *             if isinstance(py_gs, int):
 */
    (__pyx_v_gs[0]) = 0;

    /* "pygpu/gpuarray.pyx":2457
 *                 raise TypeError, "ls is not int or list"
 * 
 *         if py_gs is None:             # <<<<<<<<<<<<<<
 *             if nd != 1:
 *                 raise ValueError, "nd mismatch for gs (None)"
 */
    goto __pyx_L11;
  }

  /* "pygpu/gpuarray.pyx":2462
 *             gs[0] = 0
 *         else:
 *             if isinstance(py_gs, int):             # <<<<<<<<<<<<<<
 *                 if nd != 1:
 *                     raise ValueError, "nd mismatch for gs (int)"
 */
  /*else*/ {
    __pyx_t_1 = PyInt_Check(__pyx_v_py_gs); 
    __pyx_t_2 = (__pyx_t_1 != 0);
    if (__pyx_t_2) {

      /* "pygpu/gpuarray.pyx":2463
 *         else:
 *             if isinstance(py_gs, int):
 *                 if nd != 1:             # <<<<<<<<<<<<<<
 *                     raise ValueError, "nd mismatch for gs (int)"
 *                 gs[0] = py_gs
 */
      __pyx_t_2 = ((__pyx_v_nd != 1) != 0);
      if (__pyx_t_2) {

        /* "pygpu/gpuarray.pyx":2464
 *             if isinstance(py_gs, int):
 *                 if nd != 1:
 *                     raise ValueError, "nd mismatch for gs (int)"             # <<<<<<<<<<<<<<
 *                 gs[0] = py_gs
 *             elif isinstance(py_gs, (list, tuple)):
 */
        __Pyx_Raise(__pyx_builtin_ValueError, __pyx_kp_s_nd_mismatch_for_gs_int, 0, 0);
        __PYX_ERR(0, 2464, __pyx_L1_error)

        /* "pygpu/gpuarray.pyx":2463
 *         else:
 *             if isinstance(py_gs, int):
 *                 if nd != 1:             # <<<<<<<<<<<<<<
 *                     raise ValueError, "nd mismatch for gs (int)"
 *                 gs[0] = py_gs
 */
      }

      /* "pygpu/gpuarray.pyx":2465
 *                 if nd != 1:
 *                     raise ValueError, "nd mismatch for gs (int)"
 *                 gs[0] = py_gs             # <<<<<<<<<<<<<<
 *             elif isinstance(py_gs, (list, tuple)):
 *                 if len(py_gs) > 3:
 */
      __pyx_t_3 = __Pyx_PyInt_As_size_t(__pyx_v_py_gs); if (unlikely((__pyx_t_3 == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 2465, __pyx_L1_error)
      (__pyx_v_gs[0]) = __pyx_t_3;

      /* "pygpu/gpuarray.pyx":2462
 *             gs[0] = 0
 *         else:
 *             if isinstance(py_gs, int):             # <<<<<<<<<<<<<<
 *                 if nd != 1:
 *                     raise ValueError, "nd mismatch for gs (int)"
 */
      goto __pyx_L13;
    }

    /* "pygpu/gpuarray.pyx":2466
 *                     raise ValueError, "nd mismatch for gs (int)"
 *                 gs[0] = py_gs
 *             elif isinstance(py_gs, (list, tuple)):             # <<<<<<<<<<<<<<
 *                 if len(py_gs) > 3:
 *                     raise ValueError, "gs is not of length 3 or less"
 */
    __pyx_t_1 = PyList_Check(__pyx_v_py_gs); 
    __pyx_t_4 = (__pyx_t_1 != 0);
    if (!__pyx_t_4) {
    } else {
      __pyx_t_2 = __pyx_t_4;
      goto __pyx_L15_bool_binop_done;
    }
    __pyx_t_4 = PyTuple_Check(__pyx_v_py_gs); 
    __pyx_t_1 = (__pyx_t_4 != 0);
    __pyx_t_2 = __pyx_t_1;
    __pyx_L15_bool_binop_done:;
    __pyx_t_1 = (__pyx_t_2 != 0);
    if (__pyx_t_1) {

      /* "pygpu/gpuarray.pyx":2467
 *                 gs[0] = py_gs
 *             elif isinstance(py_gs, (list, tuple)):
 *                 if len(py_gs) > 3:             # <<<<<<<<<<<<<<
 *                     raise ValueError, "gs is not of length 3 or less"
 *                 if len(py_ls) != nd:
 */
      __pyx_t_5 = PyObject_Length(__pyx_v_py_gs); if (unlikely(__pyx_t_5 == ((Py_ssize_t)-1))) __PYX_ERR(0, 2467, __pyx_L1_error)
      __pyx_t_1 = ((__pyx_t_5 > 3) != 0);
      if (__pyx_t_1) {

        /* "pygpu/gpuarray.pyx":2468
 *             elif isinstance(py_gs, (list, tuple)):
 *                 if len(py_gs) > 3:
 *                     raise ValueError, "gs is not of length 3 or less"             # <<<<<<<<<<<<<<
 *                 if len(py_ls) != nd:
 *                     raise ValueError, "nd mismatch for gs (tuple)"
 */
        __Pyx_Raise(__pyx_builtin_ValueError, __pyx_kp_s_gs_is_not_of_length_3_or_less, 0, 0);
        __PYX_ERR(0, 2468, __pyx_L1_error)

        /* "pygpu/gpuarray.pyx":2467
 *                 gs[0] = py_gs
 *             elif isinstance(py_gs, (list, tuple)):
 *                 if len(py_gs) > 3:             # <<<<<<<<<<<<<<
 *                     raise ValueError, "gs is not of length 3 or less"
 *                 if len(py_ls) != nd:
 */
      }

      /* "pygpu/gpuarray.pyx":2469
 *                 if len(py_gs) > 3:
 *                     raise ValueError, "gs is not of length 3 or less"
 *                 if len(py_ls) != nd:             # <<<<<<<<<<<<<<
 *                     raise ValueError, "nd mismatch for gs (tuple)"
 * 
 */
      __pyx_t_5 = PyObject_Length(__pyx_v_py_ls); if (unlikely(__pyx_t_5 == ((Py_ssize_t)-1))) __PYX_ERR(0, 2469, __pyx_L1_error)
      __pyx_t_1 = ((__pyx_t_5 != __pyx_v_nd) != 0);
      if (__pyx_t_1) {

        /* "pygpu/gpuarray.pyx":2470
 *                     raise ValueError, "gs is not of length 3 or less"
 *                 if len(py_ls) != nd:
 *                     raise ValueError, "nd mismatch for gs (tuple)"             # <<<<<<<<<<<<<<
 * 
 *                 if nd >= 3:
 */
        __Pyx_Raise(__pyx_builtin_ValueError, __pyx_kp_s_nd_mismatch_for_gs_tuple, 0, 0);
        __PYX_ERR(0, 2470, __pyx_L1_error)

        /* "pygpu/gpuarray.pyx":2469
 *                 if len(py_gs) > 3:
 *                     raise ValueError, "gs is not of length 3 or less"
 *                 if len(py_ls) != nd:             # <<<<<<<<<<<<<<
 *                     raise ValueError, "nd mismatch for gs (tuple)"
 * 
 */
      }

      /* "pygpu/gpuarray.pyx":2472
 *                     raise ValueError, "nd mismatch for gs (tuple)"
 * 
 *                 if nd >= 3:             # <<<<<<<<<<<<<<
 *                     gs[2] = py_gs[2]
 *                 if nd >= 2:
 */
      __pyx_t_1 = ((__pyx_v_nd >= 3) != 0);
      if (__pyx_t_1) {

        /* "pygpu/gpuarray.pyx":2473
 * 
 *                 if nd >= 3:
 *                     gs[2] = py_gs[2]             # <<<<<<<<<<<<<<
 *                 if nd >= 2:
 *                     gs[1] = py_gs[1]
 */
        __pyx_t_6 = __Pyx_GetItemInt(__pyx_v_py_gs, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 2473, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_6);
        __pyx_t_3 = __Pyx_PyInt_As_size_t(__pyx_t_6); if (unlikely((__pyx_t_3 == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 2473, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
        (__pyx_v_gs[2]) = __pyx_t_3;

        /* "pygpu/gpuarray.pyx":2472
 *                     raise ValueError, "nd mismatch for gs (tuple)"
 * 
 *                 if nd >= 3:             # <<<<<<<<<<<<<<
 *                     gs[2] = py_gs[2]
 *                 if nd >= 2:
 */
      }

      /* "pygpu/gpuarray.pyx":2474
 *                 if nd >= 3:
 *                     gs[2] = py_gs[2]
 *                 if nd >= 2:             # <<<<<<<<<<<<<<
 *                     gs[1] = py_gs[1]
 *                 if nd >= 1:
 */
      __pyx_t_1 = ((__pyx_v_nd >= 2) != 0);
      if (__pyx_t_1) {

        /* "pygpu/gpuarray.pyx":2475
 *                     gs[2] = py_gs[2]
 *                 if nd >= 2:
 *                     gs[1] = py_gs[1]             # <<<<<<<<<<<<<<
 *                 if nd >= 1:
 *                     gs[0] = py_gs[0]
 */
        __pyx_t_6 = __Pyx_GetItemInt(__pyx_v_py_gs, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 2475, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_6);
        __pyx_t_3 = __Pyx_PyInt_As_size_t(__pyx_t_6); if (unlikely((__pyx_t_3 == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 2475, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
        (__pyx_v_gs[1]) = __pyx_t_3;

        /* "pygpu/gpuarray.pyx":2474
 *                 if nd >= 3:
 *                     gs[2] = py_gs[2]
 *                 if nd >= 2:             # <<<<<<<<<<<<<<
 *                     gs[1] = py_gs[1]
 *                 if nd >= 1:
 */
      }

      /* "pygpu/gpuarray.pyx":2476
 *                 if nd >= 2:
 *                     gs[1] = py_gs[1]
 *                 if nd >= 1:             # <<<<<<<<<<<<<<
 *                     gs[0] = py_gs[0]
 *             else:
 */
      __pyx_t_1 = ((__pyx_v_nd >= 1) != 0);
      if (__pyx_t_1) {

        /* "pygpu/gpuarray.pyx":2477
 *                     gs[1] = py_gs[1]
 *                 if nd >= 1:
 *                     gs[0] = py_gs[0]             # <<<<<<<<<<<<<<
 *             else:
 *                 raise TypeError, "gs is not int or list"
 */
        __pyx_t_6 = __Pyx_GetItemInt(__pyx_v_py_gs, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 2477, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_6);
        __pyx_t_3 = __Pyx_PyInt_As_size_t(__pyx_t_6); if (unlikely((__pyx_t_3 == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 2477, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
        (__pyx_v_gs[0]) = __pyx_t_3;

        /* "pygpu/gpuarray.pyx":2476
 *                 if nd >= 2:
 *                     gs[1] = py_gs[1]
 *                 if nd >= 1:             # <<<<<<<<<<<<<<
 *                     gs[0] = py_gs[0]
 *             else:
 */
      }

      /* "pygpu/gpuarray.pyx":2466
 *                     raise ValueError, "nd mismatch for gs (int)"
 *                 gs[0] = py_gs
 *             elif isinstance(py_gs, (list, tuple)):             # <<<<<<<<<<<<<<
 *                 if len(py_gs) > 3:
 *                     raise ValueError, "gs is not of length 3 or less"
 */
      goto __pyx_L13;
    }

    /* "pygpu/gpuarray.pyx":2479
 *                     gs[0] = py_gs[0]
 *             else:
 *                 raise TypeError, "gs is not int or list"             # <<<<<<<<<<<<<<
 * 
 *         numargs = self.numargs
 */
    /*else*/ {
      __Pyx_Raise(__pyx_builtin_TypeError, __pyx_kp_s_gs_is_not_int_or_list, 0, 0);
      __PYX_ERR(0, 2479, __pyx_L1_error)
    }
    __pyx_L13:;
  }
  __pyx_L11:;

  /* "pygpu/gpuarray.pyx":2481
 *                 raise TypeError, "gs is not int or list"
 * 
 *         numargs = self.numargs             # <<<<<<<<<<<<<<
 *         if len(py_args) != numargs:
 *             raise TypeError, "Expected %d arguments, got %d," % (numargs, len(py_args))
 */
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_numargs); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 2481, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __pyx_t_7 = __Pyx_PyInt_As_unsigned_int(__pyx_t_6); if (unlikely((__pyx_t_7 == (unsigned int)-1) && PyErr_Occurred())) __PYX_ERR(0, 2481, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_v_numargs = __pyx_t_7;

  /* "pygpu/gpuarray.pyx":2482
 * 
 *         numargs = self.numargs
 *         if len(py_args) != numargs:             # <<<<<<<<<<<<<<
 *             raise TypeError, "Expected %d arguments, got %d," % (numargs, len(py_args))
 *         kernel_property(self, GA_KERNEL_PROP_TYPES, &types)
 */
  __pyx_t_5 = PyObject_Length(__pyx_v_py_args); if (unlikely(__pyx_t_5 == ((Py_ssize_t)-1))) __PYX_ERR(0, 2482, __pyx_L1_error)
  __pyx_t_1 = ((__pyx_t_5 != __pyx_v_numargs) != 0);
  if (__pyx_t_1) {

    /* "pygpu/gpuarray.pyx":2483
 *         numargs = self.numargs
 *         if len(py_args) != numargs:
 *             raise TypeError, "Expected %d arguments, got %d," % (numargs, len(py_args))             # <<<<<<<<<<<<<<
 *         kernel_property(self, GA_KERNEL_PROP_TYPES, &types)
 *         for i in range(numargs):
 */
    __pyx_t_6 = __Pyx_PyInt_From_unsigned_int(__pyx_v_numargs); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 2483, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_5 = PyObject_Length(__pyx_v_py_args); if (unlikely(__pyx_t_5 == ((Py_ssize_t)-1))) __PYX_ERR(0, 2483, __pyx_L1_error)
    __pyx_t_8 = PyInt_FromSsize_t(__pyx_t_5); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 2483, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __pyx_t_9 = PyTuple_New(2); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 2483, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_9);
    __Pyx_GIVEREF(__pyx_t_6);
    PyTuple_SET_ITEM(__pyx_t_9, 0, __pyx_t_6);
    __Pyx_GIVEREF(__pyx_t_8);
    PyTuple_SET_ITEM(__pyx_t_9, 1, __pyx_t_8);
    __pyx_t_6 = 0;
    __pyx_t_8 = 0;
    __pyx_t_8 = __Pyx_PyString_Format(__pyx_kp_s_Expected_d_arguments_got_d, __pyx_t_9); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 2483, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
    __Pyx_Raise(__pyx_builtin_TypeError, __pyx_t_8, 0, 0);
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __PYX_ERR(0, 2483, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":2482
 * 
 *         numargs = self.numargs
 *         if len(py_args) != numargs:             # <<<<<<<<<<<<<<
 *             raise TypeError, "Expected %d arguments, got %d," % (numargs, len(py_args))
 *         kernel_property(self, GA_KERNEL_PROP_TYPES, &types)
 */
  }

  /* "pygpu/gpuarray.pyx":2484
 *         if len(py_args) != numargs:
 *             raise TypeError, "Expected %d arguments, got %d," % (numargs, len(py_args))
 *         kernel_property(self, GA_KERNEL_PROP_TYPES, &types)             # <<<<<<<<<<<<<<
 *         for i in range(numargs):
 *             self._setarg(i, types[i], py_args[i])
 */
  __pyx_t_10 = __pyx_f_5pygpu_8gpuarray_kernel_property(__pyx_v_self, GA_KERNEL_PROP_TYPES, (&__pyx_v_types)); if (unlikely(__pyx_t_10 == ((int)-1))) __PYX_ERR(0, 2484, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":2485
 *             raise TypeError, "Expected %d arguments, got %d," % (numargs, len(py_args))
 *         kernel_property(self, GA_KERNEL_PROP_TYPES, &types)
 *         for i in range(numargs):             # <<<<<<<<<<<<<<
 *             self._setarg(i, types[i], py_args[i])
 *         if py_n is not None:
 */
  __pyx_t_7 = __pyx_v_numargs;
  for (__pyx_t_11 = 0; __pyx_t_11 < __pyx_t_7; __pyx_t_11+=1) {
    __pyx_v_i = __pyx_t_11;

    /* "pygpu/gpuarray.pyx":2486
 *         kernel_property(self, GA_KERNEL_PROP_TYPES, &types)
 *         for i in range(numargs):
 *             self._setarg(i, types[i], py_args[i])             # <<<<<<<<<<<<<<
 *         if py_n is not None:
 *             if nd != 1:
 */
    __pyx_t_8 = __Pyx_GetItemInt(__pyx_v_py_args, __pyx_v_i, unsigned int, 0, __Pyx_PyInt_From_unsigned_int, 0, 0, 1); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 2486, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __pyx_t_9 = ((struct __pyx_vtabstruct_5pygpu_8gpuarray_GpuKernel *)__pyx_v_self->__pyx_vtab)->_setarg(__pyx_v_self, __pyx_v_i, (__pyx_v_types[__pyx_v_i]), __pyx_t_8); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 2486, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_9);
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
  }

  /* "pygpu/gpuarray.pyx":2487
 *         for i in range(numargs):
 *             self._setarg(i, types[i], py_args[i])
 *         if py_n is not None:             # <<<<<<<<<<<<<<
 *             if nd != 1:
 *                 raise ValueError, "n is specified and nd != 1"
 */
  __pyx_t_1 = (__pyx_v_py_n != Py_None);
  __pyx_t_2 = (__pyx_t_1 != 0);
  if (__pyx_t_2) {

    /* "pygpu/gpuarray.pyx":2488
 *             self._setarg(i, types[i], py_args[i])
 *         if py_n is not None:
 *             if nd != 1:             # <<<<<<<<<<<<<<
 *                 raise ValueError, "n is specified and nd != 1"
 *             n = py_n
 */
    __pyx_t_2 = ((__pyx_v_nd != 1) != 0);
    if (__pyx_t_2) {

      /* "pygpu/gpuarray.pyx":2489
 *         if py_n is not None:
 *             if nd != 1:
 *                 raise ValueError, "n is specified and nd != 1"             # <<<<<<<<<<<<<<
 *             n = py_n
 *             kernel_sched(self, n, &gs[0], &ls[0])
 */
      __Pyx_Raise(__pyx_builtin_ValueError, __pyx_kp_s_n_is_specified_and_nd_1, 0, 0);
      __PYX_ERR(0, 2489, __pyx_L1_error)

      /* "pygpu/gpuarray.pyx":2488
 *             self._setarg(i, types[i], py_args[i])
 *         if py_n is not None:
 *             if nd != 1:             # <<<<<<<<<<<<<<
 *                 raise ValueError, "n is specified and nd != 1"
 *             n = py_n
 */
    }

    /* "pygpu/gpuarray.pyx":2490
 *             if nd != 1:
 *                 raise ValueError, "n is specified and nd != 1"
 *             n = py_n             # <<<<<<<<<<<<<<
 *             kernel_sched(self, n, &gs[0], &ls[0])
 *         kernel_call(self, nd, gs, ls, shared, self.callbuf)
 */
    __pyx_t_3 = __Pyx_PyInt_As_size_t(__pyx_v_py_n); if (unlikely((__pyx_t_3 == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 2490, __pyx_L1_error)
    __pyx_v_n = __pyx_t_3;

    /* "pygpu/gpuarray.pyx":2491
 *                 raise ValueError, "n is specified and nd != 1"
 *             n = py_n
 *             kernel_sched(self, n, &gs[0], &ls[0])             # <<<<<<<<<<<<<<
 *         kernel_call(self, nd, gs, ls, shared, self.callbuf)
 * 
 */
    __pyx_t_10 = __pyx_f_5pygpu_8gpuarray_kernel_sched(__pyx_v_self, __pyx_v_n, (&(__pyx_v_gs[0])), (&(__pyx_v_ls[0]))); if (unlikely(__pyx_t_10 == ((int)-1))) __PYX_ERR(0, 2491, __pyx_L1_error)

    /* "pygpu/gpuarray.pyx":2487
 *         for i in range(numargs):
 *             self._setarg(i, types[i], py_args[i])
 *         if py_n is not None:             # <<<<<<<<<<<<<<
 *             if nd != 1:
 *                 raise ValueError, "n is specified and nd != 1"
 */
  }

  /* "pygpu/gpuarray.pyx":2492
 *             n = py_n
 *             kernel_sched(self, n, &gs[0], &ls[0])
 *         kernel_call(self, nd, gs, ls, shared, self.callbuf)             # <<<<<<<<<<<<<<
 * 
 *     cdef _setarg(self, unsigned int index, int typecode, object o):
 */
  __pyx_t_10 = __pyx_f_5pygpu_8gpuarray_kernel_call(__pyx_v_self, __pyx_v_nd, __pyx_v_gs, __pyx_v_ls, __pyx_v_shared, __pyx_v_self->callbuf); if (unlikely(__pyx_t_10 == ((int)-1))) __PYX_ERR(0, 2492, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":2424
 *         self.do_call(n, gs, ls, args, shared)
 * 
 *     cdef do_call(self, py_n, py_gs, py_ls, py_args, size_t shared):             # <<<<<<<<<<<<<<
 *         cdef size_t n
 *         cdef size_t gs[3]
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_XDECREF(__pyx_t_9);
  __Pyx_AddTraceback("pygpu.gpuarray.GpuKernel.do_call", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":2494
 *         kernel_call(self, nd, gs, ls, shared, self.callbuf)
 * 
 *     cdef _setarg(self, unsigned int index, int typecode, object o):             # <<<<<<<<<<<<<<
 *         if typecode == GA_BUFFER:
 *             if not isinstance(o, GpuArray):
 */

static PyObject *__pyx_f_5pygpu_8gpuarray_9GpuKernel__setarg(struct PyGpuKernelObject *__pyx_v_self, unsigned int __pyx_v_index, int __pyx_v_typecode, PyObject *__pyx_v_o) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_t_2;
  size_t __pyx_t_3;
  Py_ssize_t __pyx_t_4;
  float __pyx_t_5;
  double __pyx_t_6;
  signed char __pyx_t_7;
  unsigned char __pyx_t_8;
  short __pyx_t_9;
  unsigned short __pyx_t_10;
  int __pyx_t_11;
  unsigned int __pyx_t_12;
  long __pyx_t_13;
  unsigned long __pyx_t_14;
  PyObject *__pyx_t_15 = NULL;
  PyObject *__pyx_t_16 = NULL;
  __Pyx_RefNannySetupContext("_setarg", 0);

  /* "pygpu/gpuarray.pyx":2495
 * 
 *     cdef _setarg(self, unsigned int index, int typecode, object o):
 *         if typecode == GA_BUFFER:             # <<<<<<<<<<<<<<
 *             if not isinstance(o, GpuArray):
 *                 raise TypeError, "expected a GpuArray"
 */
  switch (__pyx_v_typecode) {
    case GA_BUFFER:

    /* "pygpu/gpuarray.pyx":2496
 *     cdef _setarg(self, unsigned int index, int typecode, object o):
 *         if typecode == GA_BUFFER:
 *             if not isinstance(o, GpuArray):             # <<<<<<<<<<<<<<
 *                 raise TypeError, "expected a GpuArray"
 *             self.callbuf[index] = <void *>((<GpuArray>o).ga.data)
 */
    __pyx_t_1 = __Pyx_TypeCheck(__pyx_v_o, __pyx_ptype_5pygpu_8gpuarray_GpuArray); 
    __pyx_t_2 = ((!(__pyx_t_1 != 0)) != 0);
    if (__pyx_t_2) {

      /* "pygpu/gpuarray.pyx":2497
 *         if typecode == GA_BUFFER:
 *             if not isinstance(o, GpuArray):
 *                 raise TypeError, "expected a GpuArray"             # <<<<<<<<<<<<<<
 *             self.callbuf[index] = <void *>((<GpuArray>o).ga.data)
 *         elif typecode == GA_SIZE:
 */
      __Pyx_Raise(__pyx_builtin_TypeError, __pyx_kp_s_expected_a_GpuArray, 0, 0);
      __PYX_ERR(0, 2497, __pyx_L1_error)

      /* "pygpu/gpuarray.pyx":2496
 *     cdef _setarg(self, unsigned int index, int typecode, object o):
 *         if typecode == GA_BUFFER:
 *             if not isinstance(o, GpuArray):             # <<<<<<<<<<<<<<
 *                 raise TypeError, "expected a GpuArray"
 *             self.callbuf[index] = <void *>((<GpuArray>o).ga.data)
 */
    }

    /* "pygpu/gpuarray.pyx":2498
 *             if not isinstance(o, GpuArray):
 *                 raise TypeError, "expected a GpuArray"
 *             self.callbuf[index] = <void *>((<GpuArray>o).ga.data)             # <<<<<<<<<<<<<<
 *         elif typecode == GA_SIZE:
 *             (<size_t *>self.callbuf[index])[0] = o
 */
    (__pyx_v_self->callbuf[__pyx_v_index]) = ((void *)((struct PyGpuArrayObject *)__pyx_v_o)->ga.data);

    /* "pygpu/gpuarray.pyx":2495
 * 
 *     cdef _setarg(self, unsigned int index, int typecode, object o):
 *         if typecode == GA_BUFFER:             # <<<<<<<<<<<<<<
 *             if not isinstance(o, GpuArray):
 *                 raise TypeError, "expected a GpuArray"
 */
    break;

    /* "pygpu/gpuarray.pyx":2499
 *                 raise TypeError, "expected a GpuArray"
 *             self.callbuf[index] = <void *>((<GpuArray>o).ga.data)
 *         elif typecode == GA_SIZE:             # <<<<<<<<<<<<<<
 *             (<size_t *>self.callbuf[index])[0] = o
 *         elif typecode == GA_SSIZE:
 */
    case GA_SIZE:

    /* "pygpu/gpuarray.pyx":2500
 *             self.callbuf[index] = <void *>((<GpuArray>o).ga.data)
 *         elif typecode == GA_SIZE:
 *             (<size_t *>self.callbuf[index])[0] = o             # <<<<<<<<<<<<<<
 *         elif typecode == GA_SSIZE:
 *             (<ssize_t *>self.callbuf[index])[0] = o
 */
    __pyx_t_3 = __Pyx_PyInt_As_size_t(__pyx_v_o); if (unlikely((__pyx_t_3 == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 2500, __pyx_L1_error)
    (((size_t *)(__pyx_v_self->callbuf[__pyx_v_index]))[0]) = __pyx_t_3;

    /* "pygpu/gpuarray.pyx":2499
 *                 raise TypeError, "expected a GpuArray"
 *             self.callbuf[index] = <void *>((<GpuArray>o).ga.data)
 *         elif typecode == GA_SIZE:             # <<<<<<<<<<<<<<
 *             (<size_t *>self.callbuf[index])[0] = o
 *         elif typecode == GA_SSIZE:
 */
    break;

    /* "pygpu/gpuarray.pyx":2501
 *         elif typecode == GA_SIZE:
 *             (<size_t *>self.callbuf[index])[0] = o
 *         elif typecode == GA_SSIZE:             # <<<<<<<<<<<<<<
 *             (<ssize_t *>self.callbuf[index])[0] = o
 *         elif typecode == GA_FLOAT:
 */
    case GA_SSIZE:

    /* "pygpu/gpuarray.pyx":2502
 *             (<size_t *>self.callbuf[index])[0] = o
 *         elif typecode == GA_SSIZE:
 *             (<ssize_t *>self.callbuf[index])[0] = o             # <<<<<<<<<<<<<<
 *         elif typecode == GA_FLOAT:
 *             (<float *>self.callbuf[index])[0] = o
 */
    __pyx_t_4 = PyInt_AsSsize_t(__pyx_v_o); if (unlikely((__pyx_t_4 == (Py_ssize_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 2502, __pyx_L1_error)
    (((Py_ssize_t *)(__pyx_v_self->callbuf[__pyx_v_index]))[0]) = __pyx_t_4;

    /* "pygpu/gpuarray.pyx":2501
 *         elif typecode == GA_SIZE:
 *             (<size_t *>self.callbuf[index])[0] = o
 *         elif typecode == GA_SSIZE:             # <<<<<<<<<<<<<<
 *             (<ssize_t *>self.callbuf[index])[0] = o
 *         elif typecode == GA_FLOAT:
 */
    break;

    /* "pygpu/gpuarray.pyx":2503
 *         elif typecode == GA_SSIZE:
 *             (<ssize_t *>self.callbuf[index])[0] = o
 *         elif typecode == GA_FLOAT:             # <<<<<<<<<<<<<<
 *             (<float *>self.callbuf[index])[0] = o
 *         elif typecode == GA_DOUBLE:
 */
    case GA_FLOAT:

    /* "pygpu/gpuarray.pyx":2504
 *             (<ssize_t *>self.callbuf[index])[0] = o
 *         elif typecode == GA_FLOAT:
 *             (<float *>self.callbuf[index])[0] = o             # <<<<<<<<<<<<<<
 *         elif typecode == GA_DOUBLE:
 *             (<double *>self.callbuf[index])[0] = o
 */
    __pyx_t_5 = __pyx_PyFloat_AsFloat(__pyx_v_o); if (unlikely((__pyx_t_5 == (float)-1) && PyErr_Occurred())) __PYX_ERR(0, 2504, __pyx_L1_error)
    (((float *)(__pyx_v_self->callbuf[__pyx_v_index]))[0]) = __pyx_t_5;

    /* "pygpu/gpuarray.pyx":2503
 *         elif typecode == GA_SSIZE:
 *             (<ssize_t *>self.callbuf[index])[0] = o
 *         elif typecode == GA_FLOAT:             # <<<<<<<<<<<<<<
 *             (<float *>self.callbuf[index])[0] = o
 *         elif typecode == GA_DOUBLE:
 */
    break;

    /* "pygpu/gpuarray.pyx":2505
 *         elif typecode == GA_FLOAT:
 *             (<float *>self.callbuf[index])[0] = o
 *         elif typecode == GA_DOUBLE:             # <<<<<<<<<<<<<<
 *             (<double *>self.callbuf[index])[0] = o
 *         elif typecode == GA_BYTE:
 */
    case GA_DOUBLE:

    /* "pygpu/gpuarray.pyx":2506
 *             (<float *>self.callbuf[index])[0] = o
 *         elif typecode == GA_DOUBLE:
 *             (<double *>self.callbuf[index])[0] = o             # <<<<<<<<<<<<<<
 *         elif typecode == GA_BYTE:
 *             (<signed char *>self.callbuf[index])[0] = o
 */
    __pyx_t_6 = __pyx_PyFloat_AsDouble(__pyx_v_o); if (unlikely((__pyx_t_6 == (double)-1) && PyErr_Occurred())) __PYX_ERR(0, 2506, __pyx_L1_error)
    (((double *)(__pyx_v_self->callbuf[__pyx_v_index]))[0]) = __pyx_t_6;

    /* "pygpu/gpuarray.pyx":2505
 *         elif typecode == GA_FLOAT:
 *             (<float *>self.callbuf[index])[0] = o
 *         elif typecode == GA_DOUBLE:             # <<<<<<<<<<<<<<
 *             (<double *>self.callbuf[index])[0] = o
 *         elif typecode == GA_BYTE:
 */
    break;

    /* "pygpu/gpuarray.pyx":2507
 *         elif typecode == GA_DOUBLE:
 *             (<double *>self.callbuf[index])[0] = o
 *         elif typecode == GA_BYTE:             # <<<<<<<<<<<<<<
 *             (<signed char *>self.callbuf[index])[0] = o
 *         elif typecode == GA_UBYTE:
 */
    case GA_BYTE:

    /* "pygpu/gpuarray.pyx":2508
 *             (<double *>self.callbuf[index])[0] = o
 *         elif typecode == GA_BYTE:
 *             (<signed char *>self.callbuf[index])[0] = o             # <<<<<<<<<<<<<<
 *         elif typecode == GA_UBYTE:
 *             (<unsigned char *>self.callbuf[index])[0] = o
 */
    __pyx_t_7 = __Pyx_PyInt_As_signed__char(__pyx_v_o); if (unlikely((__pyx_t_7 == (signed char)-1) && PyErr_Occurred())) __PYX_ERR(0, 2508, __pyx_L1_error)
    (((signed char *)(__pyx_v_self->callbuf[__pyx_v_index]))[0]) = __pyx_t_7;

    /* "pygpu/gpuarray.pyx":2507
 *         elif typecode == GA_DOUBLE:
 *             (<double *>self.callbuf[index])[0] = o
 *         elif typecode == GA_BYTE:             # <<<<<<<<<<<<<<
 *             (<signed char *>self.callbuf[index])[0] = o
 *         elif typecode == GA_UBYTE:
 */
    break;

    /* "pygpu/gpuarray.pyx":2509
 *         elif typecode == GA_BYTE:
 *             (<signed char *>self.callbuf[index])[0] = o
 *         elif typecode == GA_UBYTE:             # <<<<<<<<<<<<<<
 *             (<unsigned char *>self.callbuf[index])[0] = o
 *         elif typecode == GA_SHORT:
 */
    case GA_UBYTE:

    /* "pygpu/gpuarray.pyx":2510
 *             (<signed char *>self.callbuf[index])[0] = o
 *         elif typecode == GA_UBYTE:
 *             (<unsigned char *>self.callbuf[index])[0] = o             # <<<<<<<<<<<<<<
 *         elif typecode == GA_SHORT:
 *             (<short *>self.callbuf[index])[0] = o
 */
    __pyx_t_8 = __Pyx_PyInt_As_unsigned_char(__pyx_v_o); if (unlikely((__pyx_t_8 == (unsigned char)-1) && PyErr_Occurred())) __PYX_ERR(0, 2510, __pyx_L1_error)
    (((unsigned char *)(__pyx_v_self->callbuf[__pyx_v_index]))[0]) = __pyx_t_8;

    /* "pygpu/gpuarray.pyx":2509
 *         elif typecode == GA_BYTE:
 *             (<signed char *>self.callbuf[index])[0] = o
 *         elif typecode == GA_UBYTE:             # <<<<<<<<<<<<<<
 *             (<unsigned char *>self.callbuf[index])[0] = o
 *         elif typecode == GA_SHORT:
 */
    break;

    /* "pygpu/gpuarray.pyx":2511
 *         elif typecode == GA_UBYTE:
 *             (<unsigned char *>self.callbuf[index])[0] = o
 *         elif typecode == GA_SHORT:             # <<<<<<<<<<<<<<
 *             (<short *>self.callbuf[index])[0] = o
 *         elif typecode == GA_USHORT:
 */
    case GA_SHORT:

    /* "pygpu/gpuarray.pyx":2512
 *             (<unsigned char *>self.callbuf[index])[0] = o
 *         elif typecode == GA_SHORT:
 *             (<short *>self.callbuf[index])[0] = o             # <<<<<<<<<<<<<<
 *         elif typecode == GA_USHORT:
 *             (<unsigned short *>self.callbuf[index])[0] = o
 */
    __pyx_t_9 = __Pyx_PyInt_As_short(__pyx_v_o); if (unlikely((__pyx_t_9 == (short)-1) && PyErr_Occurred())) __PYX_ERR(0, 2512, __pyx_L1_error)
    (((short *)(__pyx_v_self->callbuf[__pyx_v_index]))[0]) = __pyx_t_9;

    /* "pygpu/gpuarray.pyx":2511
 *         elif typecode == GA_UBYTE:
 *             (<unsigned char *>self.callbuf[index])[0] = o
 *         elif typecode == GA_SHORT:             # <<<<<<<<<<<<<<
 *             (<short *>self.callbuf[index])[0] = o
 *         elif typecode == GA_USHORT:
 */
    break;

    /* "pygpu/gpuarray.pyx":2513
 *         elif typecode == GA_SHORT:
 *             (<short *>self.callbuf[index])[0] = o
 *         elif typecode == GA_USHORT:             # <<<<<<<<<<<<<<
 *             (<unsigned short *>self.callbuf[index])[0] = o
 *         elif typecode == GA_INT:
 */
    case GA_USHORT:

    /* "pygpu/gpuarray.pyx":2514
 *             (<short *>self.callbuf[index])[0] = o
 *         elif typecode == GA_USHORT:
 *             (<unsigned short *>self.callbuf[index])[0] = o             # <<<<<<<<<<<<<<
 *         elif typecode == GA_INT:
 *             (<int *>self.callbuf[index])[0] = o
 */
    __pyx_t_10 = __Pyx_PyInt_As_unsigned_short(__pyx_v_o); if (unlikely((__pyx_t_10 == (unsigned short)-1) && PyErr_Occurred())) __PYX_ERR(0, 2514, __pyx_L1_error)
    (((unsigned short *)(__pyx_v_self->callbuf[__pyx_v_index]))[0]) = __pyx_t_10;

    /* "pygpu/gpuarray.pyx":2513
 *         elif typecode == GA_SHORT:
 *             (<short *>self.callbuf[index])[0] = o
 *         elif typecode == GA_USHORT:             # <<<<<<<<<<<<<<
 *             (<unsigned short *>self.callbuf[index])[0] = o
 *         elif typecode == GA_INT:
 */
    break;

    /* "pygpu/gpuarray.pyx":2515
 *         elif typecode == GA_USHORT:
 *             (<unsigned short *>self.callbuf[index])[0] = o
 *         elif typecode == GA_INT:             # <<<<<<<<<<<<<<
 *             (<int *>self.callbuf[index])[0] = o
 *         elif typecode == GA_UINT:
 */
    case GA_INT:

    /* "pygpu/gpuarray.pyx":2516
 *             (<unsigned short *>self.callbuf[index])[0] = o
 *         elif typecode == GA_INT:
 *             (<int *>self.callbuf[index])[0] = o             # <<<<<<<<<<<<<<
 *         elif typecode == GA_UINT:
 *             (<unsigned int *>self.callbuf[index])[0] = o
 */
    __pyx_t_11 = __Pyx_PyInt_As_int(__pyx_v_o); if (unlikely((__pyx_t_11 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 2516, __pyx_L1_error)
    (((int *)(__pyx_v_self->callbuf[__pyx_v_index]))[0]) = __pyx_t_11;

    /* "pygpu/gpuarray.pyx":2515
 *         elif typecode == GA_USHORT:
 *             (<unsigned short *>self.callbuf[index])[0] = o
 *         elif typecode == GA_INT:             # <<<<<<<<<<<<<<
 *             (<int *>self.callbuf[index])[0] = o
 *         elif typecode == GA_UINT:
 */
    break;

    /* "pygpu/gpuarray.pyx":2517
 *         elif typecode == GA_INT:
 *             (<int *>self.callbuf[index])[0] = o
 *         elif typecode == GA_UINT:             # <<<<<<<<<<<<<<
 *             (<unsigned int *>self.callbuf[index])[0] = o
 *         elif typecode == GA_LONG:
 */
    case GA_UINT:

    /* "pygpu/gpuarray.pyx":2518
 *             (<int *>self.callbuf[index])[0] = o
 *         elif typecode == GA_UINT:
 *             (<unsigned int *>self.callbuf[index])[0] = o             # <<<<<<<<<<<<<<
 *         elif typecode == GA_LONG:
 *             (<long *>self.callbuf[index])[0] = o
 */
    __pyx_t_12 = __Pyx_PyInt_As_unsigned_int(__pyx_v_o); if (unlikely((__pyx_t_12 == (unsigned int)-1) && PyErr_Occurred())) __PYX_ERR(0, 2518, __pyx_L1_error)
    (((unsigned int *)(__pyx_v_self->callbuf[__pyx_v_index]))[0]) = __pyx_t_12;

    /* "pygpu/gpuarray.pyx":2517
 *         elif typecode == GA_INT:
 *             (<int *>self.callbuf[index])[0] = o
 *         elif typecode == GA_UINT:             # <<<<<<<<<<<<<<
 *             (<unsigned int *>self.callbuf[index])[0] = o
 *         elif typecode == GA_LONG:
 */
    break;

    /* "pygpu/gpuarray.pyx":2519
 *         elif typecode == GA_UINT:
 *             (<unsigned int *>self.callbuf[index])[0] = o
 *         elif typecode == GA_LONG:             # <<<<<<<<<<<<<<
 *             (<long *>self.callbuf[index])[0] = o
 *         elif typecode == GA_ULONG:
 */
    case GA_LONG:

    /* "pygpu/gpuarray.pyx":2520
 *             (<unsigned int *>self.callbuf[index])[0] = o
 *         elif typecode == GA_LONG:
 *             (<long *>self.callbuf[index])[0] = o             # <<<<<<<<<<<<<<
 *         elif typecode == GA_ULONG:
 *             (<unsigned long *>self.callbuf[index])[0] = o
 */
    __pyx_t_13 = __Pyx_PyInt_As_long(__pyx_v_o); if (unlikely((__pyx_t_13 == (long)-1) && PyErr_Occurred())) __PYX_ERR(0, 2520, __pyx_L1_error)
    (((long *)(__pyx_v_self->callbuf[__pyx_v_index]))[0]) = __pyx_t_13;

    /* "pygpu/gpuarray.pyx":2519
 *         elif typecode == GA_UINT:
 *             (<unsigned int *>self.callbuf[index])[0] = o
 *         elif typecode == GA_LONG:             # <<<<<<<<<<<<<<
 *             (<long *>self.callbuf[index])[0] = o
 *         elif typecode == GA_ULONG:
 */
    break;

    /* "pygpu/gpuarray.pyx":2521
 *         elif typecode == GA_LONG:
 *             (<long *>self.callbuf[index])[0] = o
 *         elif typecode == GA_ULONG:             # <<<<<<<<<<<<<<
 *             (<unsigned long *>self.callbuf[index])[0] = o
 *         else:
 */
    case GA_ULONG:

    /* "pygpu/gpuarray.pyx":2522
 *             (<long *>self.callbuf[index])[0] = o
 *         elif typecode == GA_ULONG:
 *             (<unsigned long *>self.callbuf[index])[0] = o             # <<<<<<<<<<<<<<
 *         else:
 *             raise ValueError("Bad typecode in _setarg: %d "
 */
    __pyx_t_14 = __Pyx_PyInt_As_unsigned_long(__pyx_v_o); if (unlikely((__pyx_t_14 == (unsigned long)-1) && PyErr_Occurred())) __PYX_ERR(0, 2522, __pyx_L1_error)
    (((unsigned long *)(__pyx_v_self->callbuf[__pyx_v_index]))[0]) = __pyx_t_14;

    /* "pygpu/gpuarray.pyx":2521
 *         elif typecode == GA_LONG:
 *             (<long *>self.callbuf[index])[0] = o
 *         elif typecode == GA_ULONG:             # <<<<<<<<<<<<<<
 *             (<unsigned long *>self.callbuf[index])[0] = o
 *         else:
 */
    break;
    default:

    /* "pygpu/gpuarray.pyx":2525
 *         else:
 *             raise ValueError("Bad typecode in _setarg: %d "
 *                              "(please report this, it is a bug)" % (typecode,))             # <<<<<<<<<<<<<<
 * 
 *     property maxlsize:
 */
    __pyx_t_15 = __Pyx_PyInt_From_int(__pyx_v_typecode); if (unlikely(!__pyx_t_15)) __PYX_ERR(0, 2525, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_15);
    __pyx_t_16 = PyTuple_New(1); if (unlikely(!__pyx_t_16)) __PYX_ERR(0, 2525, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_16);
    __Pyx_GIVEREF(__pyx_t_15);
    PyTuple_SET_ITEM(__pyx_t_16, 0, __pyx_t_15);
    __pyx_t_15 = 0;
    __pyx_t_15 = __Pyx_PyString_Format(__pyx_kp_s_Bad_typecode_in__setarg_d_please, __pyx_t_16); if (unlikely(!__pyx_t_15)) __PYX_ERR(0, 2525, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_15);
    __Pyx_DECREF(__pyx_t_16); __pyx_t_16 = 0;

    /* "pygpu/gpuarray.pyx":2524
 *             (<unsigned long *>self.callbuf[index])[0] = o
 *         else:
 *             raise ValueError("Bad typecode in _setarg: %d "             # <<<<<<<<<<<<<<
 *                              "(please report this, it is a bug)" % (typecode,))
 * 
 */
    __pyx_t_16 = PyTuple_New(1); if (unlikely(!__pyx_t_16)) __PYX_ERR(0, 2524, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_16);
    __Pyx_GIVEREF(__pyx_t_15);
    PyTuple_SET_ITEM(__pyx_t_16, 0, __pyx_t_15);
    __pyx_t_15 = 0;
    __pyx_t_15 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_t_16, NULL); if (unlikely(!__pyx_t_15)) __PYX_ERR(0, 2524, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_15);
    __Pyx_DECREF(__pyx_t_16); __pyx_t_16 = 0;
    __Pyx_Raise(__pyx_t_15, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_15); __pyx_t_15 = 0;
    __PYX_ERR(0, 2524, __pyx_L1_error)
    break;
  }

  /* "pygpu/gpuarray.pyx":2494
 *         kernel_call(self, nd, gs, ls, shared, self.callbuf)
 * 
 *     cdef _setarg(self, unsigned int index, int typecode, object o):             # <<<<<<<<<<<<<<
 *         if typecode == GA_BUFFER:
 *             if not isinstance(o, GpuArray):
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_15);
  __Pyx_XDECREF(__pyx_t_16);
  __Pyx_AddTraceback("pygpu.gpuarray.GpuKernel._setarg", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":2529
 *     property maxlsize:
 *         "Maximum local size for this kernel"
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             cdef size_t res
 *             kernel_property(self, GA_KERNEL_PROP_MAXLSIZE, &res)
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_9GpuKernel_8maxlsize_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_5pygpu_8gpuarray_9GpuKernel_8maxlsize_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_9GpuKernel_8maxlsize___get__(((struct PyGpuKernelObject *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_9GpuKernel_8maxlsize___get__(struct PyGpuKernelObject *__pyx_v_self) {
  size_t __pyx_v_res;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  __Pyx_RefNannySetupContext("__get__", 0);

  /* "pygpu/gpuarray.pyx":2531
 *         def __get__(self):
 *             cdef size_t res
 *             kernel_property(self, GA_KERNEL_PROP_MAXLSIZE, &res)             # <<<<<<<<<<<<<<
 *             return res
 * 
 */
  __pyx_t_1 = __pyx_f_5pygpu_8gpuarray_kernel_property(__pyx_v_self, GA_KERNEL_PROP_MAXLSIZE, (&__pyx_v_res)); if (unlikely(__pyx_t_1 == ((int)-1))) __PYX_ERR(0, 2531, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":2532
 *             cdef size_t res
 *             kernel_property(self, GA_KERNEL_PROP_MAXLSIZE, &res)
 *             return res             # <<<<<<<<<<<<<<
 * 
 *     property preflsize:
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_2 = __Pyx_PyInt_FromSize_t(__pyx_v_res); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2532, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_r = __pyx_t_2;
  __pyx_t_2 = 0;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":2529
 *     property maxlsize:
 *         "Maximum local size for this kernel"
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             cdef size_t res
 *             kernel_property(self, GA_KERNEL_PROP_MAXLSIZE, &res)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("pygpu.gpuarray.GpuKernel.maxlsize.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":2536
 *     property preflsize:
 *         "Preferred multiple for local size for this kernel"
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             cdef size_t res
 *             kernel_property(self, GA_KERNEL_PROP_PREFLSIZE, &res)
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_9GpuKernel_9preflsize_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_5pygpu_8gpuarray_9GpuKernel_9preflsize_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_9GpuKernel_9preflsize___get__(((struct PyGpuKernelObject *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_9GpuKernel_9preflsize___get__(struct PyGpuKernelObject *__pyx_v_self) {
  size_t __pyx_v_res;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  __Pyx_RefNannySetupContext("__get__", 0);

  /* "pygpu/gpuarray.pyx":2538
 *         def __get__(self):
 *             cdef size_t res
 *             kernel_property(self, GA_KERNEL_PROP_PREFLSIZE, &res)             # <<<<<<<<<<<<<<
 *             return res
 * 
 */
  __pyx_t_1 = __pyx_f_5pygpu_8gpuarray_kernel_property(__pyx_v_self, GA_KERNEL_PROP_PREFLSIZE, (&__pyx_v_res)); if (unlikely(__pyx_t_1 == ((int)-1))) __PYX_ERR(0, 2538, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":2539
 *             cdef size_t res
 *             kernel_property(self, GA_KERNEL_PROP_PREFLSIZE, &res)
 *             return res             # <<<<<<<<<<<<<<
 * 
 *     property numargs:
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_2 = __Pyx_PyInt_FromSize_t(__pyx_v_res); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2539, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_r = __pyx_t_2;
  __pyx_t_2 = 0;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":2536
 *     property preflsize:
 *         "Preferred multiple for local size for this kernel"
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             cdef size_t res
 *             kernel_property(self, GA_KERNEL_PROP_PREFLSIZE, &res)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("pygpu.gpuarray.GpuKernel.preflsize.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pyx":2543
 *     property numargs:
 *         "Number of arguments to kernel"
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             cdef unsigned int res
 *             kernel_property(self, GA_KERNEL_PROP_NUMARGS, &res)
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_9GpuKernel_7numargs_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_5pygpu_8gpuarray_9GpuKernel_7numargs_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_9GpuKernel_7numargs___get__(((struct PyGpuKernelObject *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_9GpuKernel_7numargs___get__(struct PyGpuKernelObject *__pyx_v_self) {
  unsigned int __pyx_v_res;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  __Pyx_RefNannySetupContext("__get__", 0);

  /* "pygpu/gpuarray.pyx":2545
 *         def __get__(self):
 *             cdef unsigned int res
 *             kernel_property(self, GA_KERNEL_PROP_NUMARGS, &res)             # <<<<<<<<<<<<<<
 *             return res
 * 
 */
  __pyx_t_1 = __pyx_f_5pygpu_8gpuarray_kernel_property(__pyx_v_self, GA_KERNEL_PROP_NUMARGS, (&__pyx_v_res)); if (unlikely(__pyx_t_1 == ((int)-1))) __PYX_ERR(0, 2545, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":2546
 *             cdef unsigned int res
 *             kernel_property(self, GA_KERNEL_PROP_NUMARGS, &res)
 *             return res             # <<<<<<<<<<<<<<
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_2 = __Pyx_PyInt_From_unsigned_int(__pyx_v_res); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 2546, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_r = __pyx_t_2;
  __pyx_t_2 = 0;
  goto __pyx_L0;

  /* "pygpu/gpuarray.pyx":2543
 *     property numargs:
 *         "Number of arguments to kernel"
 *         def __get__(self):             # <<<<<<<<<<<<<<
 *             cdef unsigned int res
 *             kernel_property(self, GA_KERNEL_PROP_NUMARGS, &res)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("pygpu.gpuarray.GpuKernel.numargs.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "pygpu/gpuarray.pxd":341
 * cdef api class GpuKernel [type PyGpuKernelType, object PyGpuKernelObject]:
 *     cdef _GpuKernel k
 *     cdef readonly GpuContext context             # <<<<<<<<<<<<<<
 *     cdef void **callbuf
 *     cdef object __weakref__
 */

/* Python wrapper */
static PyObject *__pyx_pw_5pygpu_8gpuarray_9GpuKernel_7context_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_5pygpu_8gpuarray_9GpuKernel_7context_1__get__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5pygpu_8gpuarray_9GpuKernel_7context___get__(((struct PyGpuKernelObject *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5pygpu_8gpuarray_9GpuKernel_7context___get__(struct PyGpuKernelObject *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__", 0);
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self->context));
  __pyx_r = ((PyObject *)__pyx_v_self->context);
  goto __pyx_L0;

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":214
 *         # experimental exception made for __getbuffer__ and __releasebuffer__
 *         # -- the details of this may change.
 *         def __getbuffer__(ndarray self, Py_buffer* info, int flags):             # <<<<<<<<<<<<<<
 *             # This implementation of getbuffer is geared towards Cython
 *             # requirements, and does not yet fullfill the PEP.
 */

/* Python wrapper */
static CYTHON_UNUSED int __pyx_pw_5numpy_7ndarray_1__getbuffer__(PyObject *__pyx_v_self, Py_buffer *__pyx_v_info, int __pyx_v_flags); /*proto*/
static CYTHON_UNUSED int __pyx_pw_5numpy_7ndarray_1__getbuffer__(PyObject *__pyx_v_self, Py_buffer *__pyx_v_info, int __pyx_v_flags) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__getbuffer__ (wrapper)", 0);
  __pyx_r = __pyx_pf_5numpy_7ndarray___getbuffer__(((PyArrayObject *)__pyx_v_self), ((Py_buffer *)__pyx_v_info), ((int)__pyx_v_flags));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_5numpy_7ndarray___getbuffer__(PyArrayObject *__pyx_v_self, Py_buffer *__pyx_v_info, int __pyx_v_flags) {
  int __pyx_v_copy_shape;
  int __pyx_v_i;
  int __pyx_v_ndim;
  int __pyx_v_endian_detector;
  int __pyx_v_little_endian;
  int __pyx_v_t;
  char *__pyx_v_f;
  PyArray_Descr *__pyx_v_descr = 0;
  int __pyx_v_offset;
  int __pyx_v_hasfields;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_t_2;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  int __pyx_t_5;
  PyObject *__pyx_t_6 = NULL;
  char *__pyx_t_7;
  __Pyx_RefNannySetupContext("__getbuffer__", 0);
  if (__pyx_v_info != NULL) {
    __pyx_v_info->obj = Py_None; __Pyx_INCREF(Py_None);
    __Pyx_GIVEREF(__pyx_v_info->obj);
  }

  /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":220
 *             # of flags
 * 
 *             if info == NULL: return             # <<<<<<<<<<<<<<
 * 
 *             cdef int copy_shape, i, ndim
 */
  __pyx_t_1 = ((__pyx_v_info == NULL) != 0);
  if (__pyx_t_1) {
    __pyx_r = 0;
    goto __pyx_L0;
  }

  /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":223
 * 
 *             cdef int copy_shape, i, ndim
 *             cdef int endian_detector = 1             # <<<<<<<<<<<<<<
 *             cdef bint little_endian = ((<char*>&endian_detector)[0] != 0)
 * 
 */
  __pyx_v_endian_detector = 1;

  /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":224
 *             cdef int copy_shape, i, ndim
 *             cdef int endian_detector = 1
 *             cdef bint little_endian = ((<char*>&endian_detector)[0] != 0)             # <<<<<<<<<<<<<<
 * 
 *             ndim = PyArray_NDIM(self)
 */
  __pyx_v_little_endian = ((((char *)(&__pyx_v_endian_detector))[0]) != 0);

  /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":226
 *             cdef bint little_endian = ((<char*>&endian_detector)[0] != 0)
 * 
 *             ndim = PyArray_NDIM(self)             # <<<<<<<<<<<<<<
 * 
 *             if sizeof(npy_intp) != sizeof(Py_ssize_t):
 */
  __pyx_v_ndim = PyArray_NDIM(__pyx_v_self);

  /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":228
 *             ndim = PyArray_NDIM(self)
 * 
 *             if sizeof(npy_intp) != sizeof(Py_ssize_t):             # <<<<<<<<<<<<<<
 *                 copy_shape = 1
 *             else:
 */
  __pyx_t_1 = (((sizeof(npy_intp)) != (sizeof(Py_ssize_t))) != 0);
  if (__pyx_t_1) {

    /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":229
 * 
 *             if sizeof(npy_intp) != sizeof(Py_ssize_t):
 *                 copy_shape = 1             # <<<<<<<<<<<<<<
 *             else:
 *                 copy_shape = 0
 */
    __pyx_v_copy_shape = 1;

    /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":228
 *             ndim = PyArray_NDIM(self)
 * 
 *             if sizeof(npy_intp) != sizeof(Py_ssize_t):             # <<<<<<<<<<<<<<
 *                 copy_shape = 1
 *             else:
 */
    goto __pyx_L4;
  }

  /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":231
 *                 copy_shape = 1
 *             else:
 *                 copy_shape = 0             # <<<<<<<<<<<<<<
 * 
 *             if ((flags & pybuf.PyBUF_C_CONTIGUOUS == pybuf.PyBUF_C_CONTIGUOUS)
 */
  /*else*/ {
    __pyx_v_copy_shape = 0;
  }
  __pyx_L4:;

  /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":233
 *                 copy_shape = 0
 * 
 *             if ((flags & pybuf.PyBUF_C_CONTIGUOUS == pybuf.PyBUF_C_CONTIGUOUS)             # <<<<<<<<<<<<<<
 *                 and not PyArray_CHKFLAGS(self, NPY_C_CONTIGUOUS)):
 *                 raise ValueError(u"ndarray is not C contiguous")
 */
  __pyx_t_2 = (((__pyx_v_flags & PyBUF_C_CONTIGUOUS) == PyBUF_C_CONTIGUOUS) != 0);
  if (__pyx_t_2) {
  } else {
    __pyx_t_1 = __pyx_t_2;
    goto __pyx_L6_bool_binop_done;
  }

  /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":234
 * 
 *             if ((flags & pybuf.PyBUF_C_CONTIGUOUS == pybuf.PyBUF_C_CONTIGUOUS)
 *                 and not PyArray_CHKFLAGS(self, NPY_C_CONTIGUOUS)):             # <<<<<<<<<<<<<<
 *                 raise ValueError(u"ndarray is not C contiguous")
 * 
 */
  __pyx_t_2 = ((!(PyArray_CHKFLAGS(__pyx_v_self, NPY_C_CONTIGUOUS) != 0)) != 0);
  __pyx_t_1 = __pyx_t_2;
  __pyx_L6_bool_binop_done:;

  /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":233
 *                 copy_shape = 0
 * 
 *             if ((flags & pybuf.PyBUF_C_CONTIGUOUS == pybuf.PyBUF_C_CONTIGUOUS)             # <<<<<<<<<<<<<<
 *                 and not PyArray_CHKFLAGS(self, NPY_C_CONTIGUOUS)):
 *                 raise ValueError(u"ndarray is not C contiguous")
 */
  if (__pyx_t_1) {

    /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":235
 *             if ((flags & pybuf.PyBUF_C_CONTIGUOUS == pybuf.PyBUF_C_CONTIGUOUS)
 *                 and not PyArray_CHKFLAGS(self, NPY_C_CONTIGUOUS)):
 *                 raise ValueError(u"ndarray is not C contiguous")             # <<<<<<<<<<<<<<
 * 
 *             if ((flags & pybuf.PyBUF_F_CONTIGUOUS == pybuf.PyBUF_F_CONTIGUOUS)
 */
    __pyx_t_3 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__40, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 235, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_Raise(__pyx_t_3, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __PYX_ERR(1, 235, __pyx_L1_error)

    /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":233
 *                 copy_shape = 0
 * 
 *             if ((flags & pybuf.PyBUF_C_CONTIGUOUS == pybuf.PyBUF_C_CONTIGUOUS)             # <<<<<<<<<<<<<<
 *                 and not PyArray_CHKFLAGS(self, NPY_C_CONTIGUOUS)):
 *                 raise ValueError(u"ndarray is not C contiguous")
 */
  }

  /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":237
 *                 raise ValueError(u"ndarray is not C contiguous")
 * 
 *             if ((flags & pybuf.PyBUF_F_CONTIGUOUS == pybuf.PyBUF_F_CONTIGUOUS)             # <<<<<<<<<<<<<<
 *                 and not PyArray_CHKFLAGS(self, NPY_F_CONTIGUOUS)):
 *                 raise ValueError(u"ndarray is not Fortran contiguous")
 */
  __pyx_t_2 = (((__pyx_v_flags & PyBUF_F_CONTIGUOUS) == PyBUF_F_CONTIGUOUS) != 0);
  if (__pyx_t_2) {
  } else {
    __pyx_t_1 = __pyx_t_2;
    goto __pyx_L9_bool_binop_done;
  }

  /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":238
 * 
 *             if ((flags & pybuf.PyBUF_F_CONTIGUOUS == pybuf.PyBUF_F_CONTIGUOUS)
 *                 and not PyArray_CHKFLAGS(self, NPY_F_CONTIGUOUS)):             # <<<<<<<<<<<<<<
 *                 raise ValueError(u"ndarray is not Fortran contiguous")
 * 
 */
  __pyx_t_2 = ((!(PyArray_CHKFLAGS(__pyx_v_self, NPY_F_CONTIGUOUS) != 0)) != 0);
  __pyx_t_1 = __pyx_t_2;
  __pyx_L9_bool_binop_done:;

  /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":237
 *                 raise ValueError(u"ndarray is not C contiguous")
 * 
 *             if ((flags & pybuf.PyBUF_F_CONTIGUOUS == pybuf.PyBUF_F_CONTIGUOUS)             # <<<<<<<<<<<<<<
 *                 and not PyArray_CHKFLAGS(self, NPY_F_CONTIGUOUS)):
 *                 raise ValueError(u"ndarray is not Fortran contiguous")
 */
  if (__pyx_t_1) {

    /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":239
 *             if ((flags & pybuf.PyBUF_F_CONTIGUOUS == pybuf.PyBUF_F_CONTIGUOUS)
 *                 and not PyArray_CHKFLAGS(self, NPY_F_CONTIGUOUS)):
 *                 raise ValueError(u"ndarray is not Fortran contiguous")             # <<<<<<<<<<<<<<
 * 
 *             info.buf = PyArray_DATA(self)
 */
    __pyx_t_3 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__41, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 239, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_Raise(__pyx_t_3, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __PYX_ERR(1, 239, __pyx_L1_error)

    /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":237
 *                 raise ValueError(u"ndarray is not C contiguous")
 * 
 *             if ((flags & pybuf.PyBUF_F_CONTIGUOUS == pybuf.PyBUF_F_CONTIGUOUS)             # <<<<<<<<<<<<<<
 *                 and not PyArray_CHKFLAGS(self, NPY_F_CONTIGUOUS)):
 *                 raise ValueError(u"ndarray is not Fortran contiguous")
 */
  }

  /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":241
 *                 raise ValueError(u"ndarray is not Fortran contiguous")
 * 
 *             info.buf = PyArray_DATA(self)             # <<<<<<<<<<<<<<
 *             info.ndim = ndim
 *             if copy_shape:
 */
  __pyx_v_info->buf = PyArray_DATA(__pyx_v_self);

  /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":242
 * 
 *             info.buf = PyArray_DATA(self)
 *             info.ndim = ndim             # <<<<<<<<<<<<<<
 *             if copy_shape:
 *                 # Allocate new buffer for strides and shape info.
 */
  __pyx_v_info->ndim = __pyx_v_ndim;

  /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":243
 *             info.buf = PyArray_DATA(self)
 *             info.ndim = ndim
 *             if copy_shape:             # <<<<<<<<<<<<<<
 *                 # Allocate new buffer for strides and shape info.
 *                 # This is allocated as one block, strides first.
 */
  __pyx_t_1 = (__pyx_v_copy_shape != 0);
  if (__pyx_t_1) {

    /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":246
 *                 # Allocate new buffer for strides and shape info.
 *                 # This is allocated as one block, strides first.
 *                 info.strides = <Py_ssize_t*>PyObject_Malloc(sizeof(Py_ssize_t) * 2 * <size_t>ndim)             # <<<<<<<<<<<<<<
 *                 info.shape = info.strides + ndim
 *                 for i in range(ndim):
 */
    __pyx_v_info->strides = ((Py_ssize_t *)PyObject_Malloc((((sizeof(Py_ssize_t)) * 2) * ((size_t)__pyx_v_ndim))));

    /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":247
 *                 # This is allocated as one block, strides first.
 *                 info.strides = <Py_ssize_t*>PyObject_Malloc(sizeof(Py_ssize_t) * 2 * <size_t>ndim)
 *                 info.shape = info.strides + ndim             # <<<<<<<<<<<<<<
 *                 for i in range(ndim):
 *                     info.strides[i] = PyArray_STRIDES(self)[i]
 */
    __pyx_v_info->shape = (__pyx_v_info->strides + __pyx_v_ndim);

    /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":248
 *                 info.strides = <Py_ssize_t*>PyObject_Malloc(sizeof(Py_ssize_t) * 2 * <size_t>ndim)
 *                 info.shape = info.strides + ndim
 *                 for i in range(ndim):             # <<<<<<<<<<<<<<
 *                     info.strides[i] = PyArray_STRIDES(self)[i]
 *                     info.shape[i] = PyArray_DIMS(self)[i]
 */
    __pyx_t_4 = __pyx_v_ndim;
    for (__pyx_t_5 = 0; __pyx_t_5 < __pyx_t_4; __pyx_t_5+=1) {
      __pyx_v_i = __pyx_t_5;

      /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":249
 *                 info.shape = info.strides + ndim
 *                 for i in range(ndim):
 *                     info.strides[i] = PyArray_STRIDES(self)[i]             # <<<<<<<<<<<<<<
 *                     info.shape[i] = PyArray_DIMS(self)[i]
 *             else:
 */
      (__pyx_v_info->strides[__pyx_v_i]) = (PyArray_STRIDES(__pyx_v_self)[__pyx_v_i]);

      /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":250
 *                 for i in range(ndim):
 *                     info.strides[i] = PyArray_STRIDES(self)[i]
 *                     info.shape[i] = PyArray_DIMS(self)[i]             # <<<<<<<<<<<<<<
 *             else:
 *                 info.strides = <Py_ssize_t*>PyArray_STRIDES(self)
 */
      (__pyx_v_info->shape[__pyx_v_i]) = (PyArray_DIMS(__pyx_v_self)[__pyx_v_i]);
    }

    /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":243
 *             info.buf = PyArray_DATA(self)
 *             info.ndim = ndim
 *             if copy_shape:             # <<<<<<<<<<<<<<
 *                 # Allocate new buffer for strides and shape info.
 *                 # This is allocated as one block, strides first.
 */
    goto __pyx_L11;
  }

  /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":252
 *                     info.shape[i] = PyArray_DIMS(self)[i]
 *             else:
 *                 info.strides = <Py_ssize_t*>PyArray_STRIDES(self)             # <<<<<<<<<<<<<<
 *                 info.shape = <Py_ssize_t*>PyArray_DIMS(self)
 *             info.suboffsets = NULL
 */
  /*else*/ {
    __pyx_v_info->strides = ((Py_ssize_t *)PyArray_STRIDES(__pyx_v_self));

    /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":253
 *             else:
 *                 info.strides = <Py_ssize_t*>PyArray_STRIDES(self)
 *                 info.shape = <Py_ssize_t*>PyArray_DIMS(self)             # <<<<<<<<<<<<<<
 *             info.suboffsets = NULL
 *             info.itemsize = PyArray_ITEMSIZE(self)
 */
    __pyx_v_info->shape = ((Py_ssize_t *)PyArray_DIMS(__pyx_v_self));
  }
  __pyx_L11:;

  /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":254
 *                 info.strides = <Py_ssize_t*>PyArray_STRIDES(self)
 *                 info.shape = <Py_ssize_t*>PyArray_DIMS(self)
 *             info.suboffsets = NULL             # <<<<<<<<<<<<<<
 *             info.itemsize = PyArray_ITEMSIZE(self)
 *             info.readonly = not PyArray_ISWRITEABLE(self)
 */
  __pyx_v_info->suboffsets = NULL;

  /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":255
 *                 info.shape = <Py_ssize_t*>PyArray_DIMS(self)
 *             info.suboffsets = NULL
 *             info.itemsize = PyArray_ITEMSIZE(self)             # <<<<<<<<<<<<<<
 *             info.readonly = not PyArray_ISWRITEABLE(self)
 * 
 */
  __pyx_v_info->itemsize = PyArray_ITEMSIZE(__pyx_v_self);

  /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":256
 *             info.suboffsets = NULL
 *             info.itemsize = PyArray_ITEMSIZE(self)
 *             info.readonly = not PyArray_ISWRITEABLE(self)             # <<<<<<<<<<<<<<
 * 
 *             cdef int t
 */
  __pyx_v_info->readonly = (!(PyArray_ISWRITEABLE(__pyx_v_self) != 0));

  /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":259
 * 
 *             cdef int t
 *             cdef char* f = NULL             # <<<<<<<<<<<<<<
 *             cdef dtype descr = self.descr
 *             cdef int offset
 */
  __pyx_v_f = NULL;

  /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":260
 *             cdef int t
 *             cdef char* f = NULL
 *             cdef dtype descr = self.descr             # <<<<<<<<<<<<<<
 *             cdef int offset
 * 
 */
  __pyx_t_3 = ((PyObject *)__pyx_v_self->descr);
  __Pyx_INCREF(__pyx_t_3);
  __pyx_v_descr = ((PyArray_Descr *)__pyx_t_3);
  __pyx_t_3 = 0;

  /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":263
 *             cdef int offset
 * 
 *             cdef bint hasfields = PyDataType_HASFIELDS(descr)             # <<<<<<<<<<<<<<
 * 
 *             if not hasfields and not copy_shape:
 */
  __pyx_v_hasfields = PyDataType_HASFIELDS(__pyx_v_descr);

  /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":265
 *             cdef bint hasfields = PyDataType_HASFIELDS(descr)
 * 
 *             if not hasfields and not copy_shape:             # <<<<<<<<<<<<<<
 *                 # do not call releasebuffer
 *                 info.obj = None
 */
  __pyx_t_2 = ((!(__pyx_v_hasfields != 0)) != 0);
  if (__pyx_t_2) {
  } else {
    __pyx_t_1 = __pyx_t_2;
    goto __pyx_L15_bool_binop_done;
  }
  __pyx_t_2 = ((!(__pyx_v_copy_shape != 0)) != 0);
  __pyx_t_1 = __pyx_t_2;
  __pyx_L15_bool_binop_done:;
  if (__pyx_t_1) {

    /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":267
 *             if not hasfields and not copy_shape:
 *                 # do not call releasebuffer
 *                 info.obj = None             # <<<<<<<<<<<<<<
 *             else:
 *                 # need to call releasebuffer
 */
    __Pyx_INCREF(Py_None);
    __Pyx_GIVEREF(Py_None);
    __Pyx_GOTREF(__pyx_v_info->obj);
    __Pyx_DECREF(__pyx_v_info->obj);
    __pyx_v_info->obj = Py_None;

    /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":265
 *             cdef bint hasfields = PyDataType_HASFIELDS(descr)
 * 
 *             if not hasfields and not copy_shape:             # <<<<<<<<<<<<<<
 *                 # do not call releasebuffer
 *                 info.obj = None
 */
    goto __pyx_L14;
  }

  /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":270
 *             else:
 *                 # need to call releasebuffer
 *                 info.obj = self             # <<<<<<<<<<<<<<
 * 
 *             if not hasfields:
 */
  /*else*/ {
    __Pyx_INCREF(((PyObject *)__pyx_v_self));
    __Pyx_GIVEREF(((PyObject *)__pyx_v_self));
    __Pyx_GOTREF(__pyx_v_info->obj);
    __Pyx_DECREF(__pyx_v_info->obj);
    __pyx_v_info->obj = ((PyObject *)__pyx_v_self);
  }
  __pyx_L14:;

  /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":272
 *                 info.obj = self
 * 
 *             if not hasfields:             # <<<<<<<<<<<<<<
 *                 t = descr.type_num
 *                 if ((descr.byteorder == c'>' and little_endian) or
 */
  __pyx_t_1 = ((!(__pyx_v_hasfields != 0)) != 0);
  if (__pyx_t_1) {

    /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":273
 * 
 *             if not hasfields:
 *                 t = descr.type_num             # <<<<<<<<<<<<<<
 *                 if ((descr.byteorder == c'>' and little_endian) or
 *                     (descr.byteorder == c'<' and not little_endian)):
 */
    __pyx_t_4 = __pyx_v_descr->type_num;
    __pyx_v_t = __pyx_t_4;

    /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":274
 *             if not hasfields:
 *                 t = descr.type_num
 *                 if ((descr.byteorder == c'>' and little_endian) or             # <<<<<<<<<<<<<<
 *                     (descr.byteorder == c'<' and not little_endian)):
 *                     raise ValueError(u"Non-native byte order not supported")
 */
    __pyx_t_2 = ((__pyx_v_descr->byteorder == '>') != 0);
    if (!__pyx_t_2) {
      goto __pyx_L20_next_or;
    } else {
    }
    __pyx_t_2 = (__pyx_v_little_endian != 0);
    if (!__pyx_t_2) {
    } else {
      __pyx_t_1 = __pyx_t_2;
      goto __pyx_L19_bool_binop_done;
    }
    __pyx_L20_next_or:;

    /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":275
 *                 t = descr.type_num
 *                 if ((descr.byteorder == c'>' and little_endian) or
 *                     (descr.byteorder == c'<' and not little_endian)):             # <<<<<<<<<<<<<<
 *                     raise ValueError(u"Non-native byte order not supported")
 *                 if   t == NPY_BYTE:        f = "b"
 */
    __pyx_t_2 = ((__pyx_v_descr->byteorder == '<') != 0);
    if (__pyx_t_2) {
    } else {
      __pyx_t_1 = __pyx_t_2;
      goto __pyx_L19_bool_binop_done;
    }
    __pyx_t_2 = ((!(__pyx_v_little_endian != 0)) != 0);
    __pyx_t_1 = __pyx_t_2;
    __pyx_L19_bool_binop_done:;

    /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":274
 *             if not hasfields:
 *                 t = descr.type_num
 *                 if ((descr.byteorder == c'>' and little_endian) or             # <<<<<<<<<<<<<<
 *                     (descr.byteorder == c'<' and not little_endian)):
 *                     raise ValueError(u"Non-native byte order not supported")
 */
    if (__pyx_t_1) {

      /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":276
 *                 if ((descr.byteorder == c'>' and little_endian) or
 *                     (descr.byteorder == c'<' and not little_endian)):
 *                     raise ValueError(u"Non-native byte order not supported")             # <<<<<<<<<<<<<<
 *                 if   t == NPY_BYTE:        f = "b"
 *                 elif t == NPY_UBYTE:       f = "B"
 */
      __pyx_t_3 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__42, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 276, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_Raise(__pyx_t_3, 0, 0, 0);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __PYX_ERR(1, 276, __pyx_L1_error)

      /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":274
 *             if not hasfields:
 *                 t = descr.type_num
 *                 if ((descr.byteorder == c'>' and little_endian) or             # <<<<<<<<<<<<<<
 *                     (descr.byteorder == c'<' and not little_endian)):
 *                     raise ValueError(u"Non-native byte order not supported")
 */
    }

    /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":277
 *                     (descr.byteorder == c'<' and not little_endian)):
 *                     raise ValueError(u"Non-native byte order not supported")
 *                 if   t == NPY_BYTE:        f = "b"             # <<<<<<<<<<<<<<
 *                 elif t == NPY_UBYTE:       f = "B"
 *                 elif t == NPY_SHORT:       f = "h"
 */
    switch (__pyx_v_t) {
      case NPY_BYTE:
      __pyx_v_f = ((char *)"b");
      break;

      /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":278
 *                     raise ValueError(u"Non-native byte order not supported")
 *                 if   t == NPY_BYTE:        f = "b"
 *                 elif t == NPY_UBYTE:       f = "B"             # <<<<<<<<<<<<<<
 *                 elif t == NPY_SHORT:       f = "h"
 *                 elif t == NPY_USHORT:      f = "H"
 */
      case NPY_UBYTE:
      __pyx_v_f = ((char *)"B");
      break;

      /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":279
 *                 if   t == NPY_BYTE:        f = "b"
 *                 elif t == NPY_UBYTE:       f = "B"
 *                 elif t == NPY_SHORT:       f = "h"             # <<<<<<<<<<<<<<
 *                 elif t == NPY_USHORT:      f = "H"
 *                 elif t == NPY_INT:         f = "i"
 */
      case NPY_SHORT:
      __pyx_v_f = ((char *)"h");
      break;

      /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":280
 *                 elif t == NPY_UBYTE:       f = "B"
 *                 elif t == NPY_SHORT:       f = "h"
 *                 elif t == NPY_USHORT:      f = "H"             # <<<<<<<<<<<<<<
 *                 elif t == NPY_INT:         f = "i"
 *                 elif t == NPY_UINT:        f = "I"
 */
      case NPY_USHORT:
      __pyx_v_f = ((char *)"H");
      break;

      /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":281
 *                 elif t == NPY_SHORT:       f = "h"
 *                 elif t == NPY_USHORT:      f = "H"
 *                 elif t == NPY_INT:         f = "i"             # <<<<<<<<<<<<<<
 *                 elif t == NPY_UINT:        f = "I"
 *                 elif t == NPY_LONG:        f = "l"
 */
      case NPY_INT:
      __pyx_v_f = ((char *)"i");
      break;

      /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":282
 *                 elif t == NPY_USHORT:      f = "H"
 *                 elif t == NPY_INT:         f = "i"
 *                 elif t == NPY_UINT:        f = "I"             # <<<<<<<<<<<<<<
 *                 elif t == NPY_LONG:        f = "l"
 *                 elif t == NPY_ULONG:       f = "L"
 */
      case NPY_UINT:
      __pyx_v_f = ((char *)"I");
      break;

      /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":283
 *                 elif t == NPY_INT:         f = "i"
 *                 elif t == NPY_UINT:        f = "I"
 *                 elif t == NPY_LONG:        f = "l"             # <<<<<<<<<<<<<<
 *                 elif t == NPY_ULONG:       f = "L"
 *                 elif t == NPY_LONGLONG:    f = "q"
 */
      case NPY_LONG:
      __pyx_v_f = ((char *)"l");
      break;

      /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":284
 *                 elif t == NPY_UINT:        f = "I"
 *                 elif t == NPY_LONG:        f = "l"
 *                 elif t == NPY_ULONG:       f = "L"             # <<<<<<<<<<<<<<
 *                 elif t == NPY_LONGLONG:    f = "q"
 *                 elif t == NPY_ULONGLONG:   f = "Q"
 */
      case NPY_ULONG:
      __pyx_v_f = ((char *)"L");
      break;

      /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":285
 *                 elif t == NPY_LONG:        f = "l"
 *                 elif t == NPY_ULONG:       f = "L"
 *                 elif t == NPY_LONGLONG:    f = "q"             # <<<<<<<<<<<<<<
 *                 elif t == NPY_ULONGLONG:   f = "Q"
 *                 elif t == NPY_FLOAT:       f = "f"
 */
      case NPY_LONGLONG:
      __pyx_v_f = ((char *)"q");
      break;

      /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":286
 *                 elif t == NPY_ULONG:       f = "L"
 *                 elif t == NPY_LONGLONG:    f = "q"
 *                 elif t == NPY_ULONGLONG:   f = "Q"             # <<<<<<<<<<<<<<
 *                 elif t == NPY_FLOAT:       f = "f"
 *                 elif t == NPY_DOUBLE:      f = "d"
 */
      case NPY_ULONGLONG:
      __pyx_v_f = ((char *)"Q");
      break;

      /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":287
 *                 elif t == NPY_LONGLONG:    f = "q"
 *                 elif t == NPY_ULONGLONG:   f = "Q"
 *                 elif t == NPY_FLOAT:       f = "f"             # <<<<<<<<<<<<<<
 *                 elif t == NPY_DOUBLE:      f = "d"
 *                 elif t == NPY_LONGDOUBLE:  f = "g"
 */
      case NPY_FLOAT:
      __pyx_v_f = ((char *)"f");
      break;

      /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":288
 *                 elif t == NPY_ULONGLONG:   f = "Q"
 *                 elif t == NPY_FLOAT:       f = "f"
 *                 elif t == NPY_DOUBLE:      f = "d"             # <<<<<<<<<<<<<<
 *                 elif t == NPY_LONGDOUBLE:  f = "g"
 *                 elif t == NPY_CFLOAT:      f = "Zf"
 */
      case NPY_DOUBLE:
      __pyx_v_f = ((char *)"d");
      break;

      /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":289
 *                 elif t == NPY_FLOAT:       f = "f"
 *                 elif t == NPY_DOUBLE:      f = "d"
 *                 elif t == NPY_LONGDOUBLE:  f = "g"             # <<<<<<<<<<<<<<
 *                 elif t == NPY_CFLOAT:      f = "Zf"
 *                 elif t == NPY_CDOUBLE:     f = "Zd"
 */
      case NPY_LONGDOUBLE:
      __pyx_v_f = ((char *)"g");
      break;

      /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":290
 *                 elif t == NPY_DOUBLE:      f = "d"
 *                 elif t == NPY_LONGDOUBLE:  f = "g"
 *                 elif t == NPY_CFLOAT:      f = "Zf"             # <<<<<<<<<<<<<<
 *                 elif t == NPY_CDOUBLE:     f = "Zd"
 *                 elif t == NPY_CLONGDOUBLE: f = "Zg"
 */
      case NPY_CFLOAT:
      __pyx_v_f = ((char *)"Zf");
      break;

      /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":291
 *                 elif t == NPY_LONGDOUBLE:  f = "g"
 *                 elif t == NPY_CFLOAT:      f = "Zf"
 *                 elif t == NPY_CDOUBLE:     f = "Zd"             # <<<<<<<<<<<<<<
 *                 elif t == NPY_CLONGDOUBLE: f = "Zg"
 *                 elif t == NPY_OBJECT:      f = "O"
 */
      case NPY_CDOUBLE:
      __pyx_v_f = ((char *)"Zd");
      break;

      /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":292
 *                 elif t == NPY_CFLOAT:      f = "Zf"
 *                 elif t == NPY_CDOUBLE:     f = "Zd"
 *                 elif t == NPY_CLONGDOUBLE: f = "Zg"             # <<<<<<<<<<<<<<
 *                 elif t == NPY_OBJECT:      f = "O"
 *                 else:
 */
      case NPY_CLONGDOUBLE:
      __pyx_v_f = ((char *)"Zg");
      break;

      /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":293
 *                 elif t == NPY_CDOUBLE:     f = "Zd"
 *                 elif t == NPY_CLONGDOUBLE: f = "Zg"
 *                 elif t == NPY_OBJECT:      f = "O"             # <<<<<<<<<<<<<<
 *                 else:
 *                     raise ValueError(u"unknown dtype code in numpy.pxd (%d)" % t)
 */
      case NPY_OBJECT:
      __pyx_v_f = ((char *)"O");
      break;
      default:

      /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":295
 *                 elif t == NPY_OBJECT:      f = "O"
 *                 else:
 *                     raise ValueError(u"unknown dtype code in numpy.pxd (%d)" % t)             # <<<<<<<<<<<<<<
 *                 info.format = f
 *                 return
 */
      __pyx_t_3 = __Pyx_PyInt_From_int(__pyx_v_t); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 295, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __pyx_t_6 = PyUnicode_Format(__pyx_kp_u_unknown_dtype_code_in_numpy_pxd, __pyx_t_3); if (unlikely(!__pyx_t_6)) __PYX_ERR(1, 295, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 295, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_GIVEREF(__pyx_t_6);
      PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_6);
      __pyx_t_6 = 0;
      __pyx_t_6 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_t_3, NULL); if (unlikely(!__pyx_t_6)) __PYX_ERR(1, 295, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __Pyx_Raise(__pyx_t_6, 0, 0, 0);
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __PYX_ERR(1, 295, __pyx_L1_error)
      break;
    }

    /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":296
 *                 else:
 *                     raise ValueError(u"unknown dtype code in numpy.pxd (%d)" % t)
 *                 info.format = f             # <<<<<<<<<<<<<<
 *                 return
 *             else:
 */
    __pyx_v_info->format = __pyx_v_f;

    /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":297
 *                     raise ValueError(u"unknown dtype code in numpy.pxd (%d)" % t)
 *                 info.format = f
 *                 return             # <<<<<<<<<<<<<<
 *             else:
 *                 info.format = <char*>PyObject_Malloc(_buffer_format_string_len)
 */
    __pyx_r = 0;
    goto __pyx_L0;

    /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":272
 *                 info.obj = self
 * 
 *             if not hasfields:             # <<<<<<<<<<<<<<
 *                 t = descr.type_num
 *                 if ((descr.byteorder == c'>' and little_endian) or
 */
  }

  /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":299
 *                 return
 *             else:
 *                 info.format = <char*>PyObject_Malloc(_buffer_format_string_len)             # <<<<<<<<<<<<<<
 *                 info.format[0] = c'^' # Native data types, manual alignment
 *                 offset = 0
 */
  /*else*/ {
    __pyx_v_info->format = ((char *)PyObject_Malloc(0xFF));

    /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":300
 *             else:
 *                 info.format = <char*>PyObject_Malloc(_buffer_format_string_len)
 *                 info.format[0] = c'^' # Native data types, manual alignment             # <<<<<<<<<<<<<<
 *                 offset = 0
 *                 f = _util_dtypestring(descr, info.format + 1,
 */
    (__pyx_v_info->format[0]) = '^';

    /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":301
 *                 info.format = <char*>PyObject_Malloc(_buffer_format_string_len)
 *                 info.format[0] = c'^' # Native data types, manual alignment
 *                 offset = 0             # <<<<<<<<<<<<<<
 *                 f = _util_dtypestring(descr, info.format + 1,
 *                                       info.format + _buffer_format_string_len,
 */
    __pyx_v_offset = 0;

    /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":302
 *                 info.format[0] = c'^' # Native data types, manual alignment
 *                 offset = 0
 *                 f = _util_dtypestring(descr, info.format + 1,             # <<<<<<<<<<<<<<
 *                                       info.format + _buffer_format_string_len,
 *                                       &offset)
 */
    __pyx_t_7 = __pyx_f_5numpy__util_dtypestring(__pyx_v_descr, (__pyx_v_info->format + 1), (__pyx_v_info->format + 0xFF), (&__pyx_v_offset)); if (unlikely(__pyx_t_7 == ((char *)NULL))) __PYX_ERR(1, 302, __pyx_L1_error)
    __pyx_v_f = __pyx_t_7;

    /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":305
 *                                       info.format + _buffer_format_string_len,
 *                                       &offset)
 *                 f[0] = c'\0' # Terminate format string             # <<<<<<<<<<<<<<
 * 
 *         def __releasebuffer__(ndarray self, Py_buffer* info):
 */
    (__pyx_v_f[0]) = '\x00';
  }

  /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":214
 *         # experimental exception made for __getbuffer__ and __releasebuffer__
 *         # -- the details of this may change.
 *         def __getbuffer__(ndarray self, Py_buffer* info, int flags):             # <<<<<<<<<<<<<<
 *             # This implementation of getbuffer is geared towards Cython
 *             # requirements, and does not yet fullfill the PEP.
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_AddTraceback("numpy.ndarray.__getbuffer__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  if (__pyx_v_info != NULL && __pyx_v_info->obj != NULL) {
    __Pyx_GOTREF(__pyx_v_info->obj);
    __Pyx_DECREF(__pyx_v_info->obj); __pyx_v_info->obj = NULL;
  }
  goto __pyx_L2;
  __pyx_L0:;
  if (__pyx_v_info != NULL && __pyx_v_info->obj == Py_None) {
    __Pyx_GOTREF(Py_None);
    __Pyx_DECREF(Py_None); __pyx_v_info->obj = NULL;
  }
  __pyx_L2:;
  __Pyx_XDECREF((PyObject *)__pyx_v_descr);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":307
 *                 f[0] = c'\0' # Terminate format string
 * 
 *         def __releasebuffer__(ndarray self, Py_buffer* info):             # <<<<<<<<<<<<<<
 *             if PyArray_HASFIELDS(self):
 *                 PyObject_Free(info.format)
 */

/* Python wrapper */
static CYTHON_UNUSED void __pyx_pw_5numpy_7ndarray_3__releasebuffer__(PyObject *__pyx_v_self, Py_buffer *__pyx_v_info); /*proto*/
static CYTHON_UNUSED void __pyx_pw_5numpy_7ndarray_3__releasebuffer__(PyObject *__pyx_v_self, Py_buffer *__pyx_v_info) {
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__releasebuffer__ (wrapper)", 0);
  __pyx_pf_5numpy_7ndarray_2__releasebuffer__(((PyArrayObject *)__pyx_v_self), ((Py_buffer *)__pyx_v_info));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
}

static void __pyx_pf_5numpy_7ndarray_2__releasebuffer__(PyArrayObject *__pyx_v_self, Py_buffer *__pyx_v_info) {
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  __Pyx_RefNannySetupContext("__releasebuffer__", 0);

  /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":308
 * 
 *         def __releasebuffer__(ndarray self, Py_buffer* info):
 *             if PyArray_HASFIELDS(self):             # <<<<<<<<<<<<<<
 *                 PyObject_Free(info.format)
 *             if sizeof(npy_intp) != sizeof(Py_ssize_t):
 */
  __pyx_t_1 = (PyArray_HASFIELDS(__pyx_v_self) != 0);
  if (__pyx_t_1) {

    /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":309
 *         def __releasebuffer__(ndarray self, Py_buffer* info):
 *             if PyArray_HASFIELDS(self):
 *                 PyObject_Free(info.format)             # <<<<<<<<<<<<<<
 *             if sizeof(npy_intp) != sizeof(Py_ssize_t):
 *                 PyObject_Free(info.strides)
 */
    PyObject_Free(__pyx_v_info->format);

    /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":308
 * 
 *         def __releasebuffer__(ndarray self, Py_buffer* info):
 *             if PyArray_HASFIELDS(self):             # <<<<<<<<<<<<<<
 *                 PyObject_Free(info.format)
 *             if sizeof(npy_intp) != sizeof(Py_ssize_t):
 */
  }

  /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":310
 *             if PyArray_HASFIELDS(self):
 *                 PyObject_Free(info.format)
 *             if sizeof(npy_intp) != sizeof(Py_ssize_t):             # <<<<<<<<<<<<<<
 *                 PyObject_Free(info.strides)
 *                 # info.shape was stored after info.strides in the same block
 */
  __pyx_t_1 = (((sizeof(npy_intp)) != (sizeof(Py_ssize_t))) != 0);
  if (__pyx_t_1) {

    /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":311
 *                 PyObject_Free(info.format)
 *             if sizeof(npy_intp) != sizeof(Py_ssize_t):
 *                 PyObject_Free(info.strides)             # <<<<<<<<<<<<<<
 *                 # info.shape was stored after info.strides in the same block
 * 
 */
    PyObject_Free(__pyx_v_info->strides);

    /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":310
 *             if PyArray_HASFIELDS(self):
 *                 PyObject_Free(info.format)
 *             if sizeof(npy_intp) != sizeof(Py_ssize_t):             # <<<<<<<<<<<<<<
 *                 PyObject_Free(info.strides)
 *                 # info.shape was stored after info.strides in the same block
 */
  }

  /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":307
 *                 f[0] = c'\0' # Terminate format string
 * 
 *         def __releasebuffer__(ndarray self, Py_buffer* info):             # <<<<<<<<<<<<<<
 *             if PyArray_HASFIELDS(self):
 *                 PyObject_Free(info.format)
 */

  /* function exit code */
  __Pyx_RefNannyFinishContext();
}

/* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":788
 * ctypedef npy_cdouble     complex_t
 * 
 * cdef inline object PyArray_MultiIterNew1(a):             # <<<<<<<<<<<<<<
 *     return PyArray_MultiIterNew(1, <void*>a)
 * 
 */

static CYTHON_INLINE PyObject *__pyx_f_5numpy_PyArray_MultiIterNew1(PyObject *__pyx_v_a) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("PyArray_MultiIterNew1", 0);

  /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":789
 * 
 * cdef inline object PyArray_MultiIterNew1(a):
 *     return PyArray_MultiIterNew(1, <void*>a)             # <<<<<<<<<<<<<<
 * 
 * cdef inline object PyArray_MultiIterNew2(a, b):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = PyArray_MultiIterNew(1, ((void *)__pyx_v_a)); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 789, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":788
 * ctypedef npy_cdouble     complex_t
 * 
 * cdef inline object PyArray_MultiIterNew1(a):             # <<<<<<<<<<<<<<
 *     return PyArray_MultiIterNew(1, <void*>a)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("numpy.PyArray_MultiIterNew1", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":791
 *     return PyArray_MultiIterNew(1, <void*>a)
 * 
 * cdef inline object PyArray_MultiIterNew2(a, b):             # <<<<<<<<<<<<<<
 *     return PyArray_MultiIterNew(2, <void*>a, <void*>b)
 * 
 */

static CYTHON_INLINE PyObject *__pyx_f_5numpy_PyArray_MultiIterNew2(PyObject *__pyx_v_a, PyObject *__pyx_v_b) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("PyArray_MultiIterNew2", 0);

  /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":792
 * 
 * cdef inline object PyArray_MultiIterNew2(a, b):
 *     return PyArray_MultiIterNew(2, <void*>a, <void*>b)             # <<<<<<<<<<<<<<
 * 
 * cdef inline object PyArray_MultiIterNew3(a, b, c):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = PyArray_MultiIterNew(2, ((void *)__pyx_v_a), ((void *)__pyx_v_b)); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 792, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":791
 *     return PyArray_MultiIterNew(1, <void*>a)
 * 
 * cdef inline object PyArray_MultiIterNew2(a, b):             # <<<<<<<<<<<<<<
 *     return PyArray_MultiIterNew(2, <void*>a, <void*>b)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("numpy.PyArray_MultiIterNew2", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":794
 *     return PyArray_MultiIterNew(2, <void*>a, <void*>b)
 * 
 * cdef inline object PyArray_MultiIterNew3(a, b, c):             # <<<<<<<<<<<<<<
 *     return PyArray_MultiIterNew(3, <void*>a, <void*>b, <void*> c)
 * 
 */

static CYTHON_INLINE PyObject *__pyx_f_5numpy_PyArray_MultiIterNew3(PyObject *__pyx_v_a, PyObject *__pyx_v_b, PyObject *__pyx_v_c) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("PyArray_MultiIterNew3", 0);

  /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":795
 * 
 * cdef inline object PyArray_MultiIterNew3(a, b, c):
 *     return PyArray_MultiIterNew(3, <void*>a, <void*>b, <void*> c)             # <<<<<<<<<<<<<<
 * 
 * cdef inline object PyArray_MultiIterNew4(a, b, c, d):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = PyArray_MultiIterNew(3, ((void *)__pyx_v_a), ((void *)__pyx_v_b), ((void *)__pyx_v_c)); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 795, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":794
 *     return PyArray_MultiIterNew(2, <void*>a, <void*>b)
 * 
 * cdef inline object PyArray_MultiIterNew3(a, b, c):             # <<<<<<<<<<<<<<
 *     return PyArray_MultiIterNew(3, <void*>a, <void*>b, <void*> c)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("numpy.PyArray_MultiIterNew3", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":797
 *     return PyArray_MultiIterNew(3, <void*>a, <void*>b, <void*> c)
 * 
 * cdef inline object PyArray_MultiIterNew4(a, b, c, d):             # <<<<<<<<<<<<<<
 *     return PyArray_MultiIterNew(4, <void*>a, <void*>b, <void*>c, <void*> d)
 * 
 */

static CYTHON_INLINE PyObject *__pyx_f_5numpy_PyArray_MultiIterNew4(PyObject *__pyx_v_a, PyObject *__pyx_v_b, PyObject *__pyx_v_c, PyObject *__pyx_v_d) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("PyArray_MultiIterNew4", 0);

  /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":798
 * 
 * cdef inline object PyArray_MultiIterNew4(a, b, c, d):
 *     return PyArray_MultiIterNew(4, <void*>a, <void*>b, <void*>c, <void*> d)             # <<<<<<<<<<<<<<
 * 
 * cdef inline object PyArray_MultiIterNew5(a, b, c, d, e):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = PyArray_MultiIterNew(4, ((void *)__pyx_v_a), ((void *)__pyx_v_b), ((void *)__pyx_v_c), ((void *)__pyx_v_d)); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 798, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":797
 *     return PyArray_MultiIterNew(3, <void*>a, <void*>b, <void*> c)
 * 
 * cdef inline object PyArray_MultiIterNew4(a, b, c, d):             # <<<<<<<<<<<<<<
 *     return PyArray_MultiIterNew(4, <void*>a, <void*>b, <void*>c, <void*> d)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("numpy.PyArray_MultiIterNew4", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":800
 *     return PyArray_MultiIterNew(4, <void*>a, <void*>b, <void*>c, <void*> d)
 * 
 * cdef inline object PyArray_MultiIterNew5(a, b, c, d, e):             # <<<<<<<<<<<<<<
 *     return PyArray_MultiIterNew(5, <void*>a, <void*>b, <void*>c, <void*> d, <void*> e)
 * 
 */

static CYTHON_INLINE PyObject *__pyx_f_5numpy_PyArray_MultiIterNew5(PyObject *__pyx_v_a, PyObject *__pyx_v_b, PyObject *__pyx_v_c, PyObject *__pyx_v_d, PyObject *__pyx_v_e) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("PyArray_MultiIterNew5", 0);

  /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":801
 * 
 * cdef inline object PyArray_MultiIterNew5(a, b, c, d, e):
 *     return PyArray_MultiIterNew(5, <void*>a, <void*>b, <void*>c, <void*> d, <void*> e)             # <<<<<<<<<<<<<<
 * 
 * cdef inline tuple PyDataType_SHAPE(dtype d):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = PyArray_MultiIterNew(5, ((void *)__pyx_v_a), ((void *)__pyx_v_b), ((void *)__pyx_v_c), ((void *)__pyx_v_d), ((void *)__pyx_v_e)); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 801, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":800
 *     return PyArray_MultiIterNew(4, <void*>a, <void*>b, <void*>c, <void*> d)
 * 
 * cdef inline object PyArray_MultiIterNew5(a, b, c, d, e):             # <<<<<<<<<<<<<<
 *     return PyArray_MultiIterNew(5, <void*>a, <void*>b, <void*>c, <void*> d, <void*> e)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("numpy.PyArray_MultiIterNew5", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":803
 *     return PyArray_MultiIterNew(5, <void*>a, <void*>b, <void*>c, <void*> d, <void*> e)
 * 
 * cdef inline tuple PyDataType_SHAPE(dtype d):             # <<<<<<<<<<<<<<
 *     if PyDataType_HASSUBARRAY(d):
 *         return <tuple>d.subarray.shape
 */

static CYTHON_INLINE PyObject *__pyx_f_5numpy_PyDataType_SHAPE(PyArray_Descr *__pyx_v_d) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  __Pyx_RefNannySetupContext("PyDataType_SHAPE", 0);

  /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":804
 * 
 * cdef inline tuple PyDataType_SHAPE(dtype d):
 *     if PyDataType_HASSUBARRAY(d):             # <<<<<<<<<<<<<<
 *         return <tuple>d.subarray.shape
 *     else:
 */
  __pyx_t_1 = (PyDataType_HASSUBARRAY(__pyx_v_d) != 0);
  if (__pyx_t_1) {

    /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":805
 * cdef inline tuple PyDataType_SHAPE(dtype d):
 *     if PyDataType_HASSUBARRAY(d):
 *         return <tuple>d.subarray.shape             # <<<<<<<<<<<<<<
 *     else:
 *         return ()
 */
    __Pyx_XDECREF(__pyx_r);
    __Pyx_INCREF(((PyObject*)__pyx_v_d->subarray->shape));
    __pyx_r = ((PyObject*)__pyx_v_d->subarray->shape);
    goto __pyx_L0;

    /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":804
 * 
 * cdef inline tuple PyDataType_SHAPE(dtype d):
 *     if PyDataType_HASSUBARRAY(d):             # <<<<<<<<<<<<<<
 *         return <tuple>d.subarray.shape
 *     else:
 */
  }

  /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":807
 *         return <tuple>d.subarray.shape
 *     else:
 *         return ()             # <<<<<<<<<<<<<<
 * 
 * cdef inline char* _util_dtypestring(dtype descr, char* f, char* end, int* offset) except NULL:
 */
  /*else*/ {
    __Pyx_XDECREF(__pyx_r);
    __Pyx_INCREF(__pyx_empty_tuple);
    __pyx_r = __pyx_empty_tuple;
    goto __pyx_L0;
  }

  /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":803
 *     return PyArray_MultiIterNew(5, <void*>a, <void*>b, <void*>c, <void*> d, <void*> e)
 * 
 * cdef inline tuple PyDataType_SHAPE(dtype d):             # <<<<<<<<<<<<<<
 *     if PyDataType_HASSUBARRAY(d):
 *         return <tuple>d.subarray.shape
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":809
 *         return ()
 * 
 * cdef inline char* _util_dtypestring(dtype descr, char* f, char* end, int* offset) except NULL:             # <<<<<<<<<<<<<<
 *     # Recursive utility function used in __getbuffer__ to get format
 *     # string. The new location in the format string is returned.
 */

static CYTHON_INLINE char *__pyx_f_5numpy__util_dtypestring(PyArray_Descr *__pyx_v_descr, char *__pyx_v_f, char *__pyx_v_end, int *__pyx_v_offset) {
  PyArray_Descr *__pyx_v_child = 0;
  int __pyx_v_endian_detector;
  int __pyx_v_little_endian;
  PyObject *__pyx_v_fields = 0;
  PyObject *__pyx_v_childname = NULL;
  PyObject *__pyx_v_new_offset = NULL;
  PyObject *__pyx_v_t = NULL;
  char *__pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  Py_ssize_t __pyx_t_2;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  int __pyx_t_5;
  int __pyx_t_6;
  int __pyx_t_7;
  long __pyx_t_8;
  char *__pyx_t_9;
  __Pyx_RefNannySetupContext("_util_dtypestring", 0);

  /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":814
 * 
 *     cdef dtype child
 *     cdef int endian_detector = 1             # <<<<<<<<<<<<<<
 *     cdef bint little_endian = ((<char*>&endian_detector)[0] != 0)
 *     cdef tuple fields
 */
  __pyx_v_endian_detector = 1;

  /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":815
 *     cdef dtype child
 *     cdef int endian_detector = 1
 *     cdef bint little_endian = ((<char*>&endian_detector)[0] != 0)             # <<<<<<<<<<<<<<
 *     cdef tuple fields
 * 
 */
  __pyx_v_little_endian = ((((char *)(&__pyx_v_endian_detector))[0]) != 0);

  /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":818
 *     cdef tuple fields
 * 
 *     for childname in descr.names:             # <<<<<<<<<<<<<<
 *         fields = descr.fields[childname]
 *         child, new_offset = fields
 */
  if (unlikely(__pyx_v_descr->names == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "'NoneType' object is not iterable");
    __PYX_ERR(1, 818, __pyx_L1_error)
  }
  __pyx_t_1 = __pyx_v_descr->names; __Pyx_INCREF(__pyx_t_1); __pyx_t_2 = 0;
  for (;;) {
    if (__pyx_t_2 >= PyTuple_GET_SIZE(__pyx_t_1)) break;
    #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    __pyx_t_3 = PyTuple_GET_ITEM(__pyx_t_1, __pyx_t_2); __Pyx_INCREF(__pyx_t_3); __pyx_t_2++; if (unlikely(0 < 0)) __PYX_ERR(1, 818, __pyx_L1_error)
    #else
    __pyx_t_3 = PySequence_ITEM(__pyx_t_1, __pyx_t_2); __pyx_t_2++; if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 818, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    #endif
    __Pyx_XDECREF_SET(__pyx_v_childname, __pyx_t_3);
    __pyx_t_3 = 0;

    /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":819
 * 
 *     for childname in descr.names:
 *         fields = descr.fields[childname]             # <<<<<<<<<<<<<<
 *         child, new_offset = fields
 * 
 */
    if (unlikely(__pyx_v_descr->fields == Py_None)) {
      PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
      __PYX_ERR(1, 819, __pyx_L1_error)
    }
    __pyx_t_3 = __Pyx_PyDict_GetItem(__pyx_v_descr->fields, __pyx_v_childname); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 819, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    if (!(likely(PyTuple_CheckExact(__pyx_t_3))||((__pyx_t_3) == Py_None)||(PyErr_Format(PyExc_TypeError, "Expected %.16s, got %.200s", "tuple", Py_TYPE(__pyx_t_3)->tp_name), 0))) __PYX_ERR(1, 819, __pyx_L1_error)
    __Pyx_XDECREF_SET(__pyx_v_fields, ((PyObject*)__pyx_t_3));
    __pyx_t_3 = 0;

    /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":820
 *     for childname in descr.names:
 *         fields = descr.fields[childname]
 *         child, new_offset = fields             # <<<<<<<<<<<<<<
 * 
 *         if (end - f) - <int>(new_offset - offset[0]) < 15:
 */
    if (likely(__pyx_v_fields != Py_None)) {
      PyObject* sequence = __pyx_v_fields;
      #if !CYTHON_COMPILING_IN_PYPY
      Py_ssize_t size = Py_SIZE(sequence);
      #else
      Py_ssize_t size = PySequence_Size(sequence);
      #endif
      if (unlikely(size != 2)) {
        if (size > 2) __Pyx_RaiseTooManyValuesError(2);
        else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
        __PYX_ERR(1, 820, __pyx_L1_error)
      }
      #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
      __pyx_t_3 = PyTuple_GET_ITEM(sequence, 0); 
      __pyx_t_4 = PyTuple_GET_ITEM(sequence, 1); 
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_4);
      #else
      __pyx_t_3 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 820, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __pyx_t_4 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_4)) __PYX_ERR(1, 820, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      #endif
    } else {
      __Pyx_RaiseNoneNotIterableError(); __PYX_ERR(1, 820, __pyx_L1_error)
    }
    if (!(likely(((__pyx_t_3) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_3, __pyx_ptype_5numpy_dtype))))) __PYX_ERR(1, 820, __pyx_L1_error)
    __Pyx_XDECREF_SET(__pyx_v_child, ((PyArray_Descr *)__pyx_t_3));
    __pyx_t_3 = 0;
    __Pyx_XDECREF_SET(__pyx_v_new_offset, __pyx_t_4);
    __pyx_t_4 = 0;

    /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":822
 *         child, new_offset = fields
 * 
 *         if (end - f) - <int>(new_offset - offset[0]) < 15:             # <<<<<<<<<<<<<<
 *             raise RuntimeError(u"Format string allocated too short, see comment in numpy.pxd")
 * 
 */
    __pyx_t_4 = __Pyx_PyInt_From_int((__pyx_v_offset[0])); if (unlikely(!__pyx_t_4)) __PYX_ERR(1, 822, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_3 = PyNumber_Subtract(__pyx_v_new_offset, __pyx_t_4); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 822, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_t_5 = __Pyx_PyInt_As_int(__pyx_t_3); if (unlikely((__pyx_t_5 == (int)-1) && PyErr_Occurred())) __PYX_ERR(1, 822, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_6 = ((((__pyx_v_end - __pyx_v_f) - ((int)__pyx_t_5)) < 15) != 0);
    if (__pyx_t_6) {

      /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":823
 * 
 *         if (end - f) - <int>(new_offset - offset[0]) < 15:
 *             raise RuntimeError(u"Format string allocated too short, see comment in numpy.pxd")             # <<<<<<<<<<<<<<
 * 
 *         if ((child.byteorder == c'>' and little_endian) or
 */
      __pyx_t_3 = __Pyx_PyObject_Call(__pyx_builtin_RuntimeError, __pyx_tuple__43, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 823, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_Raise(__pyx_t_3, 0, 0, 0);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __PYX_ERR(1, 823, __pyx_L1_error)

      /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":822
 *         child, new_offset = fields
 * 
 *         if (end - f) - <int>(new_offset - offset[0]) < 15:             # <<<<<<<<<<<<<<
 *             raise RuntimeError(u"Format string allocated too short, see comment in numpy.pxd")
 * 
 */
    }

    /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":825
 *             raise RuntimeError(u"Format string allocated too short, see comment in numpy.pxd")
 * 
 *         if ((child.byteorder == c'>' and little_endian) or             # <<<<<<<<<<<<<<
 *             (child.byteorder == c'<' and not little_endian)):
 *             raise ValueError(u"Non-native byte order not supported")
 */
    __pyx_t_7 = ((__pyx_v_child->byteorder == '>') != 0);
    if (!__pyx_t_7) {
      goto __pyx_L8_next_or;
    } else {
    }
    __pyx_t_7 = (__pyx_v_little_endian != 0);
    if (!__pyx_t_7) {
    } else {
      __pyx_t_6 = __pyx_t_7;
      goto __pyx_L7_bool_binop_done;
    }
    __pyx_L8_next_or:;

    /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":826
 * 
 *         if ((child.byteorder == c'>' and little_endian) or
 *             (child.byteorder == c'<' and not little_endian)):             # <<<<<<<<<<<<<<
 *             raise ValueError(u"Non-native byte order not supported")
 *             # One could encode it in the format string and have Cython
 */
    __pyx_t_7 = ((__pyx_v_child->byteorder == '<') != 0);
    if (__pyx_t_7) {
    } else {
      __pyx_t_6 = __pyx_t_7;
      goto __pyx_L7_bool_binop_done;
    }
    __pyx_t_7 = ((!(__pyx_v_little_endian != 0)) != 0);
    __pyx_t_6 = __pyx_t_7;
    __pyx_L7_bool_binop_done:;

    /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":825
 *             raise RuntimeError(u"Format string allocated too short, see comment in numpy.pxd")
 * 
 *         if ((child.byteorder == c'>' and little_endian) or             # <<<<<<<<<<<<<<
 *             (child.byteorder == c'<' and not little_endian)):
 *             raise ValueError(u"Non-native byte order not supported")
 */
    if (__pyx_t_6) {

      /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":827
 *         if ((child.byteorder == c'>' and little_endian) or
 *             (child.byteorder == c'<' and not little_endian)):
 *             raise ValueError(u"Non-native byte order not supported")             # <<<<<<<<<<<<<<
 *             # One could encode it in the format string and have Cython
 *             # complain instead, BUT: < and > in format strings also imply
 */
      __pyx_t_3 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__44, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 827, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_Raise(__pyx_t_3, 0, 0, 0);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __PYX_ERR(1, 827, __pyx_L1_error)

      /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":825
 *             raise RuntimeError(u"Format string allocated too short, see comment in numpy.pxd")
 * 
 *         if ((child.byteorder == c'>' and little_endian) or             # <<<<<<<<<<<<<<
 *             (child.byteorder == c'<' and not little_endian)):
 *             raise ValueError(u"Non-native byte order not supported")
 */
    }

    /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":837
 * 
 *         # Output padding bytes
 *         while offset[0] < new_offset:             # <<<<<<<<<<<<<<
 *             f[0] = 120 # "x"; pad byte
 *             f += 1
 */
    while (1) {
      __pyx_t_3 = __Pyx_PyInt_From_int((__pyx_v_offset[0])); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 837, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __pyx_t_4 = PyObject_RichCompare(__pyx_t_3, __pyx_v_new_offset, Py_LT); __Pyx_XGOTREF(__pyx_t_4); if (unlikely(!__pyx_t_4)) __PYX_ERR(1, 837, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_6 = __Pyx_PyObject_IsTrue(__pyx_t_4); if (unlikely(__pyx_t_6 < 0)) __PYX_ERR(1, 837, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      if (!__pyx_t_6) break;

      /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":838
 *         # Output padding bytes
 *         while offset[0] < new_offset:
 *             f[0] = 120 # "x"; pad byte             # <<<<<<<<<<<<<<
 *             f += 1
 *             offset[0] += 1
 */
      (__pyx_v_f[0]) = 0x78;

      /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":839
 *         while offset[0] < new_offset:
 *             f[0] = 120 # "x"; pad byte
 *             f += 1             # <<<<<<<<<<<<<<
 *             offset[0] += 1
 * 
 */
      __pyx_v_f = (__pyx_v_f + 1);

      /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":840
 *             f[0] = 120 # "x"; pad byte
 *             f += 1
 *             offset[0] += 1             # <<<<<<<<<<<<<<
 * 
 *         offset[0] += child.itemsize
 */
      __pyx_t_8 = 0;
      (__pyx_v_offset[__pyx_t_8]) = ((__pyx_v_offset[__pyx_t_8]) + 1);
    }

    /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":842
 *             offset[0] += 1
 * 
 *         offset[0] += child.itemsize             # <<<<<<<<<<<<<<
 * 
 *         if not PyDataType_HASFIELDS(child):
 */
    __pyx_t_8 = 0;
    (__pyx_v_offset[__pyx_t_8]) = ((__pyx_v_offset[__pyx_t_8]) + __pyx_v_child->elsize);

    /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":844
 *         offset[0] += child.itemsize
 * 
 *         if not PyDataType_HASFIELDS(child):             # <<<<<<<<<<<<<<
 *             t = child.type_num
 *             if end - f < 5:
 */
    __pyx_t_6 = ((!(PyDataType_HASFIELDS(__pyx_v_child) != 0)) != 0);
    if (__pyx_t_6) {

      /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":845
 * 
 *         if not PyDataType_HASFIELDS(child):
 *             t = child.type_num             # <<<<<<<<<<<<<<
 *             if end - f < 5:
 *                 raise RuntimeError(u"Format string allocated too short.")
 */
      __pyx_t_4 = __Pyx_PyInt_From_int(__pyx_v_child->type_num); if (unlikely(!__pyx_t_4)) __PYX_ERR(1, 845, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_XDECREF_SET(__pyx_v_t, __pyx_t_4);
      __pyx_t_4 = 0;

      /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":846
 *         if not PyDataType_HASFIELDS(child):
 *             t = child.type_num
 *             if end - f < 5:             # <<<<<<<<<<<<<<
 *                 raise RuntimeError(u"Format string allocated too short.")
 * 
 */
      __pyx_t_6 = (((__pyx_v_end - __pyx_v_f) < 5) != 0);
      if (__pyx_t_6) {

        /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":847
 *             t = child.type_num
 *             if end - f < 5:
 *                 raise RuntimeError(u"Format string allocated too short.")             # <<<<<<<<<<<<<<
 * 
 *             # Until ticket #99 is fixed, use integers to avoid warnings
 */
        __pyx_t_4 = __Pyx_PyObject_Call(__pyx_builtin_RuntimeError, __pyx_tuple__45, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(1, 847, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_4);
        __Pyx_Raise(__pyx_t_4, 0, 0, 0);
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
        __PYX_ERR(1, 847, __pyx_L1_error)

        /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":846
 *         if not PyDataType_HASFIELDS(child):
 *             t = child.type_num
 *             if end - f < 5:             # <<<<<<<<<<<<<<
 *                 raise RuntimeError(u"Format string allocated too short.")
 * 
 */
      }

      /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":850
 * 
 *             # Until ticket #99 is fixed, use integers to avoid warnings
 *             if   t == NPY_BYTE:        f[0] =  98 #"b"             # <<<<<<<<<<<<<<
 *             elif t == NPY_UBYTE:       f[0] =  66 #"B"
 *             elif t == NPY_SHORT:       f[0] = 104 #"h"
 */
      __pyx_t_4 = __Pyx_PyInt_From_enum__NPY_TYPES(NPY_BYTE); if (unlikely(!__pyx_t_4)) __PYX_ERR(1, 850, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __pyx_t_3 = PyObject_RichCompare(__pyx_v_t, __pyx_t_4, Py_EQ); __Pyx_XGOTREF(__pyx_t_3); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 850, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __pyx_t_6 = __Pyx_PyObject_IsTrue(__pyx_t_3); if (unlikely(__pyx_t_6 < 0)) __PYX_ERR(1, 850, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      if (__pyx_t_6) {
        (__pyx_v_f[0]) = 98;
        goto __pyx_L15;
      }

      /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":851
 *             # Until ticket #99 is fixed, use integers to avoid warnings
 *             if   t == NPY_BYTE:        f[0] =  98 #"b"
 *             elif t == NPY_UBYTE:       f[0] =  66 #"B"             # <<<<<<<<<<<<<<
 *             elif t == NPY_SHORT:       f[0] = 104 #"h"
 *             elif t == NPY_USHORT:      f[0] =  72 #"H"
 */
      __pyx_t_3 = __Pyx_PyInt_From_enum__NPY_TYPES(NPY_UBYTE); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 851, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __pyx_t_4 = PyObject_RichCompare(__pyx_v_t, __pyx_t_3, Py_EQ); __Pyx_XGOTREF(__pyx_t_4); if (unlikely(!__pyx_t_4)) __PYX_ERR(1, 851, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_6 = __Pyx_PyObject_IsTrue(__pyx_t_4); if (unlikely(__pyx_t_6 < 0)) __PYX_ERR(1, 851, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      if (__pyx_t_6) {
        (__pyx_v_f[0]) = 66;
        goto __pyx_L15;
      }

      /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":852
 *             if   t == NPY_BYTE:        f[0] =  98 #"b"
 *             elif t == NPY_UBYTE:       f[0] =  66 #"B"
 *             elif t == NPY_SHORT:       f[0] = 104 #"h"             # <<<<<<<<<<<<<<
 *             elif t == NPY_USHORT:      f[0] =  72 #"H"
 *             elif t == NPY_INT:         f[0] = 105 #"i"
 */
      __pyx_t_4 = __Pyx_PyInt_From_enum__NPY_TYPES(NPY_SHORT); if (unlikely(!__pyx_t_4)) __PYX_ERR(1, 852, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __pyx_t_3 = PyObject_RichCompare(__pyx_v_t, __pyx_t_4, Py_EQ); __Pyx_XGOTREF(__pyx_t_3); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 852, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __pyx_t_6 = __Pyx_PyObject_IsTrue(__pyx_t_3); if (unlikely(__pyx_t_6 < 0)) __PYX_ERR(1, 852, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      if (__pyx_t_6) {
        (__pyx_v_f[0]) = 0x68;
        goto __pyx_L15;
      }

      /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":853
 *             elif t == NPY_UBYTE:       f[0] =  66 #"B"
 *             elif t == NPY_SHORT:       f[0] = 104 #"h"
 *             elif t == NPY_USHORT:      f[0] =  72 #"H"             # <<<<<<<<<<<<<<
 *             elif t == NPY_INT:         f[0] = 105 #"i"
 *             elif t == NPY_UINT:        f[0] =  73 #"I"
 */
      __pyx_t_3 = __Pyx_PyInt_From_enum__NPY_TYPES(NPY_USHORT); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 853, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __pyx_t_4 = PyObject_RichCompare(__pyx_v_t, __pyx_t_3, Py_EQ); __Pyx_XGOTREF(__pyx_t_4); if (unlikely(!__pyx_t_4)) __PYX_ERR(1, 853, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_6 = __Pyx_PyObject_IsTrue(__pyx_t_4); if (unlikely(__pyx_t_6 < 0)) __PYX_ERR(1, 853, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      if (__pyx_t_6) {
        (__pyx_v_f[0]) = 72;
        goto __pyx_L15;
      }

      /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":854
 *             elif t == NPY_SHORT:       f[0] = 104 #"h"
 *             elif t == NPY_USHORT:      f[0] =  72 #"H"
 *             elif t == NPY_INT:         f[0] = 105 #"i"             # <<<<<<<<<<<<<<
 *             elif t == NPY_UINT:        f[0] =  73 #"I"
 *             elif t == NPY_LONG:        f[0] = 108 #"l"
 */
      __pyx_t_4 = __Pyx_PyInt_From_enum__NPY_TYPES(NPY_INT); if (unlikely(!__pyx_t_4)) __PYX_ERR(1, 854, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __pyx_t_3 = PyObject_RichCompare(__pyx_v_t, __pyx_t_4, Py_EQ); __Pyx_XGOTREF(__pyx_t_3); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 854, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __pyx_t_6 = __Pyx_PyObject_IsTrue(__pyx_t_3); if (unlikely(__pyx_t_6 < 0)) __PYX_ERR(1, 854, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      if (__pyx_t_6) {
        (__pyx_v_f[0]) = 0x69;
        goto __pyx_L15;
      }

      /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":855
 *             elif t == NPY_USHORT:      f[0] =  72 #"H"
 *             elif t == NPY_INT:         f[0] = 105 #"i"
 *             elif t == NPY_UINT:        f[0] =  73 #"I"             # <<<<<<<<<<<<<<
 *             elif t == NPY_LONG:        f[0] = 108 #"l"
 *             elif t == NPY_ULONG:       f[0] = 76  #"L"
 */
      __pyx_t_3 = __Pyx_PyInt_From_enum__NPY_TYPES(NPY_UINT); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 855, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __pyx_t_4 = PyObject_RichCompare(__pyx_v_t, __pyx_t_3, Py_EQ); __Pyx_XGOTREF(__pyx_t_4); if (unlikely(!__pyx_t_4)) __PYX_ERR(1, 855, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_6 = __Pyx_PyObject_IsTrue(__pyx_t_4); if (unlikely(__pyx_t_6 < 0)) __PYX_ERR(1, 855, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      if (__pyx_t_6) {
        (__pyx_v_f[0]) = 73;
        goto __pyx_L15;
      }

      /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":856
 *             elif t == NPY_INT:         f[0] = 105 #"i"
 *             elif t == NPY_UINT:        f[0] =  73 #"I"
 *             elif t == NPY_LONG:        f[0] = 108 #"l"             # <<<<<<<<<<<<<<
 *             elif t == NPY_ULONG:       f[0] = 76  #"L"
 *             elif t == NPY_LONGLONG:    f[0] = 113 #"q"
 */
      __pyx_t_4 = __Pyx_PyInt_From_enum__NPY_TYPES(NPY_LONG); if (unlikely(!__pyx_t_4)) __PYX_ERR(1, 856, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __pyx_t_3 = PyObject_RichCompare(__pyx_v_t, __pyx_t_4, Py_EQ); __Pyx_XGOTREF(__pyx_t_3); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 856, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __pyx_t_6 = __Pyx_PyObject_IsTrue(__pyx_t_3); if (unlikely(__pyx_t_6 < 0)) __PYX_ERR(1, 856, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      if (__pyx_t_6) {
        (__pyx_v_f[0]) = 0x6C;
        goto __pyx_L15;
      }

      /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":857
 *             elif t == NPY_UINT:        f[0] =  73 #"I"
 *             elif t == NPY_LONG:        f[0] = 108 #"l"
 *             elif t == NPY_ULONG:       f[0] = 76  #"L"             # <<<<<<<<<<<<<<
 *             elif t == NPY_LONGLONG:    f[0] = 113 #"q"
 *             elif t == NPY_ULONGLONG:   f[0] = 81  #"Q"
 */
      __pyx_t_3 = __Pyx_PyInt_From_enum__NPY_TYPES(NPY_ULONG); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 857, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __pyx_t_4 = PyObject_RichCompare(__pyx_v_t, __pyx_t_3, Py_EQ); __Pyx_XGOTREF(__pyx_t_4); if (unlikely(!__pyx_t_4)) __PYX_ERR(1, 857, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_6 = __Pyx_PyObject_IsTrue(__pyx_t_4); if (unlikely(__pyx_t_6 < 0)) __PYX_ERR(1, 857, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      if (__pyx_t_6) {
        (__pyx_v_f[0]) = 76;
        goto __pyx_L15;
      }

      /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":858
 *             elif t == NPY_LONG:        f[0] = 108 #"l"
 *             elif t == NPY_ULONG:       f[0] = 76  #"L"
 *             elif t == NPY_LONGLONG:    f[0] = 113 #"q"             # <<<<<<<<<<<<<<
 *             elif t == NPY_ULONGLONG:   f[0] = 81  #"Q"
 *             elif t == NPY_FLOAT:       f[0] = 102 #"f"
 */
      __pyx_t_4 = __Pyx_PyInt_From_enum__NPY_TYPES(NPY_LONGLONG); if (unlikely(!__pyx_t_4)) __PYX_ERR(1, 858, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __pyx_t_3 = PyObject_RichCompare(__pyx_v_t, __pyx_t_4, Py_EQ); __Pyx_XGOTREF(__pyx_t_3); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 858, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __pyx_t_6 = __Pyx_PyObject_IsTrue(__pyx_t_3); if (unlikely(__pyx_t_6 < 0)) __PYX_ERR(1, 858, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      if (__pyx_t_6) {
        (__pyx_v_f[0]) = 0x71;
        goto __pyx_L15;
      }

      /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":859
 *             elif t == NPY_ULONG:       f[0] = 76  #"L"
 *             elif t == NPY_LONGLONG:    f[0] = 113 #"q"
 *             elif t == NPY_ULONGLONG:   f[0] = 81  #"Q"             # <<<<<<<<<<<<<<
 *             elif t == NPY_FLOAT:       f[0] = 102 #"f"
 *             elif t == NPY_DOUBLE:      f[0] = 100 #"d"
 */
      __pyx_t_3 = __Pyx_PyInt_From_enum__NPY_TYPES(NPY_ULONGLONG); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 859, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __pyx_t_4 = PyObject_RichCompare(__pyx_v_t, __pyx_t_3, Py_EQ); __Pyx_XGOTREF(__pyx_t_4); if (unlikely(!__pyx_t_4)) __PYX_ERR(1, 859, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_6 = __Pyx_PyObject_IsTrue(__pyx_t_4); if (unlikely(__pyx_t_6 < 0)) __PYX_ERR(1, 859, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      if (__pyx_t_6) {
        (__pyx_v_f[0]) = 81;
        goto __pyx_L15;
      }

      /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":860
 *             elif t == NPY_LONGLONG:    f[0] = 113 #"q"
 *             elif t == NPY_ULONGLONG:   f[0] = 81  #"Q"
 *             elif t == NPY_FLOAT:       f[0] = 102 #"f"             # <<<<<<<<<<<<<<
 *             elif t == NPY_DOUBLE:      f[0] = 100 #"d"
 *             elif t == NPY_LONGDOUBLE:  f[0] = 103 #"g"
 */
      __pyx_t_4 = __Pyx_PyInt_From_enum__NPY_TYPES(NPY_FLOAT); if (unlikely(!__pyx_t_4)) __PYX_ERR(1, 860, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __pyx_t_3 = PyObject_RichCompare(__pyx_v_t, __pyx_t_4, Py_EQ); __Pyx_XGOTREF(__pyx_t_3); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 860, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __pyx_t_6 = __Pyx_PyObject_IsTrue(__pyx_t_3); if (unlikely(__pyx_t_6 < 0)) __PYX_ERR(1, 860, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      if (__pyx_t_6) {
        (__pyx_v_f[0]) = 0x66;
        goto __pyx_L15;
      }

      /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":861
 *             elif t == NPY_ULONGLONG:   f[0] = 81  #"Q"
 *             elif t == NPY_FLOAT:       f[0] = 102 #"f"
 *             elif t == NPY_DOUBLE:      f[0] = 100 #"d"             # <<<<<<<<<<<<<<
 *             elif t == NPY_LONGDOUBLE:  f[0] = 103 #"g"
 *             elif t == NPY_CFLOAT:      f[0] = 90; f[1] = 102; f += 1 # Zf
 */
      __pyx_t_3 = __Pyx_PyInt_From_enum__NPY_TYPES(NPY_DOUBLE); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 861, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __pyx_t_4 = PyObject_RichCompare(__pyx_v_t, __pyx_t_3, Py_EQ); __Pyx_XGOTREF(__pyx_t_4); if (unlikely(!__pyx_t_4)) __PYX_ERR(1, 861, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_6 = __Pyx_PyObject_IsTrue(__pyx_t_4); if (unlikely(__pyx_t_6 < 0)) __PYX_ERR(1, 861, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      if (__pyx_t_6) {
        (__pyx_v_f[0]) = 0x64;
        goto __pyx_L15;
      }

      /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":862
 *             elif t == NPY_FLOAT:       f[0] = 102 #"f"
 *             elif t == NPY_DOUBLE:      f[0] = 100 #"d"
 *             elif t == NPY_LONGDOUBLE:  f[0] = 103 #"g"             # <<<<<<<<<<<<<<
 *             elif t == NPY_CFLOAT:      f[0] = 90; f[1] = 102; f += 1 # Zf
 *             elif t == NPY_CDOUBLE:     f[0] = 90; f[1] = 100; f += 1 # Zd
 */
      __pyx_t_4 = __Pyx_PyInt_From_enum__NPY_TYPES(NPY_LONGDOUBLE); if (unlikely(!__pyx_t_4)) __PYX_ERR(1, 862, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __pyx_t_3 = PyObject_RichCompare(__pyx_v_t, __pyx_t_4, Py_EQ); __Pyx_XGOTREF(__pyx_t_3); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 862, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __pyx_t_6 = __Pyx_PyObject_IsTrue(__pyx_t_3); if (unlikely(__pyx_t_6 < 0)) __PYX_ERR(1, 862, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      if (__pyx_t_6) {
        (__pyx_v_f[0]) = 0x67;
        goto __pyx_L15;
      }

      /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":863
 *             elif t == NPY_DOUBLE:      f[0] = 100 #"d"
 *             elif t == NPY_LONGDOUBLE:  f[0] = 103 #"g"
 *             elif t == NPY_CFLOAT:      f[0] = 90; f[1] = 102; f += 1 # Zf             # <<<<<<<<<<<<<<
 *             elif t == NPY_CDOUBLE:     f[0] = 90; f[1] = 100; f += 1 # Zd
 *             elif t == NPY_CLONGDOUBLE: f[0] = 90; f[1] = 103; f += 1 # Zg
 */
      __pyx_t_3 = __Pyx_PyInt_From_enum__NPY_TYPES(NPY_CFLOAT); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 863, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __pyx_t_4 = PyObject_RichCompare(__pyx_v_t, __pyx_t_3, Py_EQ); __Pyx_XGOTREF(__pyx_t_4); if (unlikely(!__pyx_t_4)) __PYX_ERR(1, 863, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_6 = __Pyx_PyObject_IsTrue(__pyx_t_4); if (unlikely(__pyx_t_6 < 0)) __PYX_ERR(1, 863, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      if (__pyx_t_6) {
        (__pyx_v_f[0]) = 90;
        (__pyx_v_f[1]) = 0x66;
        __pyx_v_f = (__pyx_v_f + 1);
        goto __pyx_L15;
      }

      /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":864
 *             elif t == NPY_LONGDOUBLE:  f[0] = 103 #"g"
 *             elif t == NPY_CFLOAT:      f[0] = 90; f[1] = 102; f += 1 # Zf
 *             elif t == NPY_CDOUBLE:     f[0] = 90; f[1] = 100; f += 1 # Zd             # <<<<<<<<<<<<<<
 *             elif t == NPY_CLONGDOUBLE: f[0] = 90; f[1] = 103; f += 1 # Zg
 *             elif t == NPY_OBJECT:      f[0] = 79 #"O"
 */
      __pyx_t_4 = __Pyx_PyInt_From_enum__NPY_TYPES(NPY_CDOUBLE); if (unlikely(!__pyx_t_4)) __PYX_ERR(1, 864, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __pyx_t_3 = PyObject_RichCompare(__pyx_v_t, __pyx_t_4, Py_EQ); __Pyx_XGOTREF(__pyx_t_3); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 864, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __pyx_t_6 = __Pyx_PyObject_IsTrue(__pyx_t_3); if (unlikely(__pyx_t_6 < 0)) __PYX_ERR(1, 864, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      if (__pyx_t_6) {
        (__pyx_v_f[0]) = 90;
        (__pyx_v_f[1]) = 0x64;
        __pyx_v_f = (__pyx_v_f + 1);
        goto __pyx_L15;
      }

      /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":865
 *             elif t == NPY_CFLOAT:      f[0] = 90; f[1] = 102; f += 1 # Zf
 *             elif t == NPY_CDOUBLE:     f[0] = 90; f[1] = 100; f += 1 # Zd
 *             elif t == NPY_CLONGDOUBLE: f[0] = 90; f[1] = 103; f += 1 # Zg             # <<<<<<<<<<<<<<
 *             elif t == NPY_OBJECT:      f[0] = 79 #"O"
 *             else:
 */
      __pyx_t_3 = __Pyx_PyInt_From_enum__NPY_TYPES(NPY_CLONGDOUBLE); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 865, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __pyx_t_4 = PyObject_RichCompare(__pyx_v_t, __pyx_t_3, Py_EQ); __Pyx_XGOTREF(__pyx_t_4); if (unlikely(!__pyx_t_4)) __PYX_ERR(1, 865, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_6 = __Pyx_PyObject_IsTrue(__pyx_t_4); if (unlikely(__pyx_t_6 < 0)) __PYX_ERR(1, 865, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      if (__pyx_t_6) {
        (__pyx_v_f[0]) = 90;
        (__pyx_v_f[1]) = 0x67;
        __pyx_v_f = (__pyx_v_f + 1);
        goto __pyx_L15;
      }

      /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":866
 *             elif t == NPY_CDOUBLE:     f[0] = 90; f[1] = 100; f += 1 # Zd
 *             elif t == NPY_CLONGDOUBLE: f[0] = 90; f[1] = 103; f += 1 # Zg
 *             elif t == NPY_OBJECT:      f[0] = 79 #"O"             # <<<<<<<<<<<<<<
 *             else:
 *                 raise ValueError(u"unknown dtype code in numpy.pxd (%d)" % t)
 */
      __pyx_t_4 = __Pyx_PyInt_From_enum__NPY_TYPES(NPY_OBJECT); if (unlikely(!__pyx_t_4)) __PYX_ERR(1, 866, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __pyx_t_3 = PyObject_RichCompare(__pyx_v_t, __pyx_t_4, Py_EQ); __Pyx_XGOTREF(__pyx_t_3); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 866, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __pyx_t_6 = __Pyx_PyObject_IsTrue(__pyx_t_3); if (unlikely(__pyx_t_6 < 0)) __PYX_ERR(1, 866, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      if (__pyx_t_6) {
        (__pyx_v_f[0]) = 79;
        goto __pyx_L15;
      }

      /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":868
 *             elif t == NPY_OBJECT:      f[0] = 79 #"O"
 *             else:
 *                 raise ValueError(u"unknown dtype code in numpy.pxd (%d)" % t)             # <<<<<<<<<<<<<<
 *             f += 1
 *         else:
 */
      /*else*/ {
        __pyx_t_3 = PyUnicode_Format(__pyx_kp_u_unknown_dtype_code_in_numpy_pxd, __pyx_v_t); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 868, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
        __pyx_t_4 = PyTuple_New(1); if (unlikely(!__pyx_t_4)) __PYX_ERR(1, 868, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_4);
        __Pyx_GIVEREF(__pyx_t_3);
        PyTuple_SET_ITEM(__pyx_t_4, 0, __pyx_t_3);
        __pyx_t_3 = 0;
        __pyx_t_3 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_t_4, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 868, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
        __Pyx_Raise(__pyx_t_3, 0, 0, 0);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
        __PYX_ERR(1, 868, __pyx_L1_error)
      }
      __pyx_L15:;

      /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":869
 *             else:
 *                 raise ValueError(u"unknown dtype code in numpy.pxd (%d)" % t)
 *             f += 1             # <<<<<<<<<<<<<<
 *         else:
 *             # Cython ignores struct boundary information ("T{...}"),
 */
      __pyx_v_f = (__pyx_v_f + 1);

      /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":844
 *         offset[0] += child.itemsize
 * 
 *         if not PyDataType_HASFIELDS(child):             # <<<<<<<<<<<<<<
 *             t = child.type_num
 *             if end - f < 5:
 */
      goto __pyx_L13;
    }

    /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":873
 *             # Cython ignores struct boundary information ("T{...}"),
 *             # so don't output it
 *             f = _util_dtypestring(child, f, end, offset)             # <<<<<<<<<<<<<<
 *     return f
 * 
 */
    /*else*/ {
      __pyx_t_9 = __pyx_f_5numpy__util_dtypestring(__pyx_v_child, __pyx_v_f, __pyx_v_end, __pyx_v_offset); if (unlikely(__pyx_t_9 == ((char *)NULL))) __PYX_ERR(1, 873, __pyx_L1_error)
      __pyx_v_f = __pyx_t_9;
    }
    __pyx_L13:;

    /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":818
 *     cdef tuple fields
 * 
 *     for childname in descr.names:             # <<<<<<<<<<<<<<
 *         fields = descr.fields[childname]
 *         child, new_offset = fields
 */
  }
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":874
 *             # so don't output it
 *             f = _util_dtypestring(child, f, end, offset)
 *     return f             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_r = __pyx_v_f;
  goto __pyx_L0;

  /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":809
 *         return ()
 * 
 * cdef inline char* _util_dtypestring(dtype descr, char* f, char* end, int* offset) except NULL:             # <<<<<<<<<<<<<<
 *     # Recursive utility function used in __getbuffer__ to get format
 *     # string. The new location in the format string is returned.
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_AddTraceback("numpy._util_dtypestring", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_child);
  __Pyx_XDECREF(__pyx_v_fields);
  __Pyx_XDECREF(__pyx_v_childname);
  __Pyx_XDECREF(__pyx_v_new_offset);
  __Pyx_XDECREF(__pyx_v_t);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":990
 * 
 * 
 * cdef inline void set_array_base(ndarray arr, object base):             # <<<<<<<<<<<<<<
 *      cdef PyObject* baseptr
 *      if base is None:
 */

static CYTHON_INLINE void __pyx_f_5numpy_set_array_base(PyArrayObject *__pyx_v_arr, PyObject *__pyx_v_base) {
  PyObject *__pyx_v_baseptr;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_t_2;
  __Pyx_RefNannySetupContext("set_array_base", 0);

  /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":992
 * cdef inline void set_array_base(ndarray arr, object base):
 *      cdef PyObject* baseptr
 *      if base is None:             # <<<<<<<<<<<<<<
 *          baseptr = NULL
 *      else:
 */
  __pyx_t_1 = (__pyx_v_base == Py_None);
  __pyx_t_2 = (__pyx_t_1 != 0);
  if (__pyx_t_2) {

    /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":993
 *      cdef PyObject* baseptr
 *      if base is None:
 *          baseptr = NULL             # <<<<<<<<<<<<<<
 *      else:
 *          Py_INCREF(base) # important to do this before decref below!
 */
    __pyx_v_baseptr = NULL;

    /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":992
 * cdef inline void set_array_base(ndarray arr, object base):
 *      cdef PyObject* baseptr
 *      if base is None:             # <<<<<<<<<<<<<<
 *          baseptr = NULL
 *      else:
 */
    goto __pyx_L3;
  }

  /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":995
 *          baseptr = NULL
 *      else:
 *          Py_INCREF(base) # important to do this before decref below!             # <<<<<<<<<<<<<<
 *          baseptr = <PyObject*>base
 *      Py_XDECREF(arr.base)
 */
  /*else*/ {
    Py_INCREF(__pyx_v_base);

    /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":996
 *      else:
 *          Py_INCREF(base) # important to do this before decref below!
 *          baseptr = <PyObject*>base             # <<<<<<<<<<<<<<
 *      Py_XDECREF(arr.base)
 *      arr.base = baseptr
 */
    __pyx_v_baseptr = ((PyObject *)__pyx_v_base);
  }
  __pyx_L3:;

  /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":997
 *          Py_INCREF(base) # important to do this before decref below!
 *          baseptr = <PyObject*>base
 *      Py_XDECREF(arr.base)             # <<<<<<<<<<<<<<
 *      arr.base = baseptr
 * 
 */
  Py_XDECREF(__pyx_v_arr->base);

  /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":998
 *          baseptr = <PyObject*>base
 *      Py_XDECREF(arr.base)
 *      arr.base = baseptr             # <<<<<<<<<<<<<<
 * 
 * cdef inline object get_array_base(ndarray arr):
 */
  __pyx_v_arr->base = __pyx_v_baseptr;

  /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":990
 * 
 * 
 * cdef inline void set_array_base(ndarray arr, object base):             # <<<<<<<<<<<<<<
 *      cdef PyObject* baseptr
 *      if base is None:
 */

  /* function exit code */
  __Pyx_RefNannyFinishContext();
}

/* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":1000
 *      arr.base = baseptr
 * 
 * cdef inline object get_array_base(ndarray arr):             # <<<<<<<<<<<<<<
 *     if arr.base is NULL:
 *         return None
 */

static CYTHON_INLINE PyObject *__pyx_f_5numpy_get_array_base(PyArrayObject *__pyx_v_arr) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  __Pyx_RefNannySetupContext("get_array_base", 0);

  /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":1001
 * 
 * cdef inline object get_array_base(ndarray arr):
 *     if arr.base is NULL:             # <<<<<<<<<<<<<<
 *         return None
 *     else:
 */
  __pyx_t_1 = ((__pyx_v_arr->base == NULL) != 0);
  if (__pyx_t_1) {

    /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":1002
 * cdef inline object get_array_base(ndarray arr):
 *     if arr.base is NULL:
 *         return None             # <<<<<<<<<<<<<<
 *     else:
 *         return <object>arr.base
 */
    __Pyx_XDECREF(__pyx_r);
    __Pyx_INCREF(Py_None);
    __pyx_r = Py_None;
    goto __pyx_L0;

    /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":1001
 * 
 * cdef inline object get_array_base(ndarray arr):
 *     if arr.base is NULL:             # <<<<<<<<<<<<<<
 *         return None
 *     else:
 */
  }

  /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":1004
 *         return None
 *     else:
 *         return <object>arr.base             # <<<<<<<<<<<<<<
 * 
 * 
 */
  /*else*/ {
    __Pyx_XDECREF(__pyx_r);
    __Pyx_INCREF(((PyObject *)__pyx_v_arr->base));
    __pyx_r = ((PyObject *)__pyx_v_arr->base);
    goto __pyx_L0;
  }

  /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":1000
 *      arr.base = baseptr
 * 
 * cdef inline object get_array_base(ndarray arr):             # <<<<<<<<<<<<<<
 *     if arr.base is NULL:
 *         return None
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":1009
 * # Versions of the import_* functions which are more suitable for
 * # Cython code.
 * cdef inline int import_array() except -1:             # <<<<<<<<<<<<<<
 *     try:
 *         _import_array()
 */

static CYTHON_INLINE int __pyx_f_5numpy_import_array(void) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  PyObject *__pyx_t_8 = NULL;
  __Pyx_RefNannySetupContext("import_array", 0);

  /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":1010
 * # Cython code.
 * cdef inline int import_array() except -1:
 *     try:             # <<<<<<<<<<<<<<
 *         _import_array()
 *     except Exception:
 */
  {
    __Pyx_PyThreadState_declare
    __Pyx_PyThreadState_assign
    __Pyx_ExceptionSave(&__pyx_t_1, &__pyx_t_2, &__pyx_t_3);
    __Pyx_XGOTREF(__pyx_t_1);
    __Pyx_XGOTREF(__pyx_t_2);
    __Pyx_XGOTREF(__pyx_t_3);
    /*try:*/ {

      /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":1011
 * cdef inline int import_array() except -1:
 *     try:
 *         _import_array()             # <<<<<<<<<<<<<<
 *     except Exception:
 *         raise ImportError("numpy.core.multiarray failed to import")
 */
      __pyx_t_4 = _import_array(); if (unlikely(__pyx_t_4 == ((int)-1))) __PYX_ERR(1, 1011, __pyx_L3_error)

      /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":1010
 * # Cython code.
 * cdef inline int import_array() except -1:
 *     try:             # <<<<<<<<<<<<<<
 *         _import_array()
 *     except Exception:
 */
    }
    __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
    goto __pyx_L8_try_end;
    __pyx_L3_error:;

    /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":1012
 *     try:
 *         _import_array()
 *     except Exception:             # <<<<<<<<<<<<<<
 *         raise ImportError("numpy.core.multiarray failed to import")
 * 
 */
    __pyx_t_4 = __Pyx_PyErr_ExceptionMatches(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])));
    if (__pyx_t_4) {
      __Pyx_AddTraceback("numpy.import_array", __pyx_clineno, __pyx_lineno, __pyx_filename);
      if (__Pyx_GetException(&__pyx_t_5, &__pyx_t_6, &__pyx_t_7) < 0) __PYX_ERR(1, 1012, __pyx_L5_except_error)
      __Pyx_GOTREF(__pyx_t_5);
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_GOTREF(__pyx_t_7);

      /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":1013
 *         _import_array()
 *     except Exception:
 *         raise ImportError("numpy.core.multiarray failed to import")             # <<<<<<<<<<<<<<
 * 
 * cdef inline int import_umath() except -1:
 */
      __pyx_t_8 = __Pyx_PyObject_Call(__pyx_builtin_ImportError, __pyx_tuple__46, NULL); if (unlikely(!__pyx_t_8)) __PYX_ERR(1, 1013, __pyx_L5_except_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_Raise(__pyx_t_8, 0, 0, 0);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __PYX_ERR(1, 1013, __pyx_L5_except_error)
    }
    goto __pyx_L5_except_error;
    __pyx_L5_except_error:;

    /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":1010
 * # Cython code.
 * cdef inline int import_array() except -1:
 *     try:             # <<<<<<<<<<<<<<
 *         _import_array()
 *     except Exception:
 */
    __Pyx_XGIVEREF(__pyx_t_1);
    __Pyx_XGIVEREF(__pyx_t_2);
    __Pyx_XGIVEREF(__pyx_t_3);
    __Pyx_ExceptionReset(__pyx_t_1, __pyx_t_2, __pyx_t_3);
    goto __pyx_L1_error;
    __pyx_L8_try_end:;
  }

  /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":1009
 * # Versions of the import_* functions which are more suitable for
 * # Cython code.
 * cdef inline int import_array() except -1:             # <<<<<<<<<<<<<<
 *     try:
 *         _import_array()
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_AddTraceback("numpy.import_array", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":1015
 *         raise ImportError("numpy.core.multiarray failed to import")
 * 
 * cdef inline int import_umath() except -1:             # <<<<<<<<<<<<<<
 *     try:
 *         _import_umath()
 */

static CYTHON_INLINE int __pyx_f_5numpy_import_umath(void) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  PyObject *__pyx_t_8 = NULL;
  __Pyx_RefNannySetupContext("import_umath", 0);

  /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":1016
 * 
 * cdef inline int import_umath() except -1:
 *     try:             # <<<<<<<<<<<<<<
 *         _import_umath()
 *     except Exception:
 */
  {
    __Pyx_PyThreadState_declare
    __Pyx_PyThreadState_assign
    __Pyx_ExceptionSave(&__pyx_t_1, &__pyx_t_2, &__pyx_t_3);
    __Pyx_XGOTREF(__pyx_t_1);
    __Pyx_XGOTREF(__pyx_t_2);
    __Pyx_XGOTREF(__pyx_t_3);
    /*try:*/ {

      /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":1017
 * cdef inline int import_umath() except -1:
 *     try:
 *         _import_umath()             # <<<<<<<<<<<<<<
 *     except Exception:
 *         raise ImportError("numpy.core.umath failed to import")
 */
      __pyx_t_4 = _import_umath(); if (unlikely(__pyx_t_4 == ((int)-1))) __PYX_ERR(1, 1017, __pyx_L3_error)

      /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":1016
 * 
 * cdef inline int import_umath() except -1:
 *     try:             # <<<<<<<<<<<<<<
 *         _import_umath()
 *     except Exception:
 */
    }
    __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
    goto __pyx_L8_try_end;
    __pyx_L3_error:;

    /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":1018
 *     try:
 *         _import_umath()
 *     except Exception:             # <<<<<<<<<<<<<<
 *         raise ImportError("numpy.core.umath failed to import")
 * 
 */
    __pyx_t_4 = __Pyx_PyErr_ExceptionMatches(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])));
    if (__pyx_t_4) {
      __Pyx_AddTraceback("numpy.import_umath", __pyx_clineno, __pyx_lineno, __pyx_filename);
      if (__Pyx_GetException(&__pyx_t_5, &__pyx_t_6, &__pyx_t_7) < 0) __PYX_ERR(1, 1018, __pyx_L5_except_error)
      __Pyx_GOTREF(__pyx_t_5);
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_GOTREF(__pyx_t_7);

      /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":1019
 *         _import_umath()
 *     except Exception:
 *         raise ImportError("numpy.core.umath failed to import")             # <<<<<<<<<<<<<<
 * 
 * cdef inline int import_ufunc() except -1:
 */
      __pyx_t_8 = __Pyx_PyObject_Call(__pyx_builtin_ImportError, __pyx_tuple__47, NULL); if (unlikely(!__pyx_t_8)) __PYX_ERR(1, 1019, __pyx_L5_except_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_Raise(__pyx_t_8, 0, 0, 0);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __PYX_ERR(1, 1019, __pyx_L5_except_error)
    }
    goto __pyx_L5_except_error;
    __pyx_L5_except_error:;

    /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":1016
 * 
 * cdef inline int import_umath() except -1:
 *     try:             # <<<<<<<<<<<<<<
 *         _import_umath()
 *     except Exception:
 */
    __Pyx_XGIVEREF(__pyx_t_1);
    __Pyx_XGIVEREF(__pyx_t_2);
    __Pyx_XGIVEREF(__pyx_t_3);
    __Pyx_ExceptionReset(__pyx_t_1, __pyx_t_2, __pyx_t_3);
    goto __pyx_L1_error;
    __pyx_L8_try_end:;
  }

  /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":1015
 *         raise ImportError("numpy.core.multiarray failed to import")
 * 
 * cdef inline int import_umath() except -1:             # <<<<<<<<<<<<<<
 *     try:
 *         _import_umath()
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_AddTraceback("numpy.import_umath", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":1021
 *         raise ImportError("numpy.core.umath failed to import")
 * 
 * cdef inline int import_ufunc() except -1:             # <<<<<<<<<<<<<<
 *     try:
 *         _import_umath()
 */

static CYTHON_INLINE int __pyx_f_5numpy_import_ufunc(void) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  PyObject *__pyx_t_8 = NULL;
  __Pyx_RefNannySetupContext("import_ufunc", 0);

  /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":1022
 * 
 * cdef inline int import_ufunc() except -1:
 *     try:             # <<<<<<<<<<<<<<
 *         _import_umath()
 *     except Exception:
 */
  {
    __Pyx_PyThreadState_declare
    __Pyx_PyThreadState_assign
    __Pyx_ExceptionSave(&__pyx_t_1, &__pyx_t_2, &__pyx_t_3);
    __Pyx_XGOTREF(__pyx_t_1);
    __Pyx_XGOTREF(__pyx_t_2);
    __Pyx_XGOTREF(__pyx_t_3);
    /*try:*/ {

      /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":1023
 * cdef inline int import_ufunc() except -1:
 *     try:
 *         _import_umath()             # <<<<<<<<<<<<<<
 *     except Exception:
 *         raise ImportError("numpy.core.umath failed to import")
 */
      __pyx_t_4 = _import_umath(); if (unlikely(__pyx_t_4 == ((int)-1))) __PYX_ERR(1, 1023, __pyx_L3_error)

      /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":1022
 * 
 * cdef inline int import_ufunc() except -1:
 *     try:             # <<<<<<<<<<<<<<
 *         _import_umath()
 *     except Exception:
 */
    }
    __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
    goto __pyx_L8_try_end;
    __pyx_L3_error:;

    /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":1024
 *     try:
 *         _import_umath()
 *     except Exception:             # <<<<<<<<<<<<<<
 *         raise ImportError("numpy.core.umath failed to import")
 */
    __pyx_t_4 = __Pyx_PyErr_ExceptionMatches(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])));
    if (__pyx_t_4) {
      __Pyx_AddTraceback("numpy.import_ufunc", __pyx_clineno, __pyx_lineno, __pyx_filename);
      if (__Pyx_GetException(&__pyx_t_5, &__pyx_t_6, &__pyx_t_7) < 0) __PYX_ERR(1, 1024, __pyx_L5_except_error)
      __Pyx_GOTREF(__pyx_t_5);
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_GOTREF(__pyx_t_7);

      /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":1025
 *         _import_umath()
 *     except Exception:
 *         raise ImportError("numpy.core.umath failed to import")             # <<<<<<<<<<<<<<
 */
      __pyx_t_8 = __Pyx_PyObject_Call(__pyx_builtin_ImportError, __pyx_tuple__48, NULL); if (unlikely(!__pyx_t_8)) __PYX_ERR(1, 1025, __pyx_L5_except_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_Raise(__pyx_t_8, 0, 0, 0);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __PYX_ERR(1, 1025, __pyx_L5_except_error)
    }
    goto __pyx_L5_except_error;
    __pyx_L5_except_error:;

    /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":1022
 * 
 * cdef inline int import_ufunc() except -1:
 *     try:             # <<<<<<<<<<<<<<
 *         _import_umath()
 *     except Exception:
 */
    __Pyx_XGIVEREF(__pyx_t_1);
    __Pyx_XGIVEREF(__pyx_t_2);
    __Pyx_XGIVEREF(__pyx_t_3);
    __Pyx_ExceptionReset(__pyx_t_1, __pyx_t_2, __pyx_t_3);
    goto __pyx_L1_error;
    __pyx_L8_try_end:;
  }

  /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":1021
 *         raise ImportError("numpy.core.umath failed to import")
 * 
 * cdef inline int import_ufunc() except -1:             # <<<<<<<<<<<<<<
 *     try:
 *         _import_umath()
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_AddTraceback("numpy.import_ufunc", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_tp_new_5pygpu_8gpuarray_GpuContext(PyTypeObject *t, CYTHON_UNUSED PyObject *a, CYTHON_UNUSED PyObject *k) {
  struct PyGpuContextObject *p;
  PyObject *o;
  if (likely((t->tp_flags & Py_TPFLAGS_IS_ABSTRACT) == 0)) {
    o = (*t->tp_alloc)(t, 0);
  } else {
    o = (PyObject *) PyBaseObject_Type.tp_new(t, __pyx_empty_tuple, 0);
  }
  if (unlikely(!o)) return 0;
  p = ((struct PyGpuContextObject *)o);
  p->__dict__ = PyDict_New(); if (unlikely(!p->__dict__)) goto bad;p->kind = ((PyObject*)Py_None); Py_INCREF(Py_None);
  return o;
  bad:
  Py_DECREF(o); o = 0;
  return NULL;
}

static void __pyx_tp_dealloc_5pygpu_8gpuarray_GpuContext(PyObject *o) {
  struct PyGpuContextObject *p = (struct PyGpuContextObject *)o;
  #if CYTHON_USE_TP_FINALIZE
  if (unlikely(PyType_HasFeature(Py_TYPE(o), Py_TPFLAGS_HAVE_FINALIZE) && Py_TYPE(o)->tp_finalize) && !_PyGC_FINALIZED(o)) {
    if (PyObject_CallFinalizerFromDealloc(o)) return;
  }
  #endif
  PyObject_GC_UnTrack(o);
  {
    PyObject *etype, *eval, *etb;
    PyErr_Fetch(&etype, &eval, &etb);
    ++Py_REFCNT(o);
    __pyx_pw_5pygpu_8gpuarray_10GpuContext_1__dealloc__(o);
    --Py_REFCNT(o);
    PyErr_Restore(etype, eval, etb);
  }
  if (p->__weakref__) PyObject_ClearWeakRefs(o);
  if (p->__dict__) PyDict_Clear(p->__dict__);
  Py_CLEAR(p->__dict__);
  Py_CLEAR(p->kind);
  (*Py_TYPE(o)->tp_free)(o);
}

static int __pyx_tp_traverse_5pygpu_8gpuarray_GpuContext(PyObject *o, visitproc v, void *a) {
  int e;
  struct PyGpuContextObject *p = (struct PyGpuContextObject *)o;
  if (p->__dict__) {
    e = (*v)(p->__dict__, a); if (e) return e;
  }
  return 0;
}

static int __pyx_tp_clear_5pygpu_8gpuarray_GpuContext(PyObject *o) {
  PyObject* tmp;
  struct PyGpuContextObject *p = (struct PyGpuContextObject *)o;
  tmp = ((PyObject*)p->__dict__);
  p->__dict__ = ((PyObject*)Py_None); Py_INCREF(Py_None);
  Py_XDECREF(tmp);
  return 0;
}

static PyObject *__pyx___dict__getter_5pygpu_8gpuarray_GpuContext(PyObject *o, CYTHON_UNUSED void *x) {
  struct PyGpuContextObject *p = (struct PyGpuContextObject *)o;
  if (unlikely(!p->__dict__)){
    p->__dict__ = PyDict_New();
  }
  Py_XINCREF(p->__dict__);
  return p->__dict__;
}

static PyObject *__pyx_getprop_5pygpu_8gpuarray_10GpuContext_ptr(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_5pygpu_8gpuarray_10GpuContext_3ptr_1__get__(o);
}

static PyObject *__pyx_getprop_5pygpu_8gpuarray_10GpuContext_devname(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_5pygpu_8gpuarray_10GpuContext_7devname_1__get__(o);
}

static PyObject *__pyx_getprop_5pygpu_8gpuarray_10GpuContext_unique_id(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_5pygpu_8gpuarray_10GpuContext_9unique_id_1__get__(o);
}

static PyObject *__pyx_getprop_5pygpu_8gpuarray_10GpuContext_lmemsize(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_5pygpu_8gpuarray_10GpuContext_8lmemsize_1__get__(o);
}

static PyObject *__pyx_getprop_5pygpu_8gpuarray_10GpuContext_numprocs(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_5pygpu_8gpuarray_10GpuContext_8numprocs_1__get__(o);
}

static PyObject *__pyx_getprop_5pygpu_8gpuarray_10GpuContext_bin_id(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_5pygpu_8gpuarray_10GpuContext_6bin_id_1__get__(o);
}

static PyObject *__pyx_getprop_5pygpu_8gpuarray_10GpuContext_total_gmem(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_5pygpu_8gpuarray_10GpuContext_10total_gmem_1__get__(o);
}

static PyObject *__pyx_getprop_5pygpu_8gpuarray_10GpuContext_free_gmem(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_5pygpu_8gpuarray_10GpuContext_9free_gmem_1__get__(o);
}

static PyObject *__pyx_getprop_5pygpu_8gpuarray_10GpuContext_maxlsize0(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_5pygpu_8gpuarray_10GpuContext_9maxlsize0_1__get__(o);
}

static PyObject *__pyx_getprop_5pygpu_8gpuarray_10GpuContext_maxlsize1(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_5pygpu_8gpuarray_10GpuContext_9maxlsize1_1__get__(o);
}

static PyObject *__pyx_getprop_5pygpu_8gpuarray_10GpuContext_maxlsize2(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_5pygpu_8gpuarray_10GpuContext_9maxlsize2_1__get__(o);
}

static PyObject *__pyx_getprop_5pygpu_8gpuarray_10GpuContext_maxgsize0(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_5pygpu_8gpuarray_10GpuContext_9maxgsize0_1__get__(o);
}

static PyObject *__pyx_getprop_5pygpu_8gpuarray_10GpuContext_maxgsize1(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_5pygpu_8gpuarray_10GpuContext_9maxgsize1_1__get__(o);
}

static PyObject *__pyx_getprop_5pygpu_8gpuarray_10GpuContext_maxgsize2(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_5pygpu_8gpuarray_10GpuContext_9maxgsize2_1__get__(o);
}

static PyObject *__pyx_getprop_5pygpu_8gpuarray_10GpuContext_largest_memblock(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_5pygpu_8gpuarray_10GpuContext_16largest_memblock_1__get__(o);
}

static PyObject *__pyx_getprop_5pygpu_8gpuarray_10GpuContext_kind(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_5pygpu_8gpuarray_10GpuContext_4kind_1__get__(o);
}

static PyMethodDef __pyx_methods_5pygpu_8gpuarray_GpuContext[] = {
  {"__reduce__", (PyCFunction)__pyx_pw_5pygpu_8gpuarray_10GpuContext_3__reduce__, METH_NOARGS, 0},
  {"__enter__", (PyCFunction)__pyx_pw_5pygpu_8gpuarray_10GpuContext_7__enter__, METH_NOARGS, 0},
  {"__exit__", (PyCFunction)__pyx_pw_5pygpu_8gpuarray_10GpuContext_9__exit__, METH_VARARGS|METH_KEYWORDS, 0},
  {0, 0, 0, 0}
};

static struct PyGetSetDef __pyx_getsets_5pygpu_8gpuarray_GpuContext[] = {
  {(char *)"__dict__", __pyx___dict__getter_5pygpu_8gpuarray_GpuContext, 0, (char *)0, 0},
  {(char *)"ptr", __pyx_getprop_5pygpu_8gpuarray_10GpuContext_ptr, 0, (char *)"Raw pointer value for the context object", 0},
  {(char *)"devname", __pyx_getprop_5pygpu_8gpuarray_10GpuContext_devname, 0, (char *)"Device name for this context", 0},
  {(char *)"unique_id", __pyx_getprop_5pygpu_8gpuarray_10GpuContext_unique_id, 0, (char *)"Device PCI Bus ID for this context", 0},
  {(char *)"lmemsize", __pyx_getprop_5pygpu_8gpuarray_10GpuContext_lmemsize, 0, (char *)"Size of the local (shared) memory, in bytes, for this context", 0},
  {(char *)"numprocs", __pyx_getprop_5pygpu_8gpuarray_10GpuContext_numprocs, 0, (char *)"Number of compute units for this context", 0},
  {(char *)"bin_id", __pyx_getprop_5pygpu_8gpuarray_10GpuContext_bin_id, 0, (char *)"Binary compatibility id", 0},
  {(char *)"total_gmem", __pyx_getprop_5pygpu_8gpuarray_10GpuContext_total_gmem, 0, (char *)"Total size of global memory on the device", 0},
  {(char *)"free_gmem", __pyx_getprop_5pygpu_8gpuarray_10GpuContext_free_gmem, 0, (char *)"Size of free global memory on the device", 0},
  {(char *)"maxlsize0", __pyx_getprop_5pygpu_8gpuarray_10GpuContext_maxlsize0, 0, (char *)"Maximum local size for dimension 0", 0},
  {(char *)"maxlsize1", __pyx_getprop_5pygpu_8gpuarray_10GpuContext_maxlsize1, 0, (char *)"Maximum local size for dimension 1", 0},
  {(char *)"maxlsize2", __pyx_getprop_5pygpu_8gpuarray_10GpuContext_maxlsize2, 0, (char *)"Maximum local size for dimension 2", 0},
  {(char *)"maxgsize0", __pyx_getprop_5pygpu_8gpuarray_10GpuContext_maxgsize0, 0, (char *)"Maximum global size for dimension 0", 0},
  {(char *)"maxgsize1", __pyx_getprop_5pygpu_8gpuarray_10GpuContext_maxgsize1, 0, (char *)"Maximum global size for dimension 1", 0},
  {(char *)"maxgsize2", __pyx_getprop_5pygpu_8gpuarray_10GpuContext_maxgsize2, 0, (char *)"Maximum global size for dimension 2", 0},
  {(char *)"largest_memblock", __pyx_getprop_5pygpu_8gpuarray_10GpuContext_largest_memblock, 0, (char *)"Size of the largest memory block you can allocate", 0},
  {(char *)"kind", __pyx_getprop_5pygpu_8gpuarray_10GpuContext_kind, 0, (char *)0, 0},
  {0, 0, 0, 0, 0}
};

static PyTypeObject PyGpuContextType = {
  PyVarObject_HEAD_INIT(0, 0)
  "pygpu.gpuarray.GpuContext", /*tp_name*/
  sizeof(struct PyGpuContextObject), /*tp_basicsize*/
  0, /*tp_itemsize*/
  __pyx_tp_dealloc_5pygpu_8gpuarray_GpuContext, /*tp_dealloc*/
  0, /*tp_print*/
  0, /*tp_getattr*/
  0, /*tp_setattr*/
  #if PY_MAJOR_VERSION < 3
  0, /*tp_compare*/
  #endif
  #if PY_MAJOR_VERSION >= 3
  0, /*tp_as_async*/
  #endif
  0, /*tp_repr*/
  0, /*tp_as_number*/
  0, /*tp_as_sequence*/
  0, /*tp_as_mapping*/
  0, /*tp_hash*/
  0, /*tp_call*/
  0, /*tp_str*/
  0, /*tp_getattro*/
  0, /*tp_setattro*/
  0, /*tp_as_buffer*/
  Py_TPFLAGS_DEFAULT|Py_TPFLAGS_HAVE_VERSION_TAG|Py_TPFLAGS_CHECKTYPES|Py_TPFLAGS_HAVE_NEWBUFFER|Py_TPFLAGS_BASETYPE|Py_TPFLAGS_HAVE_GC, /*tp_flags*/
  "\n    Class that holds all the information pertaining to a context.\n\n    The currently implemented modules (for the `kind` parameter) are\n    \"cuda\" and \"opencl\".  Which are available depends on the build\n    options for libgpuarray.\n\n    The flag values are defined in the gpuarray/buffer.h header and\n    are in the \"Context flags\" group.  If you want to use more than\n    one value you must bitwise OR them together.\n\n    If you want an alternative interface check :meth:`~pygpu.gpuarray.init`.\n\n    Parameters\n    ----------\n    kind: str\n        module name for the context\n    devno: int\n        device number\n    flags: int\n        context flags\n\n    ", /*tp_doc*/
  __pyx_tp_traverse_5pygpu_8gpuarray_GpuContext, /*tp_traverse*/
  __pyx_tp_clear_5pygpu_8gpuarray_GpuContext, /*tp_clear*/
  0, /*tp_richcompare*/
  0, /*tp_weaklistoffset*/
  0, /*tp_iter*/
  0, /*tp_iternext*/
  __pyx_methods_5pygpu_8gpuarray_GpuContext, /*tp_methods*/
  0, /*tp_members*/
  __pyx_getsets_5pygpu_8gpuarray_GpuContext, /*tp_getset*/
  0, /*tp_base*/
  0, /*tp_dict*/
  0, /*tp_descr_get*/
  0, /*tp_descr_set*/
  offsetof(struct PyGpuContextObject, __dict__), /*tp_dictoffset*/
  __pyx_pw_5pygpu_8gpuarray_10GpuContext_5__init__, /*tp_init*/
  0, /*tp_alloc*/
  __pyx_tp_new_5pygpu_8gpuarray_GpuContext, /*tp_new*/
  0, /*tp_free*/
  0, /*tp_is_gc*/
  0, /*tp_bases*/
  0, /*tp_mro*/
  0, /*tp_cache*/
  0, /*tp_subclasses*/
  0, /*tp_weaklist*/
  0, /*tp_del*/
  0, /*tp_version_tag*/
  #if PY_VERSION_HEX >= 0x030400a1
  0, /*tp_finalize*/
  #endif
};
static struct __pyx_vtabstruct_5pygpu_8gpuarray_GpuArray __pyx_vtable_5pygpu_8gpuarray_GpuArray;

static PyObject *__pyx_tp_new_5pygpu_8gpuarray_GpuArray(PyTypeObject *t, CYTHON_UNUSED PyObject *a, CYTHON_UNUSED PyObject *k) {
  struct PyGpuArrayObject *p;
  PyObject *o;
  if (likely((t->tp_flags & Py_TPFLAGS_IS_ABSTRACT) == 0)) {
    o = (*t->tp_alloc)(t, 0);
  } else {
    o = (PyObject *) PyBaseObject_Type.tp_new(t, __pyx_empty_tuple, 0);
  }
  if (unlikely(!o)) return 0;
  p = ((struct PyGpuArrayObject *)o);
  p->__pyx_vtab = __pyx_vtabptr_5pygpu_8gpuarray_GpuArray;
  p->context = ((struct PyGpuContextObject *)Py_None); Py_INCREF(Py_None);
  p->base = Py_None; Py_INCREF(Py_None);
  if (unlikely(__pyx_pw_5pygpu_8gpuarray_8GpuArray_3__cinit__(o, __pyx_empty_tuple, NULL) < 0)) goto bad;
  return o;
  bad:
  Py_DECREF(o); o = 0;
  return NULL;
}

static void __pyx_tp_dealloc_5pygpu_8gpuarray_GpuArray(PyObject *o) {
  struct PyGpuArrayObject *p = (struct PyGpuArrayObject *)o;
  #if CYTHON_USE_TP_FINALIZE
  if (unlikely(PyType_HasFeature(Py_TYPE(o), Py_TPFLAGS_HAVE_FINALIZE) && Py_TYPE(o)->tp_finalize) && !_PyGC_FINALIZED(o)) {
    if (PyObject_CallFinalizerFromDealloc(o)) return;
  }
  #endif
  PyObject_GC_UnTrack(o);
  {
    PyObject *etype, *eval, *etb;
    PyErr_Fetch(&etype, &eval, &etb);
    ++Py_REFCNT(o);
    __pyx_pw_5pygpu_8gpuarray_8GpuArray_1__dealloc__(o);
    --Py_REFCNT(o);
    PyErr_Restore(etype, eval, etb);
  }
  if (p->__weakref__) PyObject_ClearWeakRefs(o);
  Py_CLEAR(p->context);
  Py_CLEAR(p->base);
  (*Py_TYPE(o)->tp_free)(o);
}

static int __pyx_tp_traverse_5pygpu_8gpuarray_GpuArray(PyObject *o, visitproc v, void *a) {
  int e;
  struct PyGpuArrayObject *p = (struct PyGpuArrayObject *)o;
  if (p->context) {
    e = (*v)(((PyObject *)p->context), a); if (e) return e;
  }
  if (p->base) {
    e = (*v)(p->base, a); if (e) return e;
  }
  return 0;
}

static int __pyx_tp_clear_5pygpu_8gpuarray_GpuArray(PyObject *o) {
  PyObject* tmp;
  struct PyGpuArrayObject *p = (struct PyGpuArrayObject *)o;
  tmp = ((PyObject*)p->context);
  p->context = ((struct PyGpuContextObject *)Py_None); Py_INCREF(Py_None);
  Py_XDECREF(tmp);
  tmp = ((PyObject*)p->base);
  p->base = Py_None; Py_INCREF(Py_None);
  Py_XDECREF(tmp);
  return 0;
}
static PyObject *__pyx_sq_item_5pygpu_8gpuarray_GpuArray(PyObject *o, Py_ssize_t i) {
  PyObject *r;
  PyObject *x = PyInt_FromSsize_t(i); if(!x) return 0;
  r = Py_TYPE(o)->tp_as_mapping->mp_subscript(o, x);
  Py_DECREF(x);
  return r;
}

static int __pyx_mp_ass_subscript_5pygpu_8gpuarray_GpuArray(PyObject *o, PyObject *i, PyObject *v) {
  if (v) {
    return __pyx_pw_5pygpu_8gpuarray_8GpuArray_43__setitem__(o, i, v);
  }
  else {
    PyErr_Format(PyExc_NotImplementedError,
      "Subscript deletion not supported by %.200s", Py_TYPE(o)->tp_name);
    return -1;
  }
}

static PyObject *__pyx_getprop_5pygpu_8gpuarray_8GpuArray_shape(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_5pygpu_8gpuarray_8GpuArray_5shape_1__get__(o);
}

static int __pyx_setprop_5pygpu_8gpuarray_8GpuArray_shape(PyObject *o, PyObject *v, CYTHON_UNUSED void *x) {
  if (v) {
    return __pyx_pw_5pygpu_8gpuarray_8GpuArray_5shape_3__set__(o, v);
  }
  else {
    PyErr_SetString(PyExc_NotImplementedError, "__del__");
    return -1;
  }
}

static PyObject *__pyx_getprop_5pygpu_8gpuarray_8GpuArray_T(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_5pygpu_8gpuarray_8GpuArray_1T_1__get__(o);
}

static PyObject *__pyx_getprop_5pygpu_8gpuarray_8GpuArray_size(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_5pygpu_8gpuarray_8GpuArray_4size_1__get__(o);
}

static PyObject *__pyx_getprop_5pygpu_8gpuarray_8GpuArray_strides(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_5pygpu_8gpuarray_8GpuArray_7strides_1__get__(o);
}

static int __pyx_setprop_5pygpu_8gpuarray_8GpuArray_strides(PyObject *o, PyObject *v, CYTHON_UNUSED void *x) {
  if (v) {
    return __pyx_pw_5pygpu_8gpuarray_8GpuArray_7strides_3__set__(o, v);
  }
  else {
    PyErr_SetString(PyExc_NotImplementedError, "__del__");
    return -1;
  }
}

static PyObject *__pyx_getprop_5pygpu_8gpuarray_8GpuArray_ndim(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_5pygpu_8gpuarray_8GpuArray_4ndim_1__get__(o);
}

static PyObject *__pyx_getprop_5pygpu_8gpuarray_8GpuArray_dtype(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_5pygpu_8gpuarray_8GpuArray_5dtype_1__get__(o);
}

static PyObject *__pyx_getprop_5pygpu_8gpuarray_8GpuArray_typecode(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_5pygpu_8gpuarray_8GpuArray_8typecode_1__get__(o);
}

static PyObject *__pyx_getprop_5pygpu_8gpuarray_8GpuArray_itemsize(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_5pygpu_8gpuarray_8GpuArray_8itemsize_1__get__(o);
}

static PyObject *__pyx_getprop_5pygpu_8gpuarray_8GpuArray_flags(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_5pygpu_8gpuarray_8GpuArray_5flags_1__get__(o);
}

static PyObject *__pyx_getprop_5pygpu_8gpuarray_8GpuArray_offset(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_5pygpu_8gpuarray_8GpuArray_6offset_1__get__(o);
}

static PyObject *__pyx_getprop_5pygpu_8gpuarray_8GpuArray_data(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_5pygpu_8gpuarray_8GpuArray_4data_1__get__(o);
}

static PyObject *__pyx_getprop_5pygpu_8gpuarray_8GpuArray_base_data(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_5pygpu_8gpuarray_8GpuArray_9base_data_1__get__(o);
}

static PyObject *__pyx_getprop_5pygpu_8gpuarray_8GpuArray_gpudata(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_5pygpu_8gpuarray_8GpuArray_7gpudata_1__get__(o);
}

static PyObject *__pyx_getprop_5pygpu_8gpuarray_8GpuArray_context(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_5pygpu_8gpuarray_8GpuArray_7context_1__get__(o);
}

static PyObject *__pyx_getprop_5pygpu_8gpuarray_8GpuArray_base(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_5pygpu_8gpuarray_8GpuArray_4base_1__get__(o);
}

static PyMethodDef __pyx_methods_5pygpu_8gpuarray_GpuArray[] = {
  {"__reduce__", (PyCFunction)__pyx_pw_5pygpu_8gpuarray_8GpuArray_7__reduce__, METH_NOARGS, 0},
  {"write", (PyCFunction)__pyx_pw_5pygpu_8gpuarray_8GpuArray_9write, METH_O, __pyx_doc_5pygpu_8gpuarray_8GpuArray_8write},
  {"read", (PyCFunction)__pyx_pw_5pygpu_8gpuarray_8GpuArray_11read, METH_O, __pyx_doc_5pygpu_8gpuarray_8GpuArray_10read},
  {"get_ipc_handle", (PyCFunction)__pyx_pw_5pygpu_8gpuarray_8GpuArray_13get_ipc_handle, METH_NOARGS, __pyx_doc_5pygpu_8gpuarray_8GpuArray_12get_ipc_handle},
  {"__array__", (PyCFunction)__pyx_pw_5pygpu_8gpuarray_8GpuArray_15__array__, METH_VARARGS|METH_KEYWORDS, __pyx_doc_5pygpu_8gpuarray_8GpuArray_14__array__},
  {"_empty_like_me", (PyCFunction)__pyx_pw_5pygpu_8gpuarray_8GpuArray_19_empty_like_me, METH_VARARGS|METH_KEYWORDS, __pyx_doc_5pygpu_8gpuarray_8GpuArray_18_empty_like_me},
  {"copy", (PyCFunction)__pyx_pw_5pygpu_8gpuarray_8GpuArray_21copy, METH_VARARGS|METH_KEYWORDS, __pyx_doc_5pygpu_8gpuarray_8GpuArray_20copy},
  {"transfer", (PyCFunction)__pyx_pw_5pygpu_8gpuarray_8GpuArray_23transfer, METH_O, __pyx_doc_5pygpu_8gpuarray_8GpuArray_22transfer},
  {"__copy__", (PyCFunction)__pyx_pw_5pygpu_8gpuarray_8GpuArray_25__copy__, METH_NOARGS, 0},
  {"__deepcopy__", (PyCFunction)__pyx_pw_5pygpu_8gpuarray_8GpuArray_27__deepcopy__, METH_O, 0},
  {"sync", (PyCFunction)__pyx_pw_5pygpu_8gpuarray_8GpuArray_29sync, METH_NOARGS, __pyx_doc_5pygpu_8gpuarray_8GpuArray_28sync},
  {"view", (PyCFunction)__pyx_pw_5pygpu_8gpuarray_8GpuArray_31view, METH_VARARGS|METH_KEYWORDS, __pyx_doc_5pygpu_8gpuarray_8GpuArray_30view},
  {"astype", (PyCFunction)__pyx_pw_5pygpu_8gpuarray_8GpuArray_33astype, METH_VARARGS|METH_KEYWORDS, __pyx_doc_5pygpu_8gpuarray_8GpuArray_32astype},
  {"reshape", (PyCFunction)__pyx_pw_5pygpu_8gpuarray_8GpuArray_35reshape, METH_VARARGS|METH_KEYWORDS, __pyx_doc_5pygpu_8gpuarray_8GpuArray_34reshape},
  {"transpose", (PyCFunction)__pyx_pw_5pygpu_8gpuarray_8GpuArray_37transpose, METH_VARARGS|METH_KEYWORDS, __pyx_doc_5pygpu_8gpuarray_8GpuArray_36transpose},
  {"take1", (PyCFunction)__pyx_pw_5pygpu_8gpuarray_8GpuArray_45take1, METH_O, __pyx_doc_5pygpu_8gpuarray_8GpuArray_44take1},
  {0, 0, 0, 0}
};

static struct PyGetSetDef __pyx_getsets_5pygpu_8gpuarray_GpuArray[] = {
  {(char *)"shape", __pyx_getprop_5pygpu_8gpuarray_8GpuArray_shape, __pyx_setprop_5pygpu_8gpuarray_8GpuArray_shape, (char *)"shape of this ndarray (tuple)", 0},
  {(char *)"T", __pyx_getprop_5pygpu_8gpuarray_8GpuArray_T, 0, (char *)0, 0},
  {(char *)"size", __pyx_getprop_5pygpu_8gpuarray_8GpuArray_size, 0, (char *)"The number of elements in this object.", 0},
  {(char *)"strides", __pyx_getprop_5pygpu_8gpuarray_8GpuArray_strides, __pyx_setprop_5pygpu_8gpuarray_8GpuArray_strides, (char *)"data pointer strides (in bytes)", 0},
  {(char *)"ndim", __pyx_getprop_5pygpu_8gpuarray_8GpuArray_ndim, 0, (char *)"The number of dimensions in this object", 0},
  {(char *)"dtype", __pyx_getprop_5pygpu_8gpuarray_8GpuArray_dtype, 0, (char *)"The dtype of the element", 0},
  {(char *)"typecode", __pyx_getprop_5pygpu_8gpuarray_8GpuArray_typecode, 0, (char *)"The gpuarray typecode for the data type of the array", 0},
  {(char *)"itemsize", __pyx_getprop_5pygpu_8gpuarray_8GpuArray_itemsize, 0, (char *)"The size of the base element.", 0},
  {(char *)"flags", __pyx_getprop_5pygpu_8gpuarray_8GpuArray_flags, 0, (char *)"Return a flags object describing the properties of this array.\n\n        This is mostly numpy-compatible with some exceptions:\n          * Flags are always constant (numpy allows modification of certain flags in certain cicumstances).\n          * OWNDATA is always True, since the data is refcounted in libgpuarray.\n          * UPDATEIFCOPY is not supported, therefore always False.\n        ", 0},
  {(char *)"offset", __pyx_getprop_5pygpu_8gpuarray_8GpuArray_offset, 0, (char *)"Return the offset into the gpudata pointer for this array.", 0},
  {(char *)"data", __pyx_getprop_5pygpu_8gpuarray_8GpuArray_data, 0, (char *)"Return a pointer to the raw OpenCL buffer object.\n\n        This will fail for arrays that have an offset.\n        ", 0},
  {(char *)"base_data", __pyx_getprop_5pygpu_8gpuarray_8GpuArray_base_data, 0, (char *)"Return a pointer to the backing OpenCL object.", 0},
  {(char *)"gpudata", __pyx_getprop_5pygpu_8gpuarray_8GpuArray_gpudata, 0, (char *)"Return a pointer to the raw backend object.", 0},
  {(char *)"context", __pyx_getprop_5pygpu_8gpuarray_8GpuArray_context, 0, (char *)0, 0},
  {(char *)"base", __pyx_getprop_5pygpu_8gpuarray_8GpuArray_base, 0, (char *)0, 0},
  {0, 0, 0, 0, 0}
};

static PyNumberMethods __pyx_tp_as_number_GpuArray = {
  0, /*nb_add*/
  0, /*nb_subtract*/
  0, /*nb_multiply*/
  #if PY_MAJOR_VERSION < 3 || (CYTHON_COMPILING_IN_PYPY && PY_VERSION_HEX < 0x03050000)
  0, /*nb_divide*/
  #endif
  0, /*nb_remainder*/
  0, /*nb_divmod*/
  0, /*nb_power*/
  0, /*nb_negative*/
  0, /*nb_positive*/
  0, /*nb_absolute*/
  __pyx_pw_5pygpu_8gpuarray_8GpuArray_49__nonzero__, /*nb_nonzero*/
  0, /*nb_invert*/
  0, /*nb_lshift*/
  0, /*nb_rshift*/
  0, /*nb_and*/
  0, /*nb_xor*/
  0, /*nb_or*/
  #if PY_MAJOR_VERSION < 3 || (CYTHON_COMPILING_IN_PYPY && PY_VERSION_HEX < 0x03050000)
  0, /*nb_coerce*/
  #endif
  0, /*nb_int*/
  #if PY_MAJOR_VERSION < 3
  0, /*nb_long*/
  #else
  0, /*reserved*/
  #endif
  0, /*nb_float*/
  #if PY_MAJOR_VERSION < 3 || (CYTHON_COMPILING_IN_PYPY && PY_VERSION_HEX < 0x03050000)
  0, /*nb_oct*/
  #endif
  #if PY_MAJOR_VERSION < 3 || (CYTHON_COMPILING_IN_PYPY && PY_VERSION_HEX < 0x03050000)
  0, /*nb_hex*/
  #endif
  0, /*nb_inplace_add*/
  0, /*nb_inplace_subtract*/
  0, /*nb_inplace_multiply*/
  #if PY_MAJOR_VERSION < 3 || (CYTHON_COMPILING_IN_PYPY && PY_VERSION_HEX < 0x03050000)
  0, /*nb_inplace_divide*/
  #endif
  0, /*nb_inplace_remainder*/
  0, /*nb_inplace_power*/
  0, /*nb_inplace_lshift*/
  0, /*nb_inplace_rshift*/
  0, /*nb_inplace_and*/
  0, /*nb_inplace_xor*/
  0, /*nb_inplace_or*/
  0, /*nb_floor_divide*/
  0, /*nb_true_divide*/
  0, /*nb_inplace_floor_divide*/
  0, /*nb_inplace_true_divide*/
  0, /*nb_index*/
  #if PY_VERSION_HEX >= 0x03050000
  0, /*nb_matrix_multiply*/
  #endif
  #if PY_VERSION_HEX >= 0x03050000
  0, /*nb_inplace_matrix_multiply*/
  #endif
};

static PySequenceMethods __pyx_tp_as_sequence_GpuArray = {
  __pyx_pw_5pygpu_8gpuarray_8GpuArray_39__len__, /*sq_length*/
  0, /*sq_concat*/
  0, /*sq_repeat*/
  __pyx_sq_item_5pygpu_8gpuarray_GpuArray, /*sq_item*/
  0, /*sq_slice*/
  0, /*sq_ass_item*/
  0, /*sq_ass_slice*/
  0, /*sq_contains*/
  0, /*sq_inplace_concat*/
  0, /*sq_inplace_repeat*/
};

static PyMappingMethods __pyx_tp_as_mapping_GpuArray = {
  __pyx_pw_5pygpu_8gpuarray_8GpuArray_39__len__, /*mp_length*/
  __pyx_pw_5pygpu_8gpuarray_8GpuArray_41__getitem__, /*mp_subscript*/
  __pyx_mp_ass_subscript_5pygpu_8gpuarray_GpuArray, /*mp_ass_subscript*/
};

static PyTypeObject PyGpuArrayType = {
  PyVarObject_HEAD_INIT(0, 0)
  "pygpu.gpuarray.GpuArray", /*tp_name*/
  sizeof(struct PyGpuArrayObject), /*tp_basicsize*/
  0, /*tp_itemsize*/
  __pyx_tp_dealloc_5pygpu_8gpuarray_GpuArray, /*tp_dealloc*/
  0, /*tp_print*/
  0, /*tp_getattr*/
  0, /*tp_setattr*/
  #if PY_MAJOR_VERSION < 3
  0, /*tp_compare*/
  #endif
  #if PY_MAJOR_VERSION >= 3
  0, /*tp_as_async*/
  #endif
  __pyx_pw_5pygpu_8gpuarray_8GpuArray_53__repr__, /*tp_repr*/
  &__pyx_tp_as_number_GpuArray, /*tp_as_number*/
  &__pyx_tp_as_sequence_GpuArray, /*tp_as_sequence*/
  &__pyx_tp_as_mapping_GpuArray, /*tp_as_mapping*/
  __pyx_pw_5pygpu_8gpuarray_8GpuArray_47__hash__, /*tp_hash*/
  0, /*tp_call*/
  __pyx_pw_5pygpu_8gpuarray_8GpuArray_51__str__, /*tp_str*/
  0, /*tp_getattro*/
  0, /*tp_setattro*/
  0, /*tp_as_buffer*/
  Py_TPFLAGS_DEFAULT|Py_TPFLAGS_HAVE_VERSION_TAG|Py_TPFLAGS_CHECKTYPES|Py_TPFLAGS_HAVE_NEWBUFFER|Py_TPFLAGS_BASETYPE|Py_TPFLAGS_HAVE_GC, /*tp_flags*/
  "\n    Device array\n\n    To create instances of this class use\n    :meth:`~pygpu.gpuarray.zeros`, :meth:`~pygpu.gpuarray.empty` or\n    :meth:`~pygpu.gpuarray.array`.  It cannot be instanciated\n    directly.\n\n    You can also subclass this class and make the module create your\n    instances by passing the `cls` argument to any method that return a\n    new GpuArray.  This way of creating the class will NOT call your\n    :meth:`__init__` method.\n\n    You can also implement your own :meth:`__init__` method, but you\n    must take care to ensure you properly initialized the GpuArray C\n    fields before using it or you will most likely crash the\n    interpreter.\n    ", /*tp_doc*/
  __pyx_tp_traverse_5pygpu_8gpuarray_GpuArray, /*tp_traverse*/
  __pyx_tp_clear_5pygpu_8gpuarray_GpuArray, /*tp_clear*/
  0, /*tp_richcompare*/
  0, /*tp_weaklistoffset*/
  0, /*tp_iter*/
  0, /*tp_iternext*/
  __pyx_methods_5pygpu_8gpuarray_GpuArray, /*tp_methods*/
  0, /*tp_members*/
  __pyx_getsets_5pygpu_8gpuarray_GpuArray, /*tp_getset*/
  0, /*tp_base*/
  0, /*tp_dict*/
  0, /*tp_descr_get*/
  0, /*tp_descr_set*/
  0, /*tp_dictoffset*/
  __pyx_pw_5pygpu_8gpuarray_8GpuArray_5__init__, /*tp_init*/
  0, /*tp_alloc*/
  __pyx_tp_new_5pygpu_8gpuarray_GpuArray, /*tp_new*/
  0, /*tp_free*/
  0, /*tp_is_gc*/
  0, /*tp_bases*/
  0, /*tp_mro*/
  0, /*tp_cache*/
  0, /*tp_subclasses*/
  0, /*tp_weaklist*/
  0, /*tp_del*/
  0, /*tp_version_tag*/
  #if PY_VERSION_HEX >= 0x030400a1
  0, /*tp_finalize*/
  #endif
};
static struct __pyx_vtabstruct_5pygpu_8gpuarray_GpuKernel __pyx_vtable_5pygpu_8gpuarray_GpuKernel;

static PyObject *__pyx_tp_new_5pygpu_8gpuarray_GpuKernel(PyTypeObject *t, PyObject *a, PyObject *k) {
  struct PyGpuKernelObject *p;
  PyObject *o;
  if (likely((t->tp_flags & Py_TPFLAGS_IS_ABSTRACT) == 0)) {
    o = (*t->tp_alloc)(t, 0);
  } else {
    o = (PyObject *) PyBaseObject_Type.tp_new(t, __pyx_empty_tuple, 0);
  }
  if (unlikely(!o)) return 0;
  p = ((struct PyGpuKernelObject *)o);
  p->__pyx_vtab = __pyx_vtabptr_5pygpu_8gpuarray_GpuKernel;
  p->context = ((struct PyGpuContextObject *)Py_None); Py_INCREF(Py_None);
  if (unlikely(__pyx_pw_5pygpu_8gpuarray_9GpuKernel_5__cinit__(o, a, k) < 0)) goto bad;
  return o;
  bad:
  Py_DECREF(o); o = 0;
  return NULL;
}

static void __pyx_tp_dealloc_5pygpu_8gpuarray_GpuKernel(PyObject *o) {
  struct PyGpuKernelObject *p = (struct PyGpuKernelObject *)o;
  #if CYTHON_USE_TP_FINALIZE
  if (unlikely(PyType_HasFeature(Py_TYPE(o), Py_TPFLAGS_HAVE_FINALIZE) && Py_TYPE(o)->tp_finalize) && !_PyGC_FINALIZED(o)) {
    if (PyObject_CallFinalizerFromDealloc(o)) return;
  }
  #endif
  PyObject_GC_UnTrack(o);
  {
    PyObject *etype, *eval, *etb;
    PyErr_Fetch(&etype, &eval, &etb);
    ++Py_REFCNT(o);
    __pyx_pw_5pygpu_8gpuarray_9GpuKernel_1__dealloc__(o);
    --Py_REFCNT(o);
    PyErr_Restore(etype, eval, etb);
  }
  if (p->__weakref__) PyObject_ClearWeakRefs(o);
  Py_CLEAR(p->context);
  (*Py_TYPE(o)->tp_free)(o);
}

static int __pyx_tp_traverse_5pygpu_8gpuarray_GpuKernel(PyObject *o, visitproc v, void *a) {
  int e;
  struct PyGpuKernelObject *p = (struct PyGpuKernelObject *)o;
  if (p->context) {
    e = (*v)(((PyObject *)p->context), a); if (e) return e;
  }
  return 0;
}

static int __pyx_tp_clear_5pygpu_8gpuarray_GpuKernel(PyObject *o) {
  PyObject* tmp;
  struct PyGpuKernelObject *p = (struct PyGpuKernelObject *)o;
  tmp = ((PyObject*)p->context);
  p->context = ((struct PyGpuContextObject *)Py_None); Py_INCREF(Py_None);
  Py_XDECREF(tmp);
  return 0;
}

static PyObject *__pyx_getprop_5pygpu_8gpuarray_9GpuKernel_maxlsize(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_5pygpu_8gpuarray_9GpuKernel_8maxlsize_1__get__(o);
}

static PyObject *__pyx_getprop_5pygpu_8gpuarray_9GpuKernel_preflsize(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_5pygpu_8gpuarray_9GpuKernel_9preflsize_1__get__(o);
}

static PyObject *__pyx_getprop_5pygpu_8gpuarray_9GpuKernel_numargs(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_5pygpu_8gpuarray_9GpuKernel_7numargs_1__get__(o);
}

static PyObject *__pyx_getprop_5pygpu_8gpuarray_9GpuKernel_context(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_5pygpu_8gpuarray_9GpuKernel_7context_1__get__(o);
}

static PyMethodDef __pyx_methods_5pygpu_8gpuarray_GpuKernel[] = {
  {"__reduce__", (PyCFunction)__pyx_pw_5pygpu_8gpuarray_9GpuKernel_3__reduce__, METH_NOARGS, 0},
  {0, 0, 0, 0}
};

static struct PyGetSetDef __pyx_getsets_5pygpu_8gpuarray_GpuKernel[] = {
  {(char *)"maxlsize", __pyx_getprop_5pygpu_8gpuarray_9GpuKernel_maxlsize, 0, (char *)"Maximum local size for this kernel", 0},
  {(char *)"preflsize", __pyx_getprop_5pygpu_8gpuarray_9GpuKernel_preflsize, 0, (char *)"Preferred multiple for local size for this kernel", 0},
  {(char *)"numargs", __pyx_getprop_5pygpu_8gpuarray_9GpuKernel_numargs, 0, (char *)"Number of arguments to kernel", 0},
  {(char *)"context", __pyx_getprop_5pygpu_8gpuarray_9GpuKernel_context, 0, (char *)0, 0},
  {0, 0, 0, 0, 0}
};

static PyTypeObject PyGpuKernelType = {
  PyVarObject_HEAD_INIT(0, 0)
  "pygpu.gpuarray.GpuKernel", /*tp_name*/
  sizeof(struct PyGpuKernelObject), /*tp_basicsize*/
  0, /*tp_itemsize*/
  __pyx_tp_dealloc_5pygpu_8gpuarray_GpuKernel, /*tp_dealloc*/
  0, /*tp_print*/
  0, /*tp_getattr*/
  0, /*tp_setattr*/
  #if PY_MAJOR_VERSION < 3
  0, /*tp_compare*/
  #endif
  #if PY_MAJOR_VERSION >= 3
  0, /*tp_as_async*/
  #endif
  0, /*tp_repr*/
  0, /*tp_as_number*/
  0, /*tp_as_sequence*/
  0, /*tp_as_mapping*/
  0, /*tp_hash*/
  __pyx_pw_5pygpu_8gpuarray_9GpuKernel_7__call__, /*tp_call*/
  0, /*tp_str*/
  0, /*tp_getattro*/
  0, /*tp_setattro*/
  0, /*tp_as_buffer*/
  Py_TPFLAGS_DEFAULT|Py_TPFLAGS_HAVE_VERSION_TAG|Py_TPFLAGS_CHECKTYPES|Py_TPFLAGS_HAVE_NEWBUFFER|Py_TPFLAGS_BASETYPE|Py_TPFLAGS_HAVE_GC, /*tp_flags*/
  "\n    GpuKernel(source, name, types, context=None, have_double=False, have_small=False, have_complex=False, have_half=False, cuda=False, opencl=False)\n\n    Compile a kernel on the device\n\n    The kernel function is retrieved using the provided `name` which\n    must match what you named your kernel in `source`.  You can safely\n    reuse the same name multiple times.\n\n    The `have_*` parameter are there to tell libgpuarray that we need\n    the particular type or feature to work for this kernel.  If the\n    request can't be satified a :class:`.UnsupportedException` will be\n    raised in the constructor.\n\n    Once you have the kernel object you can simply call it like so::\n\n        k = GpuKernel(...)\n        k(param1, param2, n=n)\n\n    where `n` is the minimum number of threads to run.  libgpuarray\n    will try to stay close to this number but may run a few more\n    threads to match the hardware preferred multiple and stay\n    efficient.  You should watch out for this in your code and make\n    sure to test against the size of your data.\n\n    If you want more control over thread allocation you can use the\n    `gs` and `ls` parameters like so::\n\n        k = GpuKernel(...)\n        k(param1, param2, gs=gs, ls=ls)\n\n    If you choose to use this interface, make sure to stay within the\n    limits of `k.maxlsize` or the call will fail.\n\n    Parameters\n    ----------\n    source: str\n        complete kernel source code\n    name: str\n        function name of the kernel\n    types: list or tuple\n        list of argument types\n    context: GpuContext\n        device on which the kernel is compiled\n    have_double: bool\n        ensure working doubles?\n    have_small: bool\n        ensure types smaller than float will work?\n    have_complex: bool\n        ensure complex types will work?\n    have_half: bool\n        ensure half-floats will work?\n    cuda: bool\n        kernel is cuda code?\n    opencl: bool\n        kernel is opencl code?""\n\n    Notes\n    -----\n    With the cuda backend, unless you use the cluda include, you must\n    either pass the mangled name of your kernel or declare the\n    function 'extern \"C\"', because cuda uses a C++ compiler\n    unconditionally.\n\n    .. warning::\n\n        If you do not set the `have_` flags properly, you will either\n        get a device-specific error (the good case) or silent\n        completly bogus data (the bad case).\n\n\n    ", /*tp_doc*/
  __pyx_tp_traverse_5pygpu_8gpuarray_GpuKernel, /*tp_traverse*/
  __pyx_tp_clear_5pygpu_8gpuarray_GpuKernel, /*tp_clear*/
  0, /*tp_richcompare*/
  0, /*tp_weaklistoffset*/
  0, /*tp_iter*/
  0, /*tp_iternext*/
  __pyx_methods_5pygpu_8gpuarray_GpuKernel, /*tp_methods*/
  0, /*tp_members*/
  __pyx_getsets_5pygpu_8gpuarray_GpuKernel, /*tp_getset*/
  0, /*tp_base*/
  0, /*tp_dict*/
  0, /*tp_descr_get*/
  0, /*tp_descr_set*/
  0, /*tp_dictoffset*/
  0, /*tp_init*/
  0, /*tp_alloc*/
  __pyx_tp_new_5pygpu_8gpuarray_GpuKernel, /*tp_new*/
  0, /*tp_free*/
  0, /*tp_is_gc*/
  0, /*tp_bases*/
  0, /*tp_mro*/
  0, /*tp_cache*/
  0, /*tp_subclasses*/
  0, /*tp_weaklist*/
  0, /*tp_del*/
  0, /*tp_version_tag*/
  #if PY_VERSION_HEX >= 0x030400a1
  0, /*tp_finalize*/
  #endif
};

static PyObject *__pyx_tp_new_5pygpu_8gpuarray_flags(PyTypeObject *t, PyObject *a, PyObject *k) {
  PyObject *o;
  if (likely((t->tp_flags & Py_TPFLAGS_IS_ABSTRACT) == 0)) {
    o = (*t->tp_alloc)(t, 0);
  } else {
    o = (PyObject *) PyBaseObject_Type.tp_new(t, __pyx_empty_tuple, 0);
  }
  if (unlikely(!o)) return 0;
  if (unlikely(__pyx_pw_5pygpu_8gpuarray_5flags_1__cinit__(o, a, k) < 0)) goto bad;
  return o;
  bad:
  Py_DECREF(o); o = 0;
  return NULL;
}

static void __pyx_tp_dealloc_5pygpu_8gpuarray_flags(PyObject *o) {
  #if CYTHON_USE_TP_FINALIZE
  if (unlikely(PyType_HasFeature(Py_TYPE(o), Py_TPFLAGS_HAVE_FINALIZE) && Py_TYPE(o)->tp_finalize) && (!PyType_IS_GC(Py_TYPE(o)) || !_PyGC_FINALIZED(o))) {
    if (PyObject_CallFinalizerFromDealloc(o)) return;
  }
  #endif
  (*Py_TYPE(o)->tp_free)(o);
}
static PyObject *__pyx_sq_item_5pygpu_8gpuarray_flags(PyObject *o, Py_ssize_t i) {
  PyObject *r;
  PyObject *x = PyInt_FromSsize_t(i); if(!x) return 0;
  r = Py_TYPE(o)->tp_as_mapping->mp_subscript(o, x);
  Py_DECREF(x);
  return r;
}

static PyObject *__pyx_getprop_5pygpu_8gpuarray_5flags_c_contiguous(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_5pygpu_8gpuarray_5flags_12c_contiguous_1__get__(o);
}

static PyObject *__pyx_getprop_5pygpu_8gpuarray_5flags_contiguous(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_5pygpu_8gpuarray_5flags_10contiguous_1__get__(o);
}

static PyObject *__pyx_getprop_5pygpu_8gpuarray_5flags_f_contiguous(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_5pygpu_8gpuarray_5flags_12f_contiguous_1__get__(o);
}

static PyObject *__pyx_getprop_5pygpu_8gpuarray_5flags_fortran(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_5pygpu_8gpuarray_5flags_7fortran_1__get__(o);
}

static PyObject *__pyx_getprop_5pygpu_8gpuarray_5flags_updateifcopy(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_5pygpu_8gpuarray_5flags_12updateifcopy_1__get__(o);
}

static PyObject *__pyx_getprop_5pygpu_8gpuarray_5flags_owndata(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_5pygpu_8gpuarray_5flags_7owndata_1__get__(o);
}

static PyObject *__pyx_getprop_5pygpu_8gpuarray_5flags_aligned(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_5pygpu_8gpuarray_5flags_7aligned_1__get__(o);
}

static PyObject *__pyx_getprop_5pygpu_8gpuarray_5flags_writeable(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_5pygpu_8gpuarray_5flags_9writeable_1__get__(o);
}

static PyObject *__pyx_getprop_5pygpu_8gpuarray_5flags_behaved(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_5pygpu_8gpuarray_5flags_7behaved_1__get__(o);
}

static PyObject *__pyx_getprop_5pygpu_8gpuarray_5flags_carray(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_5pygpu_8gpuarray_5flags_6carray_1__get__(o);
}

static PyObject *__pyx_getprop_5pygpu_8gpuarray_5flags_forc(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_5pygpu_8gpuarray_5flags_4forc_1__get__(o);
}

static PyObject *__pyx_getprop_5pygpu_8gpuarray_5flags_fnc(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_5pygpu_8gpuarray_5flags_3fnc_1__get__(o);
}

static PyObject *__pyx_getprop_5pygpu_8gpuarray_5flags_farray(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_5pygpu_8gpuarray_5flags_6farray_1__get__(o);
}

static PyObject *__pyx_getprop_5pygpu_8gpuarray_5flags_num(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_5pygpu_8gpuarray_5flags_3num_1__get__(o);
}

static PyMethodDef __pyx_methods_5pygpu_8gpuarray_flags[] = {
  {"__reduce__", (PyCFunction)__pyx_pw_5pygpu_8gpuarray_5flags_3__reduce__, METH_NOARGS, 0},
  {0, 0, 0, 0}
};

static struct PyGetSetDef __pyx_getsets_5pygpu_8gpuarray_flags[] = {
  {(char *)"c_contiguous", __pyx_getprop_5pygpu_8gpuarray_5flags_c_contiguous, 0, (char *)0, 0},
  {(char *)"contiguous", __pyx_getprop_5pygpu_8gpuarray_5flags_contiguous, 0, (char *)0, 0},
  {(char *)"f_contiguous", __pyx_getprop_5pygpu_8gpuarray_5flags_f_contiguous, 0, (char *)0, 0},
  {(char *)"fortran", __pyx_getprop_5pygpu_8gpuarray_5flags_fortran, 0, (char *)0, 0},
  {(char *)"updateifcopy", __pyx_getprop_5pygpu_8gpuarray_5flags_updateifcopy, 0, (char *)0, 0},
  {(char *)"owndata", __pyx_getprop_5pygpu_8gpuarray_5flags_owndata, 0, (char *)0, 0},
  {(char *)"aligned", __pyx_getprop_5pygpu_8gpuarray_5flags_aligned, 0, (char *)0, 0},
  {(char *)"writeable", __pyx_getprop_5pygpu_8gpuarray_5flags_writeable, 0, (char *)0, 0},
  {(char *)"behaved", __pyx_getprop_5pygpu_8gpuarray_5flags_behaved, 0, (char *)0, 0},
  {(char *)"carray", __pyx_getprop_5pygpu_8gpuarray_5flags_carray, 0, (char *)0, 0},
  {(char *)"forc", __pyx_getprop_5pygpu_8gpuarray_5flags_forc, 0, (char *)0, 0},
  {(char *)"fnc", __pyx_getprop_5pygpu_8gpuarray_5flags_fnc, 0, (char *)0, 0},
  {(char *)"farray", __pyx_getprop_5pygpu_8gpuarray_5flags_farray, 0, (char *)0, 0},
  {(char *)"num", __pyx_getprop_5pygpu_8gpuarray_5flags_num, 0, (char *)0, 0},
  {0, 0, 0, 0, 0}
};

static PySequenceMethods __pyx_tp_as_sequence_flags = {
  0, /*sq_length*/
  0, /*sq_concat*/
  0, /*sq_repeat*/
  __pyx_sq_item_5pygpu_8gpuarray_flags, /*sq_item*/
  0, /*sq_slice*/
  0, /*sq_ass_item*/
  0, /*sq_ass_slice*/
  0, /*sq_contains*/
  0, /*sq_inplace_concat*/
  0, /*sq_inplace_repeat*/
};

static PyMappingMethods __pyx_tp_as_mapping_flags = {
  0, /*mp_length*/
  __pyx_pw_5pygpu_8gpuarray_5flags_5__getitem__, /*mp_subscript*/
  0, /*mp_ass_subscript*/
};

static PyTypeObject __pyx_type_5pygpu_8gpuarray_flags = {
  PyVarObject_HEAD_INIT(0, 0)
  "pygpu.gpuarray.flags", /*tp_name*/
  sizeof(struct __pyx_obj_5pygpu_8gpuarray_flags), /*tp_basicsize*/
  0, /*tp_itemsize*/
  __pyx_tp_dealloc_5pygpu_8gpuarray_flags, /*tp_dealloc*/
  0, /*tp_print*/
  0, /*tp_getattr*/
  0, /*tp_setattr*/
  #if PY_MAJOR_VERSION < 3
  0, /*tp_compare*/
  #endif
  #if PY_MAJOR_VERSION >= 3
  0, /*tp_as_async*/
  #endif
  __pyx_pw_5pygpu_8gpuarray_5flags_7__repr__, /*tp_repr*/
  0, /*tp_as_number*/
  &__pyx_tp_as_sequence_flags, /*tp_as_sequence*/
  &__pyx_tp_as_mapping_flags, /*tp_as_mapping*/
  0, /*tp_hash*/
  0, /*tp_call*/
  0, /*tp_str*/
  0, /*tp_getattro*/
  0, /*tp_setattro*/
  0, /*tp_as_buffer*/
  Py_TPFLAGS_DEFAULT|Py_TPFLAGS_HAVE_VERSION_TAG|Py_TPFLAGS_CHECKTYPES|Py_TPFLAGS_HAVE_NEWBUFFER|Py_TPFLAGS_BASETYPE, /*tp_flags*/
  0, /*tp_doc*/
  0, /*tp_traverse*/
  0, /*tp_clear*/
  __pyx_pw_5pygpu_8gpuarray_5flags_9__richcmp__, /*tp_richcompare*/
  0, /*tp_weaklistoffset*/
  0, /*tp_iter*/
  0, /*tp_iternext*/
  __pyx_methods_5pygpu_8gpuarray_flags, /*tp_methods*/
  0, /*tp_members*/
  __pyx_getsets_5pygpu_8gpuarray_flags, /*tp_getset*/
  0, /*tp_base*/
  0, /*tp_dict*/
  0, /*tp_descr_get*/
  0, /*tp_descr_set*/
  0, /*tp_dictoffset*/
  0, /*tp_init*/
  0, /*tp_alloc*/
  __pyx_tp_new_5pygpu_8gpuarray_flags, /*tp_new*/
  0, /*tp_free*/
  0, /*tp_is_gc*/
  0, /*tp_bases*/
  0, /*tp_mro*/
  0, /*tp_cache*/
  0, /*tp_subclasses*/
  0, /*tp_weaklist*/
  0, /*tp_del*/
  0, /*tp_version_tag*/
  #if PY_VERSION_HEX >= 0x030400a1
  0, /*tp_finalize*/
  #endif
};

static struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct__genexpr *__pyx_freelist_5pygpu_8gpuarray___pyx_scope_struct__genexpr[8];
static int __pyx_freecount_5pygpu_8gpuarray___pyx_scope_struct__genexpr = 0;

static PyObject *__pyx_tp_new_5pygpu_8gpuarray___pyx_scope_struct__genexpr(PyTypeObject *t, CYTHON_UNUSED PyObject *a, CYTHON_UNUSED PyObject *k) {
  PyObject *o;
  if (CYTHON_COMPILING_IN_CPYTHON && likely((__pyx_freecount_5pygpu_8gpuarray___pyx_scope_struct__genexpr > 0) & (t->tp_basicsize == sizeof(struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct__genexpr)))) {
    o = (PyObject*)__pyx_freelist_5pygpu_8gpuarray___pyx_scope_struct__genexpr[--__pyx_freecount_5pygpu_8gpuarray___pyx_scope_struct__genexpr];
    memset(o, 0, sizeof(struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct__genexpr));
    (void) PyObject_INIT(o, t);
    PyObject_GC_Track(o);
  } else {
    o = (*t->tp_alloc)(t, 0);
    if (unlikely(!o)) return 0;
  }
  return o;
}

static void __pyx_tp_dealloc_5pygpu_8gpuarray___pyx_scope_struct__genexpr(PyObject *o) {
  struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct__genexpr *p = (struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct__genexpr *)o;
  PyObject_GC_UnTrack(o);
  Py_CLEAR(p->__pyx_v_k);
  Py_CLEAR(p->__pyx_v_v);
  if (CYTHON_COMPILING_IN_CPYTHON && ((__pyx_freecount_5pygpu_8gpuarray___pyx_scope_struct__genexpr < 8) & (Py_TYPE(o)->tp_basicsize == sizeof(struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct__genexpr)))) {
    __pyx_freelist_5pygpu_8gpuarray___pyx_scope_struct__genexpr[__pyx_freecount_5pygpu_8gpuarray___pyx_scope_struct__genexpr++] = ((struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct__genexpr *)o);
  } else {
    (*Py_TYPE(o)->tp_free)(o);
  }
}

static int __pyx_tp_traverse_5pygpu_8gpuarray___pyx_scope_struct__genexpr(PyObject *o, visitproc v, void *a) {
  int e;
  struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct__genexpr *p = (struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct__genexpr *)o;
  if (p->__pyx_v_k) {
    e = (*v)(p->__pyx_v_k, a); if (e) return e;
  }
  if (p->__pyx_v_v) {
    e = (*v)(p->__pyx_v_v, a); if (e) return e;
  }
  return 0;
}

static PyTypeObject __pyx_type_5pygpu_8gpuarray___pyx_scope_struct__genexpr = {
  PyVarObject_HEAD_INIT(0, 0)
  "pygpu.gpuarray.__pyx_scope_struct__genexpr", /*tp_name*/
  sizeof(struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct__genexpr), /*tp_basicsize*/
  0, /*tp_itemsize*/
  __pyx_tp_dealloc_5pygpu_8gpuarray___pyx_scope_struct__genexpr, /*tp_dealloc*/
  0, /*tp_print*/
  0, /*tp_getattr*/
  0, /*tp_setattr*/
  #if PY_MAJOR_VERSION < 3
  0, /*tp_compare*/
  #endif
  #if PY_MAJOR_VERSION >= 3
  0, /*tp_as_async*/
  #endif
  0, /*tp_repr*/
  0, /*tp_as_number*/
  0, /*tp_as_sequence*/
  0, /*tp_as_mapping*/
  0, /*tp_hash*/
  0, /*tp_call*/
  0, /*tp_str*/
  0, /*tp_getattro*/
  0, /*tp_setattro*/
  0, /*tp_as_buffer*/
  Py_TPFLAGS_DEFAULT|Py_TPFLAGS_HAVE_VERSION_TAG|Py_TPFLAGS_CHECKTYPES|Py_TPFLAGS_HAVE_NEWBUFFER|Py_TPFLAGS_HAVE_GC, /*tp_flags*/
  0, /*tp_doc*/
  __pyx_tp_traverse_5pygpu_8gpuarray___pyx_scope_struct__genexpr, /*tp_traverse*/
  0, /*tp_clear*/
  0, /*tp_richcompare*/
  0, /*tp_weaklistoffset*/
  0, /*tp_iter*/
  0, /*tp_iternext*/
  0, /*tp_methods*/
  0, /*tp_members*/
  0, /*tp_getset*/
  0, /*tp_base*/
  0, /*tp_dict*/
  0, /*tp_descr_get*/
  0, /*tp_descr_set*/
  0, /*tp_dictoffset*/
  0, /*tp_init*/
  0, /*tp_alloc*/
  __pyx_tp_new_5pygpu_8gpuarray___pyx_scope_struct__genexpr, /*tp_new*/
  0, /*tp_free*/
  0, /*tp_is_gc*/
  0, /*tp_bases*/
  0, /*tp_mro*/
  0, /*tp_cache*/
  0, /*tp_subclasses*/
  0, /*tp_weaklist*/
  0, /*tp_del*/
  0, /*tp_version_tag*/
  #if PY_VERSION_HEX >= 0x030400a1
  0, /*tp_finalize*/
  #endif
};

static struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_1___repr__ *__pyx_freelist_5pygpu_8gpuarray___pyx_scope_struct_1___repr__[8];
static int __pyx_freecount_5pygpu_8gpuarray___pyx_scope_struct_1___repr__ = 0;

static PyObject *__pyx_tp_new_5pygpu_8gpuarray___pyx_scope_struct_1___repr__(PyTypeObject *t, CYTHON_UNUSED PyObject *a, CYTHON_UNUSED PyObject *k) {
  PyObject *o;
  if (CYTHON_COMPILING_IN_CPYTHON && likely((__pyx_freecount_5pygpu_8gpuarray___pyx_scope_struct_1___repr__ > 0) & (t->tp_basicsize == sizeof(struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_1___repr__)))) {
    o = (PyObject*)__pyx_freelist_5pygpu_8gpuarray___pyx_scope_struct_1___repr__[--__pyx_freecount_5pygpu_8gpuarray___pyx_scope_struct_1___repr__];
    memset(o, 0, sizeof(struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_1___repr__));
    (void) PyObject_INIT(o, t);
    PyObject_GC_Track(o);
  } else {
    o = (*t->tp_alloc)(t, 0);
    if (unlikely(!o)) return 0;
  }
  return o;
}

static void __pyx_tp_dealloc_5pygpu_8gpuarray___pyx_scope_struct_1___repr__(PyObject *o) {
  struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_1___repr__ *p = (struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_1___repr__ *)o;
  PyObject_GC_UnTrack(o);
  Py_CLEAR(p->__pyx_v_self);
  if (CYTHON_COMPILING_IN_CPYTHON && ((__pyx_freecount_5pygpu_8gpuarray___pyx_scope_struct_1___repr__ < 8) & (Py_TYPE(o)->tp_basicsize == sizeof(struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_1___repr__)))) {
    __pyx_freelist_5pygpu_8gpuarray___pyx_scope_struct_1___repr__[__pyx_freecount_5pygpu_8gpuarray___pyx_scope_struct_1___repr__++] = ((struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_1___repr__ *)o);
  } else {
    (*Py_TYPE(o)->tp_free)(o);
  }
}

static int __pyx_tp_traverse_5pygpu_8gpuarray___pyx_scope_struct_1___repr__(PyObject *o, visitproc v, void *a) {
  int e;
  struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_1___repr__ *p = (struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_1___repr__ *)o;
  if (p->__pyx_v_self) {
    e = (*v)(((PyObject *)p->__pyx_v_self), a); if (e) return e;
  }
  return 0;
}

static int __pyx_tp_clear_5pygpu_8gpuarray___pyx_scope_struct_1___repr__(PyObject *o) {
  PyObject* tmp;
  struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_1___repr__ *p = (struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_1___repr__ *)o;
  tmp = ((PyObject*)p->__pyx_v_self);
  p->__pyx_v_self = ((struct __pyx_obj_5pygpu_8gpuarray_flags *)Py_None); Py_INCREF(Py_None);
  Py_XDECREF(tmp);
  return 0;
}

static PyTypeObject __pyx_type_5pygpu_8gpuarray___pyx_scope_struct_1___repr__ = {
  PyVarObject_HEAD_INIT(0, 0)
  "pygpu.gpuarray.__pyx_scope_struct_1___repr__", /*tp_name*/
  sizeof(struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_1___repr__), /*tp_basicsize*/
  0, /*tp_itemsize*/
  __pyx_tp_dealloc_5pygpu_8gpuarray___pyx_scope_struct_1___repr__, /*tp_dealloc*/
  0, /*tp_print*/
  0, /*tp_getattr*/
  0, /*tp_setattr*/
  #if PY_MAJOR_VERSION < 3
  0, /*tp_compare*/
  #endif
  #if PY_MAJOR_VERSION >= 3
  0, /*tp_as_async*/
  #endif
  0, /*tp_repr*/
  0, /*tp_as_number*/
  0, /*tp_as_sequence*/
  0, /*tp_as_mapping*/
  0, /*tp_hash*/
  0, /*tp_call*/
  0, /*tp_str*/
  0, /*tp_getattro*/
  0, /*tp_setattro*/
  0, /*tp_as_buffer*/
  Py_TPFLAGS_DEFAULT|Py_TPFLAGS_HAVE_VERSION_TAG|Py_TPFLAGS_CHECKTYPES|Py_TPFLAGS_HAVE_NEWBUFFER|Py_TPFLAGS_HAVE_GC, /*tp_flags*/
  0, /*tp_doc*/
  __pyx_tp_traverse_5pygpu_8gpuarray___pyx_scope_struct_1___repr__, /*tp_traverse*/
  __pyx_tp_clear_5pygpu_8gpuarray___pyx_scope_struct_1___repr__, /*tp_clear*/
  0, /*tp_richcompare*/
  0, /*tp_weaklistoffset*/
  0, /*tp_iter*/
  0, /*tp_iternext*/
  0, /*tp_methods*/
  0, /*tp_members*/
  0, /*tp_getset*/
  0, /*tp_base*/
  0, /*tp_dict*/
  0, /*tp_descr_get*/
  0, /*tp_descr_set*/
  0, /*tp_dictoffset*/
  0, /*tp_init*/
  0, /*tp_alloc*/
  __pyx_tp_new_5pygpu_8gpuarray___pyx_scope_struct_1___repr__, /*tp_new*/
  0, /*tp_free*/
  0, /*tp_is_gc*/
  0, /*tp_bases*/
  0, /*tp_mro*/
  0, /*tp_cache*/
  0, /*tp_subclasses*/
  0, /*tp_weaklist*/
  0, /*tp_del*/
  0, /*tp_version_tag*/
  #if PY_VERSION_HEX >= 0x030400a1
  0, /*tp_finalize*/
  #endif
};

static struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_2_genexpr *__pyx_freelist_5pygpu_8gpuarray___pyx_scope_struct_2_genexpr[8];
static int __pyx_freecount_5pygpu_8gpuarray___pyx_scope_struct_2_genexpr = 0;

static PyObject *__pyx_tp_new_5pygpu_8gpuarray___pyx_scope_struct_2_genexpr(PyTypeObject *t, CYTHON_UNUSED PyObject *a, CYTHON_UNUSED PyObject *k) {
  PyObject *o;
  if (CYTHON_COMPILING_IN_CPYTHON && likely((__pyx_freecount_5pygpu_8gpuarray___pyx_scope_struct_2_genexpr > 0) & (t->tp_basicsize == sizeof(struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_2_genexpr)))) {
    o = (PyObject*)__pyx_freelist_5pygpu_8gpuarray___pyx_scope_struct_2_genexpr[--__pyx_freecount_5pygpu_8gpuarray___pyx_scope_struct_2_genexpr];
    memset(o, 0, sizeof(struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_2_genexpr));
    (void) PyObject_INIT(o, t);
    PyObject_GC_Track(o);
  } else {
    o = (*t->tp_alloc)(t, 0);
    if (unlikely(!o)) return 0;
  }
  return o;
}

static void __pyx_tp_dealloc_5pygpu_8gpuarray___pyx_scope_struct_2_genexpr(PyObject *o) {
  struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_2_genexpr *p = (struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_2_genexpr *)o;
  PyObject_GC_UnTrack(o);
  Py_CLEAR(p->__pyx_outer_scope);
  Py_CLEAR(p->__pyx_v_name);
  Py_CLEAR(p->__pyx_t_0);
  if (CYTHON_COMPILING_IN_CPYTHON && ((__pyx_freecount_5pygpu_8gpuarray___pyx_scope_struct_2_genexpr < 8) & (Py_TYPE(o)->tp_basicsize == sizeof(struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_2_genexpr)))) {
    __pyx_freelist_5pygpu_8gpuarray___pyx_scope_struct_2_genexpr[__pyx_freecount_5pygpu_8gpuarray___pyx_scope_struct_2_genexpr++] = ((struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_2_genexpr *)o);
  } else {
    (*Py_TYPE(o)->tp_free)(o);
  }
}

static int __pyx_tp_traverse_5pygpu_8gpuarray___pyx_scope_struct_2_genexpr(PyObject *o, visitproc v, void *a) {
  int e;
  struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_2_genexpr *p = (struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_2_genexpr *)o;
  if (p->__pyx_outer_scope) {
    e = (*v)(((PyObject *)p->__pyx_outer_scope), a); if (e) return e;
  }
  if (p->__pyx_v_name) {
    e = (*v)(p->__pyx_v_name, a); if (e) return e;
  }
  if (p->__pyx_t_0) {
    e = (*v)(p->__pyx_t_0, a); if (e) return e;
  }
  return 0;
}

static PyTypeObject __pyx_type_5pygpu_8gpuarray___pyx_scope_struct_2_genexpr = {
  PyVarObject_HEAD_INIT(0, 0)
  "pygpu.gpuarray.__pyx_scope_struct_2_genexpr", /*tp_name*/
  sizeof(struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_2_genexpr), /*tp_basicsize*/
  0, /*tp_itemsize*/
  __pyx_tp_dealloc_5pygpu_8gpuarray___pyx_scope_struct_2_genexpr, /*tp_dealloc*/
  0, /*tp_print*/
  0, /*tp_getattr*/
  0, /*tp_setattr*/
  #if PY_MAJOR_VERSION < 3
  0, /*tp_compare*/
  #endif
  #if PY_MAJOR_VERSION >= 3
  0, /*tp_as_async*/
  #endif
  0, /*tp_repr*/
  0, /*tp_as_number*/
  0, /*tp_as_sequence*/
  0, /*tp_as_mapping*/
  0, /*tp_hash*/
  0, /*tp_call*/
  0, /*tp_str*/
  0, /*tp_getattro*/
  0, /*tp_setattro*/
  0, /*tp_as_buffer*/
  Py_TPFLAGS_DEFAULT|Py_TPFLAGS_HAVE_VERSION_TAG|Py_TPFLAGS_CHECKTYPES|Py_TPFLAGS_HAVE_NEWBUFFER|Py_TPFLAGS_HAVE_GC, /*tp_flags*/
  0, /*tp_doc*/
  __pyx_tp_traverse_5pygpu_8gpuarray___pyx_scope_struct_2_genexpr, /*tp_traverse*/
  0, /*tp_clear*/
  0, /*tp_richcompare*/
  0, /*tp_weaklistoffset*/
  0, /*tp_iter*/
  0, /*tp_iternext*/
  0, /*tp_methods*/
  0, /*tp_members*/
  0, /*tp_getset*/
  0, /*tp_base*/
  0, /*tp_dict*/
  0, /*tp_descr_get*/
  0, /*tp_descr_set*/
  0, /*tp_dictoffset*/
  0, /*tp_init*/
  0, /*tp_alloc*/
  __pyx_tp_new_5pygpu_8gpuarray___pyx_scope_struct_2_genexpr, /*tp_new*/
  0, /*tp_free*/
  0, /*tp_is_gc*/
  0, /*tp_bases*/
  0, /*tp_mro*/
  0, /*tp_cache*/
  0, /*tp_subclasses*/
  0, /*tp_weaklist*/
  0, /*tp_del*/
  0, /*tp_version_tag*/
  #if PY_VERSION_HEX >= 0x030400a1
  0, /*tp_finalize*/
  #endif
};

static struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_3___getitem__ *__pyx_freelist_5pygpu_8gpuarray___pyx_scope_struct_3___getitem__[8];
static int __pyx_freecount_5pygpu_8gpuarray___pyx_scope_struct_3___getitem__ = 0;

static PyObject *__pyx_tp_new_5pygpu_8gpuarray___pyx_scope_struct_3___getitem__(PyTypeObject *t, CYTHON_UNUSED PyObject *a, CYTHON_UNUSED PyObject *k) {
  PyObject *o;
  if (CYTHON_COMPILING_IN_CPYTHON && likely((__pyx_freecount_5pygpu_8gpuarray___pyx_scope_struct_3___getitem__ > 0) & (t->tp_basicsize == sizeof(struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_3___getitem__)))) {
    o = (PyObject*)__pyx_freelist_5pygpu_8gpuarray___pyx_scope_struct_3___getitem__[--__pyx_freecount_5pygpu_8gpuarray___pyx_scope_struct_3___getitem__];
    memset(o, 0, sizeof(struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_3___getitem__));
    (void) PyObject_INIT(o, t);
    PyObject_GC_Track(o);
  } else {
    o = (*t->tp_alloc)(t, 0);
    if (unlikely(!o)) return 0;
  }
  return o;
}

static void __pyx_tp_dealloc_5pygpu_8gpuarray___pyx_scope_struct_3___getitem__(PyObject *o) {
  struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_3___getitem__ *p = (struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_3___getitem__ *)o;
  PyObject_GC_UnTrack(o);
  Py_CLEAR(p->__pyx_v_key);
  if (CYTHON_COMPILING_IN_CPYTHON && ((__pyx_freecount_5pygpu_8gpuarray___pyx_scope_struct_3___getitem__ < 8) & (Py_TYPE(o)->tp_basicsize == sizeof(struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_3___getitem__)))) {
    __pyx_freelist_5pygpu_8gpuarray___pyx_scope_struct_3___getitem__[__pyx_freecount_5pygpu_8gpuarray___pyx_scope_struct_3___getitem__++] = ((struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_3___getitem__ *)o);
  } else {
    (*Py_TYPE(o)->tp_free)(o);
  }
}

static int __pyx_tp_traverse_5pygpu_8gpuarray___pyx_scope_struct_3___getitem__(PyObject *o, visitproc v, void *a) {
  int e;
  struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_3___getitem__ *p = (struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_3___getitem__ *)o;
  if (p->__pyx_v_key) {
    e = (*v)(p->__pyx_v_key, a); if (e) return e;
  }
  return 0;
}

static int __pyx_tp_clear_5pygpu_8gpuarray___pyx_scope_struct_3___getitem__(PyObject *o) {
  PyObject* tmp;
  struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_3___getitem__ *p = (struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_3___getitem__ *)o;
  tmp = ((PyObject*)p->__pyx_v_key);
  p->__pyx_v_key = Py_None; Py_INCREF(Py_None);
  Py_XDECREF(tmp);
  return 0;
}

static PyTypeObject __pyx_type_5pygpu_8gpuarray___pyx_scope_struct_3___getitem__ = {
  PyVarObject_HEAD_INIT(0, 0)
  "pygpu.gpuarray.__pyx_scope_struct_3___getitem__", /*tp_name*/
  sizeof(struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_3___getitem__), /*tp_basicsize*/
  0, /*tp_itemsize*/
  __pyx_tp_dealloc_5pygpu_8gpuarray___pyx_scope_struct_3___getitem__, /*tp_dealloc*/
  0, /*tp_print*/
  0, /*tp_getattr*/
  0, /*tp_setattr*/
  #if PY_MAJOR_VERSION < 3
  0, /*tp_compare*/
  #endif
  #if PY_MAJOR_VERSION >= 3
  0, /*tp_as_async*/
  #endif
  0, /*tp_repr*/
  0, /*tp_as_number*/
  0, /*tp_as_sequence*/
  0, /*tp_as_mapping*/
  0, /*tp_hash*/
  0, /*tp_call*/
  0, /*tp_str*/
  0, /*tp_getattro*/
  0, /*tp_setattro*/
  0, /*tp_as_buffer*/
  Py_TPFLAGS_DEFAULT|Py_TPFLAGS_HAVE_VERSION_TAG|Py_TPFLAGS_CHECKTYPES|Py_TPFLAGS_HAVE_NEWBUFFER|Py_TPFLAGS_HAVE_GC, /*tp_flags*/
  0, /*tp_doc*/
  __pyx_tp_traverse_5pygpu_8gpuarray___pyx_scope_struct_3___getitem__, /*tp_traverse*/
  __pyx_tp_clear_5pygpu_8gpuarray___pyx_scope_struct_3___getitem__, /*tp_clear*/
  0, /*tp_richcompare*/
  0, /*tp_weaklistoffset*/
  0, /*tp_iter*/
  0, /*tp_iternext*/
  0, /*tp_methods*/
  0, /*tp_members*/
  0, /*tp_getset*/
  0, /*tp_base*/
  0, /*tp_dict*/
  0, /*tp_descr_get*/
  0, /*tp_descr_set*/
  0, /*tp_dictoffset*/
  0, /*tp_init*/
  0, /*tp_alloc*/
  __pyx_tp_new_5pygpu_8gpuarray___pyx_scope_struct_3___getitem__, /*tp_new*/
  0, /*tp_free*/
  0, /*tp_is_gc*/
  0, /*tp_bases*/
  0, /*tp_mro*/
  0, /*tp_cache*/
  0, /*tp_subclasses*/
  0, /*tp_weaklist*/
  0, /*tp_del*/
  0, /*tp_version_tag*/
  #if PY_VERSION_HEX >= 0x030400a1
  0, /*tp_finalize*/
  #endif
};

static struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_4_genexpr *__pyx_freelist_5pygpu_8gpuarray___pyx_scope_struct_4_genexpr[8];
static int __pyx_freecount_5pygpu_8gpuarray___pyx_scope_struct_4_genexpr = 0;

static PyObject *__pyx_tp_new_5pygpu_8gpuarray___pyx_scope_struct_4_genexpr(PyTypeObject *t, CYTHON_UNUSED PyObject *a, CYTHON_UNUSED PyObject *k) {
  PyObject *o;
  if (CYTHON_COMPILING_IN_CPYTHON && likely((__pyx_freecount_5pygpu_8gpuarray___pyx_scope_struct_4_genexpr > 0) & (t->tp_basicsize == sizeof(struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_4_genexpr)))) {
    o = (PyObject*)__pyx_freelist_5pygpu_8gpuarray___pyx_scope_struct_4_genexpr[--__pyx_freecount_5pygpu_8gpuarray___pyx_scope_struct_4_genexpr];
    memset(o, 0, sizeof(struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_4_genexpr));
    (void) PyObject_INIT(o, t);
    PyObject_GC_Track(o);
  } else {
    o = (*t->tp_alloc)(t, 0);
    if (unlikely(!o)) return 0;
  }
  return o;
}

static void __pyx_tp_dealloc_5pygpu_8gpuarray___pyx_scope_struct_4_genexpr(PyObject *o) {
  struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_4_genexpr *p = (struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_4_genexpr *)o;
  PyObject_GC_UnTrack(o);
  Py_CLEAR(p->__pyx_outer_scope);
  Py_CLEAR(p->__pyx_v_k);
  if (CYTHON_COMPILING_IN_CPYTHON && ((__pyx_freecount_5pygpu_8gpuarray___pyx_scope_struct_4_genexpr < 8) & (Py_TYPE(o)->tp_basicsize == sizeof(struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_4_genexpr)))) {
    __pyx_freelist_5pygpu_8gpuarray___pyx_scope_struct_4_genexpr[__pyx_freecount_5pygpu_8gpuarray___pyx_scope_struct_4_genexpr++] = ((struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_4_genexpr *)o);
  } else {
    (*Py_TYPE(o)->tp_free)(o);
  }
}

static int __pyx_tp_traverse_5pygpu_8gpuarray___pyx_scope_struct_4_genexpr(PyObject *o, visitproc v, void *a) {
  int e;
  struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_4_genexpr *p = (struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_4_genexpr *)o;
  if (p->__pyx_outer_scope) {
    e = (*v)(((PyObject *)p->__pyx_outer_scope), a); if (e) return e;
  }
  if (p->__pyx_v_k) {
    e = (*v)(p->__pyx_v_k, a); if (e) return e;
  }
  return 0;
}

static PyTypeObject __pyx_type_5pygpu_8gpuarray___pyx_scope_struct_4_genexpr = {
  PyVarObject_HEAD_INIT(0, 0)
  "pygpu.gpuarray.__pyx_scope_struct_4_genexpr", /*tp_name*/
  sizeof(struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_4_genexpr), /*tp_basicsize*/
  0, /*tp_itemsize*/
  __pyx_tp_dealloc_5pygpu_8gpuarray___pyx_scope_struct_4_genexpr, /*tp_dealloc*/
  0, /*tp_print*/
  0, /*tp_getattr*/
  0, /*tp_setattr*/
  #if PY_MAJOR_VERSION < 3
  0, /*tp_compare*/
  #endif
  #if PY_MAJOR_VERSION >= 3
  0, /*tp_as_async*/
  #endif
  0, /*tp_repr*/
  0, /*tp_as_number*/
  0, /*tp_as_sequence*/
  0, /*tp_as_mapping*/
  0, /*tp_hash*/
  0, /*tp_call*/
  0, /*tp_str*/
  0, /*tp_getattro*/
  0, /*tp_setattro*/
  0, /*tp_as_buffer*/
  Py_TPFLAGS_DEFAULT|Py_TPFLAGS_HAVE_VERSION_TAG|Py_TPFLAGS_CHECKTYPES|Py_TPFLAGS_HAVE_NEWBUFFER|Py_TPFLAGS_HAVE_GC, /*tp_flags*/
  0, /*tp_doc*/
  __pyx_tp_traverse_5pygpu_8gpuarray___pyx_scope_struct_4_genexpr, /*tp_traverse*/
  0, /*tp_clear*/
  0, /*tp_richcompare*/
  0, /*tp_weaklistoffset*/
  0, /*tp_iter*/
  0, /*tp_iternext*/
  0, /*tp_methods*/
  0, /*tp_members*/
  0, /*tp_getset*/
  0, /*tp_base*/
  0, /*tp_dict*/
  0, /*tp_descr_get*/
  0, /*tp_descr_set*/
  0, /*tp_dictoffset*/
  0, /*tp_init*/
  0, /*tp_alloc*/
  __pyx_tp_new_5pygpu_8gpuarray___pyx_scope_struct_4_genexpr, /*tp_new*/
  0, /*tp_free*/
  0, /*tp_is_gc*/
  0, /*tp_bases*/
  0, /*tp_mro*/
  0, /*tp_cache*/
  0, /*tp_subclasses*/
  0, /*tp_weaklist*/
  0, /*tp_del*/
  0, /*tp_version_tag*/
  #if PY_VERSION_HEX >= 0x030400a1
  0, /*tp_finalize*/
  #endif
};

static struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_5_genexpr *__pyx_freelist_5pygpu_8gpuarray___pyx_scope_struct_5_genexpr[8];
static int __pyx_freecount_5pygpu_8gpuarray___pyx_scope_struct_5_genexpr = 0;

static PyObject *__pyx_tp_new_5pygpu_8gpuarray___pyx_scope_struct_5_genexpr(PyTypeObject *t, CYTHON_UNUSED PyObject *a, CYTHON_UNUSED PyObject *k) {
  PyObject *o;
  if (CYTHON_COMPILING_IN_CPYTHON && likely((__pyx_freecount_5pygpu_8gpuarray___pyx_scope_struct_5_genexpr > 0) & (t->tp_basicsize == sizeof(struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_5_genexpr)))) {
    o = (PyObject*)__pyx_freelist_5pygpu_8gpuarray___pyx_scope_struct_5_genexpr[--__pyx_freecount_5pygpu_8gpuarray___pyx_scope_struct_5_genexpr];
    memset(o, 0, sizeof(struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_5_genexpr));
    (void) PyObject_INIT(o, t);
    PyObject_GC_Track(o);
  } else {
    o = (*t->tp_alloc)(t, 0);
    if (unlikely(!o)) return 0;
  }
  return o;
}

static void __pyx_tp_dealloc_5pygpu_8gpuarray___pyx_scope_struct_5_genexpr(PyObject *o) {
  struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_5_genexpr *p = (struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_5_genexpr *)o;
  PyObject_GC_UnTrack(o);
  Py_CLEAR(p->__pyx_outer_scope);
  Py_CLEAR(p->__pyx_v_k);
  if (CYTHON_COMPILING_IN_CPYTHON && ((__pyx_freecount_5pygpu_8gpuarray___pyx_scope_struct_5_genexpr < 8) & (Py_TYPE(o)->tp_basicsize == sizeof(struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_5_genexpr)))) {
    __pyx_freelist_5pygpu_8gpuarray___pyx_scope_struct_5_genexpr[__pyx_freecount_5pygpu_8gpuarray___pyx_scope_struct_5_genexpr++] = ((struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_5_genexpr *)o);
  } else {
    (*Py_TYPE(o)->tp_free)(o);
  }
}

static int __pyx_tp_traverse_5pygpu_8gpuarray___pyx_scope_struct_5_genexpr(PyObject *o, visitproc v, void *a) {
  int e;
  struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_5_genexpr *p = (struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_5_genexpr *)o;
  if (p->__pyx_outer_scope) {
    e = (*v)(((PyObject *)p->__pyx_outer_scope), a); if (e) return e;
  }
  if (p->__pyx_v_k) {
    e = (*v)(p->__pyx_v_k, a); if (e) return e;
  }
  return 0;
}

static PyTypeObject __pyx_type_5pygpu_8gpuarray___pyx_scope_struct_5_genexpr = {
  PyVarObject_HEAD_INIT(0, 0)
  "pygpu.gpuarray.__pyx_scope_struct_5_genexpr", /*tp_name*/
  sizeof(struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_5_genexpr), /*tp_basicsize*/
  0, /*tp_itemsize*/
  __pyx_tp_dealloc_5pygpu_8gpuarray___pyx_scope_struct_5_genexpr, /*tp_dealloc*/
  0, /*tp_print*/
  0, /*tp_getattr*/
  0, /*tp_setattr*/
  #if PY_MAJOR_VERSION < 3
  0, /*tp_compare*/
  #endif
  #if PY_MAJOR_VERSION >= 3
  0, /*tp_as_async*/
  #endif
  0, /*tp_repr*/
  0, /*tp_as_number*/
  0, /*tp_as_sequence*/
  0, /*tp_as_mapping*/
  0, /*tp_hash*/
  0, /*tp_call*/
  0, /*tp_str*/
  0, /*tp_getattro*/
  0, /*tp_setattro*/
  0, /*tp_as_buffer*/
  Py_TPFLAGS_DEFAULT|Py_TPFLAGS_HAVE_VERSION_TAG|Py_TPFLAGS_CHECKTYPES|Py_TPFLAGS_HAVE_NEWBUFFER|Py_TPFLAGS_HAVE_GC, /*tp_flags*/
  0, /*tp_doc*/
  __pyx_tp_traverse_5pygpu_8gpuarray___pyx_scope_struct_5_genexpr, /*tp_traverse*/
  0, /*tp_clear*/
  0, /*tp_richcompare*/
  0, /*tp_weaklistoffset*/
  0, /*tp_iter*/
  0, /*tp_iternext*/
  0, /*tp_methods*/
  0, /*tp_members*/
  0, /*tp_getset*/
  0, /*tp_base*/
  0, /*tp_dict*/
  0, /*tp_descr_get*/
  0, /*tp_descr_set*/
  0, /*tp_dictoffset*/
  0, /*tp_init*/
  0, /*tp_alloc*/
  __pyx_tp_new_5pygpu_8gpuarray___pyx_scope_struct_5_genexpr, /*tp_new*/
  0, /*tp_free*/
  0, /*tp_is_gc*/
  0, /*tp_bases*/
  0, /*tp_mro*/
  0, /*tp_cache*/
  0, /*tp_subclasses*/
  0, /*tp_weaklist*/
  0, /*tp_del*/
  0, /*tp_version_tag*/
  #if PY_VERSION_HEX >= 0x030400a1
  0, /*tp_finalize*/
  #endif
};

static struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_6_genexpr *__pyx_freelist_5pygpu_8gpuarray___pyx_scope_struct_6_genexpr[8];
static int __pyx_freecount_5pygpu_8gpuarray___pyx_scope_struct_6_genexpr = 0;

static PyObject *__pyx_tp_new_5pygpu_8gpuarray___pyx_scope_struct_6_genexpr(PyTypeObject *t, CYTHON_UNUSED PyObject *a, CYTHON_UNUSED PyObject *k) {
  PyObject *o;
  if (CYTHON_COMPILING_IN_CPYTHON && likely((__pyx_freecount_5pygpu_8gpuarray___pyx_scope_struct_6_genexpr > 0) & (t->tp_basicsize == sizeof(struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_6_genexpr)))) {
    o = (PyObject*)__pyx_freelist_5pygpu_8gpuarray___pyx_scope_struct_6_genexpr[--__pyx_freecount_5pygpu_8gpuarray___pyx_scope_struct_6_genexpr];
    memset(o, 0, sizeof(struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_6_genexpr));
    (void) PyObject_INIT(o, t);
    PyObject_GC_Track(o);
  } else {
    o = (*t->tp_alloc)(t, 0);
    if (unlikely(!o)) return 0;
  }
  return o;
}

static void __pyx_tp_dealloc_5pygpu_8gpuarray___pyx_scope_struct_6_genexpr(PyObject *o) {
  struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_6_genexpr *p = (struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_6_genexpr *)o;
  PyObject_GC_UnTrack(o);
  Py_CLEAR(p->__pyx_outer_scope);
  Py_CLEAR(p->__pyx_v_k);
  Py_CLEAR(p->__pyx_t_0);
  if (CYTHON_COMPILING_IN_CPYTHON && ((__pyx_freecount_5pygpu_8gpuarray___pyx_scope_struct_6_genexpr < 8) & (Py_TYPE(o)->tp_basicsize == sizeof(struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_6_genexpr)))) {
    __pyx_freelist_5pygpu_8gpuarray___pyx_scope_struct_6_genexpr[__pyx_freecount_5pygpu_8gpuarray___pyx_scope_struct_6_genexpr++] = ((struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_6_genexpr *)o);
  } else {
    (*Py_TYPE(o)->tp_free)(o);
  }
}

static int __pyx_tp_traverse_5pygpu_8gpuarray___pyx_scope_struct_6_genexpr(PyObject *o, visitproc v, void *a) {
  int e;
  struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_6_genexpr *p = (struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_6_genexpr *)o;
  if (p->__pyx_outer_scope) {
    e = (*v)(((PyObject *)p->__pyx_outer_scope), a); if (e) return e;
  }
  if (p->__pyx_v_k) {
    e = (*v)(p->__pyx_v_k, a); if (e) return e;
  }
  if (p->__pyx_t_0) {
    e = (*v)(p->__pyx_t_0, a); if (e) return e;
  }
  return 0;
}

static PyTypeObject __pyx_type_5pygpu_8gpuarray___pyx_scope_struct_6_genexpr = {
  PyVarObject_HEAD_INIT(0, 0)
  "pygpu.gpuarray.__pyx_scope_struct_6_genexpr", /*tp_name*/
  sizeof(struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_6_genexpr), /*tp_basicsize*/
  0, /*tp_itemsize*/
  __pyx_tp_dealloc_5pygpu_8gpuarray___pyx_scope_struct_6_genexpr, /*tp_dealloc*/
  0, /*tp_print*/
  0, /*tp_getattr*/
  0, /*tp_setattr*/
  #if PY_MAJOR_VERSION < 3
  0, /*tp_compare*/
  #endif
  #if PY_MAJOR_VERSION >= 3
  0, /*tp_as_async*/
  #endif
  0, /*tp_repr*/
  0, /*tp_as_number*/
  0, /*tp_as_sequence*/
  0, /*tp_as_mapping*/
  0, /*tp_hash*/
  0, /*tp_call*/
  0, /*tp_str*/
  0, /*tp_getattro*/
  0, /*tp_setattro*/
  0, /*tp_as_buffer*/
  Py_TPFLAGS_DEFAULT|Py_TPFLAGS_HAVE_VERSION_TAG|Py_TPFLAGS_CHECKTYPES|Py_TPFLAGS_HAVE_NEWBUFFER|Py_TPFLAGS_HAVE_GC, /*tp_flags*/
  0, /*tp_doc*/
  __pyx_tp_traverse_5pygpu_8gpuarray___pyx_scope_struct_6_genexpr, /*tp_traverse*/
  0, /*tp_clear*/
  0, /*tp_richcompare*/
  0, /*tp_weaklistoffset*/
  0, /*tp_iter*/
  0, /*tp_iternext*/
  0, /*tp_methods*/
  0, /*tp_members*/
  0, /*tp_getset*/
  0, /*tp_base*/
  0, /*tp_dict*/
  0, /*tp_descr_get*/
  0, /*tp_descr_set*/
  0, /*tp_dictoffset*/
  0, /*tp_init*/
  0, /*tp_alloc*/
  __pyx_tp_new_5pygpu_8gpuarray___pyx_scope_struct_6_genexpr, /*tp_new*/
  0, /*tp_free*/
  0, /*tp_is_gc*/
  0, /*tp_bases*/
  0, /*tp_mro*/
  0, /*tp_cache*/
  0, /*tp_subclasses*/
  0, /*tp_weaklist*/
  0, /*tp_del*/
  0, /*tp_version_tag*/
  #if PY_VERSION_HEX >= 0x030400a1
  0, /*tp_finalize*/
  #endif
};

static struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_7___setitem__ *__pyx_freelist_5pygpu_8gpuarray___pyx_scope_struct_7___setitem__[8];
static int __pyx_freecount_5pygpu_8gpuarray___pyx_scope_struct_7___setitem__ = 0;

static PyObject *__pyx_tp_new_5pygpu_8gpuarray___pyx_scope_struct_7___setitem__(PyTypeObject *t, CYTHON_UNUSED PyObject *a, CYTHON_UNUSED PyObject *k) {
  PyObject *o;
  if (CYTHON_COMPILING_IN_CPYTHON && likely((__pyx_freecount_5pygpu_8gpuarray___pyx_scope_struct_7___setitem__ > 0) & (t->tp_basicsize == sizeof(struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_7___setitem__)))) {
    o = (PyObject*)__pyx_freelist_5pygpu_8gpuarray___pyx_scope_struct_7___setitem__[--__pyx_freecount_5pygpu_8gpuarray___pyx_scope_struct_7___setitem__];
    memset(o, 0, sizeof(struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_7___setitem__));
    (void) PyObject_INIT(o, t);
    PyObject_GC_Track(o);
  } else {
    o = (*t->tp_alloc)(t, 0);
    if (unlikely(!o)) return 0;
  }
  return o;
}

static void __pyx_tp_dealloc_5pygpu_8gpuarray___pyx_scope_struct_7___setitem__(PyObject *o) {
  struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_7___setitem__ *p = (struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_7___setitem__ *)o;
  PyObject_GC_UnTrack(o);
  Py_CLEAR(p->__pyx_v_idx);
  if (CYTHON_COMPILING_IN_CPYTHON && ((__pyx_freecount_5pygpu_8gpuarray___pyx_scope_struct_7___setitem__ < 8) & (Py_TYPE(o)->tp_basicsize == sizeof(struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_7___setitem__)))) {
    __pyx_freelist_5pygpu_8gpuarray___pyx_scope_struct_7___setitem__[__pyx_freecount_5pygpu_8gpuarray___pyx_scope_struct_7___setitem__++] = ((struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_7___setitem__ *)o);
  } else {
    (*Py_TYPE(o)->tp_free)(o);
  }
}

static int __pyx_tp_traverse_5pygpu_8gpuarray___pyx_scope_struct_7___setitem__(PyObject *o, visitproc v, void *a) {
  int e;
  struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_7___setitem__ *p = (struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_7___setitem__ *)o;
  if (p->__pyx_v_idx) {
    e = (*v)(p->__pyx_v_idx, a); if (e) return e;
  }
  return 0;
}

static int __pyx_tp_clear_5pygpu_8gpuarray___pyx_scope_struct_7___setitem__(PyObject *o) {
  PyObject* tmp;
  struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_7___setitem__ *p = (struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_7___setitem__ *)o;
  tmp = ((PyObject*)p->__pyx_v_idx);
  p->__pyx_v_idx = Py_None; Py_INCREF(Py_None);
  Py_XDECREF(tmp);
  return 0;
}

static PyTypeObject __pyx_type_5pygpu_8gpuarray___pyx_scope_struct_7___setitem__ = {
  PyVarObject_HEAD_INIT(0, 0)
  "pygpu.gpuarray.__pyx_scope_struct_7___setitem__", /*tp_name*/
  sizeof(struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_7___setitem__), /*tp_basicsize*/
  0, /*tp_itemsize*/
  __pyx_tp_dealloc_5pygpu_8gpuarray___pyx_scope_struct_7___setitem__, /*tp_dealloc*/
  0, /*tp_print*/
  0, /*tp_getattr*/
  0, /*tp_setattr*/
  #if PY_MAJOR_VERSION < 3
  0, /*tp_compare*/
  #endif
  #if PY_MAJOR_VERSION >= 3
  0, /*tp_as_async*/
  #endif
  0, /*tp_repr*/
  0, /*tp_as_number*/
  0, /*tp_as_sequence*/
  0, /*tp_as_mapping*/
  0, /*tp_hash*/
  0, /*tp_call*/
  0, /*tp_str*/
  0, /*tp_getattro*/
  0, /*tp_setattro*/
  0, /*tp_as_buffer*/
  Py_TPFLAGS_DEFAULT|Py_TPFLAGS_HAVE_VERSION_TAG|Py_TPFLAGS_CHECKTYPES|Py_TPFLAGS_HAVE_NEWBUFFER|Py_TPFLAGS_HAVE_GC, /*tp_flags*/
  0, /*tp_doc*/
  __pyx_tp_traverse_5pygpu_8gpuarray___pyx_scope_struct_7___setitem__, /*tp_traverse*/
  __pyx_tp_clear_5pygpu_8gpuarray___pyx_scope_struct_7___setitem__, /*tp_clear*/
  0, /*tp_richcompare*/
  0, /*tp_weaklistoffset*/
  0, /*tp_iter*/
  0, /*tp_iternext*/
  0, /*tp_methods*/
  0, /*tp_members*/
  0, /*tp_getset*/
  0, /*tp_base*/
  0, /*tp_dict*/
  0, /*tp_descr_get*/
  0, /*tp_descr_set*/
  0, /*tp_dictoffset*/
  0, /*tp_init*/
  0, /*tp_alloc*/
  __pyx_tp_new_5pygpu_8gpuarray___pyx_scope_struct_7___setitem__, /*tp_new*/
  0, /*tp_free*/
  0, /*tp_is_gc*/
  0, /*tp_bases*/
  0, /*tp_mro*/
  0, /*tp_cache*/
  0, /*tp_subclasses*/
  0, /*tp_weaklist*/
  0, /*tp_del*/
  0, /*tp_version_tag*/
  #if PY_VERSION_HEX >= 0x030400a1
  0, /*tp_finalize*/
  #endif
};

static struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_8_genexpr *__pyx_freelist_5pygpu_8gpuarray___pyx_scope_struct_8_genexpr[8];
static int __pyx_freecount_5pygpu_8gpuarray___pyx_scope_struct_8_genexpr = 0;

static PyObject *__pyx_tp_new_5pygpu_8gpuarray___pyx_scope_struct_8_genexpr(PyTypeObject *t, CYTHON_UNUSED PyObject *a, CYTHON_UNUSED PyObject *k) {
  PyObject *o;
  if (CYTHON_COMPILING_IN_CPYTHON && likely((__pyx_freecount_5pygpu_8gpuarray___pyx_scope_struct_8_genexpr > 0) & (t->tp_basicsize == sizeof(struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_8_genexpr)))) {
    o = (PyObject*)__pyx_freelist_5pygpu_8gpuarray___pyx_scope_struct_8_genexpr[--__pyx_freecount_5pygpu_8gpuarray___pyx_scope_struct_8_genexpr];
    memset(o, 0, sizeof(struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_8_genexpr));
    (void) PyObject_INIT(o, t);
    PyObject_GC_Track(o);
  } else {
    o = (*t->tp_alloc)(t, 0);
    if (unlikely(!o)) return 0;
  }
  return o;
}

static void __pyx_tp_dealloc_5pygpu_8gpuarray___pyx_scope_struct_8_genexpr(PyObject *o) {
  struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_8_genexpr *p = (struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_8_genexpr *)o;
  PyObject_GC_UnTrack(o);
  Py_CLEAR(p->__pyx_outer_scope);
  Py_CLEAR(p->__pyx_v_i);
  if (CYTHON_COMPILING_IN_CPYTHON && ((__pyx_freecount_5pygpu_8gpuarray___pyx_scope_struct_8_genexpr < 8) & (Py_TYPE(o)->tp_basicsize == sizeof(struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_8_genexpr)))) {
    __pyx_freelist_5pygpu_8gpuarray___pyx_scope_struct_8_genexpr[__pyx_freecount_5pygpu_8gpuarray___pyx_scope_struct_8_genexpr++] = ((struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_8_genexpr *)o);
  } else {
    (*Py_TYPE(o)->tp_free)(o);
  }
}

static int __pyx_tp_traverse_5pygpu_8gpuarray___pyx_scope_struct_8_genexpr(PyObject *o, visitproc v, void *a) {
  int e;
  struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_8_genexpr *p = (struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_8_genexpr *)o;
  if (p->__pyx_outer_scope) {
    e = (*v)(((PyObject *)p->__pyx_outer_scope), a); if (e) return e;
  }
  if (p->__pyx_v_i) {
    e = (*v)(p->__pyx_v_i, a); if (e) return e;
  }
  return 0;
}

static PyTypeObject __pyx_type_5pygpu_8gpuarray___pyx_scope_struct_8_genexpr = {
  PyVarObject_HEAD_INIT(0, 0)
  "pygpu.gpuarray.__pyx_scope_struct_8_genexpr", /*tp_name*/
  sizeof(struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_8_genexpr), /*tp_basicsize*/
  0, /*tp_itemsize*/
  __pyx_tp_dealloc_5pygpu_8gpuarray___pyx_scope_struct_8_genexpr, /*tp_dealloc*/
  0, /*tp_print*/
  0, /*tp_getattr*/
  0, /*tp_setattr*/
  #if PY_MAJOR_VERSION < 3
  0, /*tp_compare*/
  #endif
  #if PY_MAJOR_VERSION >= 3
  0, /*tp_as_async*/
  #endif
  0, /*tp_repr*/
  0, /*tp_as_number*/
  0, /*tp_as_sequence*/
  0, /*tp_as_mapping*/
  0, /*tp_hash*/
  0, /*tp_call*/
  0, /*tp_str*/
  0, /*tp_getattro*/
  0, /*tp_setattro*/
  0, /*tp_as_buffer*/
  Py_TPFLAGS_DEFAULT|Py_TPFLAGS_HAVE_VERSION_TAG|Py_TPFLAGS_CHECKTYPES|Py_TPFLAGS_HAVE_NEWBUFFER|Py_TPFLAGS_HAVE_GC, /*tp_flags*/
  0, /*tp_doc*/
  __pyx_tp_traverse_5pygpu_8gpuarray___pyx_scope_struct_8_genexpr, /*tp_traverse*/
  0, /*tp_clear*/
  0, /*tp_richcompare*/
  0, /*tp_weaklistoffset*/
  0, /*tp_iter*/
  0, /*tp_iternext*/
  0, /*tp_methods*/
  0, /*tp_members*/
  0, /*tp_getset*/
  0, /*tp_base*/
  0, /*tp_dict*/
  0, /*tp_descr_get*/
  0, /*tp_descr_set*/
  0, /*tp_dictoffset*/
  0, /*tp_init*/
  0, /*tp_alloc*/
  __pyx_tp_new_5pygpu_8gpuarray___pyx_scope_struct_8_genexpr, /*tp_new*/
  0, /*tp_free*/
  0, /*tp_is_gc*/
  0, /*tp_bases*/
  0, /*tp_mro*/
  0, /*tp_cache*/
  0, /*tp_subclasses*/
  0, /*tp_weaklist*/
  0, /*tp_del*/
  0, /*tp_version_tag*/
  #if PY_VERSION_HEX >= 0x030400a1
  0, /*tp_finalize*/
  #endif
};

static struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_9_genexpr *__pyx_freelist_5pygpu_8gpuarray___pyx_scope_struct_9_genexpr[8];
static int __pyx_freecount_5pygpu_8gpuarray___pyx_scope_struct_9_genexpr = 0;

static PyObject *__pyx_tp_new_5pygpu_8gpuarray___pyx_scope_struct_9_genexpr(PyTypeObject *t, CYTHON_UNUSED PyObject *a, CYTHON_UNUSED PyObject *k) {
  PyObject *o;
  if (CYTHON_COMPILING_IN_CPYTHON && likely((__pyx_freecount_5pygpu_8gpuarray___pyx_scope_struct_9_genexpr > 0) & (t->tp_basicsize == sizeof(struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_9_genexpr)))) {
    o = (PyObject*)__pyx_freelist_5pygpu_8gpuarray___pyx_scope_struct_9_genexpr[--__pyx_freecount_5pygpu_8gpuarray___pyx_scope_struct_9_genexpr];
    memset(o, 0, sizeof(struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_9_genexpr));
    (void) PyObject_INIT(o, t);
    PyObject_GC_Track(o);
  } else {
    o = (*t->tp_alloc)(t, 0);
    if (unlikely(!o)) return 0;
  }
  return o;
}

static void __pyx_tp_dealloc_5pygpu_8gpuarray___pyx_scope_struct_9_genexpr(PyObject *o) {
  struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_9_genexpr *p = (struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_9_genexpr *)o;
  PyObject_GC_UnTrack(o);
  Py_CLEAR(p->__pyx_outer_scope);
  Py_CLEAR(p->__pyx_v_i);
  if (CYTHON_COMPILING_IN_CPYTHON && ((__pyx_freecount_5pygpu_8gpuarray___pyx_scope_struct_9_genexpr < 8) & (Py_TYPE(o)->tp_basicsize == sizeof(struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_9_genexpr)))) {
    __pyx_freelist_5pygpu_8gpuarray___pyx_scope_struct_9_genexpr[__pyx_freecount_5pygpu_8gpuarray___pyx_scope_struct_9_genexpr++] = ((struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_9_genexpr *)o);
  } else {
    (*Py_TYPE(o)->tp_free)(o);
  }
}

static int __pyx_tp_traverse_5pygpu_8gpuarray___pyx_scope_struct_9_genexpr(PyObject *o, visitproc v, void *a) {
  int e;
  struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_9_genexpr *p = (struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_9_genexpr *)o;
  if (p->__pyx_outer_scope) {
    e = (*v)(((PyObject *)p->__pyx_outer_scope), a); if (e) return e;
  }
  if (p->__pyx_v_i) {
    e = (*v)(p->__pyx_v_i, a); if (e) return e;
  }
  return 0;
}

static PyTypeObject __pyx_type_5pygpu_8gpuarray___pyx_scope_struct_9_genexpr = {
  PyVarObject_HEAD_INIT(0, 0)
  "pygpu.gpuarray.__pyx_scope_struct_9_genexpr", /*tp_name*/
  sizeof(struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_9_genexpr), /*tp_basicsize*/
  0, /*tp_itemsize*/
  __pyx_tp_dealloc_5pygpu_8gpuarray___pyx_scope_struct_9_genexpr, /*tp_dealloc*/
  0, /*tp_print*/
  0, /*tp_getattr*/
  0, /*tp_setattr*/
  #if PY_MAJOR_VERSION < 3
  0, /*tp_compare*/
  #endif
  #if PY_MAJOR_VERSION >= 3
  0, /*tp_as_async*/
  #endif
  0, /*tp_repr*/
  0, /*tp_as_number*/
  0, /*tp_as_sequence*/
  0, /*tp_as_mapping*/
  0, /*tp_hash*/
  0, /*tp_call*/
  0, /*tp_str*/
  0, /*tp_getattro*/
  0, /*tp_setattro*/
  0, /*tp_as_buffer*/
  Py_TPFLAGS_DEFAULT|Py_TPFLAGS_HAVE_VERSION_TAG|Py_TPFLAGS_CHECKTYPES|Py_TPFLAGS_HAVE_NEWBUFFER|Py_TPFLAGS_HAVE_GC, /*tp_flags*/
  0, /*tp_doc*/
  __pyx_tp_traverse_5pygpu_8gpuarray___pyx_scope_struct_9_genexpr, /*tp_traverse*/
  0, /*tp_clear*/
  0, /*tp_richcompare*/
  0, /*tp_weaklistoffset*/
  0, /*tp_iter*/
  0, /*tp_iternext*/
  0, /*tp_methods*/
  0, /*tp_members*/
  0, /*tp_getset*/
  0, /*tp_base*/
  0, /*tp_dict*/
  0, /*tp_descr_get*/
  0, /*tp_descr_set*/
  0, /*tp_dictoffset*/
  0, /*tp_init*/
  0, /*tp_alloc*/
  __pyx_tp_new_5pygpu_8gpuarray___pyx_scope_struct_9_genexpr, /*tp_new*/
  0, /*tp_free*/
  0, /*tp_is_gc*/
  0, /*tp_bases*/
  0, /*tp_mro*/
  0, /*tp_cache*/
  0, /*tp_subclasses*/
  0, /*tp_weaklist*/
  0, /*tp_del*/
  0, /*tp_version_tag*/
  #if PY_VERSION_HEX >= 0x030400a1
  0, /*tp_finalize*/
  #endif
};

static struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_10_genexpr *__pyx_freelist_5pygpu_8gpuarray___pyx_scope_struct_10_genexpr[8];
static int __pyx_freecount_5pygpu_8gpuarray___pyx_scope_struct_10_genexpr = 0;

static PyObject *__pyx_tp_new_5pygpu_8gpuarray___pyx_scope_struct_10_genexpr(PyTypeObject *t, CYTHON_UNUSED PyObject *a, CYTHON_UNUSED PyObject *k) {
  PyObject *o;
  if (CYTHON_COMPILING_IN_CPYTHON && likely((__pyx_freecount_5pygpu_8gpuarray___pyx_scope_struct_10_genexpr > 0) & (t->tp_basicsize == sizeof(struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_10_genexpr)))) {
    o = (PyObject*)__pyx_freelist_5pygpu_8gpuarray___pyx_scope_struct_10_genexpr[--__pyx_freecount_5pygpu_8gpuarray___pyx_scope_struct_10_genexpr];
    memset(o, 0, sizeof(struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_10_genexpr));
    (void) PyObject_INIT(o, t);
    PyObject_GC_Track(o);
  } else {
    o = (*t->tp_alloc)(t, 0);
    if (unlikely(!o)) return 0;
  }
  return o;
}

static void __pyx_tp_dealloc_5pygpu_8gpuarray___pyx_scope_struct_10_genexpr(PyObject *o) {
  struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_10_genexpr *p = (struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_10_genexpr *)o;
  PyObject_GC_UnTrack(o);
  Py_CLEAR(p->__pyx_outer_scope);
  Py_CLEAR(p->__pyx_v_i);
  Py_CLEAR(p->__pyx_t_0);
  if (CYTHON_COMPILING_IN_CPYTHON && ((__pyx_freecount_5pygpu_8gpuarray___pyx_scope_struct_10_genexpr < 8) & (Py_TYPE(o)->tp_basicsize == sizeof(struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_10_genexpr)))) {
    __pyx_freelist_5pygpu_8gpuarray___pyx_scope_struct_10_genexpr[__pyx_freecount_5pygpu_8gpuarray___pyx_scope_struct_10_genexpr++] = ((struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_10_genexpr *)o);
  } else {
    (*Py_TYPE(o)->tp_free)(o);
  }
}

static int __pyx_tp_traverse_5pygpu_8gpuarray___pyx_scope_struct_10_genexpr(PyObject *o, visitproc v, void *a) {
  int e;
  struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_10_genexpr *p = (struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_10_genexpr *)o;
  if (p->__pyx_outer_scope) {
    e = (*v)(((PyObject *)p->__pyx_outer_scope), a); if (e) return e;
  }
  if (p->__pyx_v_i) {
    e = (*v)(p->__pyx_v_i, a); if (e) return e;
  }
  if (p->__pyx_t_0) {
    e = (*v)(p->__pyx_t_0, a); if (e) return e;
  }
  return 0;
}

static PyTypeObject __pyx_type_5pygpu_8gpuarray___pyx_scope_struct_10_genexpr = {
  PyVarObject_HEAD_INIT(0, 0)
  "pygpu.gpuarray.__pyx_scope_struct_10_genexpr", /*tp_name*/
  sizeof(struct __pyx_obj_5pygpu_8gpuarray___pyx_scope_struct_10_genexpr), /*tp_basicsize*/
  0, /*tp_itemsize*/
  __pyx_tp_dealloc_5pygpu_8gpuarray___pyx_scope_struct_10_genexpr, /*tp_dealloc*/
  0, /*tp_print*/
  0, /*tp_getattr*/
  0, /*tp_setattr*/
  #if PY_MAJOR_VERSION < 3
  0, /*tp_compare*/
  #endif
  #if PY_MAJOR_VERSION >= 3
  0, /*tp_as_async*/
  #endif
  0, /*tp_repr*/
  0, /*tp_as_number*/
  0, /*tp_as_sequence*/
  0, /*tp_as_mapping*/
  0, /*tp_hash*/
  0, /*tp_call*/
  0, /*tp_str*/
  0, /*tp_getattro*/
  0, /*tp_setattro*/
  0, /*tp_as_buffer*/
  Py_TPFLAGS_DEFAULT|Py_TPFLAGS_HAVE_VERSION_TAG|Py_TPFLAGS_CHECKTYPES|Py_TPFLAGS_HAVE_NEWBUFFER|Py_TPFLAGS_HAVE_GC, /*tp_flags*/
  0, /*tp_doc*/
  __pyx_tp_traverse_5pygpu_8gpuarray___pyx_scope_struct_10_genexpr, /*tp_traverse*/
  0, /*tp_clear*/
  0, /*tp_richcompare*/
  0, /*tp_weaklistoffset*/
  0, /*tp_iter*/
  0, /*tp_iternext*/
  0, /*tp_methods*/
  0, /*tp_members*/
  0, /*tp_getset*/
  0, /*tp_base*/
  0, /*tp_dict*/
  0, /*tp_descr_get*/
  0, /*tp_descr_set*/
  0, /*tp_dictoffset*/
  0, /*tp_init*/
  0, /*tp_alloc*/
  __pyx_tp_new_5pygpu_8gpuarray___pyx_scope_struct_10_genexpr, /*tp_new*/
  0, /*tp_free*/
  0, /*tp_is_gc*/
  0, /*tp_bases*/
  0, /*tp_mro*/
  0, /*tp_cache*/
  0, /*tp_subclasses*/
  0, /*tp_weaklist*/
  0, /*tp_del*/
  0, /*tp_version_tag*/
  #if PY_VERSION_HEX >= 0x030400a1
  0, /*tp_finalize*/
  #endif
};

static PyMethodDef __pyx_methods[] = {
  {"dtype_to_typecode", (PyCFunction)__pyx_pw_5pygpu_8gpuarray_11dtype_to_typecode, METH_O, __pyx_doc_5pygpu_8gpuarray_10dtype_to_typecode},
  {0, 0, 0, 0}
};

#if PY_MAJOR_VERSION >= 3
#if CYTHON_PEP489_MULTI_PHASE_INIT
static PyObject* __pyx_pymod_create(PyObject *spec, PyModuleDef *def); /*proto*/
static int __pyx_pymod_exec_gpuarray(PyObject* module); /*proto*/
static PyModuleDef_Slot __pyx_moduledef_slots[] = {
  {Py_mod_create, (void*)__pyx_pymod_create},
  {Py_mod_exec, (void*)__pyx_pymod_exec_gpuarray},
  {0, NULL}
};
#endif

static struct PyModuleDef __pyx_moduledef = {
    PyModuleDef_HEAD_INIT,
    "gpuarray",
    0, /* m_doc */
  #if CYTHON_PEP489_MULTI_PHASE_INIT
    0, /* m_size */
  #else
    -1, /* m_size */
  #endif
    __pyx_methods /* m_methods */,
  #if CYTHON_PEP489_MULTI_PHASE_INIT
    __pyx_moduledef_slots, /* m_slots */
  #else
    NULL, /* m_reload */
  #endif
    NULL, /* m_traverse */
    NULL, /* m_clear */
    NULL /* m_free */
};
#endif

static __Pyx_StringTabEntry __pyx_string_tab[] = {
  {&__pyx_kp_s_0_d_arrays_can_t_be_indexed, __pyx_k_0_d_arrays_can_t_be_indexed, sizeof(__pyx_k_0_d_arrays_can_t_be_indexed), 0, 0, 1, 0},
  {&__pyx_n_s_A, __pyx_k_A, sizeof(__pyx_k_A), 0, 0, 1, 1},
  {&__pyx_kp_s_Bad_typecode_in__setarg_d_please, __pyx_k_Bad_typecode_in__setarg_d_please, sizeof(__pyx_k_Bad_typecode_in__setarg_d_please), 0, 0, 1, 0},
  {&__pyx_n_s_C, __pyx_k_C, sizeof(__pyx_k_C), 0, 0, 1, 1},
  {&__pyx_n_s_C_CONTIGUOUS, __pyx_k_C_CONTIGUOUS, sizeof(__pyx_k_C_CONTIGUOUS), 0, 0, 1, 1},
  {&__pyx_kp_s_Called_raw_GpuArray___init, __pyx_k_Called_raw_GpuArray___init, sizeof(__pyx_k_Called_raw_GpuArray___init), 0, 0, 1, 0},
  {&__pyx_kp_s_Called_raw_GpuContext___init, __pyx_k_Called_raw_GpuContext___init, sizeof(__pyx_k_Called_raw_GpuContext___init), 0, 0, 1, 0},
  {&__pyx_kp_s_Can_t_allocate_new_type, __pyx_k_Can_t_allocate_new_type, sizeof(__pyx_k_Can_t_allocate_new_type), 0, 0, 1, 0},
  {&__pyx_kp_s_Cannot_pickle_GpuArray_object, __pyx_k_Cannot_pickle_GpuArray_object, sizeof(__pyx_k_Cannot_pickle_GpuArray_object), 0, 0, 1, 0},
  {&__pyx_kp_s_Cannot_pickle_GpuContext_object, __pyx_k_Cannot_pickle_GpuContext_object, sizeof(__pyx_k_Cannot_pickle_GpuContext_object), 0, 0, 1, 0},
  {&__pyx_kp_s_Cannot_pickle_GpuKernel_object, __pyx_k_Cannot_pickle_GpuKernel_object, sizeof(__pyx_k_Cannot_pickle_GpuKernel_object), 0, 0, 1, 0},
  {&__pyx_kp_s_Context_manager_only_works_for_c, __pyx_k_Context_manager_only_works_for_c, sizeof(__pyx_k_Context_manager_only_works_for_c), 0, 0, 1, 0},
  {&__pyx_kp_s_Could_not_get_necessary_extensio, __pyx_k_Could_not_get_necessary_extensio, sizeof(__pyx_k_Could_not_get_necessary_extensio), 0, 0, 1, 0},
  {&__pyx_kp_s_Could_not_register_type, __pyx_k_Could_not_register_type, sizeof(__pyx_k_Could_not_register_type), 0, 0, 1, 0},
  {&__pyx_kp_s_Destination_GpuArray_is_not_cont, __pyx_k_Destination_GpuArray_is_not_cont, sizeof(__pyx_k_Destination_GpuArray_is_not_cont), 0, 0, 1, 0},
  {&__pyx_kp_s_Destination_GpuArray_is_not_well, __pyx_k_Destination_GpuArray_is_not_well, sizeof(__pyx_k_Destination_GpuArray_is_not_well), 0, 0, 1, 0},
  {&__pyx_kp_s_Destination_Numpy_array_is_not_w, __pyx_k_Destination_Numpy_array_is_not_w, sizeof(__pyx_k_Destination_Numpy_array_is_not_w), 0, 0, 1, 0},
  {&__pyx_n_s_Ellipsis, __pyx_k_Ellipsis, sizeof(__pyx_k_Ellipsis), 0, 0, 1, 1},
  {&__pyx_kp_s_Exception_used_for_most_errors, __pyx_k_Exception_used_for_most_errors, sizeof(__pyx_k_Exception_used_for_most_errors), 0, 0, 1, 0},
  {&__pyx_kp_s_Expected_a_string, __pyx_k_Expected_a_string, sizeof(__pyx_k_Expected_a_string), 0, 0, 1, 0},
  {&__pyx_kp_s_Expected_d_arguments_got_d, __pyx_k_Expected_d_arguments_got_d, sizeof(__pyx_k_Expected_d_arguments_got_d), 0, 0, 1, 0},
  {&__pyx_kp_s_Expected_index_with_nd_1, __pyx_k_Expected_index_with_nd_1, sizeof(__pyx_k_Expected_index_with_nd_1), 0, 0, 1, 0},
  {&__pyx_n_s_F, __pyx_k_F, sizeof(__pyx_k_F), 0, 0, 1, 1},
  {&__pyx_n_s_F_CONTIGUOUS, __pyx_k_F_CONTIGUOUS, sizeof(__pyx_k_F_CONTIGUOUS), 0, 0, 1, 1},
  {&__pyx_kp_u_Format_string_allocated_too_shor, __pyx_k_Format_string_allocated_too_shor, sizeof(__pyx_k_Format_string_allocated_too_shor), 0, 1, 0, 0},
  {&__pyx_kp_u_Format_string_allocated_too_shor_2, __pyx_k_Format_string_allocated_too_shor_2, sizeof(__pyx_k_Format_string_allocated_too_shor_2), 0, 1, 0, 0},
  {&__pyx_n_s_GpuArrayException, __pyx_k_GpuArrayException, sizeof(__pyx_k_GpuArrayException), 0, 0, 1, 1},
  {&__pyx_kp_s_GpuArray_and_Numpy_array_do_not, __pyx_k_GpuArray_and_Numpy_array_do_not, sizeof(__pyx_k_GpuArray_and_Numpy_array_do_not), 0, 0, 1, 0},
  {&__pyx_kp_s_GpuArray_and_Numpy_array_do_not_2, __pyx_k_GpuArray_and_Numpy_array_do_not_2, sizeof(__pyx_k_GpuArray_and_Numpy_array_do_not_2), 0, 0, 1, 0},
  {&__pyx_kp_s_GpuArray_and_Numpy_array_do_not_3, __pyx_k_GpuArray_and_Numpy_array_do_not_3, sizeof(__pyx_k_GpuArray_and_Numpy_array_do_not_3), 0, 0, 1, 0},
  {&__pyx_n_s_ImportError, __pyx_k_ImportError, sizeof(__pyx_k_ImportError), 0, 0, 1, 1},
  {&__pyx_n_s_IndexError, __pyx_k_IndexError, sizeof(__pyx_k_IndexError), 0, 0, 1, 1},
  {&__pyx_kp_s_Invalid_array_or_destroyed_conte, __pyx_k_Invalid_array_or_destroyed_conte, sizeof(__pyx_k_Invalid_array_or_destroyed_conte), 0, 0, 1, 0},
  {&__pyx_kp_s_Invalid_kernel_or_destroyed_cont, __pyx_k_Invalid_kernel_or_destroyed_cont, sizeof(__pyx_k_Invalid_kernel_or_destroyed_cont), 0, 0, 1, 0},
  {&__pyx_n_s_KeyError, __pyx_k_KeyError, sizeof(__pyx_k_KeyError), 0, 0, 1, 1},
  {&__pyx_n_s_MemoryError, __pyx_k_MemoryError, sizeof(__pyx_k_MemoryError), 0, 0, 1, 1},
  {&__pyx_kp_s_Must_specify_size_n_or_both_gs_a, __pyx_k_Must_specify_size_n_or_both_gs_a, sizeof(__pyx_k_Must_specify_size_n_or_both_gs_a), 0, 0, 1, 0},
  {&__pyx_kp_s_No_context_specified, __pyx_k_No_context_specified, sizeof(__pyx_k_No_context_specified), 0, 0, 1, 0},
  {&__pyx_kp_s_No_mapping_for_s, __pyx_k_No_mapping_for_s, sizeof(__pyx_k_No_mapping_for_s), 0, 0, 1, 0},
  {&__pyx_kp_u_Non_native_byte_order_not_suppor, __pyx_k_Non_native_byte_order_not_suppor, sizeof(__pyx_k_Non_native_byte_order_not_suppor), 0, 1, 0, 0},
  {&__pyx_n_s_NotImplemented, __pyx_k_NotImplemented, sizeof(__pyx_k_NotImplemented), 0, 0, 1, 1},
  {&__pyx_n_s_NotImplementedError, __pyx_k_NotImplementedError, sizeof(__pyx_k_NotImplementedError), 0, 0, 1, 1},
  {&__pyx_kp_s_Only_works_for_cuda_contexts, __pyx_k_Only_works_for_cuda_contexts, sizeof(__pyx_k_Only_works_for_cuda_contexts), 0, 0, 1, 0},
  {&__pyx_kp_s_OpenCL_name_incorrect_Should_be, __pyx_k_OpenCL_name_incorrect_Should_be, sizeof(__pyx_k_OpenCL_name_incorrect_Should_be), 0, 0, 1, 0},
  {&__pyx_n_s_RuntimeError, __pyx_k_RuntimeError, sizeof(__pyx_k_RuntimeError), 0, 0, 1, 1},
  {&__pyx_n_s_SIZE, __pyx_k_SIZE, sizeof(__pyx_k_SIZE), 0, 0, 1, 1},
  {&__pyx_n_s_SSIZE, __pyx_k_SSIZE, sizeof(__pyx_k_SSIZE), 0, 0, 1, 1},
  {&__pyx_n_s_SystemError, __pyx_k_SystemError, sizeof(__pyx_k_SystemError), 0, 0, 1, 1},
  {&__pyx_n_s_TODO, __pyx_k_TODO, sizeof(__pyx_k_TODO), 0, 0, 1, 1},
  {&__pyx_kp_s_The_truth_value_of_a_multi_eleme, __pyx_k_The_truth_value_of_a_multi_eleme, sizeof(__pyx_k_The_truth_value_of_a_multi_eleme), 0, 0, 1, 0},
  {&__pyx_kp_s_This_array_has_an_offset, __pyx_k_This_array_has_an_offset, sizeof(__pyx_k_This_array_has_an_offset), 0, 0, 1, 0},
  {&__pyx_kp_s_This_is_for_CUDA_arrays, __pyx_k_This_is_for_CUDA_arrays, sizeof(__pyx_k_This_is_for_CUDA_arrays), 0, 0, 1, 0},
  {&__pyx_kp_s_This_is_for_OpenCL_arrays, __pyx_k_This_is_for_OpenCL_arrays, sizeof(__pyx_k_This_is_for_OpenCL_arrays), 0, 0, 1, 0},
  {&__pyx_kp_s_Truth_value_of_array_with_more_t, __pyx_k_Truth_value_of_array_with_more_t, sizeof(__pyx_k_Truth_value_of_array_with_more_t), 0, 0, 1, 0},
  {&__pyx_n_s_TypeError, __pyx_k_TypeError, sizeof(__pyx_k_TypeError), 0, 0, 1, 1},
  {&__pyx_kp_s_UTF_8, __pyx_k_UTF_8, sizeof(__pyx_k_UTF_8), 0, 0, 1, 0},
  {&__pyx_kp_s_Unknown_device_format, __pyx_k_Unknown_device_format, sizeof(__pyx_k_Unknown_device_format), 0, 0, 1, 0},
  {&__pyx_kp_s_Unknown_flag, __pyx_k_Unknown_flag, sizeof(__pyx_k_Unknown_flag), 0, 0, 1, 0},
  {&__pyx_n_s_UnsupportedException, __pyx_k_UnsupportedException, sizeof(__pyx_k_UnsupportedException), 0, 0, 1, 1},
  {&__pyx_kp_s_Valid_orders_are_A_any_C_C_F_For, __pyx_k_Valid_orders_are_A_any_C_C_F_For, sizeof(__pyx_k_Valid_orders_are_A_any_C_C_F_For), 0, 0, 1, 0},
  {&__pyx_n_s_ValueError, __pyx_k_ValueError, sizeof(__pyx_k_ValueError), 0, 0, 1, 1},
  {&__pyx_kp_s__20, __pyx_k__20, sizeof(__pyx_k__20), 0, 0, 1, 0},
  {&__pyx_kp_s__22, __pyx_k__22, sizeof(__pyx_k__22), 0, 0, 1, 0},
  {&__pyx_kp_s__4, __pyx_k__4, sizeof(__pyx_k__4), 0, 0, 1, 0},
  {&__pyx_kp_s__8, __pyx_k__8, sizeof(__pyx_k__8), 0, 0, 1, 0},
  {&__pyx_n_s_a, __pyx_k_a, sizeof(__pyx_k_a), 0, 0, 1, 1},
  {&__pyx_n_s_abi_version, __pyx_k_abi_version, sizeof(__pyx_k_abi_version), 0, 0, 1, 1},
  {&__pyx_n_s_al, __pyx_k_al, sizeof(__pyx_k_al), 0, 0, 1, 1},
  {&__pyx_n_s_aligned, __pyx_k_aligned, sizeof(__pyx_k_aligned), 0, 0, 1, 1},
  {&__pyx_n_s_als, __pyx_k_als, sizeof(__pyx_k_als), 0, 0, 1, 1},
  {&__pyx_n_s_api_version, __pyx_k_api_version, sizeof(__pyx_k_api_version), 0, 0, 1, 1},
  {&__pyx_n_s_args, __pyx_k_args, sizeof(__pyx_k_args), 0, 0, 1, 1},
  {&__pyx_n_s_array, __pyx_k_array, sizeof(__pyx_k_array), 0, 0, 1, 1},
  {&__pyx_n_s_asarray, __pyx_k_asarray, sizeof(__pyx_k_asarray), 0, 0, 1, 1},
  {&__pyx_n_s_ascontiguousarray, __pyx_k_ascontiguousarray, sizeof(__pyx_k_ascontiguousarray), 0, 0, 1, 1},
  {&__pyx_n_s_asfortranarray, __pyx_k_asfortranarray, sizeof(__pyx_k_asfortranarray), 0, 0, 1, 1},
  {&__pyx_kp_s_axes_don_t_match, __pyx_k_axes_don_t_match, sizeof(__pyx_k_axes_don_t_match), 0, 0, 1, 0},
  {&__pyx_n_s_axis, __pyx_k_axis, sizeof(__pyx_k_axis), 0, 0, 1, 1},
  {&__pyx_n_s_b, __pyx_k_b, sizeof(__pyx_k_b), 0, 0, 1, 1},
  {&__pyx_n_s_base, __pyx_k_base, sizeof(__pyx_k_base), 0, 0, 1, 1},
  {&__pyx_n_s_behaved, __pyx_k_behaved, sizeof(__pyx_k_behaved), 0, 0, 1, 1},
  {&__pyx_n_s_bool, __pyx_k_bool, sizeof(__pyx_k_bool), 0, 0, 1, 1},
  {&__pyx_n_s_c, __pyx_k_c, sizeof(__pyx_k_c), 0, 0, 1, 1},
  {&__pyx_n_s_c_contiguous, __pyx_k_c_contiguous, sizeof(__pyx_k_c_contiguous), 0, 0, 1, 1},
  {&__pyx_n_s_calloc, __pyx_k_calloc, sizeof(__pyx_k_calloc), 0, 0, 1, 1},
  {&__pyx_kp_s_cannot_copy_an_array_to_a_differ, __pyx_k_cannot_copy_an_array_to_a_differ, sizeof(__pyx_k_cannot_copy_an_array_to_a_differ), 0, 0, 1, 0},
  {&__pyx_kp_s_cannot_index_with_s, __pyx_k_cannot_index_with_s, sizeof(__pyx_k_cannot_index_with_s), 0, 0, 1, 0},
  {&__pyx_kp_s_cannot_use_more_than_one_Ellipsi, __pyx_k_cannot_use_more_than_one_Ellipsi, sizeof(__pyx_k_cannot_use_more_than_one_Ellipsi), 0, 0, 1, 0},
  {&__pyx_n_s_carray, __pyx_k_carray, sizeof(__pyx_k_carray), 0, 0, 1, 1},
  {&__pyx_n_s_cdims, __pyx_k_cdims, sizeof(__pyx_k_cdims), 0, 0, 1, 1},
  {&__pyx_n_s_cl_make_ctx, __pyx_k_cl_make_ctx, sizeof(__pyx_k_cl_make_ctx), 0, 0, 1, 1},
  {&__pyx_kp_s_cl_make_ctx_call_failed, __pyx_k_cl_make_ctx_call_failed, sizeof(__pyx_k_cl_make_ctx_call_failed), 0, 0, 1, 0},
  {&__pyx_kp_s_cl_make_ctx_extension_is_absent, __pyx_k_cl_make_ctx_extension_is_absent, sizeof(__pyx_k_cl_make_ctx_extension_is_absent), 0, 0, 1, 0},
  {&__pyx_n_s_cl_wrap_ctx, __pyx_k_cl_wrap_ctx, sizeof(__pyx_k_cl_wrap_ctx), 0, 0, 1, 1},
  {&__pyx_n_s_class, __pyx_k_class, sizeof(__pyx_k_class), 0, 0, 1, 1},
  {&__pyx_n_s_cline_in_traceback, __pyx_k_cline_in_traceback, sizeof(__pyx_k_cline_in_traceback), 0, 0, 1, 1},
  {&__pyx_n_s_close, __pyx_k_close, sizeof(__pyx_k_close), 0, 0, 1, 1},
  {&__pyx_n_s_cls, __pyx_k_cls, sizeof(__pyx_k_cls), 0, 0, 1, 1},
  {&__pyx_n_s_cname, __pyx_k_cname, sizeof(__pyx_k_cname), 0, 0, 1, 1},
  {&__pyx_n_s_complex128, __pyx_k_complex128, sizeof(__pyx_k_complex128), 0, 0, 1, 1},
  {&__pyx_n_s_complex64, __pyx_k_complex64, sizeof(__pyx_k_complex64), 0, 0, 1, 1},
  {&__pyx_kp_s_compute_axis_is_out_of_bounds, __pyx_k_compute_axis_is_out_of_bounds, sizeof(__pyx_k_compute_axis_is_out_of_bounds), 0, 0, 1, 0},
  {&__pyx_n_s_concatenate, __pyx_k_concatenate, sizeof(__pyx_k_concatenate), 0, 0, 1, 1},
  {&__pyx_n_s_context, __pyx_k_context, sizeof(__pyx_k_context), 0, 0, 1, 1},
  {&__pyx_n_s_copy, __pyx_k_copy, sizeof(__pyx_k_copy), 0, 0, 1, 1},
  {&__pyx_kp_s_could_not_allocate_cdims, __pyx_k_could_not_allocate_cdims, sizeof(__pyx_k_could_not_allocate_cdims), 0, 0, 1, 0},
  {&__pyx_n_s_count_devices, __pyx_k_count_devices, sizeof(__pyx_k_count_devices), 0, 0, 1, 1},
  {&__pyx_n_s_count_platforms, __pyx_k_count_platforms, sizeof(__pyx_k_count_platforms), 0, 0, 1, 1},
  {&__pyx_n_s_cstrides, __pyx_k_cstrides, sizeof(__pyx_k_cstrides), 0, 0, 1, 1},
  {&__pyx_n_s_ctx, __pyx_k_ctx, sizeof(__pyx_k_ctx), 0, 0, 1, 1},
  {&__pyx_kp_s_ctx_is_None_in_new_GpuArray, __pyx_k_ctx_is_None_in_new_GpuArray, sizeof(__pyx_k_ctx_is_None_in_new_GpuArray), 0, 0, 1, 0},
  {&__pyx_n_b_cuda, __pyx_k_cuda, sizeof(__pyx_k_cuda), 0, 0, 0, 1},
  {&__pyx_n_s_cuda, __pyx_k_cuda, sizeof(__pyx_k_cuda), 0, 0, 1, 1},
  {&__pyx_kp_s_cuda_enter_not_available, __pyx_k_cuda_enter_not_available, sizeof(__pyx_k_cuda_enter_not_available), 0, 0, 1, 0},
  {&__pyx_kp_s_cuda_exit_not_available, __pyx_k_cuda_exit_not_available, sizeof(__pyx_k_cuda_exit_not_available), 0, 0, 1, 0},
  {&__pyx_n_s_cuda_make_ctx, __pyx_k_cuda_make_ctx, sizeof(__pyx_k_cuda_make_ctx), 0, 0, 1, 1},
  {&__pyx_kp_s_cuda_make_ctx_call_failed, __pyx_k_cuda_make_ctx_call_failed, sizeof(__pyx_k_cuda_make_ctx_call_failed), 0, 0, 1, 0},
  {&__pyx_kp_s_cuda_make_ctx_extension_is_absen, __pyx_k_cuda_make_ctx_extension_is_absen, sizeof(__pyx_k_cuda_make_ctx_extension_is_absen), 0, 0, 1, 0},
  {&__pyx_n_s_cuda_wrap_ctx, __pyx_k_cuda_wrap_ctx, sizeof(__pyx_k_cuda_wrap_ctx), 0, 0, 1, 1},
  {&__pyx_n_s_d, __pyx_k_d, sizeof(__pyx_k_d), 0, 0, 1, 1},
  {&__pyx_n_s_data, __pyx_k_data, sizeof(__pyx_k_data), 0, 0, 1, 1},
  {&__pyx_kp_s_data_type_not_understood, __pyx_k_data_type_not_understood, sizeof(__pyx_k_data_type_not_understood), 0, 0, 1, 0},
  {&__pyx_n_s_default, __pyx_k_default, sizeof(__pyx_k_default), 0, 0, 1, 1},
  {&__pyx_n_s_dev, __pyx_k_dev, sizeof(__pyx_k_dev), 0, 0, 1, 1},
  {&__pyx_n_s_devcount, __pyx_k_devcount, sizeof(__pyx_k_devcount), 0, 0, 1, 1},
  {&__pyx_n_s_doc, __pyx_k_doc, sizeof(__pyx_k_doc), 0, 0, 1, 1},
  {&__pyx_kp_s_don_t_know_how_to_convert_to_dty, __pyx_k_don_t_know_how_to_convert_to_dty, sizeof(__pyx_k_don_t_know_how_to_convert_to_dty), 0, 0, 1, 0},
  {&__pyx_n_s_dtype, __pyx_k_dtype, sizeof(__pyx_k_dtype), 0, 0, 1, 1},
  {&__pyx_n_s_dtype_to_ctype, __pyx_k_dtype_to_ctype, sizeof(__pyx_k_dtype_to_ctype), 0, 0, 1, 1},
  {&__pyx_n_s_empty, __pyx_k_empty, sizeof(__pyx_k_empty), 0, 0, 1, 1},
  {&__pyx_n_s_empty_like_me, __pyx_k_empty_like_me, sizeof(__pyx_k_empty_like_me), 0, 0, 1, 1},
  {&__pyx_n_s_encode, __pyx_k_encode, sizeof(__pyx_k_encode), 0, 0, 1, 1},
  {&__pyx_n_s_enumerate, __pyx_k_enumerate, sizeof(__pyx_k_enumerate), 0, 0, 1, 1},
  {&__pyx_n_s_err, __pyx_k_err, sizeof(__pyx_k_err), 0, 0, 1, 1},
  {&__pyx_kp_s_expected_GpuArrays_to_concatenat, __pyx_k_expected_GpuArrays_to_concatenat, sizeof(__pyx_k_expected_GpuArrays_to_concatenat), 0, 0, 1, 0},
  {&__pyx_kp_s_expected_a_GpuArray, __pyx_k_expected_a_GpuArray, sizeof(__pyx_k_expected_a_GpuArray), 0, 0, 1, 0},
  {&__pyx_n_s_f, __pyx_k_f, sizeof(__pyx_k_f), 0, 0, 1, 1},
  {&__pyx_n_s_f_contiguous, __pyx_k_f_contiguous, sizeof(__pyx_k_f_contiguous), 0, 0, 1, 1},
  {&__pyx_kp_s_fancy_indexing_not_supported, __pyx_k_fancy_indexing_not_supported, sizeof(__pyx_k_fancy_indexing_not_supported), 0, 0, 1, 0},
  {&__pyx_n_s_farray, __pyx_k_farray, sizeof(__pyx_k_farray), 0, 0, 1, 1},
  {&__pyx_n_s_fl, __pyx_k_fl, sizeof(__pyx_k_fl), 0, 0, 1, 1},
  {&__pyx_n_s_flags, __pyx_k_flags, sizeof(__pyx_k_flags), 0, 0, 1, 1},
  {&__pyx_n_s_float16, __pyx_k_float16, sizeof(__pyx_k_float16), 0, 0, 1, 1},
  {&__pyx_n_s_float32, __pyx_k_float32, sizeof(__pyx_k_float32), 0, 0, 1, 1},
  {&__pyx_n_s_float64, __pyx_k_float64, sizeof(__pyx_k_float64), 0, 0, 1, 1},
  {&__pyx_n_s_fnc, __pyx_k_fnc, sizeof(__pyx_k_fnc), 0, 0, 1, 1},
  {&__pyx_n_s_forc, __pyx_k_forc, sizeof(__pyx_k_forc), 0, 0, 1, 1},
  {&__pyx_n_s_fortran, __pyx_k_fortran, sizeof(__pyx_k_fortran), 0, 0, 1, 1},
  {&__pyx_n_s_from_gpudata, __pyx_k_from_gpudata, sizeof(__pyx_k_from_gpudata), 0, 0, 1, 1},
  {&__pyx_n_s_genexpr, __pyx_k_genexpr, sizeof(__pyx_k_genexpr), 0, 0, 1, 1},
  {&__pyx_n_s_get, __pyx_k_get, sizeof(__pyx_k_get), 0, 0, 1, 1},
  {&__pyx_n_s_get_default_context, __pyx_k_get_default_context, sizeof(__pyx_k_get_default_context), 0, 0, 1, 1},
  {&__pyx_n_s_getitem, __pyx_k_getitem, sizeof(__pyx_k_getitem), 0, 0, 1, 1},
  {&__pyx_n_s_getitem___locals_genexpr, __pyx_k_getitem___locals_genexpr, sizeof(__pyx_k_getitem___locals_genexpr), 0, 0, 1, 1},
  {&__pyx_kp_s_gpuarray, __pyx_k_gpuarray, sizeof(__pyx_k_gpuarray), 0, 0, 1, 0},
  {&__pyx_kp_s_gpuarray_array_content_not_avail, __pyx_k_gpuarray_array_content_not_avail, sizeof(__pyx_k_gpuarray_array_content_not_avail), 0, 0, 1, 0},
  {&__pyx_n_s_gs, __pyx_k_gs, sizeof(__pyx_k_gs), 0, 0, 1, 1},
  {&__pyx_kp_s_gs_is_not_int_or_list, __pyx_k_gs_is_not_int_or_list, sizeof(__pyx_k_gs_is_not_int_or_list), 0, 0, 1, 0},
  {&__pyx_kp_s_gs_is_not_of_length_3_or_less, __pyx_k_gs_is_not_of_length_3_or_less, sizeof(__pyx_k_gs_is_not_of_length_3_or_less), 0, 0, 1, 0},
  {&__pyx_n_s_h, __pyx_k_h, sizeof(__pyx_k_h), 0, 0, 1, 1},
  {&__pyx_n_s_have_complex, __pyx_k_have_complex, sizeof(__pyx_k_have_complex), 0, 0, 1, 1},
  {&__pyx_n_s_have_double, __pyx_k_have_double, sizeof(__pyx_k_have_double), 0, 0, 1, 1},
  {&__pyx_n_s_have_half, __pyx_k_have_half, sizeof(__pyx_k_have_half), 0, 0, 1, 1},
  {&__pyx_n_s_have_small, __pyx_k_have_small, sizeof(__pyx_k_have_small), 0, 0, 1, 1},
  {&__pyx_n_s_hpy, __pyx_k_hpy, sizeof(__pyx_k_hpy), 0, 0, 1, 1},
  {&__pyx_n_s_i, __pyx_k_i, sizeof(__pyx_k_i), 0, 0, 1, 1},
  {&__pyx_n_s_id, __pyx_k_id, sizeof(__pyx_k_id), 0, 0, 1, 1},
  {&__pyx_n_s_import, __pyx_k_import, sizeof(__pyx_k_import), 0, 0, 1, 1},
  {&__pyx_n_s_ind, __pyx_k_ind, sizeof(__pyx_k_ind), 0, 0, 1, 1},
  {&__pyx_n_s_index, __pyx_k_index, sizeof(__pyx_k_index), 0, 0, 1, 1},
  {&__pyx_kp_s_index_d_out_of_bounds, __pyx_k_index_d_out_of_bounds, sizeof(__pyx_k_index_d_out_of_bounds), 0, 0, 1, 0},
  {&__pyx_kp_s_index_out_of_bounds, __pyx_k_index_out_of_bounds, sizeof(__pyx_k_index_out_of_bounds), 0, 0, 1, 0},
  {&__pyx_n_s_init, __pyx_k_init, sizeof(__pyx_k_init), 0, 0, 1, 1},
  {&__pyx_n_s_initial_cache_size, __pyx_k_initial_cache_size, sizeof(__pyx_k_initial_cache_size), 0, 0, 1, 1},
  {&__pyx_n_s_int16, __pyx_k_int16, sizeof(__pyx_k_int16), 0, 0, 1, 1},
  {&__pyx_n_s_int32, __pyx_k_int32, sizeof(__pyx_k_int32), 0, 0, 1, 1},
  {&__pyx_n_s_int64, __pyx_k_int64, sizeof(__pyx_k_int64), 0, 0, 1, 1},
  {&__pyx_n_s_int8, __pyx_k_int8, sizeof(__pyx_k_int8), 0, 0, 1, 1},
  {&__pyx_n_s_isdigit, __pyx_k_isdigit, sizeof(__pyx_k_isdigit), 0, 0, 1, 1},
  {&__pyx_n_s_iteritems, __pyx_k_iteritems, sizeof(__pyx_k_iteritems), 0, 0, 1, 1},
  {&__pyx_n_s_join, __pyx_k_join, sizeof(__pyx_k_join), 0, 0, 1, 1},
  {&__pyx_n_s_kernel_cache_path, __pyx_k_kernel_cache_path, sizeof(__pyx_k_kernel_cache_path), 0, 0, 1, 1},
  {&__pyx_n_s_kernel_cache_path_b, __pyx_k_kernel_cache_path_b, sizeof(__pyx_k_kernel_cache_path_b), 0, 0, 1, 1},
  {&__pyx_n_s_kind, __pyx_k_kind, sizeof(__pyx_k_kind), 0, 0, 1, 1},
  {&__pyx_n_s_l, __pyx_k_l, sizeof(__pyx_k_l), 0, 0, 1, 1},
  {&__pyx_n_s_ldtype, __pyx_k_ldtype, sizeof(__pyx_k_ldtype), 0, 0, 1, 1},
  {&__pyx_kp_s_len_of_unsized_object, __pyx_k_len_of_unsized_object, sizeof(__pyx_k_len_of_unsized_object), 0, 0, 1, 0},
  {&__pyx_n_s_ls, __pyx_k_ls, sizeof(__pyx_k_ls), 0, 0, 1, 1},
  {&__pyx_kp_s_ls_is_not_int_or_list, __pyx_k_ls_is_not_int_or_list, sizeof(__pyx_k_ls_is_not_int_or_list), 0, 0, 1, 0},
  {&__pyx_kp_s_ls_is_not_of_length_3_or_less, __pyx_k_ls_is_not_of_length_3_or_less, sizeof(__pyx_k_ls_is_not_of_length_3_or_less), 0, 0, 1, 0},
  {&__pyx_n_s_m, __pyx_k_m, sizeof(__pyx_k_m), 0, 0, 1, 1},
  {&__pyx_n_s_main, __pyx_k_main, sizeof(__pyx_k_main), 0, 0, 1, 1},
  {&__pyx_n_s_major_version, __pyx_k_major_version, sizeof(__pyx_k_major_version), 0, 0, 1, 1},
  {&__pyx_n_s_max_cache_size, __pyx_k_max_cache_size, sizeof(__pyx_k_max_cache_size), 0, 0, 1, 1},
  {&__pyx_n_s_maxsize, __pyx_k_maxsize, sizeof(__pyx_k_maxsize), 0, 0, 1, 1},
  {&__pyx_n_s_may_share_memory, __pyx_k_may_share_memory, sizeof(__pyx_k_may_share_memory), 0, 0, 1, 1},
  {&__pyx_n_s_metaclass, __pyx_k_metaclass, sizeof(__pyx_k_metaclass), 0, 0, 1, 1},
  {&__pyx_n_s_minor_version, __pyx_k_minor_version, sizeof(__pyx_k_minor_version), 0, 0, 1, 1},
  {&__pyx_n_s_module, __pyx_k_module, sizeof(__pyx_k_module), 0, 0, 1, 1},
  {&__pyx_n_s_multi, __pyx_k_multi, sizeof(__pyx_k_multi), 0, 0, 1, 1},
  {&__pyx_n_s_n, __pyx_k_n, sizeof(__pyx_k_n), 0, 0, 1, 1},
  {&__pyx_kp_s_n_is_specified_and_nd_1, __pyx_k_n_is_specified_and_nd_1, sizeof(__pyx_k_n_is_specified_and_nd_1), 0, 0, 1, 0},
  {&__pyx_n_s_name, __pyx_k_name, sizeof(__pyx_k_name), 0, 0, 1, 1},
  {&__pyx_n_s_nd, __pyx_k_nd, sizeof(__pyx_k_nd), 0, 0, 1, 1},
  {&__pyx_kp_s_nd_mismatch_for_gs_None, __pyx_k_nd_mismatch_for_gs_None, sizeof(__pyx_k_nd_mismatch_for_gs_None), 0, 0, 1, 0},
  {&__pyx_kp_s_nd_mismatch_for_gs_int, __pyx_k_nd_mismatch_for_gs_int, sizeof(__pyx_k_nd_mismatch_for_gs_int), 0, 0, 1, 0},
  {&__pyx_kp_s_nd_mismatch_for_gs_tuple, __pyx_k_nd_mismatch_for_gs_tuple, sizeof(__pyx_k_nd_mismatch_for_gs_tuple), 0, 0, 1, 0},
  {&__pyx_kp_u_ndarray_is_not_C_contiguous, __pyx_k_ndarray_is_not_C_contiguous, sizeof(__pyx_k_ndarray_is_not_C_contiguous), 0, 1, 0, 0},
  {&__pyx_kp_u_ndarray_is_not_Fortran_contiguou, __pyx_k_ndarray_is_not_Fortran_contiguou, sizeof(__pyx_k_ndarray_is_not_Fortran_contiguou), 0, 1, 0, 0},
  {&__pyx_n_s_ndmin, __pyx_k_ndmin, sizeof(__pyx_k_ndmin), 0, 0, 1, 1},
  {&__pyx_n_s_new, __pyx_k_new, sizeof(__pyx_k_new), 0, 0, 1, 1},
  {&__pyx_kp_s_new_strides_are_the_wrong_length, __pyx_k_new_strides_are_the_wrong_length, sizeof(__pyx_k_new_strides_are_the_wrong_length), 0, 0, 1, 0},
  {&__pyx_kp_s_new_strides_go_outside_of_alloca, __pyx_k_new_strides_go_outside_of_alloca, sizeof(__pyx_k_new_strides_go_outside_of_alloca), 0, 0, 1, 0},
  {&__pyx_n_s_np, __pyx_k_np, sizeof(__pyx_k_np), 0, 0, 1, 1},
  {&__pyx_n_s_numargs, __pyx_k_numargs, sizeof(__pyx_k_numargs), 0, 0, 1, 1},
  {&__pyx_n_s_numpy, __pyx_k_numpy, sizeof(__pyx_k_numpy), 0, 0, 1, 1},
  {&__pyx_kp_s_numpy_core_multiarray_failed_to, __pyx_k_numpy_core_multiarray_failed_to, sizeof(__pyx_k_numpy_core_multiarray_failed_to), 0, 0, 1, 0},
  {&__pyx_kp_s_numpy_core_umath_failed_to_impor, __pyx_k_numpy_core_umath_failed_to_impor, sizeof(__pyx_k_numpy_core_umath_failed_to_impor), 0, 0, 1, 0},
  {&__pyx_n_s_offset, __pyx_k_offset, sizeof(__pyx_k_offset), 0, 0, 1, 1},
  {&__pyx_n_s_open_ipc_handle, __pyx_k_open_ipc_handle, sizeof(__pyx_k_open_ipc_handle), 0, 0, 1, 1},
  {&__pyx_n_b_opencl, __pyx_k_opencl, sizeof(__pyx_k_opencl), 0, 0, 0, 1},
  {&__pyx_n_s_opencl, __pyx_k_opencl, sizeof(__pyx_k_opencl), 0, 0, 1, 1},
  {&__pyx_n_s_order, __pyx_k_order, sizeof(__pyx_k_order), 0, 0, 1, 1},
  {&__pyx_n_s_own, __pyx_k_own, sizeof(__pyx_k_own), 0, 0, 1, 1},
  {&__pyx_n_s_owndata, __pyx_k_owndata, sizeof(__pyx_k_owndata), 0, 0, 1, 1},
  {&__pyx_n_s_p, __pyx_k_p, sizeof(__pyx_k_p), 0, 0, 1, 1},
  {&__pyx_n_s_platcount, __pyx_k_platcount, sizeof(__pyx_k_platcount), 0, 0, 1, 1},
  {&__pyx_n_s_platform, __pyx_k_platform, sizeof(__pyx_k_platform), 0, 0, 1, 1},
  {&__pyx_n_s_prepare, __pyx_k_prepare, sizeof(__pyx_k_prepare), 0, 0, 1, 1},
  {&__pyx_n_s_proto, __pyx_k_proto, sizeof(__pyx_k_proto), 0, 0, 1, 1},
  {&__pyx_n_s_ptr, __pyx_k_ptr, sizeof(__pyx_k_ptr), 0, 0, 1, 1},
  {&__pyx_n_s_pygpu_gpuarray, __pyx_k_pygpu_gpuarray, sizeof(__pyx_k_pygpu_gpuarray), 0, 0, 1, 1},
  {&__pyx_kp_s_pygpu_gpuarray_pyx, __pyx_k_pygpu_gpuarray_pyx, sizeof(__pyx_k_pygpu_gpuarray_pyx), 0, 0, 1, 0},
  {&__pyx_n_s_pyx_vtable, __pyx_k_pyx_vtable, sizeof(__pyx_k_pyx_vtable), 0, 0, 1, 1},
  {&__pyx_n_s_qualname, __pyx_k_qualname, sizeof(__pyx_k_qualname), 0, 0, 1, 1},
  {&__pyx_n_s_r, __pyx_k_r, sizeof(__pyx_k_r), 0, 0, 1, 1},
  {&__pyx_n_s_range, __pyx_k_range, sizeof(__pyx_k_range), 0, 0, 1, 1},
  {&__pyx_n_s_register_dtype, __pyx_k_register_dtype, sizeof(__pyx_k_register_dtype), 0, 0, 1, 1},
  {&__pyx_n_s_repr___locals_genexpr, __pyx_k_repr___locals_genexpr, sizeof(__pyx_k_repr___locals_genexpr), 0, 0, 1, 1},
  {&__pyx_n_s_res, __pyx_k_res, sizeof(__pyx_k_res), 0, 0, 1, 1},
  {&__pyx_n_s_reshape, __pyx_k_reshape, sizeof(__pyx_k_reshape), 0, 0, 1, 1},
  {&__pyx_n_s_restype, __pyx_k_restype, sizeof(__pyx_k_restype), 0, 0, 1, 1},
  {&__pyx_n_s_rs, __pyx_k_rs, sizeof(__pyx_k_rs), 0, 0, 1, 1},
  {&__pyx_n_s_s, __pyx_k_s, sizeof(__pyx_k_s), 0, 0, 1, 1},
  {&__pyx_kp_s_s_s, __pyx_k_s_s, sizeof(__pyx_k_s_s), 0, 0, 1, 0},
  {&__pyx_n_s_sched, __pyx_k_sched, sizeof(__pyx_k_sched), 0, 0, 1, 1},
  {&__pyx_n_s_send, __pyx_k_send, sizeof(__pyx_k_send), 0, 0, 1, 1},
  {&__pyx_n_s_set_default_context, __pyx_k_set_default_context, sizeof(__pyx_k_set_default_context), 0, 0, 1, 1},
  {&__pyx_n_s_setitem, __pyx_k_setitem, sizeof(__pyx_k_setitem), 0, 0, 1, 1},
  {&__pyx_n_s_setitem___locals_genexpr, __pyx_k_setitem___locals_genexpr, sizeof(__pyx_k_setitem___locals_genexpr), 0, 0, 1, 1},
  {&__pyx_n_s_shape, __pyx_k_shape, sizeof(__pyx_k_shape), 0, 0, 1, 1},
  {&__pyx_n_s_shared, __pyx_k_shared, sizeof(__pyx_k_shared), 0, 0, 1, 1},
  {&__pyx_n_s_single, __pyx_k_single, sizeof(__pyx_k_single), 0, 0, 1, 1},
  {&__pyx_n_s_single_stream, __pyx_k_single_stream, sizeof(__pyx_k_single_stream), 0, 0, 1, 1},
  {&__pyx_n_s_size, __pyx_k_size, sizeof(__pyx_k_size), 0, 0, 1, 1},
  {&__pyx_n_s_source, __pyx_k_source, sizeof(__pyx_k_source), 0, 0, 1, 1},
  {&__pyx_n_s_split, __pyx_k_split, sizeof(__pyx_k_split), 0, 0, 1, 1},
  {&__pyx_n_s_split_2, __pyx_k_split_2, sizeof(__pyx_k_split_2), 0, 0, 1, 1},
  {&__pyx_kp_s_split_on_non_existant_axis, __pyx_k_split_on_non_existant_axis, sizeof(__pyx_k_split_on_non_existant_axis), 0, 0, 1, 0},
  {&__pyx_n_s_startswith, __pyx_k_startswith, sizeof(__pyx_k_startswith), 0, 0, 1, 1},
  {&__pyx_n_s_strides, __pyx_k_strides, sizeof(__pyx_k_strides), 0, 0, 1, 1},
  {&__pyx_kp_s_strides_must_be_the_same_length, __pyx_k_strides_must_be_the_same_length, sizeof(__pyx_k_strides_must_be_the_same_length), 0, 0, 1, 0},
  {&__pyx_n_s_sys, __pyx_k_sys, sizeof(__pyx_k_sys), 0, 0, 1, 1},
  {&__pyx_n_s_t, __pyx_k_t, sizeof(__pyx_k_t), 0, 0, 1, 1},
  {&__pyx_n_s_tb, __pyx_k_tb, sizeof(__pyx_k_tb), 0, 0, 1, 1},
  {&__pyx_n_s_test, __pyx_k_test, sizeof(__pyx_k_test), 0, 0, 1, 1},
  {&__pyx_n_s_throw, __pyx_k_throw, sizeof(__pyx_k_throw), 0, 0, 1, 1},
  {&__pyx_n_s_tmp, __pyx_k_tmp, sizeof(__pyx_k_tmp), 0, 0, 1, 1},
  {&__pyx_kp_s_too_many_indices, __pyx_k_too_many_indices, sizeof(__pyx_k_too_many_indices), 0, 0, 1, 0},
  {&__pyx_kp_s_transfer_only_works_for_contigou, __pyx_k_transfer_only_works_for_contigou, sizeof(__pyx_k_transfer_only_works_for_contigou), 0, 0, 1, 0},
  {&__pyx_n_s_typecode, __pyx_k_typecode, sizeof(__pyx_k_typecode), 0, 0, 1, 1},
  {&__pyx_n_s_types, __pyx_k_types, sizeof(__pyx_k_types), 0, 0, 1, 1},
  {&__pyx_n_s_uint16, __pyx_k_uint16, sizeof(__pyx_k_uint16), 0, 0, 1, 1},
  {&__pyx_n_s_uint32, __pyx_k_uint32, sizeof(__pyx_k_uint32), 0, 0, 1, 1},
  {&__pyx_n_s_uint64, __pyx_k_uint64, sizeof(__pyx_k_uint64), 0, 0, 1, 1},
  {&__pyx_n_s_uint8, __pyx_k_uint8, sizeof(__pyx_k_uint8), 0, 0, 1, 1},
  {&__pyx_kp_s_undefined_comparison_for_flag_ob, __pyx_k_undefined_comparison_for_flag_ob, sizeof(__pyx_k_undefined_comparison_for_flag_ob), 0, 0, 1, 0},
  {&__pyx_kp_s_unexpected_value_for_parameter_s, __pyx_k_unexpected_value_for_parameter_s, sizeof(__pyx_k_unexpected_value_for_parameter_s), 0, 0, 1, 0},
  {&__pyx_kp_s_unhashable_type_s, __pyx_k_unhashable_type_s, sizeof(__pyx_k_unhashable_type_s), 0, 0, 1, 0},
  {&__pyx_kp_u_unknown_dtype_code_in_numpy_pxd, __pyx_k_unknown_dtype_code_in_numpy_pxd, sizeof(__pyx_k_unknown_dtype_code_in_numpy_pxd), 0, 1, 0, 0},
  {&__pyx_n_s_updateifcopy, __pyx_k_updateifcopy, sizeof(__pyx_k_updateifcopy), 0, 0, 1, 1},
  {&__pyx_n_s_upper, __pyx_k_upper, sizeof(__pyx_k_upper), 0, 0, 1, 1},
  {&__pyx_n_s_v, __pyx_k_v, sizeof(__pyx_k_v), 0, 0, 1, 1},
  {&__pyx_n_s_view, __pyx_k_view, sizeof(__pyx_k_view), 0, 0, 1, 1},
  {&__pyx_n_s_writable, __pyx_k_writable, sizeof(__pyx_k_writable), 0, 0, 1, 1},
  {&__pyx_n_s_writeable, __pyx_k_writeable, sizeof(__pyx_k_writeable), 0, 0, 1, 1},
  {&__pyx_n_s_zeros, __pyx_k_zeros, sizeof(__pyx_k_zeros), 0, 0, 1, 1},
  {0, 0, 0, 0, 0, 0, 0}
};
static int __Pyx_InitCachedBuiltins(void) {
  __pyx_builtin_TypeError = __Pyx_GetBuiltinName(__pyx_n_s_TypeError); if (!__pyx_builtin_TypeError) __PYX_ERR(0, 43, __pyx_L1_error)
  __pyx_builtin_range = __Pyx_GetBuiltinName(__pyx_n_s_range); if (!__pyx_builtin_range) __PYX_ERR(0, 49, __pyx_L1_error)
  __pyx_builtin_RuntimeError = __Pyx_GetBuiltinName(__pyx_n_s_RuntimeError); if (!__pyx_builtin_RuntimeError) __PYX_ERR(0, 65, __pyx_L1_error)
  __pyx_builtin_MemoryError = __Pyx_GetBuiltinName(__pyx_n_s_MemoryError); if (!__pyx_builtin_MemoryError) __PYX_ERR(0, 143, __pyx_L1_error)
  __pyx_builtin_NotImplementedError = __Pyx_GetBuiltinName(__pyx_n_s_NotImplementedError); if (!__pyx_builtin_NotImplementedError) __PYX_ERR(0, 165, __pyx_L1_error)
  __pyx_builtin_ValueError = __Pyx_GetBuiltinName(__pyx_n_s_ValueError); if (!__pyx_builtin_ValueError) __PYX_ERR(0, 180, __pyx_L1_error)
  __pyx_builtin_IndexError = __Pyx_GetBuiltinName(__pyx_n_s_IndexError); if (!__pyx_builtin_IndexError) __PYX_ERR(0, 339, __pyx_L1_error)
  __pyx_builtin_enumerate = __Pyx_GetBuiltinName(__pyx_n_s_enumerate); if (!__pyx_builtin_enumerate) __PYX_ERR(0, 760, __pyx_L1_error)
  __pyx_builtin_KeyError = __Pyx_GetBuiltinName(__pyx_n_s_KeyError); if (!__pyx_builtin_KeyError) __PYX_ERR(0, 1210, __pyx_L1_error)
  __pyx_builtin_NotImplemented = __Pyx_GetBuiltinName(__pyx_n_s_NotImplemented); if (!__pyx_builtin_NotImplemented) __PYX_ERR(0, 1278, __pyx_L1_error)
  __pyx_builtin_Ellipsis = __Pyx_GetBuiltinName(__pyx_n_s_Ellipsis); if (!__pyx_builtin_Ellipsis) __PYX_ERR(0, 1611, __pyx_L1_error)
  __pyx_builtin_SystemError = __Pyx_GetBuiltinName(__pyx_n_s_SystemError); if (!__pyx_builtin_SystemError) __PYX_ERR(0, 1718, __pyx_L1_error)
  __pyx_builtin_id = __Pyx_GetBuiltinName(__pyx_n_s_id); if (!__pyx_builtin_id) __PYX_ERR(0, 1797, __pyx_L1_error)
  __pyx_builtin_ImportError = __Pyx_GetBuiltinName(__pyx_n_s_ImportError); if (!__pyx_builtin_ImportError) __PYX_ERR(1, 1013, __pyx_L1_error)
  return 0;
  __pyx_L1_error:;
  return -1;
}

static int __Pyx_InitCachedConstants(void) {
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__Pyx_InitCachedConstants", 0);

  /* "pygpu/gpuarray.pyx":43
 *     if isinstance(s, bytes):
 *         return s
 *     raise TypeError("Expected a string")             # <<<<<<<<<<<<<<
 * 
 * cdef size_t countis(l, object val):
 */
  __pyx_tuple_ = PyTuple_Pack(1, __pyx_kp_s_Expected_a_string); if (unlikely(!__pyx_tuple_)) __PYX_ERR(0, 43, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple_);
  __Pyx_GIVEREF(__pyx_tuple_);

  /* "pygpu/gpuarray.pyx":564
 *     cdef GpuContext res
 * 
 *     if dev.startswith('cuda'):             # <<<<<<<<<<<<<<
 *         kind = b"cuda"
 *         if dev[4:] == '':
 */
  __pyx_tuple__2 = PyTuple_Pack(1, __pyx_n_s_cuda); if (unlikely(!__pyx_tuple__2)) __PYX_ERR(0, 564, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__2);
  __Pyx_GIVEREF(__pyx_tuple__2);

  /* "pygpu/gpuarray.pyx":566
 *     if dev.startswith('cuda'):
 *         kind = b"cuda"
 *         if dev[4:] == '':             # <<<<<<<<<<<<<<
 *             devnum = -1
 *         else:
 */
  __pyx_slice__3 = PySlice_New(__pyx_int_4, Py_None, Py_None); if (unlikely(!__pyx_slice__3)) __PYX_ERR(0, 566, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_slice__3);
  __Pyx_GIVEREF(__pyx_slice__3);

  /* "pygpu/gpuarray.pyx":569
 *             devnum = -1
 *         else:
 *             devnum = int(dev[4:])             # <<<<<<<<<<<<<<
 *         gpucontext_props_cuda_dev(p, devnum)
 *     elif dev.startswith('opencl'):
 */
  __pyx_slice__5 = PySlice_New(__pyx_int_4, Py_None, Py_None); if (unlikely(!__pyx_slice__5)) __PYX_ERR(0, 569, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_slice__5);
  __Pyx_GIVEREF(__pyx_slice__5);

  /* "pygpu/gpuarray.pyx":571
 *             devnum = int(dev[4:])
 *         gpucontext_props_cuda_dev(p, devnum)
 *     elif dev.startswith('opencl'):             # <<<<<<<<<<<<<<
 *         kind = b"opencl"
 *         devspec = dev[6:].split(':')
 */
  __pyx_tuple__6 = PyTuple_Pack(1, __pyx_n_s_opencl); if (unlikely(!__pyx_tuple__6)) __PYX_ERR(0, 571, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__6);
  __Pyx_GIVEREF(__pyx_tuple__6);

  /* "pygpu/gpuarray.pyx":573
 *     elif dev.startswith('opencl'):
 *         kind = b"opencl"
 *         devspec = dev[6:].split(':')             # <<<<<<<<<<<<<<
 *         if len(devspec) < 2:
 *             raise ValueError, "OpenCL name incorrect. Should be opencl<int>:<int> instead got: " + dev
 */
  __pyx_slice__7 = PySlice_New(__pyx_int_6, Py_None, Py_None); if (unlikely(!__pyx_slice__7)) __PYX_ERR(0, 573, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_slice__7);
  __Pyx_GIVEREF(__pyx_slice__7);
  __pyx_tuple__9 = PyTuple_Pack(1, __pyx_kp_s__8); if (unlikely(!__pyx_tuple__9)) __PYX_ERR(0, 573, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__9);
  __Pyx_GIVEREF(__pyx_tuple__9);

  /* "pygpu/gpuarray.pyx":988
 *             if arg.ga.nd < ndmin:
 *                 shp = arg.shape
 *                 idx = (1,)*(ndmin-len(shp))             # <<<<<<<<<<<<<<
 *                 shp = idx + shp
 *                 arg = arg.reshape(shp)
 */
  __pyx_tuple__13 = PyTuple_New(1); if (unlikely(!__pyx_tuple__13)) __PYX_ERR(0, 988, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__13);
  __Pyx_INCREF(__pyx_int_1);
  __Pyx_GIVEREF(__pyx_int_1);
  PyTuple_SET_ITEM(__pyx_tuple__13, 0, __pyx_int_1);
  __Pyx_GIVEREF(__pyx_tuple__13);

  /* "pygpu/gpuarray.pyx":996
 *         shp = arg.shape
 *         if len(shp) < ndmin:
 *             idx = (1,)*(ndmin-len(shp))             # <<<<<<<<<<<<<<
 *             shp = idx + shp
 *         if order is None or order == 'A':
 */
  __pyx_tuple__14 = PyTuple_New(1); if (unlikely(!__pyx_tuple__14)) __PYX_ERR(0, 996, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__14);
  __Pyx_INCREF(__pyx_int_1);
  __Pyx_GIVEREF(__pyx_int_1);
  PyTuple_SET_ITEM(__pyx_tuple__14, 0, __pyx_int_1);
  __Pyx_GIVEREF(__pyx_tuple__14);

  /* "pygpu/gpuarray.pyx":1073
 *     def __enter__(self):
 *         if cuda_enter == NULL:
 *             raise RuntimeError("cuda_enter not available")             # <<<<<<<<<<<<<<
 *         if cuda_exit == NULL:
 *             raise RuntimeError("cuda_exit not available")
 */
  __pyx_tuple__15 = PyTuple_Pack(1, __pyx_kp_s_cuda_enter_not_available); if (unlikely(!__pyx_tuple__15)) __PYX_ERR(0, 1073, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__15);
  __Pyx_GIVEREF(__pyx_tuple__15);

  /* "pygpu/gpuarray.pyx":1075
 *             raise RuntimeError("cuda_enter not available")
 *         if cuda_exit == NULL:
 *             raise RuntimeError("cuda_exit not available")             # <<<<<<<<<<<<<<
 *         if self.kind != b"cuda":
 *             raise ValueError("Context manager only works for cuda")
 */
  __pyx_tuple__16 = PyTuple_Pack(1, __pyx_kp_s_cuda_exit_not_available); if (unlikely(!__pyx_tuple__16)) __PYX_ERR(0, 1075, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__16);
  __Pyx_GIVEREF(__pyx_tuple__16);

  /* "pygpu/gpuarray.pyx":1077
 *             raise RuntimeError("cuda_exit not available")
 *         if self.kind != b"cuda":
 *             raise ValueError("Context manager only works for cuda")             # <<<<<<<<<<<<<<
 *         cuda_enter(self.ctx)
 *         return self
 */
  __pyx_tuple__17 = PyTuple_Pack(1, __pyx_kp_s_Context_manager_only_works_for_c); if (unlikely(!__pyx_tuple__17)) __PYX_ERR(0, 1077, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__17);
  __Pyx_GIVEREF(__pyx_tuple__17);

  /* "pygpu/gpuarray.pyx":1205
 * 
 *         if isinstance(idx, unicode):
 *             idx = idx.encode('UTF-8')             # <<<<<<<<<<<<<<
 *         if isinstance(idx, bytes):
 *             key = idx
 */
  __pyx_tuple__18 = PyTuple_Pack(1, __pyx_kp_s_UTF_8); if (unlikely(!__pyx_tuple__18)) __PYX_ERR(0, 1205, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__18);
  __Pyx_GIVEREF(__pyx_tuple__18);

  /* "pygpu/gpuarray.pyx":1270
 *     def __repr__(self):
 *         return '\n'.join(" %s : %s" % (name.upper(), getattr(self, name))
 *                          for name in ["c_contiguous", "f_contiguous",             # <<<<<<<<<<<<<<
 *                                       "owndata", "writeable", "aligned",
 *                                       "updateifcopy"])
 */
  __pyx_tuple__19 = PyTuple_Pack(6, __pyx_n_s_c_contiguous, __pyx_n_s_f_contiguous, __pyx_n_s_owndata, __pyx_n_s_writeable, __pyx_n_s_aligned, __pyx_n_s_updateifcopy); if (unlikely(!__pyx_tuple__19)) __PYX_ERR(0, 1270, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__19);
  __Pyx_GIVEREF(__pyx_tuple__19);

  /* "pygpu/gpuarray.pyx":1428
 *     cdef unsigned int caxis = <unsigned int>compute_axis
 *     if caxis >= nd:
 *         raise ValueError("compute_axis is out of bounds")             # <<<<<<<<<<<<<<
 * 
 *     cdef size_t *cdims
 */
  __pyx_tuple__21 = PyTuple_Pack(1, __pyx_kp_s_compute_axis_is_out_of_bounds); if (unlikely(!__pyx_tuple__21)) __PYX_ERR(0, 1428, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__21);
  __Pyx_GIVEREF(__pyx_tuple__21);

  /* "pygpu/gpuarray.pyx":1746
 *             return bool(numpy.asarray(self))
 *         else:
 *             raise ValueError('The truth value of a multi-element array is ambiguous')             # <<<<<<<<<<<<<<
 * 
 *     def _empty_like_me(self, dtype=None, order='C'):
 */
  __pyx_tuple__23 = PyTuple_Pack(1, __pyx_kp_s_The_truth_value_of_a_multi_eleme); if (unlikely(!__pyx_tuple__23)) __PYX_ERR(0, 1746, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__23);
  __Pyx_GIVEREF(__pyx_tuple__23);

  /* "pygpu/gpuarray.pyx":1786
 *         if not GpuArray_ISONESEGMENT(&self.ga):
 *             # For now raise an error, may make it work later
 *             raise ValueError("transfer() only works for contigous source")             # <<<<<<<<<<<<<<
 *         r = pygpu_empty(self.ga.nd, self.ga.dimensions, self.ga.typecode,
 *                         GA_C_ORDER if GpuArray_IS_C_CONTIGUOUS(&self.ga) else GA_F_ORDER,
 */
  __pyx_tuple__24 = PyTuple_Pack(1, __pyx_kp_s_transfer_only_works_for_contigou); if (unlikely(!__pyx_tuple__24)) __PYX_ERR(0, 1786, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__24);
  __Pyx_GIVEREF(__pyx_tuple__24);

  /* "pygpu/gpuarray.pyx":1909
 *         if len(params) is 1 and isinstance(params[0], (tuple, list)):
 *             params = params[0]
 *         if params is () or params == (None,):             # <<<<<<<<<<<<<<
 *             return pygpu_transpose(self, NULL)
 *         else:
 */
  __pyx_tuple__26 = PyTuple_Pack(1, Py_None); if (unlikely(!__pyx_tuple__26)) __PYX_ERR(0, 1909, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__26);
  __Pyx_GIVEREF(__pyx_tuple__26);

  /* "pygpu/gpuarray.pyx":1964
 *         # is also required for numpy compat.
 *         try:
 *             ell_idx = key.index(Ellipsis)             # <<<<<<<<<<<<<<
 *         except ValueError:
 *             pass
 */
  __pyx_tuple__27 = PyTuple_Pack(1, __pyx_builtin_Ellipsis); if (unlikely(!__pyx_tuple__27)) __PYX_ERR(0, 1964, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__27);
  __Pyx_GIVEREF(__pyx_tuple__27);

  /* "pygpu/gpuarray.pyx":1971
 *             # objects, not counting None entries and the Ellipsis itself
 *             num_slcs = self.ga.nd - (len(key) - countis(key, None) - 1)
 *             fill_slices = (slice(None),) * num_slcs             # <<<<<<<<<<<<<<
 *             key = key[:ell_idx] + fill_slices + key[ell_idx + 1:]
 * 
 */
  __pyx_slice__28 = PySlice_New(Py_None, Py_None, Py_None); if (unlikely(!__pyx_slice__28)) __PYX_ERR(0, 1971, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_slice__28);
  __Pyx_GIVEREF(__pyx_slice__28);
  __pyx_tuple__29 = PyTuple_New(1); if (unlikely(!__pyx_tuple__29)) __PYX_ERR(0, 1971, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__29);
  __Pyx_INCREF(__pyx_slice__28);
  __Pyx_GIVEREF(__pyx_slice__28);
  PyTuple_SET_ITEM(__pyx_tuple__29, 0, __pyx_slice__28);
  __Pyx_GIVEREF(__pyx_tuple__29);

  /* "pygpu/gpuarray.pyx":1983
 *         if len(getitem_idcs) <= 1:
 *             getitem_idcs = (getitem_idcs +
 *                             (slice(None),) * (self.ga.nd - len(getitem_idcs)))             # <<<<<<<<<<<<<<
 * 
 *         # Slice into array, then reshape, accommodating for None entries in key
 */
  __pyx_slice__30 = PySlice_New(Py_None, Py_None, Py_None); if (unlikely(!__pyx_slice__30)) __PYX_ERR(0, 1983, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_slice__30);
  __Pyx_GIVEREF(__pyx_slice__30);
  __pyx_tuple__31 = PyTuple_New(1); if (unlikely(!__pyx_tuple__31)) __PYX_ERR(0, 1983, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__31);
  __Pyx_INCREF(__pyx_slice__30);
  __Pyx_GIVEREF(__pyx_slice__30);
  PyTuple_SET_ITEM(__pyx_tuple__31, 0, __pyx_slice__30);
  __Pyx_GIVEREF(__pyx_tuple__31);

  /* "pygpu/gpuarray.pyx":2040
 *                     # a[..., 1:] on any array (including 1-dim).  This
 *                     # is also required for numpy compat.
 *                     el = key.index(Ellipsis)             # <<<<<<<<<<<<<<
 *                     if isinstance(key, tuple):
 *                         key = (key[:el] +
 */
  __pyx_tuple__32 = PyTuple_Pack(1, __pyx_builtin_Ellipsis); if (unlikely(!__pyx_tuple__32)) __PYX_ERR(0, 2040, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__32);
  __Pyx_GIVEREF(__pyx_tuple__32);

  /* "pygpu/gpuarray.pyx":2043
 *                     if isinstance(key, tuple):
 *                         key = (key[:el] +
 *                                (Ellipsis,)*(self.ga.nd - (len(key) - 1)) +             # <<<<<<<<<<<<<<
 *                                key[el+1:])
 *                     else:
 */
  __pyx_tuple__33 = PyTuple_New(1); if (unlikely(!__pyx_tuple__33)) __PYX_ERR(0, 2043, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__33);
  __Pyx_INCREF(__pyx_builtin_Ellipsis);
  __Pyx_GIVEREF(__pyx_builtin_Ellipsis);
  PyTuple_SET_ITEM(__pyx_tuple__33, 0, __pyx_builtin_Ellipsis);
  __Pyx_GIVEREF(__pyx_tuple__33);

  /* "pygpu/gpuarray.pyx":2180
 *             cdef unsigned int i
 *             if len(newstrides) != self.ga.nd:
 *                 raise ValueError("new strides are the wrong length")             # <<<<<<<<<<<<<<
 *             if not strides_ok(self,  newstrides):
 *                 raise ValueError("new strides go outside of allocated memory")
 */
  __pyx_tuple__34 = PyTuple_Pack(1, __pyx_kp_s_new_strides_are_the_wrong_length); if (unlikely(!__pyx_tuple__34)) __PYX_ERR(0, 2180, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__34);
  __Pyx_GIVEREF(__pyx_tuple__34);

  /* "pygpu/gpuarray.pyx":2182
 *                 raise ValueError("new strides are the wrong length")
 *             if not strides_ok(self,  newstrides):
 *                 raise ValueError("new strides go outside of allocated memory")             # <<<<<<<<<<<<<<
 *             for i in range(self.ga.nd):
 *                 self.ga.strides[i] = newstrides[i]
 */
  __pyx_tuple__35 = PyTuple_Pack(1, __pyx_kp_s_new_strides_go_outside_of_alloca); if (unlikely(!__pyx_tuple__35)) __PYX_ERR(0, 2182, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__35);
  __Pyx_GIVEREF(__pyx_tuple__35);

  /* "pygpu/gpuarray.pyx":2230
 *         def __get__(self):
 *             if self.context.kind != b"opencl":
 *                 raise TypeError("This is for OpenCL arrays.")             # <<<<<<<<<<<<<<
 *             if self.offset != 0:
 *                 raise ValueError("This array has an offset.")
 */
  __pyx_tuple__36 = PyTuple_Pack(1, __pyx_kp_s_This_is_for_OpenCL_arrays); if (unlikely(!__pyx_tuple__36)) __PYX_ERR(0, 2230, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__36);
  __Pyx_GIVEREF(__pyx_tuple__36);

  /* "pygpu/gpuarray.pyx":2232
 *                 raise TypeError("This is for OpenCL arrays.")
 *             if self.offset != 0:
 *                 raise ValueError("This array has an offset.")             # <<<<<<<<<<<<<<
 *             # This wizadry grabs the actual backend pointer since it's
 *             # guarenteed to be the first element of the gpudata
 */
  __pyx_tuple__37 = PyTuple_Pack(1, __pyx_kp_s_This_array_has_an_offset); if (unlikely(!__pyx_tuple__37)) __PYX_ERR(0, 2232, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__37);
  __Pyx_GIVEREF(__pyx_tuple__37);

  /* "pygpu/gpuarray.pyx":2242
 *         def __get__(self):
 *             if self.context.kind != b"opencl":
 *                 raise TypeError("This is for OpenCL arrays.")             # <<<<<<<<<<<<<<
 *             # This wizadry grabs the actual backend pointer since it's
 *             # guarenteed to be the first element of the gpudata
 */
  __pyx_tuple__38 = PyTuple_Pack(1, __pyx_kp_s_This_is_for_OpenCL_arrays); if (unlikely(!__pyx_tuple__38)) __PYX_ERR(0, 2242, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__38);
  __Pyx_GIVEREF(__pyx_tuple__38);

  /* "pygpu/gpuarray.pyx":2252
 *         def __get__(self):
 *             if self.context.kind != b"cuda":
 *                 raise TypeError("This is for CUDA arrays.")             # <<<<<<<<<<<<<<
 *             # This wizadry grabs the actual backend pointer since it's
 *             # guarenteed to be the first element of the gpudata
 */
  __pyx_tuple__39 = PyTuple_Pack(1, __pyx_kp_s_This_is_for_CUDA_arrays); if (unlikely(!__pyx_tuple__39)) __PYX_ERR(0, 2252, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__39);
  __Pyx_GIVEREF(__pyx_tuple__39);

  /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":235
 *             if ((flags & pybuf.PyBUF_C_CONTIGUOUS == pybuf.PyBUF_C_CONTIGUOUS)
 *                 and not PyArray_CHKFLAGS(self, NPY_C_CONTIGUOUS)):
 *                 raise ValueError(u"ndarray is not C contiguous")             # <<<<<<<<<<<<<<
 * 
 *             if ((flags & pybuf.PyBUF_F_CONTIGUOUS == pybuf.PyBUF_F_CONTIGUOUS)
 */
  __pyx_tuple__40 = PyTuple_Pack(1, __pyx_kp_u_ndarray_is_not_C_contiguous); if (unlikely(!__pyx_tuple__40)) __PYX_ERR(1, 235, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__40);
  __Pyx_GIVEREF(__pyx_tuple__40);

  /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":239
 *             if ((flags & pybuf.PyBUF_F_CONTIGUOUS == pybuf.PyBUF_F_CONTIGUOUS)
 *                 and not PyArray_CHKFLAGS(self, NPY_F_CONTIGUOUS)):
 *                 raise ValueError(u"ndarray is not Fortran contiguous")             # <<<<<<<<<<<<<<
 * 
 *             info.buf = PyArray_DATA(self)
 */
  __pyx_tuple__41 = PyTuple_Pack(1, __pyx_kp_u_ndarray_is_not_Fortran_contiguou); if (unlikely(!__pyx_tuple__41)) __PYX_ERR(1, 239, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__41);
  __Pyx_GIVEREF(__pyx_tuple__41);

  /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":276
 *                 if ((descr.byteorder == c'>' and little_endian) or
 *                     (descr.byteorder == c'<' and not little_endian)):
 *                     raise ValueError(u"Non-native byte order not supported")             # <<<<<<<<<<<<<<
 *                 if   t == NPY_BYTE:        f = "b"
 *                 elif t == NPY_UBYTE:       f = "B"
 */
  __pyx_tuple__42 = PyTuple_Pack(1, __pyx_kp_u_Non_native_byte_order_not_suppor); if (unlikely(!__pyx_tuple__42)) __PYX_ERR(1, 276, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__42);
  __Pyx_GIVEREF(__pyx_tuple__42);

  /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":823
 * 
 *         if (end - f) - <int>(new_offset - offset[0]) < 15:
 *             raise RuntimeError(u"Format string allocated too short, see comment in numpy.pxd")             # <<<<<<<<<<<<<<
 * 
 *         if ((child.byteorder == c'>' and little_endian) or
 */
  __pyx_tuple__43 = PyTuple_Pack(1, __pyx_kp_u_Format_string_allocated_too_shor); if (unlikely(!__pyx_tuple__43)) __PYX_ERR(1, 823, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__43);
  __Pyx_GIVEREF(__pyx_tuple__43);

  /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":827
 *         if ((child.byteorder == c'>' and little_endian) or
 *             (child.byteorder == c'<' and not little_endian)):
 *             raise ValueError(u"Non-native byte order not supported")             # <<<<<<<<<<<<<<
 *             # One could encode it in the format string and have Cython
 *             # complain instead, BUT: < and > in format strings also imply
 */
  __pyx_tuple__44 = PyTuple_Pack(1, __pyx_kp_u_Non_native_byte_order_not_suppor); if (unlikely(!__pyx_tuple__44)) __PYX_ERR(1, 827, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__44);
  __Pyx_GIVEREF(__pyx_tuple__44);

  /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":847
 *             t = child.type_num
 *             if end - f < 5:
 *                 raise RuntimeError(u"Format string allocated too short.")             # <<<<<<<<<<<<<<
 * 
 *             # Until ticket #99 is fixed, use integers to avoid warnings
 */
  __pyx_tuple__45 = PyTuple_Pack(1, __pyx_kp_u_Format_string_allocated_too_shor_2); if (unlikely(!__pyx_tuple__45)) __PYX_ERR(1, 847, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__45);
  __Pyx_GIVEREF(__pyx_tuple__45);

  /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":1013
 *         _import_array()
 *     except Exception:
 *         raise ImportError("numpy.core.multiarray failed to import")             # <<<<<<<<<<<<<<
 * 
 * cdef inline int import_umath() except -1:
 */
  __pyx_tuple__46 = PyTuple_Pack(1, __pyx_kp_s_numpy_core_multiarray_failed_to); if (unlikely(!__pyx_tuple__46)) __PYX_ERR(1, 1013, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__46);
  __Pyx_GIVEREF(__pyx_tuple__46);

  /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":1019
 *         _import_umath()
 *     except Exception:
 *         raise ImportError("numpy.core.umath failed to import")             # <<<<<<<<<<<<<<
 * 
 * cdef inline int import_ufunc() except -1:
 */
  __pyx_tuple__47 = PyTuple_Pack(1, __pyx_kp_s_numpy_core_umath_failed_to_impor); if (unlikely(!__pyx_tuple__47)) __PYX_ERR(1, 1019, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__47);
  __Pyx_GIVEREF(__pyx_tuple__47);

  /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":1025
 *         _import_umath()
 *     except Exception:
 *         raise ImportError("numpy.core.umath failed to import")             # <<<<<<<<<<<<<<
 */
  __pyx_tuple__48 = PyTuple_Pack(1, __pyx_kp_s_numpy_core_umath_failed_to_impor); if (unlikely(!__pyx_tuple__48)) __PYX_ERR(1, 1025, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__48);
  __Pyx_GIVEREF(__pyx_tuple__48);

  /* "pygpu/gpuarray.pyx":14
 * from cpython.object cimport Py_EQ, Py_NE
 * 
 * def api_version():             # <<<<<<<<<<<<<<
 *     """api_version()
 *     """
 */
  __pyx_codeobj__49 = (PyObject*)__Pyx_PyCode_New(0, 0, 0, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_pygpu_gpuarray_pyx, __pyx_n_s_api_version, 14, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__49)) __PYX_ERR(0, 14, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":20
 *     return (GPUARRAY_API_VERSION, 0)
 * 
 * def abi_version():             # <<<<<<<<<<<<<<
 *     """abi_version()
 *     """
 */
  __pyx_tuple__50 = PyTuple_Pack(2, __pyx_n_s_major_version, __pyx_n_s_minor_version); if (unlikely(!__pyx_tuple__50)) __PYX_ERR(0, 20, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__50);
  __Pyx_GIVEREF(__pyx_tuple__50);
  __pyx_codeobj__51 = (PyObject*)__Pyx_PyCode_New(0, 0, 2, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__50, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_pygpu_gpuarray_pyx, __pyx_n_s_abi_version, 20, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__51)) __PYX_ERR(0, 20, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":54
 *     return count
 * 
 * def cl_wrap_ctx(size_t ptr):             # <<<<<<<<<<<<<<
 *     """
 *     cl_wrap_ctx(ptr)
 */
  __pyx_tuple__52 = PyTuple_Pack(4, __pyx_n_s_ptr, __pyx_n_s_ptr, __pyx_n_s_cl_make_ctx, __pyx_n_s_res); if (unlikely(!__pyx_tuple__52)) __PYX_ERR(0, 54, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__52);
  __Pyx_GIVEREF(__pyx_tuple__52);
  __pyx_codeobj__53 = (PyObject*)__Pyx_PyCode_New(1, 0, 4, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__52, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_pygpu_gpuarray_pyx, __pyx_n_s_cl_wrap_ctx, 54, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__53)) __PYX_ERR(0, 54, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":72
 *     return res
 * 
 * def cuda_wrap_ctx(size_t ptr, bint own):             # <<<<<<<<<<<<<<
 *     """
 *     cuda_wrap_ctx(ptr)
 */
  __pyx_tuple__54 = PyTuple_Pack(5, __pyx_n_s_ptr, __pyx_n_s_own, __pyx_n_s_cuda_make_ctx, __pyx_n_s_flags, __pyx_n_s_res); if (unlikely(!__pyx_tuple__54)) __PYX_ERR(0, 72, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__54);
  __Pyx_GIVEREF(__pyx_tuple__54);
  __pyx_codeobj__55 = (PyObject*)__Pyx_PyCode_New(2, 0, 5, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__54, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_pygpu_gpuarray_pyx, __pyx_n_s_cuda_wrap_ctx, 72, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__55)) __PYX_ERR(0, 72, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":102
 * 
 * cdef dict NP_TO_TYPE = {
 *     np.dtype('bool'): GA_BOOL,             # <<<<<<<<<<<<<<
 *     np.dtype('int8'): GA_BYTE,
 *     np.dtype('uint8'): GA_UBYTE,
 */
  __pyx_tuple__56 = PyTuple_Pack(1, __pyx_n_s_bool); if (unlikely(!__pyx_tuple__56)) __PYX_ERR(0, 102, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__56);
  __Pyx_GIVEREF(__pyx_tuple__56);

  /* "pygpu/gpuarray.pyx":103
 * cdef dict NP_TO_TYPE = {
 *     np.dtype('bool'): GA_BOOL,
 *     np.dtype('int8'): GA_BYTE,             # <<<<<<<<<<<<<<
 *     np.dtype('uint8'): GA_UBYTE,
 *     np.dtype('int16'): GA_SHORT,
 */
  __pyx_tuple__57 = PyTuple_Pack(1, __pyx_n_s_int8); if (unlikely(!__pyx_tuple__57)) __PYX_ERR(0, 103, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__57);
  __Pyx_GIVEREF(__pyx_tuple__57);

  /* "pygpu/gpuarray.pyx":104
 *     np.dtype('bool'): GA_BOOL,
 *     np.dtype('int8'): GA_BYTE,
 *     np.dtype('uint8'): GA_UBYTE,             # <<<<<<<<<<<<<<
 *     np.dtype('int16'): GA_SHORT,
 *     np.dtype('uint16'): GA_USHORT,
 */
  __pyx_tuple__58 = PyTuple_Pack(1, __pyx_n_s_uint8); if (unlikely(!__pyx_tuple__58)) __PYX_ERR(0, 104, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__58);
  __Pyx_GIVEREF(__pyx_tuple__58);

  /* "pygpu/gpuarray.pyx":105
 *     np.dtype('int8'): GA_BYTE,
 *     np.dtype('uint8'): GA_UBYTE,
 *     np.dtype('int16'): GA_SHORT,             # <<<<<<<<<<<<<<
 *     np.dtype('uint16'): GA_USHORT,
 *     np.dtype('int32'): GA_INT,
 */
  __pyx_tuple__59 = PyTuple_Pack(1, __pyx_n_s_int16); if (unlikely(!__pyx_tuple__59)) __PYX_ERR(0, 105, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__59);
  __Pyx_GIVEREF(__pyx_tuple__59);

  /* "pygpu/gpuarray.pyx":106
 *     np.dtype('uint8'): GA_UBYTE,
 *     np.dtype('int16'): GA_SHORT,
 *     np.dtype('uint16'): GA_USHORT,             # <<<<<<<<<<<<<<
 *     np.dtype('int32'): GA_INT,
 *     np.dtype('uint32'): GA_UINT,
 */
  __pyx_tuple__60 = PyTuple_Pack(1, __pyx_n_s_uint16); if (unlikely(!__pyx_tuple__60)) __PYX_ERR(0, 106, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__60);
  __Pyx_GIVEREF(__pyx_tuple__60);

  /* "pygpu/gpuarray.pyx":107
 *     np.dtype('int16'): GA_SHORT,
 *     np.dtype('uint16'): GA_USHORT,
 *     np.dtype('int32'): GA_INT,             # <<<<<<<<<<<<<<
 *     np.dtype('uint32'): GA_UINT,
 *     np.dtype('int64'): GA_LONG,
 */
  __pyx_tuple__61 = PyTuple_Pack(1, __pyx_n_s_int32); if (unlikely(!__pyx_tuple__61)) __PYX_ERR(0, 107, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__61);
  __Pyx_GIVEREF(__pyx_tuple__61);

  /* "pygpu/gpuarray.pyx":108
 *     np.dtype('uint16'): GA_USHORT,
 *     np.dtype('int32'): GA_INT,
 *     np.dtype('uint32'): GA_UINT,             # <<<<<<<<<<<<<<
 *     np.dtype('int64'): GA_LONG,
 *     np.dtype('uint64'): GA_ULONG,
 */
  __pyx_tuple__62 = PyTuple_Pack(1, __pyx_n_s_uint32); if (unlikely(!__pyx_tuple__62)) __PYX_ERR(0, 108, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__62);
  __Pyx_GIVEREF(__pyx_tuple__62);

  /* "pygpu/gpuarray.pyx":109
 *     np.dtype('int32'): GA_INT,
 *     np.dtype('uint32'): GA_UINT,
 *     np.dtype('int64'): GA_LONG,             # <<<<<<<<<<<<<<
 *     np.dtype('uint64'): GA_ULONG,
 *     np.dtype('float32'): GA_FLOAT,
 */
  __pyx_tuple__63 = PyTuple_Pack(1, __pyx_n_s_int64); if (unlikely(!__pyx_tuple__63)) __PYX_ERR(0, 109, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__63);
  __Pyx_GIVEREF(__pyx_tuple__63);

  /* "pygpu/gpuarray.pyx":110
 *     np.dtype('uint32'): GA_UINT,
 *     np.dtype('int64'): GA_LONG,
 *     np.dtype('uint64'): GA_ULONG,             # <<<<<<<<<<<<<<
 *     np.dtype('float32'): GA_FLOAT,
 *     np.dtype('float64'): GA_DOUBLE,
 */
  __pyx_tuple__64 = PyTuple_Pack(1, __pyx_n_s_uint64); if (unlikely(!__pyx_tuple__64)) __PYX_ERR(0, 110, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__64);
  __Pyx_GIVEREF(__pyx_tuple__64);

  /* "pygpu/gpuarray.pyx":111
 *     np.dtype('int64'): GA_LONG,
 *     np.dtype('uint64'): GA_ULONG,
 *     np.dtype('float32'): GA_FLOAT,             # <<<<<<<<<<<<<<
 *     np.dtype('float64'): GA_DOUBLE,
 *     np.dtype('complex64'): GA_CFLOAT,
 */
  __pyx_tuple__65 = PyTuple_Pack(1, __pyx_n_s_float32); if (unlikely(!__pyx_tuple__65)) __PYX_ERR(0, 111, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__65);
  __Pyx_GIVEREF(__pyx_tuple__65);

  /* "pygpu/gpuarray.pyx":112
 *     np.dtype('uint64'): GA_ULONG,
 *     np.dtype('float32'): GA_FLOAT,
 *     np.dtype('float64'): GA_DOUBLE,             # <<<<<<<<<<<<<<
 *     np.dtype('complex64'): GA_CFLOAT,
 *     np.dtype('complex128'): GA_CDOUBLE,
 */
  __pyx_tuple__66 = PyTuple_Pack(1, __pyx_n_s_float64); if (unlikely(!__pyx_tuple__66)) __PYX_ERR(0, 112, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__66);
  __Pyx_GIVEREF(__pyx_tuple__66);

  /* "pygpu/gpuarray.pyx":113
 *     np.dtype('float32'): GA_FLOAT,
 *     np.dtype('float64'): GA_DOUBLE,
 *     np.dtype('complex64'): GA_CFLOAT,             # <<<<<<<<<<<<<<
 *     np.dtype('complex128'): GA_CDOUBLE,
 *     np.dtype('float16'): GA_HALF,
 */
  __pyx_tuple__67 = PyTuple_Pack(1, __pyx_n_s_complex64); if (unlikely(!__pyx_tuple__67)) __PYX_ERR(0, 113, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__67);
  __Pyx_GIVEREF(__pyx_tuple__67);

  /* "pygpu/gpuarray.pyx":114
 *     np.dtype('float64'): GA_DOUBLE,
 *     np.dtype('complex64'): GA_CFLOAT,
 *     np.dtype('complex128'): GA_CDOUBLE,             # <<<<<<<<<<<<<<
 *     np.dtype('float16'): GA_HALF,
 * }
 */
  __pyx_tuple__68 = PyTuple_Pack(1, __pyx_n_s_complex128); if (unlikely(!__pyx_tuple__68)) __PYX_ERR(0, 114, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__68);
  __Pyx_GIVEREF(__pyx_tuple__68);

  /* "pygpu/gpuarray.pyx":115
 *     np.dtype('complex64'): GA_CFLOAT,
 *     np.dtype('complex128'): GA_CDOUBLE,
 *     np.dtype('float16'): GA_HALF,             # <<<<<<<<<<<<<<
 * }
 * 
 */
  __pyx_tuple__69 = PyTuple_Pack(1, __pyx_n_s_float16); if (unlikely(!__pyx_tuple__69)) __PYX_ERR(0, 115, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__69);
  __Pyx_GIVEREF(__pyx_tuple__69);

  /* "pygpu/gpuarray.pyx":120
 * cdef dict TYPE_TO_NP = dict((v, k) for k, v in NP_TO_TYPE.iteritems())
 * 
 * def register_dtype(np.dtype dtype, cname):             # <<<<<<<<<<<<<<
 *     """
 *     register_dtype(dtype, cname)
 */
  __pyx_tuple__70 = PyTuple_Pack(5, __pyx_n_s_dtype, __pyx_n_s_cname, __pyx_n_s_t, __pyx_n_s_typecode, __pyx_n_s_tmp); if (unlikely(!__pyx_tuple__70)) __PYX_ERR(0, 120, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__70);
  __Pyx_GIVEREF(__pyx_tuple__70);
  __pyx_codeobj__71 = (PyObject*)__Pyx_PyCode_New(2, 0, 5, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__70, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_pygpu_gpuarray_pyx, __pyx_n_s_register_dtype, 120, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__71)) __PYX_ERR(0, 120, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":211
 *     raise ValueError, "don't know how to convert to dtype: %s"%(dtype,)
 * 
 * def dtype_to_ctype(dtype):             # <<<<<<<<<<<<<<
 *     """
 *     dtype_to_ctype(dtype)
 */
  __pyx_tuple__72 = PyTuple_Pack(4, __pyx_n_s_dtype, __pyx_n_s_typecode, __pyx_n_s_t, __pyx_n_s_res); if (unlikely(!__pyx_tuple__72)) __PYX_ERR(0, 211, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__72);
  __Pyx_GIVEREF(__pyx_tuple__72);
  __pyx_codeobj__73 = (PyObject*)__Pyx_PyCode_New(1, 0, 4, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__72, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_pygpu_gpuarray_pyx, __pyx_n_s_dtype_to_ctype, 211, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__73)) __PYX_ERR(0, 211, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":489
 *         raise get_exc(err), gpucontext_error(c.ctx, err)
 * 
 * def set_default_context(GpuContext ctx):             # <<<<<<<<<<<<<<
 *     """
 *     set_default_context(ctx)
 */
  __pyx_tuple__74 = PyTuple_Pack(1, __pyx_n_s_ctx); if (unlikely(!__pyx_tuple__74)) __PYX_ERR(0, 489, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__74);
  __Pyx_GIVEREF(__pyx_tuple__74);
  __pyx_codeobj__75 = (PyObject*)__Pyx_PyCode_New(1, 0, 1, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__74, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_pygpu_gpuarray_pyx, __pyx_n_s_set_default_context, 489, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__75)) __PYX_ERR(0, 489, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":515
 *     default_context = ctx
 * 
 * def get_default_context():             # <<<<<<<<<<<<<<
 *     """
 *     get_default_context()
 */
  __pyx_codeobj__76 = (PyObject*)__Pyx_PyCode_New(0, 0, 0, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_pygpu_gpuarray_pyx, __pyx_n_s_get_default_context, 515, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__76)) __PYX_ERR(0, 515, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":534
 *     return isinstance(o, GpuArray)
 * 
 * def count_platforms(kind):             # <<<<<<<<<<<<<<
 *     """
 *     count_platforms(kind)
 */
  __pyx_tuple__77 = PyTuple_Pack(3, __pyx_n_s_kind, __pyx_n_s_platcount, __pyx_n_s_err); if (unlikely(!__pyx_tuple__77)) __PYX_ERR(0, 534, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__77);
  __Pyx_GIVEREF(__pyx_tuple__77);
  __pyx_codeobj__78 = (PyObject*)__Pyx_PyCode_New(1, 0, 3, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__77, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_pygpu_gpuarray_pyx, __pyx_n_s_count_platforms, 534, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__78)) __PYX_ERR(0, 534, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":547
 *     return platcount
 * 
 * def count_devices(kind, unsigned int platform):             # <<<<<<<<<<<<<<
 *     """
 *     count_devices(kind, platform)
 */
  __pyx_tuple__79 = PyTuple_Pack(4, __pyx_n_s_kind, __pyx_n_s_platform, __pyx_n_s_devcount, __pyx_n_s_err); if (unlikely(!__pyx_tuple__79)) __PYX_ERR(0, 547, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__79);
  __Pyx_GIVEREF(__pyx_tuple__79);
  __pyx_codeobj__80 = (PyObject*)__Pyx_PyCode_New(2, 0, 4, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__79, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_pygpu_gpuarray_pyx, __pyx_n_s_count_devices, 547, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__80)) __PYX_ERR(0, 547, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":590
 *     return res
 * 
 * def init(dev, sched='default', single_stream=False, kernel_cache_path=None,             # <<<<<<<<<<<<<<
 *          max_cache_size=sys.maxsize, initial_cache_size=0):
 *     """
 */
  __pyx_tuple__81 = PyTuple_Pack(9, __pyx_n_s_dev, __pyx_n_s_sched, __pyx_n_s_single_stream, __pyx_n_s_kernel_cache_path, __pyx_n_s_max_cache_size, __pyx_n_s_initial_cache_size, __pyx_n_s_p, __pyx_n_s_err, __pyx_n_s_kernel_cache_path_b); if (unlikely(!__pyx_tuple__81)) __PYX_ERR(0, 590, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__81);
  __Pyx_GIVEREF(__pyx_tuple__81);
  __pyx_codeobj__82 = (PyObject*)__Pyx_PyCode_New(6, 0, 9, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__81, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_pygpu_gpuarray_pyx, __pyx_n_s_init, 590, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__82)) __PYX_ERR(0, 590, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":660
 *     return pygpu_init(dev, p)
 * 
 * def zeros(shape, dtype=GA_DOUBLE, order='C', GpuContext context=None,             # <<<<<<<<<<<<<<
 *           cls=None):
 *     """
 */
  __pyx_tuple__83 = PyTuple_Pack(6, __pyx_n_s_shape, __pyx_n_s_dtype, __pyx_n_s_order, __pyx_n_s_context, __pyx_n_s_cls, __pyx_n_s_res); if (unlikely(!__pyx_tuple__83)) __PYX_ERR(0, 660, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__83);
  __Pyx_GIVEREF(__pyx_tuple__83);
  __pyx_codeobj__84 = (PyObject*)__Pyx_PyCode_New(5, 0, 6, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__83, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_pygpu_gpuarray_pyx, __pyx_n_s_zeros, 660, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__84)) __PYX_ERR(0, 660, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":725
 *     return 0
 * 
 * def empty(shape, dtype=GA_DOUBLE, order='C', GpuContext context=None,             # <<<<<<<<<<<<<<
 *           cls=None):
 *     """
 */
  __pyx_tuple__85 = PyTuple_Pack(9, __pyx_n_s_shape, __pyx_n_s_dtype, __pyx_n_s_order, __pyx_n_s_context, __pyx_n_s_cls, __pyx_n_s_cdims, __pyx_n_s_nd, __pyx_n_s_i, __pyx_n_s_d); if (unlikely(!__pyx_tuple__85)) __PYX_ERR(0, 725, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__85);
  __Pyx_GIVEREF(__pyx_tuple__85);
  __pyx_codeobj__86 = (PyObject*)__Pyx_PyCode_New(5, 0, 9, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__85, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_pygpu_gpuarray_pyx, __pyx_n_s_empty, 725, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__86)) __PYX_ERR(0, 725, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":768
 *         free(cdims)
 * 
 * def asarray(a, dtype=None, order='A', GpuContext context=None):             # <<<<<<<<<<<<<<
 *     """
 *     asarray(a, dtype=None, order='A', context=None)
 */
  __pyx_tuple__87 = PyTuple_Pack(4, __pyx_n_s_a, __pyx_n_s_dtype, __pyx_n_s_order, __pyx_n_s_context); if (unlikely(!__pyx_tuple__87)) __PYX_ERR(0, 768, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__87);
  __Pyx_GIVEREF(__pyx_tuple__87);
  __pyx_codeobj__88 = (PyObject*)__Pyx_PyCode_New(4, 0, 4, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__87, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_pygpu_gpuarray_pyx, __pyx_n_s_asarray, 768, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__88)) __PYX_ERR(0, 768, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":797
 *                  cls=GpuArray)
 * 
 * def ascontiguousarray(a, dtype=None, GpuContext context=None):             # <<<<<<<<<<<<<<
 *     """
 *     ascontiguousarray(a, dtype=None, context=None)
 */
  __pyx_tuple__89 = PyTuple_Pack(3, __pyx_n_s_a, __pyx_n_s_dtype, __pyx_n_s_context); if (unlikely(!__pyx_tuple__89)) __PYX_ERR(0, 797, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__89);
  __Pyx_GIVEREF(__pyx_tuple__89);
  __pyx_codeobj__90 = (PyObject*)__Pyx_PyCode_New(3, 0, 3, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__89, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_pygpu_gpuarray_pyx, __pyx_n_s_ascontiguousarray, 797, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__90)) __PYX_ERR(0, 797, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":819
 *                  context=context)
 * 
 * def asfortranarray(a, dtype=None, GpuArray context=None):             # <<<<<<<<<<<<<<
 *     """
 *     asfortranarray(a, dtype=None, context=None)
 */
  __pyx_tuple__91 = PyTuple_Pack(3, __pyx_n_s_a, __pyx_n_s_dtype, __pyx_n_s_context); if (unlikely(!__pyx_tuple__91)) __PYX_ERR(0, 819, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__91);
  __Pyx_GIVEREF(__pyx_tuple__91);
  __pyx_codeobj__92 = (PyObject*)__Pyx_PyCode_New(3, 0, 3, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__91, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_pygpu_gpuarray_pyx, __pyx_n_s_asfortranarray, 819, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__92)) __PYX_ERR(0, 819, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":841
 *                  context=context)
 * 
 * def may_share_memory(GpuArray a not None, GpuArray b not None):             # <<<<<<<<<<<<<<
 *     """
 *     may_share_memory(a, b)
 */
  __pyx_tuple__93 = PyTuple_Pack(2, __pyx_n_s_a, __pyx_n_s_b); if (unlikely(!__pyx_tuple__93)) __PYX_ERR(0, 841, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__93);
  __Pyx_GIVEREF(__pyx_tuple__93);
  __pyx_codeobj__94 = (PyObject*)__Pyx_PyCode_New(2, 0, 2, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__93, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_pygpu_gpuarray_pyx, __pyx_n_s_may_share_memory, 841, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__94)) __PYX_ERR(0, 841, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":849
 *     return array_share(a, b)
 * 
 * def from_gpudata(size_t data, offset, dtype, shape, GpuContext context=None,             # <<<<<<<<<<<<<<
 *                  strides=None, writable=True, base=None, cls=None):
 *     """
 */
  __pyx_tuple__95 = PyTuple_Pack(17, __pyx_n_s_data, __pyx_n_s_offset, __pyx_n_s_dtype, __pyx_n_s_shape, __pyx_n_s_context, __pyx_n_s_strides, __pyx_n_s_writable, __pyx_n_s_base, __pyx_n_s_cls, __pyx_n_s_cdims, __pyx_n_s_cstrides, __pyx_n_s_nd, __pyx_n_s_size, __pyx_n_s_typecode, __pyx_n_s_i, __pyx_n_s_d, __pyx_n_s_s); if (unlikely(!__pyx_tuple__95)) __PYX_ERR(0, 849, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__95);
  __Pyx_GIVEREF(__pyx_tuple__95);
  __pyx_codeobj__96 = (PyObject*)__Pyx_PyCode_New(9, 0, 17, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__95, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_pygpu_gpuarray_pyx, __pyx_n_s_from_gpudata, 849, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__96)) __PYX_ERR(0, 849, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":931
 *         free(cstrides)
 * 
 * def array(proto, dtype=None, copy=True, order=None, unsigned int ndmin=0,             # <<<<<<<<<<<<<<
 *           GpuContext context=None, cls=None):
 *     """
 */
  __pyx_tuple__97 = PyTuple_Pack(7, __pyx_n_s_proto, __pyx_n_s_dtype, __pyx_n_s_copy, __pyx_n_s_order, __pyx_n_s_ndmin, __pyx_n_s_context, __pyx_n_s_cls); if (unlikely(!__pyx_tuple__97)) __PYX_ERR(0, 931, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__97);
  __Pyx_GIVEREF(__pyx_tuple__97);
  __pyx_codeobj__98 = (PyObject*)__Pyx_PyCode_New(7, 0, 7, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__97, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_pygpu_gpuarray_pyx, __pyx_n_s_array, 931, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__98)) __PYX_ERR(0, 931, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":1467
 *     return 0
 * 
 * def _split(GpuArray a, ind, unsigned int axis):             # <<<<<<<<<<<<<<
 *     """
 *     _split(a, ind, axis)
 */
  __pyx_tuple__99 = PyTuple_Pack(9, __pyx_n_s_a, __pyx_n_s_ind, __pyx_n_s_axis, __pyx_n_s_r, __pyx_n_s_i, __pyx_n_s_m, __pyx_n_s_v, __pyx_n_s_p, __pyx_n_s_rs); if (unlikely(!__pyx_tuple__99)) __PYX_ERR(0, 1467, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__99);
  __Pyx_GIVEREF(__pyx_tuple__99);
  __pyx_codeobj__100 = (PyObject*)__Pyx_PyCode_New(3, 0, 9, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__99, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_pygpu_gpuarray_pyx, __pyx_n_s_split_2, 1467, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__100)) __PYX_ERR(0, 1467, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":1505
 *     return res
 * 
 * def _concatenate(list al, unsigned int axis, int restype, object cls,             # <<<<<<<<<<<<<<
 *                  GpuContext context):
 *     """
 */
  __pyx_tuple__101 = PyTuple_Pack(7, __pyx_n_s_al, __pyx_n_s_axis, __pyx_n_s_restype, __pyx_n_s_cls, __pyx_n_s_context, __pyx_n_s_i, __pyx_n_s_als); if (unlikely(!__pyx_tuple__101)) __PYX_ERR(0, 1505, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__101);
  __Pyx_GIVEREF(__pyx_tuple__101);
  __pyx_codeobj__102 = (PyObject*)__Pyx_PyCode_New(5, 0, 7, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__101, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_pygpu_gpuarray_pyx, __pyx_n_s_concatenate, 1505, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__102)) __PYX_ERR(0, 1505, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":1530
 * cuda_open_ipc_handle = <gpudata *(*)(gpucontext *, GpuArrayIpcMemHandle *, size_t)>gpuarray_get_extension("cuda_open_ipc_handle")
 * 
 * def open_ipc_handle(GpuContext c, bytes hpy, size_t l):             # <<<<<<<<<<<<<<
 *     """
 *     open_ipc_handle(c, hpy, l)
 */
  __pyx_tuple__103 = PyTuple_Pack(6, __pyx_n_s_c, __pyx_n_s_hpy, __pyx_n_s_l, __pyx_n_s_b, __pyx_n_s_h, __pyx_n_s_d); if (unlikely(!__pyx_tuple__103)) __PYX_ERR(0, 1530, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__103);
  __Pyx_GIVEREF(__pyx_tuple__103);
  __pyx_codeobj__104 = (PyObject*)__Pyx_PyCode_New(3, 0, 6, 0, CO_OPTIMIZED|CO_NEWLOCALS, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__103, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_pygpu_gpuarray_pyx, __pyx_n_s_open_ipc_handle, 1530, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__104)) __PYX_ERR(0, 1530, __pyx_L1_error)
  __Pyx_RefNannyFinishContext();
  return 0;
  __pyx_L1_error:;
  __Pyx_RefNannyFinishContext();
  return -1;
}

static int __Pyx_InitGlobals(void) {
  if (__Pyx_InitStrings(__pyx_string_tab) < 0) __PYX_ERR(0, 1, __pyx_L1_error);
  __pyx_int_0 = PyInt_FromLong(0); if (unlikely(!__pyx_int_0)) __PYX_ERR(0, 1, __pyx_L1_error)
  __pyx_int_1 = PyInt_FromLong(1); if (unlikely(!__pyx_int_1)) __PYX_ERR(0, 1, __pyx_L1_error)
  __pyx_int_4 = PyInt_FromLong(4); if (unlikely(!__pyx_int_4)) __PYX_ERR(0, 1, __pyx_L1_error)
  __pyx_int_6 = PyInt_FromLong(6); if (unlikely(!__pyx_int_6)) __PYX_ERR(0, 1, __pyx_L1_error)
  __pyx_int_neg_1 = PyInt_FromLong(-1); if (unlikely(!__pyx_int_neg_1)) __PYX_ERR(0, 1, __pyx_L1_error)
  return 0;
  __pyx_L1_error:;
  return -1;
}

#if PY_MAJOR_VERSION < 3
PyMODINIT_FUNC initgpuarray(void); /*proto*/
PyMODINIT_FUNC initgpuarray(void)
#else
PyMODINIT_FUNC PyInit_gpuarray(void); /*proto*/
PyMODINIT_FUNC PyInit_gpuarray(void)
#if CYTHON_PEP489_MULTI_PHASE_INIT
{
  return PyModuleDef_Init(&__pyx_moduledef);
}
static int __Pyx_copy_spec_to_module(PyObject *spec, PyObject *moddict, const char* from_name, const char* to_name) {
    PyObject *value = PyObject_GetAttrString(spec, from_name);
    int result = 0;
    if (likely(value)) {
        result = PyDict_SetItemString(moddict, to_name, value);
        Py_DECREF(value);
    } else if (PyErr_ExceptionMatches(PyExc_AttributeError)) {
        PyErr_Clear();
    } else {
        result = -1;
    }
    return result;
}
static PyObject* __pyx_pymod_create(PyObject *spec, CYTHON_UNUSED PyModuleDef *def) {
    PyObject *module = NULL, *moddict, *modname;
    if (__pyx_m)
        return __Pyx_NewRef(__pyx_m);
    modname = PyObject_GetAttrString(spec, "name");
    if (unlikely(!modname)) goto bad;
    module = PyModule_NewObject(modname);
    Py_DECREF(modname);
    if (unlikely(!module)) goto bad;
    moddict = PyModule_GetDict(module);
    if (unlikely(!moddict)) goto bad;
    if (unlikely(__Pyx_copy_spec_to_module(spec, moddict, "loader", "__loader__") < 0)) goto bad;
    if (unlikely(__Pyx_copy_spec_to_module(spec, moddict, "origin", "__file__") < 0)) goto bad;
    if (unlikely(__Pyx_copy_spec_to_module(spec, moddict, "parent", "__package__") < 0)) goto bad;
    if (unlikely(__Pyx_copy_spec_to_module(spec, moddict, "submodule_search_locations", "__path__") < 0)) goto bad;
    return module;
bad:
    Py_XDECREF(module);
    return NULL;
}


static int __pyx_pymod_exec_gpuarray(PyObject *__pyx_pyinit_module)
#endif
#endif
{
  PyObject *__pyx_t_1 = NULL;
  int __pyx_t_2;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  __Pyx_RefNannyDeclarations
  #if CYTHON_PEP489_MULTI_PHASE_INIT
  if (__pyx_m && __pyx_m == __pyx_pyinit_module) return 0;
  #endif
  #if CYTHON_REFNANNY
  __Pyx_RefNanny = __Pyx_RefNannyImportAPI("refnanny");
  if (!__Pyx_RefNanny) {
      PyErr_Clear();
      __Pyx_RefNanny = __Pyx_RefNannyImportAPI("Cython.Runtime.refnanny");
      if (!__Pyx_RefNanny)
          Py_FatalError("failed to import 'refnanny' module");
  }
  #endif
  __Pyx_RefNannySetupContext("PyMODINIT_FUNC PyInit_gpuarray(void)", 0);
  if (__Pyx_check_binary_version() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  __pyx_empty_tuple = PyTuple_New(0); if (unlikely(!__pyx_empty_tuple)) __PYX_ERR(0, 1, __pyx_L1_error)
  __pyx_empty_bytes = PyBytes_FromStringAndSize("", 0); if (unlikely(!__pyx_empty_bytes)) __PYX_ERR(0, 1, __pyx_L1_error)
  __pyx_empty_unicode = PyUnicode_FromStringAndSize("", 0); if (unlikely(!__pyx_empty_unicode)) __PYX_ERR(0, 1, __pyx_L1_error)
  #ifdef __Pyx_CyFunction_USED
  if (__pyx_CyFunction_init() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  #endif
  #ifdef __Pyx_FusedFunction_USED
  if (__pyx_FusedFunction_init() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  #endif
  #ifdef __Pyx_Coroutine_USED
  if (__pyx_Coroutine_init() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  #endif
  #ifdef __Pyx_Generator_USED
  if (__pyx_Generator_init() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  #endif
  #ifdef __Pyx_AsyncGen_USED
  if (__pyx_AsyncGen_init() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  #endif
  #ifdef __Pyx_StopAsyncIteration_USED
  if (__pyx_StopAsyncIteration_init() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  #endif
  /*--- Library function declarations ---*/
  /*--- Threads initialization code ---*/
  #if defined(__PYX_FORCE_INIT_THREADS) && __PYX_FORCE_INIT_THREADS
  #ifdef WITH_THREAD /* Python build with threading support? */
  PyEval_InitThreads();
  #endif
  #endif
  /*--- Module creation code ---*/
  #if CYTHON_PEP489_MULTI_PHASE_INIT
  __pyx_m = __pyx_pyinit_module;
  Py_INCREF(__pyx_m);
  #else
  #if PY_MAJOR_VERSION < 3
  __pyx_m = Py_InitModule4("gpuarray", __pyx_methods, 0, 0, PYTHON_API_VERSION); Py_XINCREF(__pyx_m);
  #else
  __pyx_m = PyModule_Create(&__pyx_moduledef);
  #endif
  if (unlikely(!__pyx_m)) __PYX_ERR(0, 1, __pyx_L1_error)
  #endif
  __pyx_d = PyModule_GetDict(__pyx_m); if (unlikely(!__pyx_d)) __PYX_ERR(0, 1, __pyx_L1_error)
  Py_INCREF(__pyx_d);
  __pyx_b = PyImport_AddModule(__Pyx_BUILTIN_MODULE_NAME); if (unlikely(!__pyx_b)) __PYX_ERR(0, 1, __pyx_L1_error)
  __pyx_cython_runtime = PyImport_AddModule((char *) "cython_runtime"); if (unlikely(!__pyx_cython_runtime)) __PYX_ERR(0, 1, __pyx_L1_error)
  #if CYTHON_COMPILING_IN_PYPY
  Py_INCREF(__pyx_b);
  #endif
  if (PyObject_SetAttrString(__pyx_m, "__builtins__", __pyx_b) < 0) __PYX_ERR(0, 1, __pyx_L1_error);
  /*--- Initialize various global constants etc. ---*/
  if (__Pyx_InitGlobals() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  #if PY_MAJOR_VERSION < 3 && (__PYX_DEFAULT_STRING_ENCODING_IS_ASCII || __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT)
  if (__Pyx_init_sys_getdefaultencoding_params() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  #endif
  if (__pyx_module_is_main_pygpu__gpuarray) {
    if (PyObject_SetAttrString(__pyx_m, "__name__", __pyx_n_s_main) < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  }
  #if PY_MAJOR_VERSION >= 3
  {
    PyObject *modules = PyImport_GetModuleDict(); if (unlikely(!modules)) __PYX_ERR(0, 1, __pyx_L1_error)
    if (!PyDict_GetItemString(modules, "pygpu.gpuarray")) {
      if (unlikely(PyDict_SetItemString(modules, "pygpu.gpuarray", __pyx_m) < 0)) __PYX_ERR(0, 1, __pyx_L1_error)
    }
  }
  #endif
  /*--- Builtin init code ---*/
  if (__Pyx_InitCachedBuiltins() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  /*--- Constants init code ---*/
  if (__Pyx_InitCachedConstants() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  /*--- Global init code ---*/
  __pyx_v_5pygpu_8gpuarray_NP_TO_TYPE = ((PyObject*)Py_None); Py_INCREF(Py_None);
  __pyx_v_5pygpu_8gpuarray_TYPE_TO_NP = ((PyObject*)Py_None); Py_INCREF(Py_None);
  __pyx_v_5pygpu_8gpuarray_default_context = ((struct PyGpuContextObject *)Py_None); Py_INCREF(Py_None);
  /*--- Variable export code ---*/
  /*--- Function export code ---*/
  if (__Pyx_ExportFunction("PyArray_Empty", (void (*)(void))__pyx_f_5pygpu_8gpuarray_PyArray_Empty, "PyObject *(int, npy_intp *, PyArray_Descr *, int)") < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  if (__Pyx_ExportFunction("get_exc", (void (*)(void))__pyx_f_5pygpu_8gpuarray_get_exc, "PyTypeObject *(int)") < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  if (__Pyx_ExportFunction("dtype_to_npdtype", (void (*)(void))__pyx_f_5pygpu_8gpuarray_dtype_to_npdtype, "PyArray_Descr *(PyObject *)") < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  if (__Pyx_ExportFunction("typecode_to_dtype", (void (*)(void))__pyx_f_5pygpu_8gpuarray_typecode_to_dtype, "PyArray_Descr *(int)") < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  if (__Pyx_ExportFunction("get_typecode", (void (*)(void))__pyx_f_5pygpu_8gpuarray_get_typecode, "int (PyObject *)") < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  if (__Pyx_ExportFunction("dtype_to_typecode", (void (*)(void))__pyx_f_5pygpu_8gpuarray_dtype_to_typecode, "int (PyObject *, int __pyx_skip_dispatch)") < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  if (__Pyx_ExportFunction("to_ga_order", (void (*)(void))__pyx_f_5pygpu_8gpuarray_to_ga_order, "ga_order (PyObject *)") < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  if (__Pyx_ExportFunction("py_CHKFLAGS", (void (*)(void))__pyx_f_5pygpu_8gpuarray_py_CHKFLAGS, "int (struct PyGpuArrayObject *, int)") < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  if (__Pyx_ExportFunction("py_ISONESEGMENT", (void (*)(void))__pyx_f_5pygpu_8gpuarray_py_ISONESEGMENT, "int (struct PyGpuArrayObject *)") < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  if (__Pyx_ExportFunction("array_empty", (void (*)(void))__pyx_f_5pygpu_8gpuarray_array_empty, "int (struct PyGpuArrayObject *, gpucontext *, int, unsigned int, size_t const *, ga_order)") < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  if (__Pyx_ExportFunction("array_fromdata", (void (*)(void))__pyx_f_5pygpu_8gpuarray_array_fromdata, "int (struct PyGpuArrayObject *, gpudata *, size_t, int, unsigned int, size_t const *, Py_ssize_t const *, int)") < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  if (__Pyx_ExportFunction("array_view", (void (*)(void))__pyx_f_5pygpu_8gpuarray_array_view, "int (struct PyGpuArrayObject *, struct PyGpuArrayObject *)") < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  if (__Pyx_ExportFunction("array_sync", (void (*)(void))__pyx_f_5pygpu_8gpuarray_array_sync, "int (struct PyGpuArrayObject *)") < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  if (__Pyx_ExportFunction("array_index", (void (*)(void))__pyx_f_5pygpu_8gpuarray_array_index, "int (struct PyGpuArrayObject *, struct PyGpuArrayObject *, Py_ssize_t const *, Py_ssize_t const *, Py_ssize_t const *)") < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  if (__Pyx_ExportFunction("array_take1", (void (*)(void))__pyx_f_5pygpu_8gpuarray_array_take1, "int (struct PyGpuArrayObject *, struct PyGpuArrayObject *, struct PyGpuArrayObject *, int)") < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  if (__Pyx_ExportFunction("array_setarray", (void (*)(void))__pyx_f_5pygpu_8gpuarray_array_setarray, "int (struct PyGpuArrayObject *, struct PyGpuArrayObject *)") < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  if (__Pyx_ExportFunction("array_reshape", (void (*)(void))__pyx_f_5pygpu_8gpuarray_array_reshape, "int (struct PyGpuArrayObject *, struct PyGpuArrayObject *, unsigned int, size_t const *, ga_order, int)") < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  if (__Pyx_ExportFunction("array_transpose", (void (*)(void))__pyx_f_5pygpu_8gpuarray_array_transpose, "int (struct PyGpuArrayObject *, struct PyGpuArrayObject *, unsigned int const *)") < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  if (__Pyx_ExportFunction("array_clear", (void (*)(void))__pyx_f_5pygpu_8gpuarray_array_clear, "int (struct PyGpuArrayObject *)") < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  if (__Pyx_ExportFunction("array_share", (void (*)(void))__pyx_f_5pygpu_8gpuarray_array_share, "int (struct PyGpuArrayObject *, struct PyGpuArrayObject *)") < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  if (__Pyx_ExportFunction("array_context", (void (*)(void))__pyx_f_5pygpu_8gpuarray_array_context, "gpucontext *(struct PyGpuArrayObject *)") < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  if (__Pyx_ExportFunction("array_move", (void (*)(void))__pyx_f_5pygpu_8gpuarray_array_move, "int (struct PyGpuArrayObject *, struct PyGpuArrayObject *)") < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  if (__Pyx_ExportFunction("array_write", (void (*)(void))__pyx_f_5pygpu_8gpuarray_array_write, "int (struct PyGpuArrayObject *, void *, size_t)") < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  if (__Pyx_ExportFunction("array_read", (void (*)(void))__pyx_f_5pygpu_8gpuarray_array_read, "int (void *, size_t, struct PyGpuArrayObject *)") < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  if (__Pyx_ExportFunction("array_memset", (void (*)(void))__pyx_f_5pygpu_8gpuarray_array_memset, "int (struct PyGpuArrayObject *, int)") < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  if (__Pyx_ExportFunction("array_copy", (void (*)(void))__pyx_f_5pygpu_8gpuarray_array_copy, "int (struct PyGpuArrayObject *, struct PyGpuArrayObject *, ga_order)") < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  if (__Pyx_ExportFunction("array_transfer", (void (*)(void))__pyx_f_5pygpu_8gpuarray_array_transfer, "int (struct PyGpuArrayObject *, struct PyGpuArrayObject *)") < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  if (__Pyx_ExportFunction("kernel_error", (void (*)(void))__pyx_f_5pygpu_8gpuarray_kernel_error, "char const *(struct PyGpuKernelObject *, int)") < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  if (__Pyx_ExportFunction("kernel_init", (void (*)(void))__pyx_f_5pygpu_8gpuarray_kernel_init, "int (struct PyGpuKernelObject *, gpucontext *, unsigned int, char const **, size_t const *, char const *, unsigned int, int const *, int)") < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  if (__Pyx_ExportFunction("kernel_clear", (void (*)(void))__pyx_f_5pygpu_8gpuarray_kernel_clear, "int (struct PyGpuKernelObject *)") < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  if (__Pyx_ExportFunction("kernel_context", (void (*)(void))__pyx_f_5pygpu_8gpuarray_kernel_context, "gpucontext *(struct PyGpuKernelObject *)") < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  if (__Pyx_ExportFunction("kernel_sched", (void (*)(void))__pyx_f_5pygpu_8gpuarray_kernel_sched, "int (struct PyGpuKernelObject *, size_t, size_t *, size_t *)") < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  if (__Pyx_ExportFunction("kernel_call", (void (*)(void))__pyx_f_5pygpu_8gpuarray_kernel_call, "int (struct PyGpuKernelObject *, unsigned int, size_t const *, size_t const *, size_t, void **)") < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  if (__Pyx_ExportFunction("kernel_property", (void (*)(void))__pyx_f_5pygpu_8gpuarray_kernel_property, "int (struct PyGpuKernelObject *, int, void *)") < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  if (__Pyx_ExportFunction("ctx_property", (void (*)(void))__pyx_f_5pygpu_8gpuarray_ctx_property, "int (struct PyGpuContextObject *, int, void *)") < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  if (__Pyx_ExportFunction("ensure_context", (void (*)(void))__pyx_f_5pygpu_8gpuarray_ensure_context, "struct PyGpuContextObject *(struct PyGpuContextObject *)") < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  if (__Pyx_ExportFunction("pygpu_default_context", (void (*)(void))__pyx_f_5pygpu_8gpuarray_pygpu_default_context, "struct PyGpuContextObject *(void)") < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  if (__Pyx_ExportFunction("pygpu_GpuArray_Check", (void (*)(void))__pyx_f_5pygpu_8gpuarray_pygpu_GpuArray_Check, "int (PyObject *)") < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  if (__Pyx_ExportFunction("pygpu_init", (void (*)(void))__pyx_f_5pygpu_8gpuarray_pygpu_init, "struct PyGpuContextObject *(PyObject *, gpucontext_props *)") < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  if (__Pyx_ExportFunction("pygpu_zeros", (void (*)(void))__pyx_f_5pygpu_8gpuarray_pygpu_zeros, "struct PyGpuArrayObject *(unsigned int, size_t const *, int, ga_order, struct PyGpuContextObject *, PyObject *)") < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  if (__Pyx_ExportFunction("pygpu_empty", (void (*)(void))__pyx_f_5pygpu_8gpuarray_pygpu_empty, "struct PyGpuArrayObject *(unsigned int, size_t const *, int, ga_order, struct PyGpuContextObject *, PyObject *)") < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  if (__Pyx_ExportFunction("pygpu_fromgpudata", (void (*)(void))__pyx_f_5pygpu_8gpuarray_pygpu_fromgpudata, "struct PyGpuArrayObject *(gpudata *, size_t, int, unsigned int, size_t const *, Py_ssize_t const *, struct PyGpuContextObject *, int, PyObject *, PyObject *)") < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  if (__Pyx_ExportFunction("pygpu_copy", (void (*)(void))__pyx_f_5pygpu_8gpuarray_pygpu_copy, "struct PyGpuArrayObject *(struct PyGpuArrayObject *, ga_order)") < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  if (__Pyx_ExportFunction("pygpu_move", (void (*)(void))__pyx_f_5pygpu_8gpuarray_pygpu_move, "int (struct PyGpuArrayObject *, struct PyGpuArrayObject *)") < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  if (__Pyx_ExportFunction("pygpu_view", (void (*)(void))__pyx_f_5pygpu_8gpuarray_pygpu_view, "struct PyGpuArrayObject *(struct PyGpuArrayObject *, PyObject *)") < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  if (__Pyx_ExportFunction("pygpu_sync", (void (*)(void))__pyx_f_5pygpu_8gpuarray_pygpu_sync, "int (struct PyGpuArrayObject *)") < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  if (__Pyx_ExportFunction("pygpu_empty_like", (void (*)(void))__pyx_f_5pygpu_8gpuarray_pygpu_empty_like, "struct PyGpuArrayObject *(struct PyGpuArrayObject *, ga_order, int)") < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  if (__Pyx_ExportFunction("pygpu_as_ndarray", (void (*)(void))__pyx_f_5pygpu_8gpuarray_pygpu_as_ndarray, "PyArrayObject *(struct PyGpuArrayObject *)") < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  if (__Pyx_ExportFunction("_pygpu_as_ndarray", (void (*)(void))__pyx_f_5pygpu_8gpuarray__pygpu_as_ndarray, "PyArrayObject *(struct PyGpuArrayObject *, PyArray_Descr *)") < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  if (__Pyx_ExportFunction("pygpu_index", (void (*)(void))__pyx_f_5pygpu_8gpuarray_pygpu_index, "struct PyGpuArrayObject *(struct PyGpuArrayObject *, Py_ssize_t const *, Py_ssize_t const *, Py_ssize_t const *)") < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  if (__Pyx_ExportFunction("pygpu_reshape", (void (*)(void))__pyx_f_5pygpu_8gpuarray_pygpu_reshape, "struct PyGpuArrayObject *(struct PyGpuArrayObject *, unsigned int, size_t const *, ga_order, int, int)") < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  if (__Pyx_ExportFunction("pygpu_transpose", (void (*)(void))__pyx_f_5pygpu_8gpuarray_pygpu_transpose, "struct PyGpuArrayObject *(struct PyGpuArrayObject *, unsigned int const *)") < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  if (__Pyx_ExportFunction("pygpu_transfer", (void (*)(void))__pyx_f_5pygpu_8gpuarray_pygpu_transfer, "int (struct PyGpuArrayObject *, struct PyGpuArrayObject *)") < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  if (__Pyx_ExportFunction("pygpu_concatenate", (void (*)(void))__pyx_f_5pygpu_8gpuarray_pygpu_concatenate, "struct PyGpuArrayObject *(GpuArray const **, size_t, unsigned int, int, PyObject *, struct PyGpuContextObject *)") < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  if (__Pyx_ExportFunction("new_GpuArray", (void (*)(void))__pyx_f_5pygpu_8gpuarray_new_GpuArray, "struct PyGpuArrayObject *(PyObject *, struct PyGpuContextObject *, PyObject *)") < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  /*--- Type init code ---*/
  if (PyType_Ready(&PyGpuContextType) < 0) __PYX_ERR(0, 1036, __pyx_L1_error)
  PyGpuContextType.tp_print = 0;
  if (PyObject_SetAttrString(__pyx_m, "GpuContext", (PyObject *)&PyGpuContextType) < 0) __PYX_ERR(0, 1036, __pyx_L1_error)
  if (PyGpuContextType.tp_weaklistoffset == 0) PyGpuContextType.tp_weaklistoffset = offsetof(struct PyGpuContextObject, __weakref__);
  __pyx_ptype_5pygpu_8gpuarray_GpuContext = &PyGpuContextType;
  __pyx_vtabptr_5pygpu_8gpuarray_GpuArray = &__pyx_vtable_5pygpu_8gpuarray_GpuArray;
  __pyx_vtable_5pygpu_8gpuarray_GpuArray.__pyx___index_helper = (PyObject *(*)(struct PyGpuArrayObject *, PyObject *, unsigned int, Py_ssize_t *, Py_ssize_t *, Py_ssize_t *))__pyx_f_5pygpu_8gpuarray_8GpuArray___index_helper;
  __pyx_vtable_5pygpu_8gpuarray_GpuArray.__pyx___cgetitem__ = (PyObject *(*)(struct PyGpuArrayObject *, PyObject *))__pyx_f_5pygpu_8gpuarray_8GpuArray___cgetitem__;
  if (PyType_Ready(&PyGpuArrayType) < 0) __PYX_ERR(0, 1558, __pyx_L1_error)
  PyGpuArrayType.tp_print = 0;
  if (__Pyx_SetVtable(PyGpuArrayType.tp_dict, __pyx_vtabptr_5pygpu_8gpuarray_GpuArray) < 0) __PYX_ERR(0, 1558, __pyx_L1_error)
  if (PyObject_SetAttrString(__pyx_m, "GpuArray", (PyObject *)&PyGpuArrayType) < 0) __PYX_ERR(0, 1558, __pyx_L1_error)
  if (PyGpuArrayType.tp_weaklistoffset == 0) PyGpuArrayType.tp_weaklistoffset = offsetof(struct PyGpuArrayObject, __weakref__);
  __pyx_ptype_5pygpu_8gpuarray_GpuArray = &PyGpuArrayType;
  __pyx_vtabptr_5pygpu_8gpuarray_GpuKernel = &__pyx_vtable_5pygpu_8gpuarray_GpuKernel;
  __pyx_vtable_5pygpu_8gpuarray_GpuKernel.do_call = (PyObject *(*)(struct PyGpuKernelObject *, PyObject *, PyObject *, PyObject *, PyObject *, size_t))__pyx_f_5pygpu_8gpuarray_9GpuKernel_do_call;
  __pyx_vtable_5pygpu_8gpuarray_GpuKernel._setarg = (PyObject *(*)(struct PyGpuKernelObject *, unsigned int, int, PyObject *))__pyx_f_5pygpu_8gpuarray_9GpuKernel__setarg;
  if (PyType_Ready(&PyGpuKernelType) < 0) __PYX_ERR(0, 2269, __pyx_L1_error)
  PyGpuKernelType.tp_print = 0;
  #if CYTHON_COMPILING_IN_CPYTHON
  {
    PyObject *wrapper = PyObject_GetAttrString((PyObject *)&PyGpuKernelType, "__call__"); if (unlikely(!wrapper)) __PYX_ERR(0, 2269, __pyx_L1_error)
    if (Py_TYPE(wrapper) == &PyWrapperDescr_Type) {
      __pyx_wrapperbase_5pygpu_8gpuarray_9GpuKernel_6__call__ = *((PyWrapperDescrObject *)wrapper)->d_base;
      __pyx_wrapperbase_5pygpu_8gpuarray_9GpuKernel_6__call__.doc = __pyx_doc_5pygpu_8gpuarray_9GpuKernel_6__call__;
      ((PyWrapperDescrObject *)wrapper)->d_base = &__pyx_wrapperbase_5pygpu_8gpuarray_9GpuKernel_6__call__;
    }
  }
  #endif
  if (__Pyx_SetVtable(PyGpuKernelType.tp_dict, __pyx_vtabptr_5pygpu_8gpuarray_GpuKernel) < 0) __PYX_ERR(0, 2269, __pyx_L1_error)
  if (PyObject_SetAttrString(__pyx_m, "GpuKernel", (PyObject *)&PyGpuKernelType) < 0) __PYX_ERR(0, 2269, __pyx_L1_error)
  if (PyGpuKernelType.tp_weaklistoffset == 0) PyGpuKernelType.tp_weaklistoffset = offsetof(struct PyGpuKernelObject, __weakref__);
  __pyx_ptype_5pygpu_8gpuarray_GpuKernel = &PyGpuKernelType;
  if (PyType_Ready(&__pyx_type_5pygpu_8gpuarray_flags) < 0) __PYX_ERR(0, 1190, __pyx_L1_error)
  __pyx_type_5pygpu_8gpuarray_flags.tp_print = 0;
  if (PyObject_SetAttrString(__pyx_m, "flags", (PyObject *)&__pyx_type_5pygpu_8gpuarray_flags) < 0) __PYX_ERR(0, 1190, __pyx_L1_error)
  __pyx_ptype_5pygpu_8gpuarray_flags = &__pyx_type_5pygpu_8gpuarray_flags;
  if (PyType_Ready(&__pyx_type_5pygpu_8gpuarray___pyx_scope_struct__genexpr) < 0) __PYX_ERR(0, 118, __pyx_L1_error)
  __pyx_type_5pygpu_8gpuarray___pyx_scope_struct__genexpr.tp_print = 0;
  __pyx_ptype_5pygpu_8gpuarray___pyx_scope_struct__genexpr = &__pyx_type_5pygpu_8gpuarray___pyx_scope_struct__genexpr;
  if (PyType_Ready(&__pyx_type_5pygpu_8gpuarray___pyx_scope_struct_1___repr__) < 0) __PYX_ERR(0, 1268, __pyx_L1_error)
  __pyx_type_5pygpu_8gpuarray___pyx_scope_struct_1___repr__.tp_print = 0;
  __pyx_ptype_5pygpu_8gpuarray___pyx_scope_struct_1___repr__ = &__pyx_type_5pygpu_8gpuarray___pyx_scope_struct_1___repr__;
  if (PyType_Ready(&__pyx_type_5pygpu_8gpuarray___pyx_scope_struct_2_genexpr) < 0) __PYX_ERR(0, 1269, __pyx_L1_error)
  __pyx_type_5pygpu_8gpuarray___pyx_scope_struct_2_genexpr.tp_print = 0;
  __pyx_ptype_5pygpu_8gpuarray___pyx_scope_struct_2_genexpr = &__pyx_type_5pygpu_8gpuarray___pyx_scope_struct_2_genexpr;
  if (PyType_Ready(&__pyx_type_5pygpu_8gpuarray___pyx_scope_struct_3___getitem__) < 0) __PYX_ERR(0, 1928, __pyx_L1_error)
  __pyx_type_5pygpu_8gpuarray___pyx_scope_struct_3___getitem__.tp_print = 0;
  __pyx_ptype_5pygpu_8gpuarray___pyx_scope_struct_3___getitem__ = &__pyx_type_5pygpu_8gpuarray___pyx_scope_struct_3___getitem__;
  if (PyType_Ready(&__pyx_type_5pygpu_8gpuarray___pyx_scope_struct_4_genexpr) < 0) __PYX_ERR(0, 1939, __pyx_L1_error)
  __pyx_type_5pygpu_8gpuarray___pyx_scope_struct_4_genexpr.tp_print = 0;
  __pyx_ptype_5pygpu_8gpuarray___pyx_scope_struct_4_genexpr = &__pyx_type_5pygpu_8gpuarray___pyx_scope_struct_4_genexpr;
  if (PyType_Ready(&__pyx_type_5pygpu_8gpuarray___pyx_scope_struct_5_genexpr) < 0) __PYX_ERR(0, 1949, __pyx_L1_error)
  __pyx_type_5pygpu_8gpuarray___pyx_scope_struct_5_genexpr.tp_print = 0;
  __pyx_ptype_5pygpu_8gpuarray___pyx_scope_struct_5_genexpr = &__pyx_type_5pygpu_8gpuarray___pyx_scope_struct_5_genexpr;
  if (PyType_Ready(&__pyx_type_5pygpu_8gpuarray___pyx_scope_struct_6_genexpr) < 0) __PYX_ERR(0, 1975, __pyx_L1_error)
  __pyx_type_5pygpu_8gpuarray___pyx_scope_struct_6_genexpr.tp_print = 0;
  __pyx_ptype_5pygpu_8gpuarray___pyx_scope_struct_6_genexpr = &__pyx_type_5pygpu_8gpuarray___pyx_scope_struct_6_genexpr;
  if (PyType_Ready(&__pyx_type_5pygpu_8gpuarray___pyx_scope_struct_7___setitem__) < 0) __PYX_ERR(0, 2071, __pyx_L1_error)
  __pyx_type_5pygpu_8gpuarray___pyx_scope_struct_7___setitem__.tp_print = 0;
  __pyx_ptype_5pygpu_8gpuarray___pyx_scope_struct_7___setitem__ = &__pyx_type_5pygpu_8gpuarray___pyx_scope_struct_7___setitem__;
  if (PyType_Ready(&__pyx_type_5pygpu_8gpuarray___pyx_scope_struct_8_genexpr) < 0) __PYX_ERR(0, 2075, __pyx_L1_error)
  __pyx_type_5pygpu_8gpuarray___pyx_scope_struct_8_genexpr.tp_print = 0;
  __pyx_ptype_5pygpu_8gpuarray___pyx_scope_struct_8_genexpr = &__pyx_type_5pygpu_8gpuarray___pyx_scope_struct_8_genexpr;
  if (PyType_Ready(&__pyx_type_5pygpu_8gpuarray___pyx_scope_struct_9_genexpr) < 0) __PYX_ERR(0, 2084, __pyx_L1_error)
  __pyx_type_5pygpu_8gpuarray___pyx_scope_struct_9_genexpr.tp_print = 0;
  __pyx_ptype_5pygpu_8gpuarray___pyx_scope_struct_9_genexpr = &__pyx_type_5pygpu_8gpuarray___pyx_scope_struct_9_genexpr;
  if (PyType_Ready(&__pyx_type_5pygpu_8gpuarray___pyx_scope_struct_10_genexpr) < 0) __PYX_ERR(0, 2093, __pyx_L1_error)
  __pyx_type_5pygpu_8gpuarray___pyx_scope_struct_10_genexpr.tp_print = 0;
  __pyx_ptype_5pygpu_8gpuarray___pyx_scope_struct_10_genexpr = &__pyx_type_5pygpu_8gpuarray___pyx_scope_struct_10_genexpr;
  /*--- Type import code ---*/
  __pyx_ptype_7cpython_4type_type = __Pyx_ImportType(__Pyx_BUILTIN_MODULE_NAME, "type", 
  #if CYTHON_COMPILING_IN_PYPY
  sizeof(PyTypeObject),
  #else
  sizeof(PyHeapTypeObject),
  #endif
  0); if (unlikely(!__pyx_ptype_7cpython_4type_type)) __PYX_ERR(2, 9, __pyx_L1_error)
  __pyx_ptype_7cpython_4bool_bool = __Pyx_ImportType(__Pyx_BUILTIN_MODULE_NAME, "bool", sizeof(PyBoolObject), 0); if (unlikely(!__pyx_ptype_7cpython_4bool_bool)) __PYX_ERR(3, 8, __pyx_L1_error)
  __pyx_ptype_7cpython_7complex_complex = __Pyx_ImportType(__Pyx_BUILTIN_MODULE_NAME, "complex", sizeof(PyComplexObject), 0); if (unlikely(!__pyx_ptype_7cpython_7complex_complex)) __PYX_ERR(4, 15, __pyx_L1_error)
  __pyx_ptype_5numpy_dtype = __Pyx_ImportType("numpy", "dtype", sizeof(PyArray_Descr), 0); if (unlikely(!__pyx_ptype_5numpy_dtype)) __PYX_ERR(1, 163, __pyx_L1_error)
  __pyx_ptype_5numpy_flatiter = __Pyx_ImportType("numpy", "flatiter", sizeof(PyArrayIterObject), 0); if (unlikely(!__pyx_ptype_5numpy_flatiter)) __PYX_ERR(1, 185, __pyx_L1_error)
  __pyx_ptype_5numpy_broadcast = __Pyx_ImportType("numpy", "broadcast", sizeof(PyArrayMultiIterObject), 0); if (unlikely(!__pyx_ptype_5numpy_broadcast)) __PYX_ERR(1, 189, __pyx_L1_error)
  __pyx_ptype_5numpy_ndarray = __Pyx_ImportType("numpy", "ndarray", sizeof(PyArrayObject), 0); if (unlikely(!__pyx_ptype_5numpy_ndarray)) __PYX_ERR(1, 198, __pyx_L1_error)
  __pyx_ptype_5numpy_ufunc = __Pyx_ImportType("numpy", "ufunc", sizeof(PyUFuncObject), 0); if (unlikely(!__pyx_ptype_5numpy_ufunc)) __PYX_ERR(1, 885, __pyx_L1_error)
  /*--- Variable import code ---*/
  /*--- Function import code ---*/
  /*--- Execution code ---*/
  #if defined(__Pyx_Generator_USED) || defined(__Pyx_Coroutine_USED)
  if (__Pyx_patch_abc() < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  #endif

  /* "pygpu/gpuarray.pyx":7
 * 
 * cimport numpy as np
 * import numpy as np             # <<<<<<<<<<<<<<
 * 
 * import sys
 */
  __pyx_t_1 = __Pyx_Import(__pyx_n_s_numpy, 0, -1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 7, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_np, __pyx_t_1) < 0) __PYX_ERR(0, 7, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "pygpu/gpuarray.pyx":9
 * import numpy as np
 * 
 * import sys             # <<<<<<<<<<<<<<
 * 
 * from cpython cimport Py_INCREF, PyNumber_Index
 */
  __pyx_t_1 = __Pyx_Import(__pyx_n_s_sys, 0, -1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 9, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_sys, __pyx_t_1) < 0) __PYX_ERR(0, 9, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "pygpu/gpuarray.pyx":14
 * from cpython.object cimport Py_EQ, Py_NE
 * 
 * def api_version():             # <<<<<<<<<<<<<<
 *     """api_version()
 *     """
 */
  __pyx_t_1 = PyCFunction_NewEx(&__pyx_mdef_5pygpu_8gpuarray_1api_version, NULL, __pyx_n_s_pygpu_gpuarray); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 14, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_api_version, __pyx_t_1) < 0) __PYX_ERR(0, 14, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "pygpu/gpuarray.pyx":20
 *     return (GPUARRAY_API_VERSION, 0)
 * 
 * def abi_version():             # <<<<<<<<<<<<<<
 *     """abi_version()
 *     """
 */
  __pyx_t_1 = PyCFunction_NewEx(&__pyx_mdef_5pygpu_8gpuarray_3abi_version, NULL, __pyx_n_s_pygpu_gpuarray); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 20, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_abi_version, __pyx_t_1) < 0) __PYX_ERR(0, 20, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "pygpu/gpuarray.pyx":27
 *     return (major_version, minor_version)
 * 
 * np.import_array()             # <<<<<<<<<<<<<<
 * 
 * # to export the numeric value
 */
  __pyx_t_2 = __pyx_f_5numpy_import_array(); if (unlikely(__pyx_t_2 == ((int)-1))) __PYX_ERR(0, 27, __pyx_L1_error)

  /* "pygpu/gpuarray.pyx":30
 * 
 * # to export the numeric value
 * SIZE = GA_SIZE             # <<<<<<<<<<<<<<
 * SSIZE = GA_SSIZE
 * 
 */
  __pyx_t_1 = __Pyx_PyInt_From_enum__GPUARRAY_TYPES(GA_SIZE); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 30, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_SIZE, __pyx_t_1) < 0) __PYX_ERR(0, 30, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "pygpu/gpuarray.pyx":31
 * # to export the numeric value
 * SIZE = GA_SIZE
 * SSIZE = GA_SSIZE             # <<<<<<<<<<<<<<
 * 
 * # Numpy API steals dtype references and this breaks cython
 */
  __pyx_t_1 = __Pyx_PyInt_From_enum__GPUARRAY_TYPES(GA_SSIZE); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 31, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_SSIZE, __pyx_t_1) < 0) __PYX_ERR(0, 31, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "pygpu/gpuarray.pyx":54
 *     return count
 * 
 * def cl_wrap_ctx(size_t ptr):             # <<<<<<<<<<<<<<
 *     """
 *     cl_wrap_ctx(ptr)
 */
  __pyx_t_1 = PyCFunction_NewEx(&__pyx_mdef_5pygpu_8gpuarray_5cl_wrap_ctx, NULL, __pyx_n_s_pygpu_gpuarray); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 54, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cl_wrap_ctx, __pyx_t_1) < 0) __PYX_ERR(0, 54, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "pygpu/gpuarray.pyx":72
 *     return res
 * 
 * def cuda_wrap_ctx(size_t ptr, bint own):             # <<<<<<<<<<<<<<
 *     """
 *     cuda_wrap_ctx(ptr)
 */
  __pyx_t_1 = PyCFunction_NewEx(&__pyx_mdef_5pygpu_8gpuarray_7cuda_wrap_ctx, NULL, __pyx_n_s_pygpu_gpuarray); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 72, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cuda_wrap_ctx, __pyx_t_1) < 0) __PYX_ERR(0, 72, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "pygpu/gpuarray.pyx":99
 *     return res
 * 
 * import numpy             # <<<<<<<<<<<<<<
 * 
 * cdef dict NP_TO_TYPE = {
 */
  __pyx_t_1 = __Pyx_Import(__pyx_n_s_numpy, 0, -1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 99, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_numpy, __pyx_t_1) < 0) __PYX_ERR(0, 99, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "pygpu/gpuarray.pyx":102
 * 
 * cdef dict NP_TO_TYPE = {
 *     np.dtype('bool'): GA_BOOL,             # <<<<<<<<<<<<<<
 *     np.dtype('int8'): GA_BYTE,
 *     np.dtype('uint8'): GA_UBYTE,
 */
  __pyx_t_1 = __Pyx_PyDict_NewPresized(14); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 102, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_PyObject_Call(((PyObject *)__pyx_ptype_5numpy_dtype), __pyx_tuple__56, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 102, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_4 = __Pyx_PyInt_From_enum__GPUARRAY_TYPES(GA_BOOL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 102, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  if (PyDict_SetItem(__pyx_t_1, __pyx_t_3, __pyx_t_4) < 0) __PYX_ERR(0, 102, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;

  /* "pygpu/gpuarray.pyx":103
 * cdef dict NP_TO_TYPE = {
 *     np.dtype('bool'): GA_BOOL,
 *     np.dtype('int8'): GA_BYTE,             # <<<<<<<<<<<<<<
 *     np.dtype('uint8'): GA_UBYTE,
 *     np.dtype('int16'): GA_SHORT,
 */
  __pyx_t_4 = __Pyx_PyObject_Call(((PyObject *)__pyx_ptype_5numpy_dtype), __pyx_tuple__57, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 103, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_3 = __Pyx_PyInt_From_enum__GPUARRAY_TYPES(GA_BYTE); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 103, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  if (PyDict_SetItem(__pyx_t_1, __pyx_t_4, __pyx_t_3) < 0) __PYX_ERR(0, 102, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

  /* "pygpu/gpuarray.pyx":104
 *     np.dtype('bool'): GA_BOOL,
 *     np.dtype('int8'): GA_BYTE,
 *     np.dtype('uint8'): GA_UBYTE,             # <<<<<<<<<<<<<<
 *     np.dtype('int16'): GA_SHORT,
 *     np.dtype('uint16'): GA_USHORT,
 */
  __pyx_t_3 = __Pyx_PyObject_Call(((PyObject *)__pyx_ptype_5numpy_dtype), __pyx_tuple__58, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 104, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_4 = __Pyx_PyInt_From_enum__GPUARRAY_TYPES(GA_UBYTE); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 104, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  if (PyDict_SetItem(__pyx_t_1, __pyx_t_3, __pyx_t_4) < 0) __PYX_ERR(0, 102, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;

  /* "pygpu/gpuarray.pyx":105
 *     np.dtype('int8'): GA_BYTE,
 *     np.dtype('uint8'): GA_UBYTE,
 *     np.dtype('int16'): GA_SHORT,             # <<<<<<<<<<<<<<
 *     np.dtype('uint16'): GA_USHORT,
 *     np.dtype('int32'): GA_INT,
 */
  __pyx_t_4 = __Pyx_PyObject_Call(((PyObject *)__pyx_ptype_5numpy_dtype), __pyx_tuple__59, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 105, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_3 = __Pyx_PyInt_From_enum__GPUARRAY_TYPES(GA_SHORT); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 105, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  if (PyDict_SetItem(__pyx_t_1, __pyx_t_4, __pyx_t_3) < 0) __PYX_ERR(0, 102, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

  /* "pygpu/gpuarray.pyx":106
 *     np.dtype('uint8'): GA_UBYTE,
 *     np.dtype('int16'): GA_SHORT,
 *     np.dtype('uint16'): GA_USHORT,             # <<<<<<<<<<<<<<
 *     np.dtype('int32'): GA_INT,
 *     np.dtype('uint32'): GA_UINT,
 */
  __pyx_t_3 = __Pyx_PyObject_Call(((PyObject *)__pyx_ptype_5numpy_dtype), __pyx_tuple__60, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 106, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_4 = __Pyx_PyInt_From_enum__GPUARRAY_TYPES(GA_USHORT); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 106, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  if (PyDict_SetItem(__pyx_t_1, __pyx_t_3, __pyx_t_4) < 0) __PYX_ERR(0, 102, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;

  /* "pygpu/gpuarray.pyx":107
 *     np.dtype('int16'): GA_SHORT,
 *     np.dtype('uint16'): GA_USHORT,
 *     np.dtype('int32'): GA_INT,             # <<<<<<<<<<<<<<
 *     np.dtype('uint32'): GA_UINT,
 *     np.dtype('int64'): GA_LONG,
 */
  __pyx_t_4 = __Pyx_PyObject_Call(((PyObject *)__pyx_ptype_5numpy_dtype), __pyx_tuple__61, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 107, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_3 = __Pyx_PyInt_From_enum__GPUARRAY_TYPES(GA_INT); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 107, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  if (PyDict_SetItem(__pyx_t_1, __pyx_t_4, __pyx_t_3) < 0) __PYX_ERR(0, 102, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

  /* "pygpu/gpuarray.pyx":108
 *     np.dtype('uint16'): GA_USHORT,
 *     np.dtype('int32'): GA_INT,
 *     np.dtype('uint32'): GA_UINT,             # <<<<<<<<<<<<<<
 *     np.dtype('int64'): GA_LONG,
 *     np.dtype('uint64'): GA_ULONG,
 */
  __pyx_t_3 = __Pyx_PyObject_Call(((PyObject *)__pyx_ptype_5numpy_dtype), __pyx_tuple__62, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 108, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_4 = __Pyx_PyInt_From_enum__GPUARRAY_TYPES(GA_UINT); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 108, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  if (PyDict_SetItem(__pyx_t_1, __pyx_t_3, __pyx_t_4) < 0) __PYX_ERR(0, 102, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;

  /* "pygpu/gpuarray.pyx":109
 *     np.dtype('int32'): GA_INT,
 *     np.dtype('uint32'): GA_UINT,
 *     np.dtype('int64'): GA_LONG,             # <<<<<<<<<<<<<<
 *     np.dtype('uint64'): GA_ULONG,
 *     np.dtype('float32'): GA_FLOAT,
 */
  __pyx_t_4 = __Pyx_PyObject_Call(((PyObject *)__pyx_ptype_5numpy_dtype), __pyx_tuple__63, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 109, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_3 = __Pyx_PyInt_From_enum__GPUARRAY_TYPES(GA_LONG); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 109, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  if (PyDict_SetItem(__pyx_t_1, __pyx_t_4, __pyx_t_3) < 0) __PYX_ERR(0, 102, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

  /* "pygpu/gpuarray.pyx":110
 *     np.dtype('uint32'): GA_UINT,
 *     np.dtype('int64'): GA_LONG,
 *     np.dtype('uint64'): GA_ULONG,             # <<<<<<<<<<<<<<
 *     np.dtype('float32'): GA_FLOAT,
 *     np.dtype('float64'): GA_DOUBLE,
 */
  __pyx_t_3 = __Pyx_PyObject_Call(((PyObject *)__pyx_ptype_5numpy_dtype), __pyx_tuple__64, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 110, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_4 = __Pyx_PyInt_From_enum__GPUARRAY_TYPES(GA_ULONG); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 110, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  if (PyDict_SetItem(__pyx_t_1, __pyx_t_3, __pyx_t_4) < 0) __PYX_ERR(0, 102, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;

  /* "pygpu/gpuarray.pyx":111
 *     np.dtype('int64'): GA_LONG,
 *     np.dtype('uint64'): GA_ULONG,
 *     np.dtype('float32'): GA_FLOAT,             # <<<<<<<<<<<<<<
 *     np.dtype('float64'): GA_DOUBLE,
 *     np.dtype('complex64'): GA_CFLOAT,
 */
  __pyx_t_4 = __Pyx_PyObject_Call(((PyObject *)__pyx_ptype_5numpy_dtype), __pyx_tuple__65, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 111, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_3 = __Pyx_PyInt_From_enum__GPUARRAY_TYPES(GA_FLOAT); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 111, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  if (PyDict_SetItem(__pyx_t_1, __pyx_t_4, __pyx_t_3) < 0) __PYX_ERR(0, 102, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

  /* "pygpu/gpuarray.pyx":112
 *     np.dtype('uint64'): GA_ULONG,
 *     np.dtype('float32'): GA_FLOAT,
 *     np.dtype('float64'): GA_DOUBLE,             # <<<<<<<<<<<<<<
 *     np.dtype('complex64'): GA_CFLOAT,
 *     np.dtype('complex128'): GA_CDOUBLE,
 */
  __pyx_t_3 = __Pyx_PyObject_Call(((PyObject *)__pyx_ptype_5numpy_dtype), __pyx_tuple__66, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 112, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_4 = __Pyx_PyInt_From_enum__GPUARRAY_TYPES(GA_DOUBLE); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 112, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  if (PyDict_SetItem(__pyx_t_1, __pyx_t_3, __pyx_t_4) < 0) __PYX_ERR(0, 102, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;

  /* "pygpu/gpuarray.pyx":113
 *     np.dtype('float32'): GA_FLOAT,
 *     np.dtype('float64'): GA_DOUBLE,
 *     np.dtype('complex64'): GA_CFLOAT,             # <<<<<<<<<<<<<<
 *     np.dtype('complex128'): GA_CDOUBLE,
 *     np.dtype('float16'): GA_HALF,
 */
  __pyx_t_4 = __Pyx_PyObject_Call(((PyObject *)__pyx_ptype_5numpy_dtype), __pyx_tuple__67, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 113, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_3 = __Pyx_PyInt_From_enum__GPUARRAY_TYPES(GA_CFLOAT); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 113, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  if (PyDict_SetItem(__pyx_t_1, __pyx_t_4, __pyx_t_3) < 0) __PYX_ERR(0, 102, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

  /* "pygpu/gpuarray.pyx":114
 *     np.dtype('float64'): GA_DOUBLE,
 *     np.dtype('complex64'): GA_CFLOAT,
 *     np.dtype('complex128'): GA_CDOUBLE,             # <<<<<<<<<<<<<<
 *     np.dtype('float16'): GA_HALF,
 * }
 */
  __pyx_t_3 = __Pyx_PyObject_Call(((PyObject *)__pyx_ptype_5numpy_dtype), __pyx_tuple__68, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 114, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_4 = __Pyx_PyInt_From_enum__GPUARRAY_TYPES(GA_CDOUBLE); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 114, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  if (PyDict_SetItem(__pyx_t_1, __pyx_t_3, __pyx_t_4) < 0) __PYX_ERR(0, 102, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;

  /* "pygpu/gpuarray.pyx":115
 *     np.dtype('complex64'): GA_CFLOAT,
 *     np.dtype('complex128'): GA_CDOUBLE,
 *     np.dtype('float16'): GA_HALF,             # <<<<<<<<<<<<<<
 * }
 * 
 */
  __pyx_t_4 = __Pyx_PyObject_Call(((PyObject *)__pyx_ptype_5numpy_dtype), __pyx_tuple__69, NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 115, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_3 = __Pyx_PyInt_From_enum__GPUARRAY_TYPES(GA_HALF); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 115, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  if (PyDict_SetItem(__pyx_t_1, __pyx_t_4, __pyx_t_3) < 0) __PYX_ERR(0, 102, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_XGOTREF(__pyx_v_5pygpu_8gpuarray_NP_TO_TYPE);
  __Pyx_DECREF_SET(__pyx_v_5pygpu_8gpuarray_NP_TO_TYPE, ((PyObject*)__pyx_t_1));
  __Pyx_GIVEREF(__pyx_t_1);
  __pyx_t_1 = 0;

  /* "pygpu/gpuarray.pyx":118
 * }
 * 
 * cdef dict TYPE_TO_NP = dict((v, k) for k, v in NP_TO_TYPE.iteritems())             # <<<<<<<<<<<<<<
 * 
 * def register_dtype(np.dtype dtype, cname):
 */
  __pyx_t_1 = __pyx_pf_5pygpu_8gpuarray_46genexpr(NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 118, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_Generator_Next(__pyx_t_1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 118, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_XGOTREF(__pyx_v_5pygpu_8gpuarray_TYPE_TO_NP);
  __Pyx_DECREF_SET(__pyx_v_5pygpu_8gpuarray_TYPE_TO_NP, ((PyObject*)__pyx_t_3));
  __Pyx_GIVEREF(__pyx_t_3);
  __pyx_t_3 = 0;

  /* "pygpu/gpuarray.pyx":120
 * cdef dict TYPE_TO_NP = dict((v, k) for k, v in NP_TO_TYPE.iteritems())
 * 
 * def register_dtype(np.dtype dtype, cname):             # <<<<<<<<<<<<<<
 *     """
 *     register_dtype(dtype, cname)
 */
  __pyx_t_3 = PyCFunction_NewEx(&__pyx_mdef_5pygpu_8gpuarray_9register_dtype, NULL, __pyx_n_s_pygpu_gpuarray); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 120, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_register_dtype, __pyx_t_3) < 0) __PYX_ERR(0, 120, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

  /* "pygpu/gpuarray.pyx":211
 *     raise ValueError, "don't know how to convert to dtype: %s"%(dtype,)
 * 
 * def dtype_to_ctype(dtype):             # <<<<<<<<<<<<<<
 *     """
 *     dtype_to_ctype(dtype)
 */
  __pyx_t_3 = PyCFunction_NewEx(&__pyx_mdef_5pygpu_8gpuarray_13dtype_to_ctype, NULL, __pyx_n_s_pygpu_gpuarray); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 211, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_dtype_to_ctype, __pyx_t_3) < 0) __PYX_ERR(0, 211, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

  /* "pygpu/gpuarray.pyx":270
 * 
 * 
 * class GpuArrayException(Exception):             # <<<<<<<<<<<<<<
 *     """
 *     Exception used for most errors related to libgpuarray.
 */
  __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 270, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_INCREF(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])));
  __Pyx_GIVEREF(((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])));
  PyTuple_SET_ITEM(__pyx_t_3, 0, ((PyObject *)(&((PyTypeObject*)PyExc_Exception)[0])));
  __pyx_t_1 = __Pyx_CalculateMetaclass(NULL, __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 270, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = __Pyx_Py3MetaclassPrepare(__pyx_t_1, __pyx_t_3, __pyx_n_s_GpuArrayException, __pyx_n_s_GpuArrayException, (PyObject *) NULL, __pyx_n_s_pygpu_gpuarray, __pyx_kp_s_Exception_used_for_most_errors); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 270, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_5 = __Pyx_Py3ClassCreate(__pyx_t_1, __pyx_n_s_GpuArrayException, __pyx_t_3, __pyx_t_4, NULL, 0, 1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 270, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_GpuArrayException, __pyx_t_5) < 0) __PYX_ERR(0, 270, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

  /* "pygpu/gpuarray.pyx":275
 *     """
 * 
 * class UnsupportedException(GpuArrayException):             # <<<<<<<<<<<<<<
 *     pass
 * 
 */
  __pyx_t_3 = __Pyx_GetModuleGlobalName(__pyx_n_s_GpuArrayException); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 275, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_1 = PyTuple_New(1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 275, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_GIVEREF(__pyx_t_3);
  PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_t_3);
  __pyx_t_3 = 0;
  __pyx_t_3 = __Pyx_CalculateMetaclass(NULL, __pyx_t_1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 275, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_4 = __Pyx_Py3MetaclassPrepare(__pyx_t_3, __pyx_t_1, __pyx_n_s_UnsupportedException, __pyx_n_s_UnsupportedException, (PyObject *) NULL, __pyx_n_s_pygpu_gpuarray, (PyObject *) NULL); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 275, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_5 = __Pyx_Py3ClassCreate(__pyx_t_3, __pyx_n_s_UnsupportedException, __pyx_t_1, __pyx_t_4, NULL, 0, 1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 275, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_UnsupportedException, __pyx_t_5) < 0) __PYX_ERR(0, 275, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "pygpu/gpuarray.pyx":481
 *     return default_context
 * 
 * cdef GpuContext default_context = None             # <<<<<<<<<<<<<<
 * 
 * cdef int ctx_property(GpuContext c, int prop_id, void *res) except -1:
 */
  __Pyx_INCREF(Py_None);
  __Pyx_XGOTREF(((PyObject *)__pyx_v_5pygpu_8gpuarray_default_context));
  __Pyx_DECREF_SET(__pyx_v_5pygpu_8gpuarray_default_context, ((struct PyGpuContextObject *)Py_None));
  __Pyx_GIVEREF(Py_None);

  /* "pygpu/gpuarray.pyx":489
 *         raise get_exc(err), gpucontext_error(c.ctx, err)
 * 
 * def set_default_context(GpuContext ctx):             # <<<<<<<<<<<<<<
 *     """
 *     set_default_context(ctx)
 */
  __pyx_t_1 = PyCFunction_NewEx(&__pyx_mdef_5pygpu_8gpuarray_15set_default_context, NULL, __pyx_n_s_pygpu_gpuarray); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 489, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_set_default_context, __pyx_t_1) < 0) __PYX_ERR(0, 489, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "pygpu/gpuarray.pyx":515
 *     default_context = ctx
 * 
 * def get_default_context():             # <<<<<<<<<<<<<<
 *     """
 *     get_default_context()
 */
  __pyx_t_1 = PyCFunction_NewEx(&__pyx_mdef_5pygpu_8gpuarray_17get_default_context, NULL, __pyx_n_s_pygpu_gpuarray); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 515, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_get_default_context, __pyx_t_1) < 0) __PYX_ERR(0, 515, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "pygpu/gpuarray.pyx":534
 *     return isinstance(o, GpuArray)
 * 
 * def count_platforms(kind):             # <<<<<<<<<<<<<<
 *     """
 *     count_platforms(kind)
 */
  __pyx_t_1 = PyCFunction_NewEx(&__pyx_mdef_5pygpu_8gpuarray_19count_platforms, NULL, __pyx_n_s_pygpu_gpuarray); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 534, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_count_platforms, __pyx_t_1) < 0) __PYX_ERR(0, 534, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "pygpu/gpuarray.pyx":547
 *     return platcount
 * 
 * def count_devices(kind, unsigned int platform):             # <<<<<<<<<<<<<<
 *     """
 *     count_devices(kind, platform)
 */
  __pyx_t_1 = PyCFunction_NewEx(&__pyx_mdef_5pygpu_8gpuarray_21count_devices, NULL, __pyx_n_s_pygpu_gpuarray); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 547, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_count_devices, __pyx_t_1) < 0) __PYX_ERR(0, 547, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "pygpu/gpuarray.pyx":591
 * 
 * def init(dev, sched='default', single_stream=False, kernel_cache_path=None,
 *          max_cache_size=sys.maxsize, initial_cache_size=0):             # <<<<<<<<<<<<<<
 *     """
 *     init(dev, sched='default', single_stream=False, kernel_cache_path=None,
 */
  __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_sys); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 591, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_maxsize); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 591, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_k__10 = __pyx_t_3;
  __Pyx_GIVEREF(__pyx_t_3);
  __pyx_t_3 = 0;

  /* "pygpu/gpuarray.pyx":590
 *     return res
 * 
 * def init(dev, sched='default', single_stream=False, kernel_cache_path=None,             # <<<<<<<<<<<<<<
 *          max_cache_size=sys.maxsize, initial_cache_size=0):
 *     """
 */
  __pyx_t_3 = PyCFunction_NewEx(&__pyx_mdef_5pygpu_8gpuarray_23init, NULL, __pyx_n_s_pygpu_gpuarray); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 590, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_init, __pyx_t_3) < 0) __PYX_ERR(0, 590, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

  /* "pygpu/gpuarray.pyx":660
 *     return pygpu_init(dev, p)
 * 
 * def zeros(shape, dtype=GA_DOUBLE, order='C', GpuContext context=None,             # <<<<<<<<<<<<<<
 *           cls=None):
 *     """
 */
  __pyx_t_3 = __Pyx_PyInt_From_enum__GPUARRAY_TYPES(GA_DOUBLE); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 660, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_k__11 = __pyx_t_3;
  __Pyx_GIVEREF(__pyx_t_3);
  __pyx_t_3 = 0;
  __pyx_t_3 = PyCFunction_NewEx(&__pyx_mdef_5pygpu_8gpuarray_25zeros, NULL, __pyx_n_s_pygpu_gpuarray); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 660, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_zeros, __pyx_t_3) < 0) __PYX_ERR(0, 660, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

  /* "pygpu/gpuarray.pyx":725
 *     return 0
 * 
 * def empty(shape, dtype=GA_DOUBLE, order='C', GpuContext context=None,             # <<<<<<<<<<<<<<
 *           cls=None):
 *     """
 */
  __pyx_t_3 = __Pyx_PyInt_From_enum__GPUARRAY_TYPES(GA_DOUBLE); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 725, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_k__12 = __pyx_t_3;
  __Pyx_GIVEREF(__pyx_t_3);
  __pyx_t_3 = 0;
  __pyx_t_3 = PyCFunction_NewEx(&__pyx_mdef_5pygpu_8gpuarray_27empty, NULL, __pyx_n_s_pygpu_gpuarray); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 725, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_empty, __pyx_t_3) < 0) __PYX_ERR(0, 725, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

  /* "pygpu/gpuarray.pyx":768
 *         free(cdims)
 * 
 * def asarray(a, dtype=None, order='A', GpuContext context=None):             # <<<<<<<<<<<<<<
 *     """
 *     asarray(a, dtype=None, order='A', context=None)
 */
  __pyx_t_3 = PyCFunction_NewEx(&__pyx_mdef_5pygpu_8gpuarray_29asarray, NULL, __pyx_n_s_pygpu_gpuarray); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 768, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_asarray, __pyx_t_3) < 0) __PYX_ERR(0, 768, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

  /* "pygpu/gpuarray.pyx":797
 *                  cls=GpuArray)
 * 
 * def ascontiguousarray(a, dtype=None, GpuContext context=None):             # <<<<<<<<<<<<<<
 *     """
 *     ascontiguousarray(a, dtype=None, context=None)
 */
  __pyx_t_3 = PyCFunction_NewEx(&__pyx_mdef_5pygpu_8gpuarray_31ascontiguousarray, NULL, __pyx_n_s_pygpu_gpuarray); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 797, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_ascontiguousarray, __pyx_t_3) < 0) __PYX_ERR(0, 797, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

  /* "pygpu/gpuarray.pyx":819
 *                  context=context)
 * 
 * def asfortranarray(a, dtype=None, GpuArray context=None):             # <<<<<<<<<<<<<<
 *     """
 *     asfortranarray(a, dtype=None, context=None)
 */
  __pyx_t_3 = PyCFunction_NewEx(&__pyx_mdef_5pygpu_8gpuarray_33asfortranarray, NULL, __pyx_n_s_pygpu_gpuarray); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 819, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_asfortranarray, __pyx_t_3) < 0) __PYX_ERR(0, 819, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

  /* "pygpu/gpuarray.pyx":841
 *                  context=context)
 * 
 * def may_share_memory(GpuArray a not None, GpuArray b not None):             # <<<<<<<<<<<<<<
 *     """
 *     may_share_memory(a, b)
 */
  __pyx_t_3 = PyCFunction_NewEx(&__pyx_mdef_5pygpu_8gpuarray_35may_share_memory, NULL, __pyx_n_s_pygpu_gpuarray); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 841, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_may_share_memory, __pyx_t_3) < 0) __PYX_ERR(0, 841, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

  /* "pygpu/gpuarray.pyx":849
 *     return array_share(a, b)
 * 
 * def from_gpudata(size_t data, offset, dtype, shape, GpuContext context=None,             # <<<<<<<<<<<<<<
 *                  strides=None, writable=True, base=None, cls=None):
 *     """
 */
  __pyx_t_3 = PyCFunction_NewEx(&__pyx_mdef_5pygpu_8gpuarray_37from_gpudata, NULL, __pyx_n_s_pygpu_gpuarray); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 849, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_from_gpudata, __pyx_t_3) < 0) __PYX_ERR(0, 849, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

  /* "pygpu/gpuarray.pyx":931
 *         free(cstrides)
 * 
 * def array(proto, dtype=None, copy=True, order=None, unsigned int ndmin=0,             # <<<<<<<<<<<<<<
 *           GpuContext context=None, cls=None):
 *     """
 */
  __pyx_t_3 = PyCFunction_NewEx(&__pyx_mdef_5pygpu_8gpuarray_39array, NULL, __pyx_n_s_pygpu_gpuarray); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 931, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_array, __pyx_t_3) < 0) __PYX_ERR(0, 931, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

  /* "pygpu/gpuarray.pyx":1033
 * cdef void (*cuda_exit)(gpucontext *)
 * 
 * cuda_enter = <void (*)(gpucontext *)>gpuarray_get_extension("cuda_enter")             # <<<<<<<<<<<<<<
 * cuda_exit = <void (*)(gpucontext *)>gpuarray_get_extension("cuda_exit")
 * 
 */
  __pyx_v_5pygpu_8gpuarray_cuda_enter = ((void (*)(gpucontext *))gpuarray_get_extension(((char const *)"cuda_enter")));

  /* "pygpu/gpuarray.pyx":1034
 * 
 * cuda_enter = <void (*)(gpucontext *)>gpuarray_get_extension("cuda_enter")
 * cuda_exit = <void (*)(gpucontext *)>gpuarray_get_extension("cuda_exit")             # <<<<<<<<<<<<<<
 * 
 * cdef class GpuContext:
 */
  __pyx_v_5pygpu_8gpuarray_cuda_exit = ((void (*)(gpucontext *))gpuarray_get_extension(((char const *)"cuda_exit")));

  /* "pygpu/gpuarray.pyx":1467
 *     return 0
 * 
 * def _split(GpuArray a, ind, unsigned int axis):             # <<<<<<<<<<<<<<
 *     """
 *     _split(a, ind, axis)
 */
  __pyx_t_3 = PyCFunction_NewEx(&__pyx_mdef_5pygpu_8gpuarray_41_split, NULL, __pyx_n_s_pygpu_gpuarray); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1467, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_split_2, __pyx_t_3) < 0) __PYX_ERR(0, 1467, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

  /* "pygpu/gpuarray.pyx":1505
 *     return res
 * 
 * def _concatenate(list al, unsigned int axis, int restype, object cls,             # <<<<<<<<<<<<<<
 *                  GpuContext context):
 *     """
 */
  __pyx_t_3 = PyCFunction_NewEx(&__pyx_mdef_5pygpu_8gpuarray_43_concatenate, NULL, __pyx_n_s_pygpu_gpuarray); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1505, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_concatenate, __pyx_t_3) < 0) __PYX_ERR(0, 1505, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

  /* "pygpu/gpuarray.pyx":1527
 * cdef gpudata *(*cuda_open_ipc_handle)(gpucontext *, GpuArrayIpcMemHandle *, size_t)
 * 
 * cuda_get_ipc_handle = <int (*)(gpudata *, GpuArrayIpcMemHandle *)>gpuarray_get_extension("cuda_get_ipc_handle")             # <<<<<<<<<<<<<<
 * cuda_open_ipc_handle = <gpudata *(*)(gpucontext *, GpuArrayIpcMemHandle *, size_t)>gpuarray_get_extension("cuda_open_ipc_handle")
 * 
 */
  __pyx_v_5pygpu_8gpuarray_cuda_get_ipc_handle = ((int (*)(gpudata *, GpuArrayIpcMemHandle *))gpuarray_get_extension(((char const *)"cuda_get_ipc_handle")));

  /* "pygpu/gpuarray.pyx":1528
 * 
 * cuda_get_ipc_handle = <int (*)(gpudata *, GpuArrayIpcMemHandle *)>gpuarray_get_extension("cuda_get_ipc_handle")
 * cuda_open_ipc_handle = <gpudata *(*)(gpucontext *, GpuArrayIpcMemHandle *, size_t)>gpuarray_get_extension("cuda_open_ipc_handle")             # <<<<<<<<<<<<<<
 * 
 * def open_ipc_handle(GpuContext c, bytes hpy, size_t l):
 */
  __pyx_v_5pygpu_8gpuarray_cuda_open_ipc_handle = ((gpudata *(*)(gpucontext *, GpuArrayIpcMemHandle *, size_t))gpuarray_get_extension(((char const *)"cuda_open_ipc_handle")));

  /* "pygpu/gpuarray.pyx":1530
 * cuda_open_ipc_handle = <gpudata *(*)(gpucontext *, GpuArrayIpcMemHandle *, size_t)>gpuarray_get_extension("cuda_open_ipc_handle")
 * 
 * def open_ipc_handle(GpuContext c, bytes hpy, size_t l):             # <<<<<<<<<<<<<<
 *     """
 *     open_ipc_handle(c, hpy, l)
 */
  __pyx_t_3 = PyCFunction_NewEx(&__pyx_mdef_5pygpu_8gpuarray_45open_ipc_handle, NULL, __pyx_n_s_pygpu_gpuarray); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1530, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_open_ipc_handle, __pyx_t_3) < 0) __PYX_ERR(0, 1530, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

  /* "pygpu/gpuarray.pyx":1813
 *         pygpu_sync(self)
 * 
 *     def view(self, object cls=GpuArray):             # <<<<<<<<<<<<<<
 *         """
 *         view(cls=GpuArray)
 */
  __Pyx_INCREF(((PyObject *)__pyx_ptype_5pygpu_8gpuarray_GpuArray));
  __pyx_k__25 = ((PyObject *)__pyx_ptype_5pygpu_8gpuarray_GpuArray);
  __Pyx_GIVEREF(__pyx_ptype_5pygpu_8gpuarray_GpuArray);

  /* "pygpu/gpuarray.pyx":1
 * cimport libc.stdio             # <<<<<<<<<<<<<<
 * from libc.stdlib cimport malloc, calloc, free
 * from cpython.mem cimport PyMem_Malloc, PyMem_Free
 */
  __pyx_t_3 = __Pyx_PyDict_NewPresized(0); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_test, __pyx_t_3) < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

  /* "../../../../usr/local/lib/python2.7/dist-packages/Cython/Includes/numpy/__init__.pxd":1021
 *         raise ImportError("numpy.core.umath failed to import")
 * 
 * cdef inline int import_ufunc() except -1:             # <<<<<<<<<<<<<<
 *     try:
 *         _import_umath()
 */

  /*--- Wrapped vars code ---*/

  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  if (__pyx_m) {
    if (__pyx_d) {
      __Pyx_AddTraceback("init pygpu.gpuarray", 0, __pyx_lineno, __pyx_filename);
    }
    Py_DECREF(__pyx_m); __pyx_m = 0;
  } else if (!PyErr_Occurred()) {
    PyErr_SetString(PyExc_ImportError, "init pygpu.gpuarray");
  }
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  #if CYTHON_PEP489_MULTI_PHASE_INIT
  return (__pyx_m != NULL) ? 0 : -1;
  #elif PY_MAJOR_VERSION >= 3
  return __pyx_m;
  #else
  return;
  #endif
}

/* --- Runtime support code --- */
/* Refnanny */
#if CYTHON_REFNANNY
static __Pyx_RefNannyAPIStruct *__Pyx_RefNannyImportAPI(const char *modname) {
    PyObject *m = NULL, *p = NULL;
    void *r = NULL;
    m = PyImport_ImportModule((char *)modname);
    if (!m) goto end;
    p = PyObject_GetAttrString(m, (char *)"RefNannyAPI");
    if (!p) goto end;
    r = PyLong_AsVoidPtr(p);
end:
    Py_XDECREF(p);
    Py_XDECREF(m);
    return (__Pyx_RefNannyAPIStruct *)r;
}
#endif

/* GetBuiltinName */
static PyObject *__Pyx_GetBuiltinName(PyObject *name) {
    PyObject* result = __Pyx_PyObject_GetAttrStr(__pyx_b, name);
    if (unlikely(!result)) {
        PyErr_Format(PyExc_NameError,
#if PY_MAJOR_VERSION >= 3
            "name '%U' is not defined", name);
#else
            "name '%.200s' is not defined", PyString_AS_STRING(name));
#endif
    }
    return result;
}

/* IterFinish */
static CYTHON_INLINE int __Pyx_IterFinish(void) {
#if CYTHON_FAST_THREAD_STATE
    PyThreadState *tstate = __Pyx_PyThreadState_Current;
    PyObject* exc_type = tstate->curexc_type;
    if (unlikely(exc_type)) {
        if (likely(__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) {
            PyObject *exc_value, *exc_tb;
            exc_value = tstate->curexc_value;
            exc_tb = tstate->curexc_traceback;
            tstate->curexc_type = 0;
            tstate->curexc_value = 0;
            tstate->curexc_traceback = 0;
            Py_DECREF(exc_type);
            Py_XDECREF(exc_value);
            Py_XDECREF(exc_tb);
            return 0;
        } else {
            return -1;
        }
    }
    return 0;
#else
    if (unlikely(PyErr_Occurred())) {
        if (likely(PyErr_ExceptionMatches(PyExc_StopIteration))) {
            PyErr_Clear();
            return 0;
        } else {
            return -1;
        }
    }
    return 0;
#endif
}

/* PyFunctionFastCall */
#if CYTHON_FAST_PYCALL
#include "frameobject.h"
static PyObject* __Pyx_PyFunction_FastCallNoKw(PyCodeObject *co, PyObject **args, Py_ssize_t na,
                                               PyObject *globals) {
    PyFrameObject *f;
    PyThreadState *tstate = __Pyx_PyThreadState_Current;
    PyObject **fastlocals;
    Py_ssize_t i;
    PyObject *result;
    assert(globals != NULL);
    /* XXX Perhaps we should create a specialized
       PyFrame_New() that doesn't take locals, but does
       take builtins without sanity checking them.
       */
    assert(tstate != NULL);
    f = PyFrame_New(tstate, co, globals, NULL);
    if (f == NULL) {
        return NULL;
    }
    fastlocals = f->f_localsplus;
    for (i = 0; i < na; i++) {
        Py_INCREF(*args);
        fastlocals[i] = *args++;
    }
    result = PyEval_EvalFrameEx(f,0);
    ++tstate->recursion_depth;
    Py_DECREF(f);
    --tstate->recursion_depth;
    return result;
}
#if 1 || PY_VERSION_HEX < 0x030600B1
static PyObject *__Pyx_PyFunction_FastCallDict(PyObject *func, PyObject **args, int nargs, PyObject *kwargs) {
    PyCodeObject *co = (PyCodeObject *)PyFunction_GET_CODE(func);
    PyObject *globals = PyFunction_GET_GLOBALS(func);
    PyObject *argdefs = PyFunction_GET_DEFAULTS(func);
    PyObject *closure;
#if PY_MAJOR_VERSION >= 3
    PyObject *kwdefs;
#endif
    PyObject *kwtuple, **k;
    PyObject **d;
    Py_ssize_t nd;
    Py_ssize_t nk;
    PyObject *result;
    assert(kwargs == NULL || PyDict_Check(kwargs));
    nk = kwargs ? PyDict_Size(kwargs) : 0;
    if (Py_EnterRecursiveCall((char*)" while calling a Python object")) {
        return NULL;
    }
    if (
#if PY_MAJOR_VERSION >= 3
            co->co_kwonlyargcount == 0 &&
#endif
            likely(kwargs == NULL || nk == 0) &&
            co->co_flags == (CO_OPTIMIZED | CO_NEWLOCALS | CO_NOFREE)) {
        if (argdefs == NULL && co->co_argcount == nargs) {
            result = __Pyx_PyFunction_FastCallNoKw(co, args, nargs, globals);
            goto done;
        }
        else if (nargs == 0 && argdefs != NULL
                 && co->co_argcount == Py_SIZE(argdefs)) {
            /* function called with no arguments, but all parameters have
               a default value: use default values as arguments .*/
            args = &PyTuple_GET_ITEM(argdefs, 0);
            result =__Pyx_PyFunction_FastCallNoKw(co, args, Py_SIZE(argdefs), globals);
            goto done;
        }
    }
    if (kwargs != NULL) {
        Py_ssize_t pos, i;
        kwtuple = PyTuple_New(2 * nk);
        if (kwtuple == NULL) {
            result = NULL;
            goto done;
        }
        k = &PyTuple_GET_ITEM(kwtuple, 0);
        pos = i = 0;
        while (PyDict_Next(kwargs, &pos, &k[i], &k[i+1])) {
            Py_INCREF(k[i]);
            Py_INCREF(k[i+1]);
            i += 2;
        }
        nk = i / 2;
    }
    else {
        kwtuple = NULL;
        k = NULL;
    }
    closure = PyFunction_GET_CLOSURE(func);
#if PY_MAJOR_VERSION >= 3
    kwdefs = PyFunction_GET_KW_DEFAULTS(func);
#endif
    if (argdefs != NULL) {
        d = &PyTuple_GET_ITEM(argdefs, 0);
        nd = Py_SIZE(argdefs);
    }
    else {
        d = NULL;
        nd = 0;
    }
#if PY_MAJOR_VERSION >= 3
    result = PyEval_EvalCodeEx((PyObject*)co, globals, (PyObject *)NULL,
                               args, nargs,
                               k, (int)nk,
                               d, (int)nd, kwdefs, closure);
#else
    result = PyEval_EvalCodeEx(co, globals, (PyObject *)NULL,
                               args, nargs,
                               k, (int)nk,
                               d, (int)nd, closure);
#endif
    Py_XDECREF(kwtuple);
done:
    Py_LeaveRecursiveCall();
    return result;
}
#endif
#endif

/* PyObjectCall */
#if CYTHON_COMPILING_IN_CPYTHON
static CYTHON_INLINE PyObject* __Pyx_PyObject_Call(PyObject *func, PyObject *arg, PyObject *kw) {
    PyObject *result;
    ternaryfunc call = func->ob_type->tp_call;
    if (unlikely(!call))
        return PyObject_Call(func, arg, kw);
    if (unlikely(Py_EnterRecursiveCall((char*)" while calling a Python object")))
        return NULL;
    result = (*call)(func, arg, kw);
    Py_LeaveRecursiveCall();
    if (unlikely(!result) && unlikely(!PyErr_Occurred())) {
        PyErr_SetString(
            PyExc_SystemError,
            "NULL result without error in PyObject_Call");
    }
    return result;
}
#endif

/* PyObjectCallMethO */
#if CYTHON_COMPILING_IN_CPYTHON
static CYTHON_INLINE PyObject* __Pyx_PyObject_CallMethO(PyObject *func, PyObject *arg) {
    PyObject *self, *result;
    PyCFunction cfunc;
    cfunc = PyCFunction_GET_FUNCTION(func);
    self = PyCFunction_GET_SELF(func);
    if (unlikely(Py_EnterRecursiveCall((char*)" while calling a Python object")))
        return NULL;
    result = cfunc(self, arg);
    Py_LeaveRecursiveCall();
    if (unlikely(!result) && unlikely(!PyErr_Occurred())) {
        PyErr_SetString(
            PyExc_SystemError,
            "NULL result without error in PyObject_Call");
    }
    return result;
}
#endif

/* PyObjectCallNoArg */
#if CYTHON_COMPILING_IN_CPYTHON
static CYTHON_INLINE PyObject* __Pyx_PyObject_CallNoArg(PyObject *func) {
#if CYTHON_FAST_PYCALL
    if (PyFunction_Check(func)) {
        return __Pyx_PyFunction_FastCall(func, NULL, 0);
    }
#endif
#ifdef __Pyx_CyFunction_USED
    if (likely(PyCFunction_Check(func) || __Pyx_TypeCheck(func, __pyx_CyFunctionType))) {
#else
    if (likely(PyCFunction_Check(func))) {
#endif
        if (likely(PyCFunction_GET_FLAGS(func) & METH_NOARGS)) {
            return __Pyx_PyObject_CallMethO(func, NULL);
        }
    }
    return __Pyx_PyObject_Call(func, __pyx_empty_tuple, NULL);
}
#endif

/* PyCFunctionFastCall */
  #if CYTHON_FAST_PYCCALL
static CYTHON_INLINE PyObject * __Pyx_PyCFunction_FastCall(PyObject *func_obj, PyObject **args, Py_ssize_t nargs) {
    PyCFunctionObject *func = (PyCFunctionObject*)func_obj;
    PyCFunction meth = PyCFunction_GET_FUNCTION(func);
    PyObject *self = PyCFunction_GET_SELF(func);
    int flags = PyCFunction_GET_FLAGS(func);
    assert(PyCFunction_Check(func));
    assert(METH_FASTCALL == (flags & ~(METH_CLASS | METH_STATIC | METH_COEXIST | METH_KEYWORDS)));
    assert(nargs >= 0);
    assert(nargs == 0 || args != NULL);
    /* _PyCFunction_FastCallDict() must not be called with an exception set,
       because it may clear it (directly or indirectly) and so the
       caller loses its exception */
    assert(!PyErr_Occurred());
    if ((PY_VERSION_HEX < 0x030700A0) || unlikely(flags & METH_KEYWORDS)) {
        return (*((__Pyx_PyCFunctionFastWithKeywords)meth)) (self, args, nargs, NULL);
    } else {
        return (*((__Pyx_PyCFunctionFast)meth)) (self, args, nargs);
    }
}
#endif

/* PyObjectCallOneArg */
  #if CYTHON_COMPILING_IN_CPYTHON
static PyObject* __Pyx__PyObject_CallOneArg(PyObject *func, PyObject *arg) {
    PyObject *result;
    PyObject *args = PyTuple_New(1);
    if (unlikely(!args)) return NULL;
    Py_INCREF(arg);
    PyTuple_SET_ITEM(args, 0, arg);
    result = __Pyx_PyObject_Call(func, args, NULL);
    Py_DECREF(args);
    return result;
}
static CYTHON_INLINE PyObject* __Pyx_PyObject_CallOneArg(PyObject *func, PyObject *arg) {
#if CYTHON_FAST_PYCALL
    if (PyFunction_Check(func)) {
        return __Pyx_PyFunction_FastCall(func, &arg, 1);
    }
#endif
    if (likely(PyCFunction_Check(func))) {
        if (likely(PyCFunction_GET_FLAGS(func) & METH_O)) {
            return __Pyx_PyObject_CallMethO(func, arg);
#if CYTHON_FAST_PYCCALL
        } else if (PyCFunction_GET_FLAGS(func) & METH_FASTCALL) {
            return __Pyx_PyCFunction_FastCall(func, &arg, 1);
#endif
        }
    }
    return __Pyx__PyObject_CallOneArg(func, arg);
}
#else
static CYTHON_INLINE PyObject* __Pyx_PyObject_CallOneArg(PyObject *func, PyObject *arg) {
    PyObject *result;
    PyObject *args = PyTuple_Pack(1, arg);
    if (unlikely(!args)) return NULL;
    result = __Pyx_PyObject_Call(func, args, NULL);
    Py_DECREF(args);
    return result;
}
#endif

/* PyObjectCallMethod0 */
  static PyObject* __Pyx_PyObject_CallMethod0(PyObject* obj, PyObject* method_name) {
    PyObject *method, *result = NULL;
    method = __Pyx_PyObject_GetAttrStr(obj, method_name);
    if (unlikely(!method)) goto bad;
#if CYTHON_UNPACK_METHODS
    if (likely(PyMethod_Check(method))) {
        PyObject *self = PyMethod_GET_SELF(method);
        if (likely(self)) {
            PyObject *function = PyMethod_GET_FUNCTION(method);
            result = __Pyx_PyObject_CallOneArg(function, self);
            Py_DECREF(method);
            return result;
        }
    }
#endif
    result = __Pyx_PyObject_CallNoArg(method);
    Py_DECREF(method);
bad:
    return result;
}

/* RaiseNeedMoreValuesToUnpack */
  static CYTHON_INLINE void __Pyx_RaiseNeedMoreValuesError(Py_ssize_t index) {
    PyErr_Format(PyExc_ValueError,
                 "need more than %" CYTHON_FORMAT_SSIZE_T "d value%.1s to unpack",
                 index, (index == 1) ? "" : "s");
}

/* RaiseTooManyValuesToUnpack */
  static CYTHON_INLINE void __Pyx_RaiseTooManyValuesError(Py_ssize_t expected) {
    PyErr_Format(PyExc_ValueError,
                 "too many values to unpack (expected %" CYTHON_FORMAT_SSIZE_T "d)", expected);
}

/* UnpackItemEndCheck */
  static int __Pyx_IternextUnpackEndCheck(PyObject *retval, Py_ssize_t expected) {
    if (unlikely(retval)) {
        Py_DECREF(retval);
        __Pyx_RaiseTooManyValuesError(expected);
        return -1;
    } else {
        return __Pyx_IterFinish();
    }
    return 0;
}

/* RaiseNoneIterError */
  static CYTHON_INLINE void __Pyx_RaiseNoneNotIterableError(void) {
    PyErr_SetString(PyExc_TypeError, "'NoneType' object is not iterable");
}

/* UnpackTupleError */
  static void __Pyx_UnpackTupleError(PyObject *t, Py_ssize_t index) {
    if (t == Py_None) {
      __Pyx_RaiseNoneNotIterableError();
    } else if (PyTuple_GET_SIZE(t) < index) {
      __Pyx_RaiseNeedMoreValuesError(PyTuple_GET_SIZE(t));
    } else {
      __Pyx_RaiseTooManyValuesError(index);
    }
}

/* UnpackTuple2 */
  static CYTHON_INLINE int __Pyx_unpack_tuple2_exact(
        PyObject* tuple, PyObject** pvalue1, PyObject** pvalue2, int decref_tuple) {
    PyObject *value1 = NULL, *value2 = NULL;
#if CYTHON_COMPILING_IN_PYPY
    value1 = PySequence_ITEM(tuple, 0);  if (unlikely(!value1)) goto bad;
    value2 = PySequence_ITEM(tuple, 1);  if (unlikely(!value2)) goto bad;
#else
    value1 = PyTuple_GET_ITEM(tuple, 0);  Py_INCREF(value1);
    value2 = PyTuple_GET_ITEM(tuple, 1);  Py_INCREF(value2);
#endif
    if (decref_tuple) {
        Py_DECREF(tuple);
    }
    *pvalue1 = value1;
    *pvalue2 = value2;
    return 0;
#if CYTHON_COMPILING_IN_PYPY
bad:
    Py_XDECREF(value1);
    Py_XDECREF(value2);
    if (decref_tuple) { Py_XDECREF(tuple); }
    return -1;
#endif
}
static int __Pyx_unpack_tuple2_generic(PyObject* tuple, PyObject** pvalue1, PyObject** pvalue2,
                                       int has_known_size, int decref_tuple) {
    Py_ssize_t index;
    PyObject *value1 = NULL, *value2 = NULL, *iter = NULL;
    iternextfunc iternext;
    iter = PyObject_GetIter(tuple);
    if (unlikely(!iter)) goto bad;
    if (decref_tuple) { Py_DECREF(tuple); tuple = NULL; }
    iternext = Py_TYPE(iter)->tp_iternext;
    value1 = iternext(iter); if (unlikely(!value1)) { index = 0; goto unpacking_failed; }
    value2 = iternext(iter); if (unlikely(!value2)) { index = 1; goto unpacking_failed; }
    if (!has_known_size && unlikely(__Pyx_IternextUnpackEndCheck(iternext(iter), 2))) goto bad;
    Py_DECREF(iter);
    *pvalue1 = value1;
    *pvalue2 = value2;
    return 0;
unpacking_failed:
    if (!has_known_size && __Pyx_IterFinish() == 0)
        __Pyx_RaiseNeedMoreValuesError(index);
bad:
    Py_XDECREF(iter);
    Py_XDECREF(value1);
    Py_XDECREF(value2);
    if (decref_tuple) { Py_XDECREF(tuple); }
    return -1;
}

/* dict_iter */
  static CYTHON_INLINE PyObject* __Pyx_dict_iterator(PyObject* iterable, int is_dict, PyObject* method_name,
                                                   Py_ssize_t* p_orig_length, int* p_source_is_dict) {
    is_dict = is_dict || likely(PyDict_CheckExact(iterable));
    *p_source_is_dict = is_dict;
    if (is_dict) {
#if !CYTHON_COMPILING_IN_PYPY
        *p_orig_length = PyDict_Size(iterable);
        Py_INCREF(iterable);
        return iterable;
#elif PY_MAJOR_VERSION >= 3
        static PyObject *py_items = NULL, *py_keys = NULL, *py_values = NULL;
        PyObject **pp = NULL;
        if (method_name) {
            const char *name = PyUnicode_AsUTF8(method_name);
            if (strcmp(name, "iteritems") == 0) pp = &py_items;
            else if (strcmp(name, "iterkeys") == 0) pp = &py_keys;
            else if (strcmp(name, "itervalues") == 0) pp = &py_values;
            if (pp) {
                if (!*pp) {
                    *pp = PyUnicode_FromString(name + 4);
                    if (!*pp)
                        return NULL;
                }
                method_name = *pp;
            }
        }
#endif
    }
    *p_orig_length = 0;
    if (method_name) {
        PyObject* iter;
        iterable = __Pyx_PyObject_CallMethod0(iterable, method_name);
        if (!iterable)
            return NULL;
#if !CYTHON_COMPILING_IN_PYPY
        if (PyTuple_CheckExact(iterable) || PyList_CheckExact(iterable))
            return iterable;
#endif
        iter = PyObject_GetIter(iterable);
        Py_DECREF(iterable);
        return iter;
    }
    return PyObject_GetIter(iterable);
}
static CYTHON_INLINE int __Pyx_dict_iter_next(
        PyObject* iter_obj, CYTHON_NCP_UNUSED Py_ssize_t orig_length, CYTHON_NCP_UNUSED Py_ssize_t* ppos,
        PyObject** pkey, PyObject** pvalue, PyObject** pitem, int source_is_dict) {
    PyObject* next_item;
#if !CYTHON_COMPILING_IN_PYPY
    if (source_is_dict) {
        PyObject *key, *value;
        if (unlikely(orig_length != PyDict_Size(iter_obj))) {
            PyErr_SetString(PyExc_RuntimeError, "dictionary changed size during iteration");
            return -1;
        }
        if (unlikely(!PyDict_Next(iter_obj, ppos, &key, &value))) {
            return 0;
        }
        if (pitem) {
            PyObject* tuple = PyTuple_New(2);
            if (unlikely(!tuple)) {
                return -1;
            }
            Py_INCREF(key);
            Py_INCREF(value);
            PyTuple_SET_ITEM(tuple, 0, key);
            PyTuple_SET_ITEM(tuple, 1, value);
            *pitem = tuple;
        } else {
            if (pkey) {
                Py_INCREF(key);
                *pkey = key;
            }
            if (pvalue) {
                Py_INCREF(value);
                *pvalue = value;
            }
        }
        return 1;
    } else if (PyTuple_CheckExact(iter_obj)) {
        Py_ssize_t pos = *ppos;
        if (unlikely(pos >= PyTuple_GET_SIZE(iter_obj))) return 0;
        *ppos = pos + 1;
        next_item = PyTuple_GET_ITEM(iter_obj, pos);
        Py_INCREF(next_item);
    } else if (PyList_CheckExact(iter_obj)) {
        Py_ssize_t pos = *ppos;
        if (unlikely(pos >= PyList_GET_SIZE(iter_obj))) return 0;
        *ppos = pos + 1;
        next_item = PyList_GET_ITEM(iter_obj, pos);
        Py_INCREF(next_item);
    } else
#endif
    {
        next_item = PyIter_Next(iter_obj);
        if (unlikely(!next_item)) {
            return __Pyx_IterFinish();
        }
    }
    if (pitem) {
        *pitem = next_item;
    } else if (pkey && pvalue) {
        if (__Pyx_unpack_tuple2(next_item, pkey, pvalue, source_is_dict, source_is_dict, 1))
            return -1;
    } else if (pkey) {
        *pkey = next_item;
    } else {
        *pvalue = next_item;
    }
    return 1;
}

/* None */
  static CYTHON_INLINE long __Pyx_div_long(long a, long b) {
    long q = a / b;
    long r = a - q*b;
    q -= ((r != 0) & ((r ^ b) < 0));
    return q;
}

/* None */
  static CYTHON_INLINE long __Pyx_mod_long(long a, long b) {
    long r = a % b;
    r += ((r != 0) & ((r ^ b) < 0)) * b;
    return r;
}

/* PyErrFetchRestore */
  #if CYTHON_FAST_THREAD_STATE
static CYTHON_INLINE void __Pyx_ErrRestoreInState(PyThreadState *tstate, PyObject *type, PyObject *value, PyObject *tb) {
    PyObject *tmp_type, *tmp_value, *tmp_tb;
    tmp_type = tstate->curexc_type;
    tmp_value = tstate->curexc_value;
    tmp_tb = tstate->curexc_traceback;
    tstate->curexc_type = type;
    tstate->curexc_value = value;
    tstate->curexc_traceback = tb;
    Py_XDECREF(tmp_type);
    Py_XDECREF(tmp_value);
    Py_XDECREF(tmp_tb);
}
static CYTHON_INLINE void __Pyx_ErrFetchInState(PyThreadState *tstate, PyObject **type, PyObject **value, PyObject **tb) {
    *type = tstate->curexc_type;
    *value = tstate->curexc_value;
    *tb = tstate->curexc_traceback;
    tstate->curexc_type = 0;
    tstate->curexc_value = 0;
    tstate->curexc_traceback = 0;
}
#endif

/* RaiseException */
  #if PY_MAJOR_VERSION < 3
static void __Pyx_Raise(PyObject *type, PyObject *value, PyObject *tb,
                        CYTHON_UNUSED PyObject *cause) {
    __Pyx_PyThreadState_declare
    Py_XINCREF(type);
    if (!value || value == Py_None)
        value = NULL;
    else
        Py_INCREF(value);
    if (!tb || tb == Py_None)
        tb = NULL;
    else {
        Py_INCREF(tb);
        if (!PyTraceBack_Check(tb)) {
            PyErr_SetString(PyExc_TypeError,
                "raise: arg 3 must be a traceback or None");
            goto raise_error;
        }
    }
    if (PyType_Check(type)) {
#if CYTHON_COMPILING_IN_PYPY
        if (!value) {
            Py_INCREF(Py_None);
            value = Py_None;
        }
#endif
        PyErr_NormalizeException(&type, &value, &tb);
    } else {
        if (value) {
            PyErr_SetString(PyExc_TypeError,
                "instance exception may not have a separate value");
            goto raise_error;
        }
        value = type;
        type = (PyObject*) Py_TYPE(type);
        Py_INCREF(type);
        if (!PyType_IsSubtype((PyTypeObject *)type, (PyTypeObject *)PyExc_BaseException)) {
            PyErr_SetString(PyExc_TypeError,
                "raise: exception class must be a subclass of BaseException");
            goto raise_error;
        }
    }
    __Pyx_PyThreadState_assign
    __Pyx_ErrRestore(type, value, tb);
    return;
raise_error:
    Py_XDECREF(value);
    Py_XDECREF(type);
    Py_XDECREF(tb);
    return;
}
#else
static void __Pyx_Raise(PyObject *type, PyObject *value, PyObject *tb, PyObject *cause) {
    PyObject* owned_instance = NULL;
    if (tb == Py_None) {
        tb = 0;
    } else if (tb && !PyTraceBack_Check(tb)) {
        PyErr_SetString(PyExc_TypeError,
            "raise: arg 3 must be a traceback or None");
        goto bad;
    }
    if (value == Py_None)
        value = 0;
    if (PyExceptionInstance_Check(type)) {
        if (value) {
            PyErr_SetString(PyExc_TypeError,
                "instance exception may not have a separate value");
            goto bad;
        }
        value = type;
        type = (PyObject*) Py_TYPE(value);
    } else if (PyExceptionClass_Check(type)) {
        PyObject *instance_class = NULL;
        if (value && PyExceptionInstance_Check(value)) {
            instance_class = (PyObject*) Py_TYPE(value);
            if (instance_class != type) {
                int is_subclass = PyObject_IsSubclass(instance_class, type);
                if (!is_subclass) {
                    instance_class = NULL;
                } else if (unlikely(is_subclass == -1)) {
                    goto bad;
                } else {
                    type = instance_class;
                }
            }
        }
        if (!instance_class) {
            PyObject *args;
            if (!value)
                args = PyTuple_New(0);
            else if (PyTuple_Check(value)) {
                Py_INCREF(value);
                args = value;
            } else
                args = PyTuple_Pack(1, value);
            if (!args)
                goto bad;
            owned_instance = PyObject_Call(type, args, NULL);
            Py_DECREF(args);
            if (!owned_instance)
                goto bad;
            value = owned_instance;
            if (!PyExceptionInstance_Check(value)) {
                PyErr_Format(PyExc_TypeError,
                             "calling %R should have returned an instance of "
                             "BaseException, not %R",
                             type, Py_TYPE(value));
                goto bad;
            }
        }
    } else {
        PyErr_SetString(PyExc_TypeError,
            "raise: exception class must be a subclass of BaseException");
        goto bad;
    }
    if (cause) {
        PyObject *fixed_cause;
        if (cause == Py_None) {
            fixed_cause = NULL;
        } else if (PyExceptionClass_Check(cause)) {
            fixed_cause = PyObject_CallObject(cause, NULL);
            if (fixed_cause == NULL)
                goto bad;
        } else if (PyExceptionInstance_Check(cause)) {
            fixed_cause = cause;
            Py_INCREF(fixed_cause);
        } else {
            PyErr_SetString(PyExc_TypeError,
                            "exception causes must derive from "
                            "BaseException");
            goto bad;
        }
        PyException_SetCause(value, fixed_cause);
    }
    PyErr_SetObject(type, value);
    if (tb) {
#if CYTHON_COMPILING_IN_PYPY
        PyObject *tmp_type, *tmp_value, *tmp_tb;
        PyErr_Fetch(&tmp_type, &tmp_value, &tmp_tb);
        Py_INCREF(tb);
        PyErr_Restore(tmp_type, tmp_value, tb);
        Py_XDECREF(tmp_tb);
#else
        PyThreadState *tstate = __Pyx_PyThreadState_Current;
        PyObject* tmp_tb = tstate->curexc_traceback;
        if (tb != tmp_tb) {
            Py_INCREF(tb);
            tstate->curexc_traceback = tb;
            Py_XDECREF(tmp_tb);
        }
#endif
    }
bad:
    Py_XDECREF(owned_instance);
    return;
}
#endif

/* GetItemInt */
  static PyObject *__Pyx_GetItemInt_Generic(PyObject *o, PyObject* j) {
    PyObject *r;
    if (!j) return NULL;
    r = PyObject_GetItem(o, j);
    Py_DECREF(j);
    return r;
}
static CYTHON_INLINE PyObject *__Pyx_GetItemInt_List_Fast(PyObject *o, Py_ssize_t i,
                                                              CYTHON_NCP_UNUSED int wraparound,
                                                              CYTHON_NCP_UNUSED int boundscheck) {
#if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    Py_ssize_t wrapped_i = i;
    if (wraparound & unlikely(i < 0)) {
        wrapped_i += PyList_GET_SIZE(o);
    }
    if ((!boundscheck) || likely((0 <= wrapped_i) & (wrapped_i < PyList_GET_SIZE(o)))) {
        PyObject *r = PyList_GET_ITEM(o, wrapped_i);
        Py_INCREF(r);
        return r;
    }
    return __Pyx_GetItemInt_Generic(o, PyInt_FromSsize_t(i));
#else
    return PySequence_GetItem(o, i);
#endif
}
static CYTHON_INLINE PyObject *__Pyx_GetItemInt_Tuple_Fast(PyObject *o, Py_ssize_t i,
                                                              CYTHON_NCP_UNUSED int wraparound,
                                                              CYTHON_NCP_UNUSED int boundscheck) {
#if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    Py_ssize_t wrapped_i = i;
    if (wraparound & unlikely(i < 0)) {
        wrapped_i += PyTuple_GET_SIZE(o);
    }
    if ((!boundscheck) || likely((0 <= wrapped_i) & (wrapped_i < PyTuple_GET_SIZE(o)))) {
        PyObject *r = PyTuple_GET_ITEM(o, wrapped_i);
        Py_INCREF(r);
        return r;
    }
    return __Pyx_GetItemInt_Generic(o, PyInt_FromSsize_t(i));
#else
    return PySequence_GetItem(o, i);
#endif
}
static CYTHON_INLINE PyObject *__Pyx_GetItemInt_Fast(PyObject *o, Py_ssize_t i, int is_list,
                                                     CYTHON_NCP_UNUSED int wraparound,
                                                     CYTHON_NCP_UNUSED int boundscheck) {
#if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS && CYTHON_USE_TYPE_SLOTS
    if (is_list || PyList_CheckExact(o)) {
        Py_ssize_t n = ((!wraparound) | likely(i >= 0)) ? i : i + PyList_GET_SIZE(o);
        if ((!boundscheck) || (likely((n >= 0) & (n < PyList_GET_SIZE(o))))) {
            PyObject *r = PyList_GET_ITEM(o, n);
            Py_INCREF(r);
            return r;
        }
    }
    else if (PyTuple_CheckExact(o)) {
        Py_ssize_t n = ((!wraparound) | likely(i >= 0)) ? i : i + PyTuple_GET_SIZE(o);
        if ((!boundscheck) || likely((n >= 0) & (n < PyTuple_GET_SIZE(o)))) {
            PyObject *r = PyTuple_GET_ITEM(o, n);
            Py_INCREF(r);
            return r;
        }
    } else {
        PySequenceMethods *m = Py_TYPE(o)->tp_as_sequence;
        if (likely(m && m->sq_item)) {
            if (wraparound && unlikely(i < 0) && likely(m->sq_length)) {
                Py_ssize_t l = m->sq_length(o);
                if (likely(l >= 0)) {
                    i += l;
                } else {
                    if (!PyErr_ExceptionMatches(PyExc_OverflowError))
                        return NULL;
                    PyErr_Clear();
                }
            }
            return m->sq_item(o, i);
        }
    }
#else
    if (is_list || PySequence_Check(o)) {
        return PySequence_GetItem(o, i);
    }
#endif
    return __Pyx_GetItemInt_Generic(o, PyInt_FromSsize_t(i));
}

/* WriteUnraisableException */
  static void __Pyx_WriteUnraisable(const char *name, CYTHON_UNUSED int clineno,
                                  CYTHON_UNUSED int lineno, CYTHON_UNUSED const char *filename,
                                  int full_traceback, CYTHON_UNUSED int nogil) {
    PyObject *old_exc, *old_val, *old_tb;
    PyObject *ctx;
    __Pyx_PyThreadState_declare
#ifdef WITH_THREAD
    PyGILState_STATE state;
    if (nogil)
        state = PyGILState_Ensure();
#ifdef _MSC_VER
    else state = (PyGILState_STATE)-1;
#endif
#endif
    __Pyx_PyThreadState_assign
    __Pyx_ErrFetch(&old_exc, &old_val, &old_tb);
    if (full_traceback) {
        Py_XINCREF(old_exc);
        Py_XINCREF(old_val);
        Py_XINCREF(old_tb);
        __Pyx_ErrRestore(old_exc, old_val, old_tb);
        PyErr_PrintEx(1);
    }
    #if PY_MAJOR_VERSION < 3
    ctx = PyString_FromString(name);
    #else
    ctx = PyUnicode_FromString(name);
    #endif
    __Pyx_ErrRestore(old_exc, old_val, old_tb);
    if (!ctx) {
        PyErr_WriteUnraisable(Py_None);
    } else {
        PyErr_WriteUnraisable(ctx);
        Py_DECREF(ctx);
    }
#ifdef WITH_THREAD
    if (nogil)
        PyGILState_Release(state);
#endif
}

/* ExtTypeTest */
  static CYTHON_INLINE int __Pyx_TypeTest(PyObject *obj, PyTypeObject *type) {
    if (unlikely(!type)) {
        PyErr_SetString(PyExc_SystemError, "Missing type object");
        return 0;
    }
    if (likely(__Pyx_TypeCheck(obj, type)))
        return 1;
    PyErr_Format(PyExc_TypeError, "Cannot convert %.200s to %.200s",
                 Py_TYPE(obj)->tp_name, type->tp_name);
    return 0;
}

/* RaiseArgTupleInvalid */
  static void __Pyx_RaiseArgtupleInvalid(
    const char* func_name,
    int exact,
    Py_ssize_t num_min,
    Py_ssize_t num_max,
    Py_ssize_t num_found)
{
    Py_ssize_t num_expected;
    const char *more_or_less;
    if (num_found < num_min) {
        num_expected = num_min;
        more_or_less = "at least";
    } else {
        num_expected = num_max;
        more_or_less = "at most";
    }
    if (exact) {
        more_or_less = "exactly";
    }
    PyErr_Format(PyExc_TypeError,
                 "%.200s() takes %.8s %" CYTHON_FORMAT_SSIZE_T "d positional argument%.1s (%" CYTHON_FORMAT_SSIZE_T "d given)",
                 func_name, more_or_less, num_expected,
                 (num_expected == 1) ? "" : "s", num_found);
}

/* RaiseDoubleKeywords */
  static void __Pyx_RaiseDoubleKeywordsError(
    const char* func_name,
    PyObject* kw_name)
{
    PyErr_Format(PyExc_TypeError,
        #if PY_MAJOR_VERSION >= 3
        "%s() got multiple values for keyword argument '%U'", func_name, kw_name);
        #else
        "%s() got multiple values for keyword argument '%s'", func_name,
        PyString_AsString(kw_name));
        #endif
}

/* ParseKeywords */
  static int __Pyx_ParseOptionalKeywords(
    PyObject *kwds,
    PyObject **argnames[],
    PyObject *kwds2,
    PyObject *values[],
    Py_ssize_t num_pos_args,
    const char* function_name)
{
    PyObject *key = 0, *value = 0;
    Py_ssize_t pos = 0;
    PyObject*** name;
    PyObject*** first_kw_arg = argnames + num_pos_args;
    while (PyDict_Next(kwds, &pos, &key, &value)) {
        name = first_kw_arg;
        while (*name && (**name != key)) name++;
        if (*name) {
            values[name-argnames] = value;
            continue;
        }
        name = first_kw_arg;
        #if PY_MAJOR_VERSION < 3
        if (likely(PyString_CheckExact(key)) || likely(PyString_Check(key))) {
            while (*name) {
                if ((CYTHON_COMPILING_IN_PYPY || PyString_GET_SIZE(**name) == PyString_GET_SIZE(key))
                        && _PyString_Eq(**name, key)) {
                    values[name-argnames] = value;
                    break;
                }
                name++;
            }
            if (*name) continue;
            else {
                PyObject*** argname = argnames;
                while (argname != first_kw_arg) {
                    if ((**argname == key) || (
                            (CYTHON_COMPILING_IN_PYPY || PyString_GET_SIZE(**argname) == PyString_GET_SIZE(key))
                             && _PyString_Eq(**argname, key))) {
                        goto arg_passed_twice;
                    }
                    argname++;
                }
            }
        } else
        #endif
        if (likely(PyUnicode_Check(key))) {
            while (*name) {
                int cmp = (**name == key) ? 0 :
                #if !CYTHON_COMPILING_IN_PYPY && PY_MAJOR_VERSION >= 3
                    (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :
                #endif
                    PyUnicode_Compare(**name, key);
                if (cmp < 0 && unlikely(PyErr_Occurred())) goto bad;
                if (cmp == 0) {
                    values[name-argnames] = value;
                    break;
                }
                name++;
            }
            if (*name) continue;
            else {
                PyObject*** argname = argnames;
                while (argname != first_kw_arg) {
                    int cmp = (**argname == key) ? 0 :
                    #if !CYTHON_COMPILING_IN_PYPY && PY_MAJOR_VERSION >= 3
                        (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :
                    #endif
                        PyUnicode_Compare(**argname, key);
                    if (cmp < 0 && unlikely(PyErr_Occurred())) goto bad;
                    if (cmp == 0) goto arg_passed_twice;
                    argname++;
                }
            }
        } else
            goto invalid_keyword_type;
        if (kwds2) {
            if (unlikely(PyDict_SetItem(kwds2, key, value))) goto bad;
        } else {
            goto invalid_keyword;
        }
    }
    return 0;
arg_passed_twice:
    __Pyx_RaiseDoubleKeywordsError(function_name, key);
    goto bad;
invalid_keyword_type:
    PyErr_Format(PyExc_TypeError,
        "%.200s() keywords must be strings", function_name);
    goto bad;
invalid_keyword:
    PyErr_Format(PyExc_TypeError,
    #if PY_MAJOR_VERSION < 3
        "%.200s() got an unexpected keyword argument '%.200s'",
        function_name, PyString_AsString(key));
    #else
        "%s() got an unexpected keyword argument '%U'",
        function_name, key);
    #endif
bad:
    return -1;
}

/* ArgTypeTest */
  static int __Pyx__ArgTypeTest(PyObject *obj, PyTypeObject *type, const char *name, int exact)
{
    if (unlikely(!type)) {
        PyErr_SetString(PyExc_SystemError, "Missing type object");
        return 0;
    }
    else if (exact) {
        #if PY_MAJOR_VERSION == 2
        if ((type == &PyBaseString_Type) && likely(__Pyx_PyBaseString_CheckExact(obj))) return 1;
        #endif
    }
    else {
        if (likely(__Pyx_TypeCheck(obj, type))) return 1;
    }
    PyErr_Format(PyExc_TypeError,
        "Argument '%.200s' has incorrect type (expected %.200s, got %.200s)",
        name, type->tp_name, Py_TYPE(obj)->tp_name);
    return 0;
}

/* dict_getitem_default */
  static PyObject* __Pyx_PyDict_GetItemDefault(PyObject* d, PyObject* key, PyObject* default_value) {
    PyObject* value;
#if PY_MAJOR_VERSION >= 3 && !CYTHON_COMPILING_IN_PYPY
    value = PyDict_GetItemWithError(d, key);
    if (unlikely(!value)) {
        if (unlikely(PyErr_Occurred()))
            return NULL;
        value = default_value;
    }
    Py_INCREF(value);
#else
    if (PyString_CheckExact(key) || PyUnicode_CheckExact(key) || PyInt_CheckExact(key)) {
        value = PyDict_GetItem(d, key);
        if (unlikely(!value)) {
            value = default_value;
        }
        Py_INCREF(value);
    } else {
        if (default_value == Py_None)
            default_value = NULL;
        value = PyObject_CallMethodObjArgs(
            d, __pyx_n_s_get, key, default_value, NULL);
    }
#endif
    return value;
}

/* SaveResetException */
  #if CYTHON_FAST_THREAD_STATE
static CYTHON_INLINE void __Pyx__ExceptionSave(PyThreadState *tstate, PyObject **type, PyObject **value, PyObject **tb) {
    #if PY_VERSION_HEX >= 0x030700A2
    *type = tstate->exc_state.exc_type;
    *value = tstate->exc_state.exc_value;
    *tb = tstate->exc_state.exc_traceback;
    #else
    *type = tstate->exc_type;
    *value = tstate->exc_value;
    *tb = tstate->exc_traceback;
    #endif
    Py_XINCREF(*type);
    Py_XINCREF(*value);
    Py_XINCREF(*tb);
}
static CYTHON_INLINE void __Pyx__ExceptionReset(PyThreadState *tstate, PyObject *type, PyObject *value, PyObject *tb) {
    PyObject *tmp_type, *tmp_value, *tmp_tb;
    #if PY_VERSION_HEX >= 0x030700A2
    tmp_type = tstate->exc_state.exc_type;
    tmp_value = tstate->exc_state.exc_value;
    tmp_tb = tstate->exc_state.exc_traceback;
    tstate->exc_state.exc_type = type;
    tstate->exc_state.exc_value = value;
    tstate->exc_state.exc_traceback = tb;
    #else
    tmp_type = tstate->exc_type;
    tmp_value = tstate->exc_value;
    tmp_tb = tstate->exc_traceback;
    tstate->exc_type = type;
    tstate->exc_value = value;
    tstate->exc_traceback = tb;
    #endif
    Py_XDECREF(tmp_type);
    Py_XDECREF(tmp_value);
    Py_XDECREF(tmp_tb);
}
#endif

/* PyErrExceptionMatches */
  #if CYTHON_FAST_THREAD_STATE
static int __Pyx_PyErr_ExceptionMatchesTuple(PyObject *exc_type, PyObject *tuple) {
    Py_ssize_t i, n;
    n = PyTuple_GET_SIZE(tuple);
#if PY_MAJOR_VERSION >= 3
    for (i=0; i<n; i++) {
        if (exc_type == PyTuple_GET_ITEM(tuple, i)) return 1;
    }
#endif
    for (i=0; i<n; i++) {
        if (__Pyx_PyErr_GivenExceptionMatches(exc_type, PyTuple_GET_ITEM(tuple, i))) return 1;
    }
    return 0;
}
static CYTHON_INLINE int __Pyx_PyErr_ExceptionMatchesInState(PyThreadState* tstate, PyObject* err) {
    PyObject *exc_type = tstate->curexc_type;
    if (exc_type == err) return 1;
    if (unlikely(!exc_type)) return 0;
    if (unlikely(PyTuple_Check(err)))
        return __Pyx_PyErr_ExceptionMatchesTuple(exc_type, err);
    return __Pyx_PyErr_GivenExceptionMatches(exc_type, err);
}
#endif

/* decode_c_bytes */
  static CYTHON_INLINE PyObject* __Pyx_decode_c_bytes(
         const char* cstring, Py_ssize_t length, Py_ssize_t start, Py_ssize_t stop,
         const char* encoding, const char* errors,
         PyObject* (*decode_func)(const char *s, Py_ssize_t size, const char *errors)) {
    if (unlikely((start < 0) | (stop < 0))) {
        if (start < 0) {
            start += length;
            if (start < 0)
                start = 0;
        }
        if (stop < 0)
            stop += length;
    }
    if (stop > length)
        stop = length;
    length = stop - start;
    if (unlikely(length <= 0))
        return PyUnicode_FromUnicode(NULL, 0);
    cstring += start;
    if (decode_func) {
        return decode_func(cstring, length, errors);
    } else {
        return PyUnicode_Decode(cstring, length, encoding, errors);
    }
}

/* BytesEquals */
  static CYTHON_INLINE int __Pyx_PyBytes_Equals(PyObject* s1, PyObject* s2, int equals) {
#if CYTHON_COMPILING_IN_PYPY
    return PyObject_RichCompareBool(s1, s2, equals);
#else
    if (s1 == s2) {
        return (equals == Py_EQ);
    } else if (PyBytes_CheckExact(s1) & PyBytes_CheckExact(s2)) {
        const char *ps1, *ps2;
        Py_ssize_t length = PyBytes_GET_SIZE(s1);
        if (length != PyBytes_GET_SIZE(s2))
            return (equals == Py_NE);
        ps1 = PyBytes_AS_STRING(s1);
        ps2 = PyBytes_AS_STRING(s2);
        if (ps1[0] != ps2[0]) {
            return (equals == Py_NE);
        } else if (length == 1) {
            return (equals == Py_EQ);
        } else {
            int result;
#if CYTHON_USE_UNICODE_INTERNALS
            Py_hash_t hash1, hash2;
            hash1 = ((PyBytesObject*)s1)->ob_shash;
            hash2 = ((PyBytesObject*)s2)->ob_shash;
            if (hash1 != hash2 && hash1 != -1 && hash2 != -1) {
                return (equals == Py_NE);
            }
#endif
            result = memcmp(ps1, ps2, (size_t)length);
            return (equals == Py_EQ) ? (result == 0) : (result != 0);
        }
    } else if ((s1 == Py_None) & PyBytes_CheckExact(s2)) {
        return (equals == Py_NE);
    } else if ((s2 == Py_None) & PyBytes_CheckExact(s1)) {
        return (equals == Py_NE);
    } else {
        int result;
        PyObject* py_result = PyObject_RichCompare(s1, s2, equals);
        if (!py_result)
            return -1;
        result = __Pyx_PyObject_IsTrue(py_result);
        Py_DECREF(py_result);
        return result;
    }
#endif
}

/* UnicodeEquals */
  static CYTHON_INLINE int __Pyx_PyUnicode_Equals(PyObject* s1, PyObject* s2, int equals) {
#if CYTHON_COMPILING_IN_PYPY
    return PyObject_RichCompareBool(s1, s2, equals);
#else
#if PY_MAJOR_VERSION < 3
    PyObject* owned_ref = NULL;
#endif
    int s1_is_unicode, s2_is_unicode;
    if (s1 == s2) {
        goto return_eq;
    }
    s1_is_unicode = PyUnicode_CheckExact(s1);
    s2_is_unicode = PyUnicode_CheckExact(s2);
#if PY_MAJOR_VERSION < 3
    if ((s1_is_unicode & (!s2_is_unicode)) && PyString_CheckExact(s2)) {
        owned_ref = PyUnicode_FromObject(s2);
        if (unlikely(!owned_ref))
            return -1;
        s2 = owned_ref;
        s2_is_unicode = 1;
    } else if ((s2_is_unicode & (!s1_is_unicode)) && PyString_CheckExact(s1)) {
        owned_ref = PyUnicode_FromObject(s1);
        if (unlikely(!owned_ref))
            return -1;
        s1 = owned_ref;
        s1_is_unicode = 1;
    } else if (((!s2_is_unicode) & (!s1_is_unicode))) {
        return __Pyx_PyBytes_Equals(s1, s2, equals);
    }
#endif
    if (s1_is_unicode & s2_is_unicode) {
        Py_ssize_t length;
        int kind;
        void *data1, *data2;
        if (unlikely(__Pyx_PyUnicode_READY(s1) < 0) || unlikely(__Pyx_PyUnicode_READY(s2) < 0))
            return -1;
        length = __Pyx_PyUnicode_GET_LENGTH(s1);
        if (length != __Pyx_PyUnicode_GET_LENGTH(s2)) {
            goto return_ne;
        }
#if CYTHON_USE_UNICODE_INTERNALS
        {
            Py_hash_t hash1, hash2;
        #if CYTHON_PEP393_ENABLED
            hash1 = ((PyASCIIObject*)s1)->hash;
            hash2 = ((PyASCIIObject*)s2)->hash;
        #else
            hash1 = ((PyUnicodeObject*)s1)->hash;
            hash2 = ((PyUnicodeObject*)s2)->hash;
        #endif
            if (hash1 != hash2 && hash1 != -1 && hash2 != -1) {
                goto return_ne;
            }
        }
#endif
        kind = __Pyx_PyUnicode_KIND(s1);
        if (kind != __Pyx_PyUnicode_KIND(s2)) {
            goto return_ne;
        }
        data1 = __Pyx_PyUnicode_DATA(s1);
        data2 = __Pyx_PyUnicode_DATA(s2);
        if (__Pyx_PyUnicode_READ(kind, data1, 0) != __Pyx_PyUnicode_READ(kind, data2, 0)) {
            goto return_ne;
        } else if (length == 1) {
            goto return_eq;
        } else {
            int result = memcmp(data1, data2, (size_t)(length * kind));
            #if PY_MAJOR_VERSION < 3
            Py_XDECREF(owned_ref);
            #endif
            return (equals == Py_EQ) ? (result == 0) : (result != 0);
        }
    } else if ((s1 == Py_None) & s2_is_unicode) {
        goto return_ne;
    } else if ((s2 == Py_None) & s1_is_unicode) {
        goto return_ne;
    } else {
        int result;
        PyObject* py_result = PyObject_RichCompare(s1, s2, equals);
        if (!py_result)
            return -1;
        result = __Pyx_PyObject_IsTrue(py_result);
        Py_DECREF(py_result);
        return result;
    }
return_eq:
    #if PY_MAJOR_VERSION < 3
    Py_XDECREF(owned_ref);
    #endif
    return (equals == Py_EQ);
return_ne:
    #if PY_MAJOR_VERSION < 3
    Py_XDECREF(owned_ref);
    #endif
    return (equals == Py_NE);
#endif
}

/* GetModuleGlobalName */
  static CYTHON_INLINE PyObject *__Pyx_GetModuleGlobalName(PyObject *name) {
    PyObject *result;
#if !CYTHON_AVOID_BORROWED_REFS
    result = PyDict_GetItem(__pyx_d, name);
    if (likely(result)) {
        Py_INCREF(result);
    } else {
#else
    result = PyObject_GetItem(__pyx_d, name);
    if (!result) {
        PyErr_Clear();
#endif
        result = __Pyx_GetBuiltinName(name);
    }
    return result;
}

/* decode_c_string */
    static CYTHON_INLINE PyObject* __Pyx_decode_c_string(
         const char* cstring, Py_ssize_t start, Py_ssize_t stop,
         const char* encoding, const char* errors,
         PyObject* (*decode_func)(const char *s, Py_ssize_t size, const char *errors)) {
    Py_ssize_t length;
    if (unlikely((start < 0) | (stop < 0))) {
        size_t slen = strlen(cstring);
        if (unlikely(slen > (size_t) PY_SSIZE_T_MAX)) {
            PyErr_SetString(PyExc_OverflowError,
                            "c-string too long to convert to Python");
            return NULL;
        }
        length = (Py_ssize_t) slen;
        if (start < 0) {
            start += length;
            if (start < 0)
                start = 0;
        }
        if (stop < 0)
            stop += length;
    }
    length = stop - start;
    if (unlikely(length <= 0))
        return PyUnicode_FromUnicode(NULL, 0);
    cstring += start;
    if (decode_func) {
        return decode_func(cstring, length, errors);
    } else {
        return PyUnicode_Decode(cstring, length, encoding, errors);
    }
}

/* GetException */
    #if CYTHON_FAST_THREAD_STATE
static int __Pyx__GetException(PyThreadState *tstate, PyObject **type, PyObject **value, PyObject **tb) {
#else
static int __Pyx_GetException(PyObject **type, PyObject **value, PyObject **tb) {
#endif
    PyObject *local_type, *local_value, *local_tb;
#if CYTHON_FAST_THREAD_STATE
    PyObject *tmp_type, *tmp_value, *tmp_tb;
    local_type = tstate->curexc_type;
    local_value = tstate->curexc_value;
    local_tb = tstate->curexc_traceback;
    tstate->curexc_type = 0;
    tstate->curexc_value = 0;
    tstate->curexc_traceback = 0;
#else
    PyErr_Fetch(&local_type, &local_value, &local_tb);
#endif
    PyErr_NormalizeException(&local_type, &local_value, &local_tb);
#if CYTHON_FAST_THREAD_STATE
    if (unlikely(tstate->curexc_type))
#else
    if (unlikely(PyErr_Occurred()))
#endif
        goto bad;
    #if PY_MAJOR_VERSION >= 3
    if (local_tb) {
        if (unlikely(PyException_SetTraceback(local_value, local_tb) < 0))
            goto bad;
    }
    #endif
    Py_XINCREF(local_tb);
    Py_XINCREF(local_type);
    Py_XINCREF(local_value);
    *type = local_type;
    *value = local_value;
    *tb = local_tb;
#if CYTHON_FAST_THREAD_STATE
    #if PY_VERSION_HEX >= 0x030700A2
    tmp_type = tstate->exc_state.exc_type;
    tmp_value = tstate->exc_state.exc_value;
    tmp_tb = tstate->exc_state.exc_traceback;
    tstate->exc_state.exc_type = local_type;
    tstate->exc_state.exc_value = local_value;
    tstate->exc_state.exc_traceback = local_tb;
    #else
    tmp_type = tstate->exc_type;
    tmp_value = tstate->exc_value;
    tmp_tb = tstate->exc_traceback;
    tstate->exc_type = local_type;
    tstate->exc_value = local_value;
    tstate->exc_traceback = local_tb;
    #endif
    Py_XDECREF(tmp_type);
    Py_XDECREF(tmp_value);
    Py_XDECREF(tmp_tb);
#else
    PyErr_SetExcInfo(local_type, local_value, local_tb);
#endif
    return 0;
bad:
    *type = 0;
    *value = 0;
    *tb = 0;
    Py_XDECREF(local_type);
    Py_XDECREF(local_value);
    Py_XDECREF(local_tb);
    return -1;
}

/* SwapException */
      #if CYTHON_FAST_THREAD_STATE
static CYTHON_INLINE void __Pyx__ExceptionSwap(PyThreadState *tstate, PyObject **type, PyObject **value, PyObject **tb) {
    PyObject *tmp_type, *tmp_value, *tmp_tb;
    #if PY_VERSION_HEX >= 0x030700A2
    tmp_type = tstate->exc_state.exc_type;
    tmp_value = tstate->exc_state.exc_value;
    tmp_tb = tstate->exc_state.exc_traceback;
    tstate->exc_state.exc_type = *type;
    tstate->exc_state.exc_value = *value;
    tstate->exc_state.exc_traceback = *tb;
    #else
    tmp_type = tstate->exc_type;
    tmp_value = tstate->exc_value;
    tmp_tb = tstate->exc_traceback;
    tstate->exc_type = *type;
    tstate->exc_value = *value;
    tstate->exc_traceback = *tb;
    #endif
    *type = tmp_type;
    *value = tmp_value;
    *tb = tmp_tb;
}
#else
static CYTHON_INLINE void __Pyx_ExceptionSwap(PyObject **type, PyObject **value, PyObject **tb) {
    PyObject *tmp_type, *tmp_value, *tmp_tb;
    PyErr_GetExcInfo(&tmp_type, &tmp_value, &tmp_tb);
    PyErr_SetExcInfo(*type, *value, *tb);
    *type = tmp_type;
    *value = tmp_value;
    *tb = tmp_tb;
}
#endif

/* SliceObject */
      static CYTHON_INLINE PyObject* __Pyx_PyObject_GetSlice(PyObject* obj,
        Py_ssize_t cstart, Py_ssize_t cstop,
        PyObject** _py_start, PyObject** _py_stop, PyObject** _py_slice,
        int has_cstart, int has_cstop, CYTHON_UNUSED int wraparound) {
#if CYTHON_USE_TYPE_SLOTS
    PyMappingMethods* mp;
#if PY_MAJOR_VERSION < 3
    PySequenceMethods* ms = Py_TYPE(obj)->tp_as_sequence;
    if (likely(ms && ms->sq_slice)) {
        if (!has_cstart) {
            if (_py_start && (*_py_start != Py_None)) {
                cstart = __Pyx_PyIndex_AsSsize_t(*_py_start);
                if ((cstart == (Py_ssize_t)-1) && PyErr_Occurred()) goto bad;
            } else
                cstart = 0;
        }
        if (!has_cstop) {
            if (_py_stop && (*_py_stop != Py_None)) {
                cstop = __Pyx_PyIndex_AsSsize_t(*_py_stop);
                if ((cstop == (Py_ssize_t)-1) && PyErr_Occurred()) goto bad;
            } else
                cstop = PY_SSIZE_T_MAX;
        }
        if (wraparound && unlikely((cstart < 0) | (cstop < 0)) && likely(ms->sq_length)) {
            Py_ssize_t l = ms->sq_length(obj);
            if (likely(l >= 0)) {
                if (cstop < 0) {
                    cstop += l;
                    if (cstop < 0) cstop = 0;
                }
                if (cstart < 0) {
                    cstart += l;
                    if (cstart < 0) cstart = 0;
                }
            } else {
                if (!PyErr_ExceptionMatches(PyExc_OverflowError))
                    goto bad;
                PyErr_Clear();
            }
        }
        return ms->sq_slice(obj, cstart, cstop);
    }
#endif
    mp = Py_TYPE(obj)->tp_as_mapping;
    if (likely(mp && mp->mp_subscript))
#endif
    {
        PyObject* result;
        PyObject *py_slice, *py_start, *py_stop;
        if (_py_slice) {
            py_slice = *_py_slice;
        } else {
            PyObject* owned_start = NULL;
            PyObject* owned_stop = NULL;
            if (_py_start) {
                py_start = *_py_start;
            } else {
                if (has_cstart) {
                    owned_start = py_start = PyInt_FromSsize_t(cstart);
                    if (unlikely(!py_start)) goto bad;
                } else
                    py_start = Py_None;
            }
            if (_py_stop) {
                py_stop = *_py_stop;
            } else {
                if (has_cstop) {
                    owned_stop = py_stop = PyInt_FromSsize_t(cstop);
                    if (unlikely(!py_stop)) {
                        Py_XDECREF(owned_start);
                        goto bad;
                    }
                } else
                    py_stop = Py_None;
            }
            py_slice = PySlice_New(py_start, py_stop, Py_None);
            Py_XDECREF(owned_start);
            Py_XDECREF(owned_stop);
            if (unlikely(!py_slice)) goto bad;
        }
#if CYTHON_USE_TYPE_SLOTS
        result = mp->mp_subscript(obj, py_slice);
#else
        result = PyObject_GetItem(obj, py_slice);
#endif
        if (!_py_slice) {
            Py_DECREF(py_slice);
        }
        return result;
    }
    PyErr_Format(PyExc_TypeError,
        "'%.200s' object is unsliceable", Py_TYPE(obj)->tp_name);
bad:
    return NULL;
}

/* PyIntBinop */
      #if !CYTHON_COMPILING_IN_PYPY
static PyObject* __Pyx_PyInt_AddObjC(PyObject *op1, PyObject *op2, CYTHON_UNUSED long intval, CYTHON_UNUSED int inplace) {
    #if PY_MAJOR_VERSION < 3
    if (likely(PyInt_CheckExact(op1))) {
        const long b = intval;
        long x;
        long a = PyInt_AS_LONG(op1);
            x = (long)((unsigned long)a + b);
            if (likely((x^a) >= 0 || (x^b) >= 0))
                return PyInt_FromLong(x);
            return PyLong_Type.tp_as_number->nb_add(op1, op2);
    }
    #endif
    #if CYTHON_USE_PYLONG_INTERNALS
    if (likely(PyLong_CheckExact(op1))) {
        const long b = intval;
        long a, x;
#ifdef HAVE_LONG_LONG
        const PY_LONG_LONG llb = intval;
        PY_LONG_LONG lla, llx;
#endif
        const digit* digits = ((PyLongObject*)op1)->ob_digit;
        const Py_ssize_t size = Py_SIZE(op1);
        if (likely(__Pyx_sst_abs(size) <= 1)) {
            a = likely(size) ? digits[0] : 0;
            if (size == -1) a = -a;
        } else {
            switch (size) {
                case -2:
                    if (8 * sizeof(long) - 1 > 2 * PyLong_SHIFT) {
                        a = -(long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
#ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 2 * PyLong_SHIFT) {
                        lla = -(PY_LONG_LONG) (((((unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
#endif
                    }
                case 2:
                    if (8 * sizeof(long) - 1 > 2 * PyLong_SHIFT) {
                        a = (long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
#ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 2 * PyLong_SHIFT) {
                        lla = (PY_LONG_LONG) (((((unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
#endif
                    }
                case -3:
                    if (8 * sizeof(long) - 1 > 3 * PyLong_SHIFT) {
                        a = -(long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
#ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 3 * PyLong_SHIFT) {
                        lla = -(PY_LONG_LONG) (((((((unsigned PY_LONG_LONG)digits[2]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
#endif
                    }
                case 3:
                    if (8 * sizeof(long) - 1 > 3 * PyLong_SHIFT) {
                        a = (long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
#ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 3 * PyLong_SHIFT) {
                        lla = (PY_LONG_LONG) (((((((unsigned PY_LONG_LONG)digits[2]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
#endif
                    }
                case -4:
                    if (8 * sizeof(long) - 1 > 4 * PyLong_SHIFT) {
                        a = -(long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
#ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 4 * PyLong_SHIFT) {
                        lla = -(PY_LONG_LONG) (((((((((unsigned PY_LONG_LONG)digits[3]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[2]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
#endif
                    }
                case 4:
                    if (8 * sizeof(long) - 1 > 4 * PyLong_SHIFT) {
                        a = (long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
#ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 4 * PyLong_SHIFT) {
                        lla = (PY_LONG_LONG) (((((((((unsigned PY_LONG_LONG)digits[3]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[2]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
#endif
                    }
                default: return PyLong_Type.tp_as_number->nb_add(op1, op2);
            }
        }
                x = a + b;
            return PyLong_FromLong(x);
#ifdef HAVE_LONG_LONG
        long_long:
                llx = lla + llb;
            return PyLong_FromLongLong(llx);
#endif
        
        
    }
    #endif
    if (PyFloat_CheckExact(op1)) {
        const long b = intval;
        double a = PyFloat_AS_DOUBLE(op1);
            double result;
            PyFPE_START_PROTECT("add", return NULL)
            result = ((double)a) + (double)b;
            PyFPE_END_PROTECT(result)
            return PyFloat_FromDouble(result);
    }
    return (inplace ? PyNumber_InPlaceAdd : PyNumber_Add)(op1, op2);
}
#endif

/* None */
      static CYTHON_INLINE void __Pyx_RaiseUnboundLocalError(const char *varname) {
    PyErr_Format(PyExc_UnboundLocalError, "local variable '%s' referenced before assignment", varname);
}

/* KeywordStringCheck */
      static int __Pyx_CheckKeywordStrings(
    PyObject *kwdict,
    const char* function_name,
    int kw_allowed)
{
    PyObject* key = 0;
    Py_ssize_t pos = 0;
#if CYTHON_COMPILING_IN_PYPY
    if (!kw_allowed && PyDict_Next(kwdict, &pos, &key, 0))
        goto invalid_keyword;
    return 1;
#else
    while (PyDict_Next(kwdict, &pos, &key, 0)) {
        #if PY_MAJOR_VERSION < 3
        if (unlikely(!PyString_Check(key)))
        #endif
            if (unlikely(!PyUnicode_Check(key)))
                goto invalid_keyword_type;
    }
    if ((!kw_allowed) && unlikely(key))
        goto invalid_keyword;
    return 1;
invalid_keyword_type:
    PyErr_Format(PyExc_TypeError,
        "%.200s() keywords must be strings", function_name);
    return 0;
#endif
invalid_keyword:
    PyErr_Format(PyExc_TypeError,
    #if PY_MAJOR_VERSION < 3
        "%.200s() got an unexpected keyword argument '%.200s'",
        function_name, PyString_AsString(key));
    #else
        "%s() got an unexpected keyword argument '%U'",
        function_name, key);
    #endif
    return 0;
}

/* None */
      static CYTHON_INLINE void __Pyx_RaiseClosureNameError(const char *varname) {
    PyErr_Format(PyExc_NameError, "free variable '%s' referenced before assignment in enclosing scope", varname);
}

/* GetAttr */
      static CYTHON_INLINE PyObject *__Pyx_GetAttr(PyObject *o, PyObject *n) {
#if CYTHON_USE_TYPE_SLOTS
#if PY_MAJOR_VERSION >= 3
    if (likely(PyUnicode_Check(n)))
#else
    if (likely(PyString_Check(n)))
#endif
        return __Pyx_PyObject_GetAttrStr(o, n);
#endif
    return PyObject_GetAttr(o, n);
}

/* StringJoin */
      #if !CYTHON_COMPILING_IN_CPYTHON
static CYTHON_INLINE PyObject* __Pyx_PyBytes_Join(PyObject* sep, PyObject* values) {
    return PyObject_CallMethodObjArgs(sep, __pyx_n_s_join, values, NULL);
}
#endif

/* SetItemInt */
      static int __Pyx_SetItemInt_Generic(PyObject *o, PyObject *j, PyObject *v) {
    int r;
    if (!j) return -1;
    r = PyObject_SetItem(o, j, v);
    Py_DECREF(j);
    return r;
}
static CYTHON_INLINE int __Pyx_SetItemInt_Fast(PyObject *o, Py_ssize_t i, PyObject *v, int is_list,
                                               CYTHON_NCP_UNUSED int wraparound, CYTHON_NCP_UNUSED int boundscheck) {
#if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS && CYTHON_USE_TYPE_SLOTS
    if (is_list || PyList_CheckExact(o)) {
        Py_ssize_t n = (!wraparound) ? i : ((likely(i >= 0)) ? i : i + PyList_GET_SIZE(o));
        if ((!boundscheck) || likely((n >= 0) & (n < PyList_GET_SIZE(o)))) {
            PyObject* old = PyList_GET_ITEM(o, n);
            Py_INCREF(v);
            PyList_SET_ITEM(o, n, v);
            Py_DECREF(old);
            return 1;
        }
    } else {
        PySequenceMethods *m = Py_TYPE(o)->tp_as_sequence;
        if (likely(m && m->sq_ass_item)) {
            if (wraparound && unlikely(i < 0) && likely(m->sq_length)) {
                Py_ssize_t l = m->sq_length(o);
                if (likely(l >= 0)) {
                    i += l;
                } else {
                    if (!PyErr_ExceptionMatches(PyExc_OverflowError))
                        return -1;
                    PyErr_Clear();
                }
            }
            return m->sq_ass_item(o, i, v);
        }
    }
#else
#if CYTHON_COMPILING_IN_PYPY
    if (is_list || (PySequence_Check(o) && !PyDict_Check(o))) {
#else
    if (is_list || PySequence_Check(o)) {
#endif
        return PySequence_SetItem(o, i, v);
    }
#endif
    return __Pyx_SetItemInt_Generic(o, PyInt_FromSsize_t(i), v);
}

/* PyIntBinop */
        #if !CYTHON_COMPILING_IN_PYPY
static PyObject* __Pyx_PyInt_EqObjC(PyObject *op1, PyObject *op2, CYTHON_UNUSED long intval, CYTHON_UNUSED int inplace) {
    if (op1 == op2) {
        Py_RETURN_TRUE;
    }
    #if PY_MAJOR_VERSION < 3
    if (likely(PyInt_CheckExact(op1))) {
        const long b = intval;
        long a = PyInt_AS_LONG(op1);
        if (a == b) {
            Py_RETURN_TRUE;
        } else {
            Py_RETURN_FALSE;
        }
    }
    #endif
    #if CYTHON_USE_PYLONG_INTERNALS
    if (likely(PyLong_CheckExact(op1))) {
        const long b = intval;
        long a;
        const digit* digits = ((PyLongObject*)op1)->ob_digit;
        const Py_ssize_t size = Py_SIZE(op1);
        if (likely(__Pyx_sst_abs(size) <= 1)) {
            a = likely(size) ? digits[0] : 0;
            if (size == -1) a = -a;
        } else {
            switch (size) {
                case -2:
                    if (8 * sizeof(long) - 1 > 2 * PyLong_SHIFT) {
                        a = -(long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
                    }
                case 2:
                    if (8 * sizeof(long) - 1 > 2 * PyLong_SHIFT) {
                        a = (long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
                    }
                case -3:
                    if (8 * sizeof(long) - 1 > 3 * PyLong_SHIFT) {
                        a = -(long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
                    }
                case 3:
                    if (8 * sizeof(long) - 1 > 3 * PyLong_SHIFT) {
                        a = (long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
                    }
                case -4:
                    if (8 * sizeof(long) - 1 > 4 * PyLong_SHIFT) {
                        a = -(long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
                    }
                case 4:
                    if (8 * sizeof(long) - 1 > 4 * PyLong_SHIFT) {
                        a = (long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
                    }
                #if PyLong_SHIFT < 30 && PyLong_SHIFT != 15
                default: return PyLong_Type.tp_richcompare(op1, op2, Py_EQ);
                #else
                default: Py_RETURN_FALSE;
                #endif
            }
        }
            if (a == b) {
                Py_RETURN_TRUE;
            } else {
                Py_RETURN_FALSE;
            }
    }
    #endif
    if (PyFloat_CheckExact(op1)) {
        const long b = intval;
        double a = PyFloat_AS_DOUBLE(op1);
            if ((double)a == (double)b) {
                Py_RETURN_TRUE;
            } else {
                Py_RETURN_FALSE;
            }
    }
    return PyObject_RichCompare(op1, op2, Py_EQ);
}
#endif

/* SetVTable */
        static int __Pyx_SetVtable(PyObject *dict, void *vtable) {
#if PY_VERSION_HEX >= 0x02070000
    PyObject *ob = PyCapsule_New(vtable, 0, 0);
#else
    PyObject *ob = PyCObject_FromVoidPtr(vtable, 0);
#endif
    if (!ob)
        goto bad;
    if (PyDict_SetItem(dict, __pyx_n_s_pyx_vtable, ob) < 0)
        goto bad;
    Py_DECREF(ob);
    return 0;
bad:
    Py_XDECREF(ob);
    return -1;
}

/* Import */
        static PyObject *__Pyx_Import(PyObject *name, PyObject *from_list, int level) {
    PyObject *empty_list = 0;
    PyObject *module = 0;
    PyObject *global_dict = 0;
    PyObject *empty_dict = 0;
    PyObject *list;
    #if PY_MAJOR_VERSION < 3
    PyObject *py_import;
    py_import = __Pyx_PyObject_GetAttrStr(__pyx_b, __pyx_n_s_import);
    if (!py_import)
        goto bad;
    #endif
    if (from_list)
        list = from_list;
    else {
        empty_list = PyList_New(0);
        if (!empty_list)
            goto bad;
        list = empty_list;
    }
    global_dict = PyModule_GetDict(__pyx_m);
    if (!global_dict)
        goto bad;
    empty_dict = PyDict_New();
    if (!empty_dict)
        goto bad;
    {
        #if PY_MAJOR_VERSION >= 3
        if (level == -1) {
            if (strchr(__Pyx_MODULE_NAME, '.')) {
                module = PyImport_ImportModuleLevelObject(
                    name, global_dict, empty_dict, list, 1);
                if (!module) {
                    if (!PyErr_ExceptionMatches(PyExc_ImportError))
                        goto bad;
                    PyErr_Clear();
                }
            }
            level = 0;
        }
        #endif
        if (!module) {
            #if PY_MAJOR_VERSION < 3
            PyObject *py_level = PyInt_FromLong(level);
            if (!py_level)
                goto bad;
            module = PyObject_CallFunctionObjArgs(py_import,
                name, global_dict, empty_dict, list, py_level, NULL);
            Py_DECREF(py_level);
            #else
            module = PyImport_ImportModuleLevelObject(
                name, global_dict, empty_dict, list, level);
            #endif
        }
    }
bad:
    #if PY_MAJOR_VERSION < 3
    Py_XDECREF(py_import);
    #endif
    Py_XDECREF(empty_list);
    Py_XDECREF(empty_dict);
    return module;
}

/* CalculateMetaclass */
        static PyObject *__Pyx_CalculateMetaclass(PyTypeObject *metaclass, PyObject *bases) {
    Py_ssize_t i, nbases = PyTuple_GET_SIZE(bases);
    for (i=0; i < nbases; i++) {
        PyTypeObject *tmptype;
        PyObject *tmp = PyTuple_GET_ITEM(bases, i);
        tmptype = Py_TYPE(tmp);
#if PY_MAJOR_VERSION < 3
        if (tmptype == &PyClass_Type)
            continue;
#endif
        if (!metaclass) {
            metaclass = tmptype;
            continue;
        }
        if (PyType_IsSubtype(metaclass, tmptype))
            continue;
        if (PyType_IsSubtype(tmptype, metaclass)) {
            metaclass = tmptype;
            continue;
        }
        PyErr_SetString(PyExc_TypeError,
                        "metaclass conflict: "
                        "the metaclass of a derived class "
                        "must be a (non-strict) subclass "
                        "of the metaclasses of all its bases");
        return NULL;
    }
    if (!metaclass) {
#if PY_MAJOR_VERSION < 3
        metaclass = &PyClass_Type;
#else
        metaclass = &PyType_Type;
#endif
    }
    Py_INCREF((PyObject*) metaclass);
    return (PyObject*) metaclass;
}

/* Py3ClassCreate */
        static PyObject *__Pyx_Py3MetaclassPrepare(PyObject *metaclass, PyObject *bases, PyObject *name,
                                           PyObject *qualname, PyObject *mkw, PyObject *modname, PyObject *doc) {
    PyObject *ns;
    if (metaclass) {
        PyObject *prep = __Pyx_PyObject_GetAttrStr(metaclass, __pyx_n_s_prepare);
        if (prep) {
            PyObject *pargs = PyTuple_Pack(2, name, bases);
            if (unlikely(!pargs)) {
                Py_DECREF(prep);
                return NULL;
            }
            ns = PyObject_Call(prep, pargs, mkw);
            Py_DECREF(prep);
            Py_DECREF(pargs);
        } else {
            if (unlikely(!PyErr_ExceptionMatches(PyExc_AttributeError)))
                return NULL;
            PyErr_Clear();
            ns = PyDict_New();
        }
    } else {
        ns = PyDict_New();
    }
    if (unlikely(!ns))
        return NULL;
    if (unlikely(PyObject_SetItem(ns, __pyx_n_s_module, modname) < 0)) goto bad;
    if (unlikely(PyObject_SetItem(ns, __pyx_n_s_qualname, qualname) < 0)) goto bad;
    if (unlikely(doc && PyObject_SetItem(ns, __pyx_n_s_doc, doc) < 0)) goto bad;
    return ns;
bad:
    Py_DECREF(ns);
    return NULL;
}
static PyObject *__Pyx_Py3ClassCreate(PyObject *metaclass, PyObject *name, PyObject *bases,
                                      PyObject *dict, PyObject *mkw,
                                      int calculate_metaclass, int allow_py2_metaclass) {
    PyObject *result, *margs;
    PyObject *owned_metaclass = NULL;
    if (allow_py2_metaclass) {
        owned_metaclass = PyObject_GetItem(dict, __pyx_n_s_metaclass);
        if (owned_metaclass) {
            metaclass = owned_metaclass;
        } else if (likely(PyErr_ExceptionMatches(PyExc_KeyError))) {
            PyErr_Clear();
        } else {
            return NULL;
        }
    }
    if (calculate_metaclass && (!metaclass || PyType_Check(metaclass))) {
        metaclass = __Pyx_CalculateMetaclass((PyTypeObject*) metaclass, bases);
        Py_XDECREF(owned_metaclass);
        if (unlikely(!metaclass))
            return NULL;
        owned_metaclass = metaclass;
    }
    margs = PyTuple_Pack(3, name, bases, dict);
    if (unlikely(!margs)) {
        result = NULL;
    } else {
        result = PyObject_Call(metaclass, margs, mkw);
        Py_DECREF(margs);
    }
    Py_XDECREF(owned_metaclass);
    return result;
}

/* CLineInTraceback */
        #ifndef CYTHON_CLINE_IN_TRACEBACK
static int __Pyx_CLineForTraceback(CYTHON_UNUSED PyThreadState *tstate, int c_line) {
    PyObject *use_cline;
    PyObject *ptype, *pvalue, *ptraceback;
#if CYTHON_COMPILING_IN_CPYTHON
    PyObject **cython_runtime_dict;
#endif
    __Pyx_ErrFetchInState(tstate, &ptype, &pvalue, &ptraceback);
#if CYTHON_COMPILING_IN_CPYTHON
    cython_runtime_dict = _PyObject_GetDictPtr(__pyx_cython_runtime);
    if (likely(cython_runtime_dict)) {
      use_cline = PyDict_GetItem(*cython_runtime_dict, __pyx_n_s_cline_in_traceback);
    } else
#endif
    {
      PyObject *use_cline_obj = __Pyx_PyObject_GetAttrStr(__pyx_cython_runtime, __pyx_n_s_cline_in_traceback);
      if (use_cline_obj) {
        use_cline = PyObject_Not(use_cline_obj) ? Py_False : Py_True;
        Py_DECREF(use_cline_obj);
      } else {
        PyErr_Clear();
        use_cline = NULL;
      }
    }
    if (!use_cline) {
        c_line = 0;
        PyObject_SetAttr(__pyx_cython_runtime, __pyx_n_s_cline_in_traceback, Py_False);
    }
    else if (PyObject_Not(use_cline) != 0) {
        c_line = 0;
    }
    __Pyx_ErrRestoreInState(tstate, ptype, pvalue, ptraceback);
    return c_line;
}
#endif

/* CodeObjectCache */
        static int __pyx_bisect_code_objects(__Pyx_CodeObjectCacheEntry* entries, int count, int code_line) {
    int start = 0, mid = 0, end = count - 1;
    if (end >= 0 && code_line > entries[end].code_line) {
        return count;
    }
    while (start < end) {
        mid = start + (end - start) / 2;
        if (code_line < entries[mid].code_line) {
            end = mid;
        } else if (code_line > entries[mid].code_line) {
             start = mid + 1;
        } else {
            return mid;
        }
    }
    if (code_line <= entries[mid].code_line) {
        return mid;
    } else {
        return mid + 1;
    }
}
static PyCodeObject *__pyx_find_code_object(int code_line) {
    PyCodeObject* code_object;
    int pos;
    if (unlikely(!code_line) || unlikely(!__pyx_code_cache.entries)) {
        return NULL;
    }
    pos = __pyx_bisect_code_objects(__pyx_code_cache.entries, __pyx_code_cache.count, code_line);
    if (unlikely(pos >= __pyx_code_cache.count) || unlikely(__pyx_code_cache.entries[pos].code_line != code_line)) {
        return NULL;
    }
    code_object = __pyx_code_cache.entries[pos].code_object;
    Py_INCREF(code_object);
    return code_object;
}
static void __pyx_insert_code_object(int code_line, PyCodeObject* code_object) {
    int pos, i;
    __Pyx_CodeObjectCacheEntry* entries = __pyx_code_cache.entries;
    if (unlikely(!code_line)) {
        return;
    }
    if (unlikely(!entries)) {
        entries = (__Pyx_CodeObjectCacheEntry*)PyMem_Malloc(64*sizeof(__Pyx_CodeObjectCacheEntry));
        if (likely(entries)) {
            __pyx_code_cache.entries = entries;
            __pyx_code_cache.max_count = 64;
            __pyx_code_cache.count = 1;
            entries[0].code_line = code_line;
            entries[0].code_object = code_object;
            Py_INCREF(code_object);
        }
        return;
    }
    pos = __pyx_bisect_code_objects(__pyx_code_cache.entries, __pyx_code_cache.count, code_line);
    if ((pos < __pyx_code_cache.count) && unlikely(__pyx_code_cache.entries[pos].code_line == code_line)) {
        PyCodeObject* tmp = entries[pos].code_object;
        entries[pos].code_object = code_object;
        Py_DECREF(tmp);
        return;
    }
    if (__pyx_code_cache.count == __pyx_code_cache.max_count) {
        int new_max = __pyx_code_cache.max_count + 64;
        entries = (__Pyx_CodeObjectCacheEntry*)PyMem_Realloc(
            __pyx_code_cache.entries, (size_t)new_max*sizeof(__Pyx_CodeObjectCacheEntry));
        if (unlikely(!entries)) {
            return;
        }
        __pyx_code_cache.entries = entries;
        __pyx_code_cache.max_count = new_max;
    }
    for (i=__pyx_code_cache.count; i>pos; i--) {
        entries[i] = entries[i-1];
    }
    entries[pos].code_line = code_line;
    entries[pos].code_object = code_object;
    __pyx_code_cache.count++;
    Py_INCREF(code_object);
}

/* AddTraceback */
        #include "compile.h"
#include "frameobject.h"
#include "traceback.h"
static PyCodeObject* __Pyx_CreateCodeObjectForTraceback(
            const char *funcname, int c_line,
            int py_line, const char *filename) {
    PyCodeObject *py_code = 0;
    PyObject *py_srcfile = 0;
    PyObject *py_funcname = 0;
    #if PY_MAJOR_VERSION < 3
    py_srcfile = PyString_FromString(filename);
    #else
    py_srcfile = PyUnicode_FromString(filename);
    #endif
    if (!py_srcfile) goto bad;
    if (c_line) {
        #if PY_MAJOR_VERSION < 3
        py_funcname = PyString_FromFormat( "%s (%s:%d)", funcname, __pyx_cfilenm, c_line);
        #else
        py_funcname = PyUnicode_FromFormat( "%s (%s:%d)", funcname, __pyx_cfilenm, c_line);
        #endif
    }
    else {
        #if PY_MAJOR_VERSION < 3
        py_funcname = PyString_FromString(funcname);
        #else
        py_funcname = PyUnicode_FromString(funcname);
        #endif
    }
    if (!py_funcname) goto bad;
    py_code = __Pyx_PyCode_New(
        0,
        0,
        0,
        0,
        0,
        __pyx_empty_bytes, /*PyObject *code,*/
        __pyx_empty_tuple, /*PyObject *consts,*/
        __pyx_empty_tuple, /*PyObject *names,*/
        __pyx_empty_tuple, /*PyObject *varnames,*/
        __pyx_empty_tuple, /*PyObject *freevars,*/
        __pyx_empty_tuple, /*PyObject *cellvars,*/
        py_srcfile,   /*PyObject *filename,*/
        py_funcname,  /*PyObject *name,*/
        py_line,
        __pyx_empty_bytes  /*PyObject *lnotab*/
    );
    Py_DECREF(py_srcfile);
    Py_DECREF(py_funcname);
    return py_code;
bad:
    Py_XDECREF(py_srcfile);
    Py_XDECREF(py_funcname);
    return NULL;
}
static void __Pyx_AddTraceback(const char *funcname, int c_line,
                               int py_line, const char *filename) {
    PyCodeObject *py_code = 0;
    PyFrameObject *py_frame = 0;
    PyThreadState *tstate = __Pyx_PyThreadState_Current;
    if (c_line) {
        c_line = __Pyx_CLineForTraceback(tstate, c_line);
    }
    py_code = __pyx_find_code_object(c_line ? -c_line : py_line);
    if (!py_code) {
        py_code = __Pyx_CreateCodeObjectForTraceback(
            funcname, c_line, py_line, filename);
        if (!py_code) goto bad;
        __pyx_insert_code_object(c_line ? -c_line : py_line, py_code);
    }
    py_frame = PyFrame_New(
        tstate,            /*PyThreadState *tstate,*/
        py_code,           /*PyCodeObject *code,*/
        __pyx_d,    /*PyObject *globals,*/
        0                  /*PyObject *locals*/
    );
    if (!py_frame) goto bad;
    __Pyx_PyFrame_SetLineNumber(py_frame, py_line);
    PyTraceBack_Here(py_frame);
bad:
    Py_XDECREF(py_code);
    Py_XDECREF(py_frame);
}

/* CIntToPy */
        static CYTHON_INLINE PyObject* __Pyx_PyInt_From_enum__GPUARRAY_TYPES(enum GPUARRAY_TYPES value) {
    const enum GPUARRAY_TYPES neg_one = (enum GPUARRAY_TYPES) -1, const_zero = (enum GPUARRAY_TYPES) 0;
    const int is_unsigned = neg_one > const_zero;
    if (is_unsigned) {
        if (sizeof(enum GPUARRAY_TYPES) < sizeof(long)) {
            return PyInt_FromLong((long) value);
        } else if (sizeof(enum GPUARRAY_TYPES) <= sizeof(unsigned long)) {
            return PyLong_FromUnsignedLong((unsigned long) value);
#ifdef HAVE_LONG_LONG
        } else if (sizeof(enum GPUARRAY_TYPES) <= sizeof(unsigned PY_LONG_LONG)) {
            return PyLong_FromUnsignedLongLong((unsigned PY_LONG_LONG) value);
#endif
        }
    } else {
        if (sizeof(enum GPUARRAY_TYPES) <= sizeof(long)) {
            return PyInt_FromLong((long) value);
#ifdef HAVE_LONG_LONG
        } else if (sizeof(enum GPUARRAY_TYPES) <= sizeof(PY_LONG_LONG)) {
            return PyLong_FromLongLong((PY_LONG_LONG) value);
#endif
        }
    }
    {
        int one = 1; int little = (int)*(unsigned char *)&one;
        unsigned char *bytes = (unsigned char *)&value;
        return _PyLong_FromByteArray(bytes, sizeof(enum GPUARRAY_TYPES),
                                     little, !is_unsigned);
    }
}

/* CIntFromPyVerify */
        #define __PYX_VERIFY_RETURN_INT(target_type, func_type, func_value)\
    __PYX__VERIFY_RETURN_INT(target_type, func_type, func_value, 0)
#define __PYX_VERIFY_RETURN_INT_EXC(target_type, func_type, func_value)\
    __PYX__VERIFY_RETURN_INT(target_type, func_type, func_value, 1)
#define __PYX__VERIFY_RETURN_INT(target_type, func_type, func_value, exc)\
    {\
        func_type value = func_value;\
        if (sizeof(target_type) < sizeof(func_type)) {\
            if (unlikely(value != (func_type) (target_type) value)) {\
                func_type zero = 0;\
                if (exc && unlikely(value == (func_type)-1 && PyErr_Occurred()))\
                    return (target_type) -1;\
                if (is_unsigned && unlikely(value < zero))\
                    goto raise_neg_overflow;\
                else\
                    goto raise_overflow;\
            }\
        }\
        return (target_type) value;\
    }

/* CIntToPy */
        static CYTHON_INLINE PyObject* __Pyx_PyInt_From_int(int value) {
    const int neg_one = (int) -1, const_zero = (int) 0;
    const int is_unsigned = neg_one > const_zero;
    if (is_unsigned) {
        if (sizeof(int) < sizeof(long)) {
            return PyInt_FromLong((long) value);
        } else if (sizeof(int) <= sizeof(unsigned long)) {
            return PyLong_FromUnsignedLong((unsigned long) value);
#ifdef HAVE_LONG_LONG
        } else if (sizeof(int) <= sizeof(unsigned PY_LONG_LONG)) {
            return PyLong_FromUnsignedLongLong((unsigned PY_LONG_LONG) value);
#endif
        }
    } else {
        if (sizeof(int) <= sizeof(long)) {
            return PyInt_FromLong((long) value);
#ifdef HAVE_LONG_LONG
        } else if (sizeof(int) <= sizeof(PY_LONG_LONG)) {
            return PyLong_FromLongLong((PY_LONG_LONG) value);
#endif
        }
    }
    {
        int one = 1; int little = (int)*(unsigned char *)&one;
        unsigned char *bytes = (unsigned char *)&value;
        return _PyLong_FromByteArray(bytes, sizeof(int),
                                     little, !is_unsigned);
    }
}

/* CIntToPy */
        static CYTHON_INLINE PyObject* __Pyx_PyInt_From_long(long value) {
    const long neg_one = (long) -1, const_zero = (long) 0;
    const int is_unsigned = neg_one > const_zero;
    if (is_unsigned) {
        if (sizeof(long) < sizeof(long)) {
            return PyInt_FromLong((long) value);
        } else if (sizeof(long) <= sizeof(unsigned long)) {
            return PyLong_FromUnsignedLong((unsigned long) value);
#ifdef HAVE_LONG_LONG
        } else if (sizeof(long) <= sizeof(unsigned PY_LONG_LONG)) {
            return PyLong_FromUnsignedLongLong((unsigned PY_LONG_LONG) value);
#endif
        }
    } else {
        if (sizeof(long) <= sizeof(long)) {
            return PyInt_FromLong((long) value);
#ifdef HAVE_LONG_LONG
        } else if (sizeof(long) <= sizeof(PY_LONG_LONG)) {
            return PyLong_FromLongLong((PY_LONG_LONG) value);
#endif
        }
    }
    {
        int one = 1; int little = (int)*(unsigned char *)&one;
        unsigned char *bytes = (unsigned char *)&value;
        return _PyLong_FromByteArray(bytes, sizeof(long),
                                     little, !is_unsigned);
    }
}

/* CIntToPy */
        static CYTHON_INLINE PyObject* __Pyx_PyInt_From_unsigned_int(unsigned int value) {
    const unsigned int neg_one = (unsigned int) -1, const_zero = (unsigned int) 0;
    const int is_unsigned = neg_one > const_zero;
    if (is_unsigned) {
        if (sizeof(unsigned int) < sizeof(long)) {
            return PyInt_FromLong((long) value);
        } else if (sizeof(unsigned int) <= sizeof(unsigned long)) {
            return PyLong_FromUnsignedLong((unsigned long) value);
#ifdef HAVE_LONG_LONG
        } else if (sizeof(unsigned int) <= sizeof(unsigned PY_LONG_LONG)) {
            return PyLong_FromUnsignedLongLong((unsigned PY_LONG_LONG) value);
#endif
        }
    } else {
        if (sizeof(unsigned int) <= sizeof(long)) {
            return PyInt_FromLong((long) value);
#ifdef HAVE_LONG_LONG
        } else if (sizeof(unsigned int) <= sizeof(PY_LONG_LONG)) {
            return PyLong_FromLongLong((PY_LONG_LONG) value);
#endif
        }
    }
    {
        int one = 1; int little = (int)*(unsigned char *)&one;
        unsigned char *bytes = (unsigned char *)&value;
        return _PyLong_FromByteArray(bytes, sizeof(unsigned int),
                                     little, !is_unsigned);
    }
}

/* Declarations */
        #if CYTHON_CCOMPLEX
  #ifdef __cplusplus
    static CYTHON_INLINE __pyx_t_float_complex __pyx_t_float_complex_from_parts(float x, float y) {
      return ::std::complex< float >(x, y);
    }
  #else
    static CYTHON_INLINE __pyx_t_float_complex __pyx_t_float_complex_from_parts(float x, float y) {
      return x + y*(__pyx_t_float_complex)_Complex_I;
    }
  #endif
#else
    static CYTHON_INLINE __pyx_t_float_complex __pyx_t_float_complex_from_parts(float x, float y) {
      __pyx_t_float_complex z;
      z.real = x;
      z.imag = y;
      return z;
    }
#endif

/* Arithmetic */
        #if CYTHON_CCOMPLEX
#else
    static CYTHON_INLINE int __Pyx_c_eq_float(__pyx_t_float_complex a, __pyx_t_float_complex b) {
       return (a.real == b.real) && (a.imag == b.imag);
    }
    static CYTHON_INLINE __pyx_t_float_complex __Pyx_c_sum_float(__pyx_t_float_complex a, __pyx_t_float_complex b) {
        __pyx_t_float_complex z;
        z.real = a.real + b.real;
        z.imag = a.imag + b.imag;
        return z;
    }
    static CYTHON_INLINE __pyx_t_float_complex __Pyx_c_diff_float(__pyx_t_float_complex a, __pyx_t_float_complex b) {
        __pyx_t_float_complex z;
        z.real = a.real - b.real;
        z.imag = a.imag - b.imag;
        return z;
    }
    static CYTHON_INLINE __pyx_t_float_complex __Pyx_c_prod_float(__pyx_t_float_complex a, __pyx_t_float_complex b) {
        __pyx_t_float_complex z;
        z.real = a.real * b.real - a.imag * b.imag;
        z.imag = a.real * b.imag + a.imag * b.real;
        return z;
    }
    #if 1
    static CYTHON_INLINE __pyx_t_float_complex __Pyx_c_quot_float(__pyx_t_float_complex a, __pyx_t_float_complex b) {
        if (b.imag == 0) {
            return __pyx_t_float_complex_from_parts(a.real / b.real, a.imag / b.real);
        } else if (fabsf(b.real) >= fabsf(b.imag)) {
            if (b.real == 0 && b.imag == 0) {
                return __pyx_t_float_complex_from_parts(a.real / b.real, a.imag / b.imag);
            } else {
                float r = b.imag / b.real;
                float s = 1.0 / (b.real + b.imag * r);
                return __pyx_t_float_complex_from_parts(
                    (a.real + a.imag * r) * s, (a.imag - a.real * r) * s);
            }
        } else {
            float r = b.real / b.imag;
            float s = 1.0 / (b.imag + b.real * r);
            return __pyx_t_float_complex_from_parts(
                (a.real * r + a.imag) * s, (a.imag * r - a.real) * s);
        }
    }
    #else
    static CYTHON_INLINE __pyx_t_float_complex __Pyx_c_quot_float(__pyx_t_float_complex a, __pyx_t_float_complex b) {
        if (b.imag == 0) {
            return __pyx_t_float_complex_from_parts(a.real / b.real, a.imag / b.real);
        } else {
            float denom = b.real * b.real + b.imag * b.imag;
            return __pyx_t_float_complex_from_parts(
                (a.real * b.real + a.imag * b.imag) / denom,
                (a.imag * b.real - a.real * b.imag) / denom);
        }
    }
    #endif
    static CYTHON_INLINE __pyx_t_float_complex __Pyx_c_neg_float(__pyx_t_float_complex a) {
        __pyx_t_float_complex z;
        z.real = -a.real;
        z.imag = -a.imag;
        return z;
    }
    static CYTHON_INLINE int __Pyx_c_is_zero_float(__pyx_t_float_complex a) {
       return (a.real == 0) && (a.imag == 0);
    }
    static CYTHON_INLINE __pyx_t_float_complex __Pyx_c_conj_float(__pyx_t_float_complex a) {
        __pyx_t_float_complex z;
        z.real =  a.real;
        z.imag = -a.imag;
        return z;
    }
    #if 1
        static CYTHON_INLINE float __Pyx_c_abs_float(__pyx_t_float_complex z) {
          #if !defined(HAVE_HYPOT) || defined(_MSC_VER)
            return sqrtf(z.real*z.real + z.imag*z.imag);
          #else
            return hypotf(z.real, z.imag);
          #endif
        }
        static CYTHON_INLINE __pyx_t_float_complex __Pyx_c_pow_float(__pyx_t_float_complex a, __pyx_t_float_complex b) {
            __pyx_t_float_complex z;
            float r, lnr, theta, z_r, z_theta;
            if (b.imag == 0 && b.real == (int)b.real) {
                if (b.real < 0) {
                    float denom = a.real * a.real + a.imag * a.imag;
                    a.real = a.real / denom;
                    a.imag = -a.imag / denom;
                    b.real = -b.real;
                }
                switch ((int)b.real) {
                    case 0:
                        z.real = 1;
                        z.imag = 0;
                        return z;
                    case 1:
                        return a;
                    case 2:
                        z = __Pyx_c_prod_float(a, a);
                        return __Pyx_c_prod_float(a, a);
                    case 3:
                        z = __Pyx_c_prod_float(a, a);
                        return __Pyx_c_prod_float(z, a);
                    case 4:
                        z = __Pyx_c_prod_float(a, a);
                        return __Pyx_c_prod_float(z, z);
                }
            }
            if (a.imag == 0) {
                if (a.real == 0) {
                    return a;
                } else if (b.imag == 0) {
                    z.real = powf(a.real, b.real);
                    z.imag = 0;
                    return z;
                } else if (a.real > 0) {
                    r = a.real;
                    theta = 0;
                } else {
                    r = -a.real;
                    theta = atan2f(0, -1);
                }
            } else {
                r = __Pyx_c_abs_float(a);
                theta = atan2f(a.imag, a.real);
            }
            lnr = logf(r);
            z_r = expf(lnr * b.real - theta * b.imag);
            z_theta = theta * b.real + lnr * b.imag;
            z.real = z_r * cosf(z_theta);
            z.imag = z_r * sinf(z_theta);
            return z;
        }
    #endif
#endif

/* Declarations */
        #if CYTHON_CCOMPLEX
  #ifdef __cplusplus
    static CYTHON_INLINE __pyx_t_double_complex __pyx_t_double_complex_from_parts(double x, double y) {
      return ::std::complex< double >(x, y);
    }
  #else
    static CYTHON_INLINE __pyx_t_double_complex __pyx_t_double_complex_from_parts(double x, double y) {
      return x + y*(__pyx_t_double_complex)_Complex_I;
    }
  #endif
#else
    static CYTHON_INLINE __pyx_t_double_complex __pyx_t_double_complex_from_parts(double x, double y) {
      __pyx_t_double_complex z;
      z.real = x;
      z.imag = y;
      return z;
    }
#endif

/* Arithmetic */
        #if CYTHON_CCOMPLEX
#else
    static CYTHON_INLINE int __Pyx_c_eq_double(__pyx_t_double_complex a, __pyx_t_double_complex b) {
       return (a.real == b.real) && (a.imag == b.imag);
    }
    static CYTHON_INLINE __pyx_t_double_complex __Pyx_c_sum_double(__pyx_t_double_complex a, __pyx_t_double_complex b) {
        __pyx_t_double_complex z;
        z.real = a.real + b.real;
        z.imag = a.imag + b.imag;
        return z;
    }
    static CYTHON_INLINE __pyx_t_double_complex __Pyx_c_diff_double(__pyx_t_double_complex a, __pyx_t_double_complex b) {
        __pyx_t_double_complex z;
        z.real = a.real - b.real;
        z.imag = a.imag - b.imag;
        return z;
    }
    static CYTHON_INLINE __pyx_t_double_complex __Pyx_c_prod_double(__pyx_t_double_complex a, __pyx_t_double_complex b) {
        __pyx_t_double_complex z;
        z.real = a.real * b.real - a.imag * b.imag;
        z.imag = a.real * b.imag + a.imag * b.real;
        return z;
    }
    #if 1
    static CYTHON_INLINE __pyx_t_double_complex __Pyx_c_quot_double(__pyx_t_double_complex a, __pyx_t_double_complex b) {
        if (b.imag == 0) {
            return __pyx_t_double_complex_from_parts(a.real / b.real, a.imag / b.real);
        } else if (fabs(b.real) >= fabs(b.imag)) {
            if (b.real == 0 && b.imag == 0) {
                return __pyx_t_double_complex_from_parts(a.real / b.real, a.imag / b.imag);
            } else {
                double r = b.imag / b.real;
                double s = 1.0 / (b.real + b.imag * r);
                return __pyx_t_double_complex_from_parts(
                    (a.real + a.imag * r) * s, (a.imag - a.real * r) * s);
            }
        } else {
            double r = b.real / b.imag;
            double s = 1.0 / (b.imag + b.real * r);
            return __pyx_t_double_complex_from_parts(
                (a.real * r + a.imag) * s, (a.imag * r - a.real) * s);
        }
    }
    #else
    static CYTHON_INLINE __pyx_t_double_complex __Pyx_c_quot_double(__pyx_t_double_complex a, __pyx_t_double_complex b) {
        if (b.imag == 0) {
            return __pyx_t_double_complex_from_parts(a.real / b.real, a.imag / b.real);
        } else {
            double denom = b.real * b.real + b.imag * b.imag;
            return __pyx_t_double_complex_from_parts(
                (a.real * b.real + a.imag * b.imag) / denom,
                (a.imag * b.real - a.real * b.imag) / denom);
        }
    }
    #endif
    static CYTHON_INLINE __pyx_t_double_complex __Pyx_c_neg_double(__pyx_t_double_complex a) {
        __pyx_t_double_complex z;
        z.real = -a.real;
        z.imag = -a.imag;
        return z;
    }
    static CYTHON_INLINE int __Pyx_c_is_zero_double(__pyx_t_double_complex a) {
       return (a.real == 0) && (a.imag == 0);
    }
    static CYTHON_INLINE __pyx_t_double_complex __Pyx_c_conj_double(__pyx_t_double_complex a) {
        __pyx_t_double_complex z;
        z.real =  a.real;
        z.imag = -a.imag;
        return z;
    }
    #if 1
        static CYTHON_INLINE double __Pyx_c_abs_double(__pyx_t_double_complex z) {
          #if !defined(HAVE_HYPOT) || defined(_MSC_VER)
            return sqrt(z.real*z.real + z.imag*z.imag);
          #else
            return hypot(z.real, z.imag);
          #endif
        }
        static CYTHON_INLINE __pyx_t_double_complex __Pyx_c_pow_double(__pyx_t_double_complex a, __pyx_t_double_complex b) {
            __pyx_t_double_complex z;
            double r, lnr, theta, z_r, z_theta;
            if (b.imag == 0 && b.real == (int)b.real) {
                if (b.real < 0) {
                    double denom = a.real * a.real + a.imag * a.imag;
                    a.real = a.real / denom;
                    a.imag = -a.imag / denom;
                    b.real = -b.real;
                }
                switch ((int)b.real) {
                    case 0:
                        z.real = 1;
                        z.imag = 0;
                        return z;
                    case 1:
                        return a;
                    case 2:
                        z = __Pyx_c_prod_double(a, a);
                        return __Pyx_c_prod_double(a, a);
                    case 3:
                        z = __Pyx_c_prod_double(a, a);
                        return __Pyx_c_prod_double(z, a);
                    case 4:
                        z = __Pyx_c_prod_double(a, a);
                        return __Pyx_c_prod_double(z, z);
                }
            }
            if (a.imag == 0) {
                if (a.real == 0) {
                    return a;
                } else if (b.imag == 0) {
                    z.real = pow(a.real, b.real);
                    z.imag = 0;
                    return z;
                } else if (a.real > 0) {
                    r = a.real;
                    theta = 0;
                } else {
                    r = -a.real;
                    theta = atan2(0, -1);
                }
            } else {
                r = __Pyx_c_abs_double(a);
                theta = atan2(a.imag, a.real);
            }
            lnr = log(r);
            z_r = exp(lnr * b.real - theta * b.imag);
            z_theta = theta * b.real + lnr * b.imag;
            z.real = z_r * cos(z_theta);
            z.imag = z_r * sin(z_theta);
            return z;
        }
    #endif
#endif

/* CIntToPy */
        static CYTHON_INLINE PyObject* __Pyx_PyInt_From_enum__NPY_TYPES(enum NPY_TYPES value) {
    const enum NPY_TYPES neg_one = (enum NPY_TYPES) -1, const_zero = (enum NPY_TYPES) 0;
    const int is_unsigned = neg_one > const_zero;
    if (is_unsigned) {
        if (sizeof(enum NPY_TYPES) < sizeof(long)) {
            return PyInt_FromLong((long) value);
        } else if (sizeof(enum NPY_TYPES) <= sizeof(unsigned long)) {
            return PyLong_FromUnsignedLong((unsigned long) value);
#ifdef HAVE_LONG_LONG
        } else if (sizeof(enum NPY_TYPES) <= sizeof(unsigned PY_LONG_LONG)) {
            return PyLong_FromUnsignedLongLong((unsigned PY_LONG_LONG) value);
#endif
        }
    } else {
        if (sizeof(enum NPY_TYPES) <= sizeof(long)) {
            return PyInt_FromLong((long) value);
#ifdef HAVE_LONG_LONG
        } else if (sizeof(enum NPY_TYPES) <= sizeof(PY_LONG_LONG)) {
            return PyLong_FromLongLong((PY_LONG_LONG) value);
#endif
        }
    }
    {
        int one = 1; int little = (int)*(unsigned char *)&one;
        unsigned char *bytes = (unsigned char *)&value;
        return _PyLong_FromByteArray(bytes, sizeof(enum NPY_TYPES),
                                     little, !is_unsigned);
    }
}

/* CIntFromPy */
        static CYTHON_INLINE size_t __Pyx_PyInt_As_size_t(PyObject *x) {
    const size_t neg_one = (size_t) -1, const_zero = (size_t) 0;
    const int is_unsigned = neg_one > const_zero;
#if PY_MAJOR_VERSION < 3
    if (likely(PyInt_Check(x))) {
        if (sizeof(size_t) < sizeof(long)) {
            __PYX_VERIFY_RETURN_INT(size_t, long, PyInt_AS_LONG(x))
        } else {
            long val = PyInt_AS_LONG(x);
            if (is_unsigned && unlikely(val < 0)) {
                goto raise_neg_overflow;
            }
            return (size_t) val;
        }
    } else
#endif
    if (likely(PyLong_Check(x))) {
        if (is_unsigned) {
#if CYTHON_USE_PYLONG_INTERNALS
            const digit* digits = ((PyLongObject*)x)->ob_digit;
            switch (Py_SIZE(x)) {
                case  0: return (size_t) 0;
                case  1: __PYX_VERIFY_RETURN_INT(size_t, digit, digits[0])
                case 2:
                    if (8 * sizeof(size_t) > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(size_t, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(size_t) >= 2 * PyLong_SHIFT) {
                            return (size_t) (((((size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
                        }
                    }
                    break;
                case 3:
                    if (8 * sizeof(size_t) > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(size_t, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(size_t) >= 3 * PyLong_SHIFT) {
                            return (size_t) (((((((size_t)digits[2]) << PyLong_SHIFT) | (size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
                        }
                    }
                    break;
                case 4:
                    if (8 * sizeof(size_t) > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(size_t, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(size_t) >= 4 * PyLong_SHIFT) {
                            return (size_t) (((((((((size_t)digits[3]) << PyLong_SHIFT) | (size_t)digits[2]) << PyLong_SHIFT) | (size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
                        }
                    }
                    break;
            }
#endif
#if CYTHON_COMPILING_IN_CPYTHON
            if (unlikely(Py_SIZE(x) < 0)) {
                goto raise_neg_overflow;
            }
#else
            {
                int result = PyObject_RichCompareBool(x, Py_False, Py_LT);
                if (unlikely(result < 0))
                    return (size_t) -1;
                if (unlikely(result == 1))
                    goto raise_neg_overflow;
            }
#endif
            if (sizeof(size_t) <= sizeof(unsigned long)) {
                __PYX_VERIFY_RETURN_INT_EXC(size_t, unsigned long, PyLong_AsUnsignedLong(x))
#ifdef HAVE_LONG_LONG
            } else if (sizeof(size_t) <= sizeof(unsigned PY_LONG_LONG)) {
                __PYX_VERIFY_RETURN_INT_EXC(size_t, unsigned PY_LONG_LONG, PyLong_AsUnsignedLongLong(x))
#endif
            }
        } else {
#if CYTHON_USE_PYLONG_INTERNALS
            const digit* digits = ((PyLongObject*)x)->ob_digit;
            switch (Py_SIZE(x)) {
                case  0: return (size_t) 0;
                case -1: __PYX_VERIFY_RETURN_INT(size_t, sdigit, (sdigit) (-(sdigit)digits[0]))
                case  1: __PYX_VERIFY_RETURN_INT(size_t,  digit, +digits[0])
                case -2:
                    if (8 * sizeof(size_t) - 1 > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(size_t, long, -(long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(size_t) - 1 > 2 * PyLong_SHIFT) {
                            return (size_t) (((size_t)-1)*(((((size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0])));
                        }
                    }
                    break;
                case 2:
                    if (8 * sizeof(size_t) > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(size_t, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(size_t) - 1 > 2 * PyLong_SHIFT) {
                            return (size_t) ((((((size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0])));
                        }
                    }
                    break;
                case -3:
                    if (8 * sizeof(size_t) - 1 > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(size_t, long, -(long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(size_t) - 1 > 3 * PyLong_SHIFT) {
                            return (size_t) (((size_t)-1)*(((((((size_t)digits[2]) << PyLong_SHIFT) | (size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0])));
                        }
                    }
                    break;
                case 3:
                    if (8 * sizeof(size_t) > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(size_t, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(size_t) - 1 > 3 * PyLong_SHIFT) {
                            return (size_t) ((((((((size_t)digits[2]) << PyLong_SHIFT) | (size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0])));
                        }
                    }
                    break;
                case -4:
                    if (8 * sizeof(size_t) - 1 > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(size_t, long, -(long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(size_t) - 1 > 4 * PyLong_SHIFT) {
                            return (size_t) (((size_t)-1)*(((((((((size_t)digits[3]) << PyLong_SHIFT) | (size_t)digits[2]) << PyLong_SHIFT) | (size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0])));
                        }
                    }
                    break;
                case 4:
                    if (8 * sizeof(size_t) > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(size_t, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(size_t) - 1 > 4 * PyLong_SHIFT) {
                            return (size_t) ((((((((((size_t)digits[3]) << PyLong_SHIFT) | (size_t)digits[2]) << PyLong_SHIFT) | (size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0])));
                        }
                    }
                    break;
            }
#endif
            if (sizeof(size_t) <= sizeof(long)) {
                __PYX_VERIFY_RETURN_INT_EXC(size_t, long, PyLong_AsLong(x))
#ifdef HAVE_LONG_LONG
            } else if (sizeof(size_t) <= sizeof(PY_LONG_LONG)) {
                __PYX_VERIFY_RETURN_INT_EXC(size_t, PY_LONG_LONG, PyLong_AsLongLong(x))
#endif
            }
        }
        {
#if CYTHON_COMPILING_IN_PYPY && !defined(_PyLong_AsByteArray)
            PyErr_SetString(PyExc_RuntimeError,
                            "_PyLong_AsByteArray() not available in PyPy, cannot convert large numbers");
#else
            size_t val;
            PyObject *v = __Pyx_PyNumber_IntOrLong(x);
 #if PY_MAJOR_VERSION < 3
            if (likely(v) && !PyLong_Check(v)) {
                PyObject *tmp = v;
                v = PyNumber_Long(tmp);
                Py_DECREF(tmp);
            }
 #endif
            if (likely(v)) {
                int one = 1; int is_little = (int)*(unsigned char *)&one;
                unsigned char *bytes = (unsigned char *)&val;
                int ret = _PyLong_AsByteArray((PyLongObject *)v,
                                              bytes, sizeof(val),
                                              is_little, !is_unsigned);
                Py_DECREF(v);
                if (likely(!ret))
                    return val;
            }
#endif
            return (size_t) -1;
        }
    } else {
        size_t val;
        PyObject *tmp = __Pyx_PyNumber_IntOrLong(x);
        if (!tmp) return (size_t) -1;
        val = __Pyx_PyInt_As_size_t(tmp);
        Py_DECREF(tmp);
        return val;
    }
raise_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "value too large to convert to size_t");
    return (size_t) -1;
raise_neg_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "can't convert negative value to size_t");
    return (size_t) -1;
}

/* CIntFromPy */
        static CYTHON_INLINE unsigned int __Pyx_PyInt_As_unsigned_int(PyObject *x) {
    const unsigned int neg_one = (unsigned int) -1, const_zero = (unsigned int) 0;
    const int is_unsigned = neg_one > const_zero;
#if PY_MAJOR_VERSION < 3
    if (likely(PyInt_Check(x))) {
        if (sizeof(unsigned int) < sizeof(long)) {
            __PYX_VERIFY_RETURN_INT(unsigned int, long, PyInt_AS_LONG(x))
        } else {
            long val = PyInt_AS_LONG(x);
            if (is_unsigned && unlikely(val < 0)) {
                goto raise_neg_overflow;
            }
            return (unsigned int) val;
        }
    } else
#endif
    if (likely(PyLong_Check(x))) {
        if (is_unsigned) {
#if CYTHON_USE_PYLONG_INTERNALS
            const digit* digits = ((PyLongObject*)x)->ob_digit;
            switch (Py_SIZE(x)) {
                case  0: return (unsigned int) 0;
                case  1: __PYX_VERIFY_RETURN_INT(unsigned int, digit, digits[0])
                case 2:
                    if (8 * sizeof(unsigned int) > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(unsigned int, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(unsigned int) >= 2 * PyLong_SHIFT) {
                            return (unsigned int) (((((unsigned int)digits[1]) << PyLong_SHIFT) | (unsigned int)digits[0]));
                        }
                    }
                    break;
                case 3:
                    if (8 * sizeof(unsigned int) > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(unsigned int, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(unsigned int) >= 3 * PyLong_SHIFT) {
                            return (unsigned int) (((((((unsigned int)digits[2]) << PyLong_SHIFT) | (unsigned int)digits[1]) << PyLong_SHIFT) | (unsigned int)digits[0]));
                        }
                    }
                    break;
                case 4:
                    if (8 * sizeof(unsigned int) > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(unsigned int, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(unsigned int) >= 4 * PyLong_SHIFT) {
                            return (unsigned int) (((((((((unsigned int)digits[3]) << PyLong_SHIFT) | (unsigned int)digits[2]) << PyLong_SHIFT) | (unsigned int)digits[1]) << PyLong_SHIFT) | (unsigned int)digits[0]));
                        }
                    }
                    break;
            }
#endif
#if CYTHON_COMPILING_IN_CPYTHON
            if (unlikely(Py_SIZE(x) < 0)) {
                goto raise_neg_overflow;
            }
#else
            {
                int result = PyObject_RichCompareBool(x, Py_False, Py_LT);
                if (unlikely(result < 0))
                    return (unsigned int) -1;
                if (unlikely(result == 1))
                    goto raise_neg_overflow;
            }
#endif
            if (sizeof(unsigned int) <= sizeof(unsigned long)) {
                __PYX_VERIFY_RETURN_INT_EXC(unsigned int, unsigned long, PyLong_AsUnsignedLong(x))
#ifdef HAVE_LONG_LONG
            } else if (sizeof(unsigned int) <= sizeof(unsigned PY_LONG_LONG)) {
                __PYX_VERIFY_RETURN_INT_EXC(unsigned int, unsigned PY_LONG_LONG, PyLong_AsUnsignedLongLong(x))
#endif
            }
        } else {
#if CYTHON_USE_PYLONG_INTERNALS
            const digit* digits = ((PyLongObject*)x)->ob_digit;
            switch (Py_SIZE(x)) {
                case  0: return (unsigned int) 0;
                case -1: __PYX_VERIFY_RETURN_INT(unsigned int, sdigit, (sdigit) (-(sdigit)digits[0]))
                case  1: __PYX_VERIFY_RETURN_INT(unsigned int,  digit, +digits[0])
                case -2:
                    if (8 * sizeof(unsigned int) - 1 > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(unsigned int, long, -(long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(unsigned int) - 1 > 2 * PyLong_SHIFT) {
                            return (unsigned int) (((unsigned int)-1)*(((((unsigned int)digits[1]) << PyLong_SHIFT) | (unsigned int)digits[0])));
                        }
                    }
                    break;
                case 2:
                    if (8 * sizeof(unsigned int) > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(unsigned int, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(unsigned int) - 1 > 2 * PyLong_SHIFT) {
                            return (unsigned int) ((((((unsigned int)digits[1]) << PyLong_SHIFT) | (unsigned int)digits[0])));
                        }
                    }
                    break;
                case -3:
                    if (8 * sizeof(unsigned int) - 1 > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(unsigned int, long, -(long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(unsigned int) - 1 > 3 * PyLong_SHIFT) {
                            return (unsigned int) (((unsigned int)-1)*(((((((unsigned int)digits[2]) << PyLong_SHIFT) | (unsigned int)digits[1]) << PyLong_SHIFT) | (unsigned int)digits[0])));
                        }
                    }
                    break;
                case 3:
                    if (8 * sizeof(unsigned int) > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(unsigned int, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(unsigned int) - 1 > 3 * PyLong_SHIFT) {
                            return (unsigned int) ((((((((unsigned int)digits[2]) << PyLong_SHIFT) | (unsigned int)digits[1]) << PyLong_SHIFT) | (unsigned int)digits[0])));
                        }
                    }
                    break;
                case -4:
                    if (8 * sizeof(unsigned int) - 1 > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(unsigned int, long, -(long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(unsigned int) - 1 > 4 * PyLong_SHIFT) {
                            return (unsigned int) (((unsigned int)-1)*(((((((((unsigned int)digits[3]) << PyLong_SHIFT) | (unsigned int)digits[2]) << PyLong_SHIFT) | (unsigned int)digits[1]) << PyLong_SHIFT) | (unsigned int)digits[0])));
                        }
                    }
                    break;
                case 4:
                    if (8 * sizeof(unsigned int) > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(unsigned int, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(unsigned int) - 1 > 4 * PyLong_SHIFT) {
                            return (unsigned int) ((((((((((unsigned int)digits[3]) << PyLong_SHIFT) | (unsigned int)digits[2]) << PyLong_SHIFT) | (unsigned int)digits[1]) << PyLong_SHIFT) | (unsigned int)digits[0])));
                        }
                    }
                    break;
            }
#endif
            if (sizeof(unsigned int) <= sizeof(long)) {
                __PYX_VERIFY_RETURN_INT_EXC(unsigned int, long, PyLong_AsLong(x))
#ifdef HAVE_LONG_LONG
            } else if (sizeof(unsigned int) <= sizeof(PY_LONG_LONG)) {
                __PYX_VERIFY_RETURN_INT_EXC(unsigned int, PY_LONG_LONG, PyLong_AsLongLong(x))
#endif
            }
        }
        {
#if CYTHON_COMPILING_IN_PYPY && !defined(_PyLong_AsByteArray)
            PyErr_SetString(PyExc_RuntimeError,
                            "_PyLong_AsByteArray() not available in PyPy, cannot convert large numbers");
#else
            unsigned int val;
            PyObject *v = __Pyx_PyNumber_IntOrLong(x);
 #if PY_MAJOR_VERSION < 3
            if (likely(v) && !PyLong_Check(v)) {
                PyObject *tmp = v;
                v = PyNumber_Long(tmp);
                Py_DECREF(tmp);
            }
 #endif
            if (likely(v)) {
                int one = 1; int is_little = (int)*(unsigned char *)&one;
                unsigned char *bytes = (unsigned char *)&val;
                int ret = _PyLong_AsByteArray((PyLongObject *)v,
                                              bytes, sizeof(val),
                                              is_little, !is_unsigned);
                Py_DECREF(v);
                if (likely(!ret))
                    return val;
            }
#endif
            return (unsigned int) -1;
        }
    } else {
        unsigned int val;
        PyObject *tmp = __Pyx_PyNumber_IntOrLong(x);
        if (!tmp) return (unsigned int) -1;
        val = __Pyx_PyInt_As_unsigned_int(tmp);
        Py_DECREF(tmp);
        return val;
    }
raise_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "value too large to convert to unsigned int");
    return (unsigned int) -1;
raise_neg_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "can't convert negative value to unsigned int");
    return (unsigned int) -1;
}

/* CIntFromPy */
        static CYTHON_INLINE int __Pyx_PyInt_As_int(PyObject *x) {
    const int neg_one = (int) -1, const_zero = (int) 0;
    const int is_unsigned = neg_one > const_zero;
#if PY_MAJOR_VERSION < 3
    if (likely(PyInt_Check(x))) {
        if (sizeof(int) < sizeof(long)) {
            __PYX_VERIFY_RETURN_INT(int, long, PyInt_AS_LONG(x))
        } else {
            long val = PyInt_AS_LONG(x);
            if (is_unsigned && unlikely(val < 0)) {
                goto raise_neg_overflow;
            }
            return (int) val;
        }
    } else
#endif
    if (likely(PyLong_Check(x))) {
        if (is_unsigned) {
#if CYTHON_USE_PYLONG_INTERNALS
            const digit* digits = ((PyLongObject*)x)->ob_digit;
            switch (Py_SIZE(x)) {
                case  0: return (int) 0;
                case  1: __PYX_VERIFY_RETURN_INT(int, digit, digits[0])
                case 2:
                    if (8 * sizeof(int) > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) >= 2 * PyLong_SHIFT) {
                            return (int) (((((int)digits[1]) << PyLong_SHIFT) | (int)digits[0]));
                        }
                    }
                    break;
                case 3:
                    if (8 * sizeof(int) > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) >= 3 * PyLong_SHIFT) {
                            return (int) (((((((int)digits[2]) << PyLong_SHIFT) | (int)digits[1]) << PyLong_SHIFT) | (int)digits[0]));
                        }
                    }
                    break;
                case 4:
                    if (8 * sizeof(int) > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) >= 4 * PyLong_SHIFT) {
                            return (int) (((((((((int)digits[3]) << PyLong_SHIFT) | (int)digits[2]) << PyLong_SHIFT) | (int)digits[1]) << PyLong_SHIFT) | (int)digits[0]));
                        }
                    }
                    break;
            }
#endif
#if CYTHON_COMPILING_IN_CPYTHON
            if (unlikely(Py_SIZE(x) < 0)) {
                goto raise_neg_overflow;
            }
#else
            {
                int result = PyObject_RichCompareBool(x, Py_False, Py_LT);
                if (unlikely(result < 0))
                    return (int) -1;
                if (unlikely(result == 1))
                    goto raise_neg_overflow;
            }
#endif
            if (sizeof(int) <= sizeof(unsigned long)) {
                __PYX_VERIFY_RETURN_INT_EXC(int, unsigned long, PyLong_AsUnsignedLong(x))
#ifdef HAVE_LONG_LONG
            } else if (sizeof(int) <= sizeof(unsigned PY_LONG_LONG)) {
                __PYX_VERIFY_RETURN_INT_EXC(int, unsigned PY_LONG_LONG, PyLong_AsUnsignedLongLong(x))
#endif
            }
        } else {
#if CYTHON_USE_PYLONG_INTERNALS
            const digit* digits = ((PyLongObject*)x)->ob_digit;
            switch (Py_SIZE(x)) {
                case  0: return (int) 0;
                case -1: __PYX_VERIFY_RETURN_INT(int, sdigit, (sdigit) (-(sdigit)digits[0]))
                case  1: __PYX_VERIFY_RETURN_INT(int,  digit, +digits[0])
                case -2:
                    if (8 * sizeof(int) - 1 > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, long, -(long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) - 1 > 2 * PyLong_SHIFT) {
                            return (int) (((int)-1)*(((((int)digits[1]) << PyLong_SHIFT) | (int)digits[0])));
                        }
                    }
                    break;
                case 2:
                    if (8 * sizeof(int) > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) - 1 > 2 * PyLong_SHIFT) {
                            return (int) ((((((int)digits[1]) << PyLong_SHIFT) | (int)digits[0])));
                        }
                    }
                    break;
                case -3:
                    if (8 * sizeof(int) - 1 > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, long, -(long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) - 1 > 3 * PyLong_SHIFT) {
                            return (int) (((int)-1)*(((((((int)digits[2]) << PyLong_SHIFT) | (int)digits[1]) << PyLong_SHIFT) | (int)digits[0])));
                        }
                    }
                    break;
                case 3:
                    if (8 * sizeof(int) > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) - 1 > 3 * PyLong_SHIFT) {
                            return (int) ((((((((int)digits[2]) << PyLong_SHIFT) | (int)digits[1]) << PyLong_SHIFT) | (int)digits[0])));
                        }
                    }
                    break;
                case -4:
                    if (8 * sizeof(int) - 1 > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, long, -(long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) - 1 > 4 * PyLong_SHIFT) {
                            return (int) (((int)-1)*(((((((((int)digits[3]) << PyLong_SHIFT) | (int)digits[2]) << PyLong_SHIFT) | (int)digits[1]) << PyLong_SHIFT) | (int)digits[0])));
                        }
                    }
                    break;
                case 4:
                    if (8 * sizeof(int) > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) - 1 > 4 * PyLong_SHIFT) {
                            return (int) ((((((((((int)digits[3]) << PyLong_SHIFT) | (int)digits[2]) << PyLong_SHIFT) | (int)digits[1]) << PyLong_SHIFT) | (int)digits[0])));
                        }
                    }
                    break;
            }
#endif
            if (sizeof(int) <= sizeof(long)) {
                __PYX_VERIFY_RETURN_INT_EXC(int, long, PyLong_AsLong(x))
#ifdef HAVE_LONG_LONG
            } else if (sizeof(int) <= sizeof(PY_LONG_LONG)) {
                __PYX_VERIFY_RETURN_INT_EXC(int, PY_LONG_LONG, PyLong_AsLongLong(x))
#endif
            }
        }
        {
#if CYTHON_COMPILING_IN_PYPY && !defined(_PyLong_AsByteArray)
            PyErr_SetString(PyExc_RuntimeError,
                            "_PyLong_AsByteArray() not available in PyPy, cannot convert large numbers");
#else
            int val;
            PyObject *v = __Pyx_PyNumber_IntOrLong(x);
 #if PY_MAJOR_VERSION < 3
            if (likely(v) && !PyLong_Check(v)) {
                PyObject *tmp = v;
                v = PyNumber_Long(tmp);
                Py_DECREF(tmp);
            }
 #endif
            if (likely(v)) {
                int one = 1; int is_little = (int)*(unsigned char *)&one;
                unsigned char *bytes = (unsigned char *)&val;
                int ret = _PyLong_AsByteArray((PyLongObject *)v,
                                              bytes, sizeof(val),
                                              is_little, !is_unsigned);
                Py_DECREF(v);
                if (likely(!ret))
                    return val;
            }
#endif
            return (int) -1;
        }
    } else {
        int val;
        PyObject *tmp = __Pyx_PyNumber_IntOrLong(x);
        if (!tmp) return (int) -1;
        val = __Pyx_PyInt_As_int(tmp);
        Py_DECREF(tmp);
        return val;
    }
raise_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "value too large to convert to int");
    return (int) -1;
raise_neg_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "can't convert negative value to int");
    return (int) -1;
}

/* CIntFromPy */
        static CYTHON_INLINE signed char __Pyx_PyInt_As_signed__char(PyObject *x) {
    const signed char neg_one = (signed char) -1, const_zero = (signed char) 0;
    const int is_unsigned = neg_one > const_zero;
#if PY_MAJOR_VERSION < 3
    if (likely(PyInt_Check(x))) {
        if (sizeof(signed char) < sizeof(long)) {
            __PYX_VERIFY_RETURN_INT(signed char, long, PyInt_AS_LONG(x))
        } else {
            long val = PyInt_AS_LONG(x);
            if (is_unsigned && unlikely(val < 0)) {
                goto raise_neg_overflow;
            }
            return (signed char) val;
        }
    } else
#endif
    if (likely(PyLong_Check(x))) {
        if (is_unsigned) {
#if CYTHON_USE_PYLONG_INTERNALS
            const digit* digits = ((PyLongObject*)x)->ob_digit;
            switch (Py_SIZE(x)) {
                case  0: return (signed char) 0;
                case  1: __PYX_VERIFY_RETURN_INT(signed char, digit, digits[0])
                case 2:
                    if (8 * sizeof(signed char) > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(signed char, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(signed char) >= 2 * PyLong_SHIFT) {
                            return (signed char) (((((signed char)digits[1]) << PyLong_SHIFT) | (signed char)digits[0]));
                        }
                    }
                    break;
                case 3:
                    if (8 * sizeof(signed char) > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(signed char, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(signed char) >= 3 * PyLong_SHIFT) {
                            return (signed char) (((((((signed char)digits[2]) << PyLong_SHIFT) | (signed char)digits[1]) << PyLong_SHIFT) | (signed char)digits[0]));
                        }
                    }
                    break;
                case 4:
                    if (8 * sizeof(signed char) > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(signed char, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(signed char) >= 4 * PyLong_SHIFT) {
                            return (signed char) (((((((((signed char)digits[3]) << PyLong_SHIFT) | (signed char)digits[2]) << PyLong_SHIFT) | (signed char)digits[1]) << PyLong_SHIFT) | (signed char)digits[0]));
                        }
                    }
                    break;
            }
#endif
#if CYTHON_COMPILING_IN_CPYTHON
            if (unlikely(Py_SIZE(x) < 0)) {
                goto raise_neg_overflow;
            }
#else
            {
                int result = PyObject_RichCompareBool(x, Py_False, Py_LT);
                if (unlikely(result < 0))
                    return (signed char) -1;
                if (unlikely(result == 1))
                    goto raise_neg_overflow;
            }
#endif
            if (sizeof(signed char) <= sizeof(unsigned long)) {
                __PYX_VERIFY_RETURN_INT_EXC(signed char, unsigned long, PyLong_AsUnsignedLong(x))
#ifdef HAVE_LONG_LONG
            } else if (sizeof(signed char) <= sizeof(unsigned PY_LONG_LONG)) {
                __PYX_VERIFY_RETURN_INT_EXC(signed char, unsigned PY_LONG_LONG, PyLong_AsUnsignedLongLong(x))
#endif
            }
        } else {
#if CYTHON_USE_PYLONG_INTERNALS
            const digit* digits = ((PyLongObject*)x)->ob_digit;
            switch (Py_SIZE(x)) {
                case  0: return (signed char) 0;
                case -1: __PYX_VERIFY_RETURN_INT(signed char, sdigit, (sdigit) (-(sdigit)digits[0]))
                case  1: __PYX_VERIFY_RETURN_INT(signed char,  digit, +digits[0])
                case -2:
                    if (8 * sizeof(signed char) - 1 > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(signed char, long, -(long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(signed char) - 1 > 2 * PyLong_SHIFT) {
                            return (signed char) (((signed char)-1)*(((((signed char)digits[1]) << PyLong_SHIFT) | (signed char)digits[0])));
                        }
                    }
                    break;
                case 2:
                    if (8 * sizeof(signed char) > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(signed char, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(signed char) - 1 > 2 * PyLong_SHIFT) {
                            return (signed char) ((((((signed char)digits[1]) << PyLong_SHIFT) | (signed char)digits[0])));
                        }
                    }
                    break;
                case -3:
                    if (8 * sizeof(signed char) - 1 > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(signed char, long, -(long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(signed char) - 1 > 3 * PyLong_SHIFT) {
                            return (signed char) (((signed char)-1)*(((((((signed char)digits[2]) << PyLong_SHIFT) | (signed char)digits[1]) << PyLong_SHIFT) | (signed char)digits[0])));
                        }
                    }
                    break;
                case 3:
                    if (8 * sizeof(signed char) > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(signed char, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(signed char) - 1 > 3 * PyLong_SHIFT) {
                            return (signed char) ((((((((signed char)digits[2]) << PyLong_SHIFT) | (signed char)digits[1]) << PyLong_SHIFT) | (signed char)digits[0])));
                        }
                    }
                    break;
                case -4:
                    if (8 * sizeof(signed char) - 1 > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(signed char, long, -(long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(signed char) - 1 > 4 * PyLong_SHIFT) {
                            return (signed char) (((signed char)-1)*(((((((((signed char)digits[3]) << PyLong_SHIFT) | (signed char)digits[2]) << PyLong_SHIFT) | (signed char)digits[1]) << PyLong_SHIFT) | (signed char)digits[0])));
                        }
                    }
                    break;
                case 4:
                    if (8 * sizeof(signed char) > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(signed char, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(signed char) - 1 > 4 * PyLong_SHIFT) {
                            return (signed char) ((((((((((signed char)digits[3]) << PyLong_SHIFT) | (signed char)digits[2]) << PyLong_SHIFT) | (signed char)digits[1]) << PyLong_SHIFT) | (signed char)digits[0])));
                        }
                    }
                    break;
            }
#endif
            if (sizeof(signed char) <= sizeof(long)) {
                __PYX_VERIFY_RETURN_INT_EXC(signed char, long, PyLong_AsLong(x))
#ifdef HAVE_LONG_LONG
            } else if (sizeof(signed char) <= sizeof(PY_LONG_LONG)) {
                __PYX_VERIFY_RETURN_INT_EXC(signed char, PY_LONG_LONG, PyLong_AsLongLong(x))
#endif
            }
        }
        {
#if CYTHON_COMPILING_IN_PYPY && !defined(_PyLong_AsByteArray)
            PyErr_SetString(PyExc_RuntimeError,
                            "_PyLong_AsByteArray() not available in PyPy, cannot convert large numbers");
#else
            signed char val;
            PyObject *v = __Pyx_PyNumber_IntOrLong(x);
 #if PY_MAJOR_VERSION < 3
            if (likely(v) && !PyLong_Check(v)) {
                PyObject *tmp = v;
                v = PyNumber_Long(tmp);
                Py_DECREF(tmp);
            }
 #endif
            if (likely(v)) {
                int one = 1; int is_little = (int)*(unsigned char *)&one;
                unsigned char *bytes = (unsigned char *)&val;
                int ret = _PyLong_AsByteArray((PyLongObject *)v,
                                              bytes, sizeof(val),
                                              is_little, !is_unsigned);
                Py_DECREF(v);
                if (likely(!ret))
                    return val;
            }
#endif
            return (signed char) -1;
        }
    } else {
        signed char val;
        PyObject *tmp = __Pyx_PyNumber_IntOrLong(x);
        if (!tmp) return (signed char) -1;
        val = __Pyx_PyInt_As_signed__char(tmp);
        Py_DECREF(tmp);
        return val;
    }
raise_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "value too large to convert to signed char");
    return (signed char) -1;
raise_neg_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "can't convert negative value to signed char");
    return (signed char) -1;
}

/* CIntFromPy */
        static CYTHON_INLINE unsigned char __Pyx_PyInt_As_unsigned_char(PyObject *x) {
    const unsigned char neg_one = (unsigned char) -1, const_zero = (unsigned char) 0;
    const int is_unsigned = neg_one > const_zero;
#if PY_MAJOR_VERSION < 3
    if (likely(PyInt_Check(x))) {
        if (sizeof(unsigned char) < sizeof(long)) {
            __PYX_VERIFY_RETURN_INT(unsigned char, long, PyInt_AS_LONG(x))
        } else {
            long val = PyInt_AS_LONG(x);
            if (is_unsigned && unlikely(val < 0)) {
                goto raise_neg_overflow;
            }
            return (unsigned char) val;
        }
    } else
#endif
    if (likely(PyLong_Check(x))) {
        if (is_unsigned) {
#if CYTHON_USE_PYLONG_INTERNALS
            const digit* digits = ((PyLongObject*)x)->ob_digit;
            switch (Py_SIZE(x)) {
                case  0: return (unsigned char) 0;
                case  1: __PYX_VERIFY_RETURN_INT(unsigned char, digit, digits[0])
                case 2:
                    if (8 * sizeof(unsigned char) > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(unsigned char, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(unsigned char) >= 2 * PyLong_SHIFT) {
                            return (unsigned char) (((((unsigned char)digits[1]) << PyLong_SHIFT) | (unsigned char)digits[0]));
                        }
                    }
                    break;
                case 3:
                    if (8 * sizeof(unsigned char) > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(unsigned char, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(unsigned char) >= 3 * PyLong_SHIFT) {
                            return (unsigned char) (((((((unsigned char)digits[2]) << PyLong_SHIFT) | (unsigned char)digits[1]) << PyLong_SHIFT) | (unsigned char)digits[0]));
                        }
                    }
                    break;
                case 4:
                    if (8 * sizeof(unsigned char) > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(unsigned char, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(unsigned char) >= 4 * PyLong_SHIFT) {
                            return (unsigned char) (((((((((unsigned char)digits[3]) << PyLong_SHIFT) | (unsigned char)digits[2]) << PyLong_SHIFT) | (unsigned char)digits[1]) << PyLong_SHIFT) | (unsigned char)digits[0]));
                        }
                    }
                    break;
            }
#endif
#if CYTHON_COMPILING_IN_CPYTHON
            if (unlikely(Py_SIZE(x) < 0)) {
                goto raise_neg_overflow;
            }
#else
            {
                int result = PyObject_RichCompareBool(x, Py_False, Py_LT);
                if (unlikely(result < 0))
                    return (unsigned char) -1;
                if (unlikely(result == 1))
                    goto raise_neg_overflow;
            }
#endif
            if (sizeof(unsigned char) <= sizeof(unsigned long)) {
                __PYX_VERIFY_RETURN_INT_EXC(unsigned char, unsigned long, PyLong_AsUnsignedLong(x))
#ifdef HAVE_LONG_LONG
            } else if (sizeof(unsigned char) <= sizeof(unsigned PY_LONG_LONG)) {
                __PYX_VERIFY_RETURN_INT_EXC(unsigned char, unsigned PY_LONG_LONG, PyLong_AsUnsignedLongLong(x))
#endif
            }
        } else {
#if CYTHON_USE_PYLONG_INTERNALS
            const digit* digits = ((PyLongObject*)x)->ob_digit;
            switch (Py_SIZE(x)) {
                case  0: return (unsigned char) 0;
                case -1: __PYX_VERIFY_RETURN_INT(unsigned char, sdigit, (sdigit) (-(sdigit)digits[0]))
                case  1: __PYX_VERIFY_RETURN_INT(unsigned char,  digit, +digits[0])
                case -2:
                    if (8 * sizeof(unsigned char) - 1 > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(unsigned char, long, -(long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(unsigned char) - 1 > 2 * PyLong_SHIFT) {
                            return (unsigned char) (((unsigned char)-1)*(((((unsigned char)digits[1]) << PyLong_SHIFT) | (unsigned char)digits[0])));
                        }
                    }
                    break;
                case 2:
                    if (8 * sizeof(unsigned char) > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(unsigned char, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(unsigned char) - 1 > 2 * PyLong_SHIFT) {
                            return (unsigned char) ((((((unsigned char)digits[1]) << PyLong_SHIFT) | (unsigned char)digits[0])));
                        }
                    }
                    break;
                case -3:
                    if (8 * sizeof(unsigned char) - 1 > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(unsigned char, long, -(long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(unsigned char) - 1 > 3 * PyLong_SHIFT) {
                            return (unsigned char) (((unsigned char)-1)*(((((((unsigned char)digits[2]) << PyLong_SHIFT) | (unsigned char)digits[1]) << PyLong_SHIFT) | (unsigned char)digits[0])));
                        }
                    }
                    break;
                case 3:
                    if (8 * sizeof(unsigned char) > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(unsigned char, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(unsigned char) - 1 > 3 * PyLong_SHIFT) {
                            return (unsigned char) ((((((((unsigned char)digits[2]) << PyLong_SHIFT) | (unsigned char)digits[1]) << PyLong_SHIFT) | (unsigned char)digits[0])));
                        }
                    }
                    break;
                case -4:
                    if (8 * sizeof(unsigned char) - 1 > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(unsigned char, long, -(long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(unsigned char) - 1 > 4 * PyLong_SHIFT) {
                            return (unsigned char) (((unsigned char)-1)*(((((((((unsigned char)digits[3]) << PyLong_SHIFT) | (unsigned char)digits[2]) << PyLong_SHIFT) | (unsigned char)digits[1]) << PyLong_SHIFT) | (unsigned char)digits[0])));
                        }
                    }
                    break;
                case 4:
                    if (8 * sizeof(unsigned char) > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(unsigned char, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(unsigned char) - 1 > 4 * PyLong_SHIFT) {
                            return (unsigned char) ((((((((((unsigned char)digits[3]) << PyLong_SHIFT) | (unsigned char)digits[2]) << PyLong_SHIFT) | (unsigned char)digits[1]) << PyLong_SHIFT) | (unsigned char)digits[0])));
                        }
                    }
                    break;
            }
#endif
            if (sizeof(unsigned char) <= sizeof(long)) {
                __PYX_VERIFY_RETURN_INT_EXC(unsigned char, long, PyLong_AsLong(x))
#ifdef HAVE_LONG_LONG
            } else if (sizeof(unsigned char) <= sizeof(PY_LONG_LONG)) {
                __PYX_VERIFY_RETURN_INT_EXC(unsigned char, PY_LONG_LONG, PyLong_AsLongLong(x))
#endif
            }
        }
        {
#if CYTHON_COMPILING_IN_PYPY && !defined(_PyLong_AsByteArray)
            PyErr_SetString(PyExc_RuntimeError,
                            "_PyLong_AsByteArray() not available in PyPy, cannot convert large numbers");
#else
            unsigned char val;
            PyObject *v = __Pyx_PyNumber_IntOrLong(x);
 #if PY_MAJOR_VERSION < 3
            if (likely(v) && !PyLong_Check(v)) {
                PyObject *tmp = v;
                v = PyNumber_Long(tmp);
                Py_DECREF(tmp);
            }
 #endif
            if (likely(v)) {
                int one = 1; int is_little = (int)*(unsigned char *)&one;
                unsigned char *bytes = (unsigned char *)&val;
                int ret = _PyLong_AsByteArray((PyLongObject *)v,
                                              bytes, sizeof(val),
                                              is_little, !is_unsigned);
                Py_DECREF(v);
                if (likely(!ret))
                    return val;
            }
#endif
            return (unsigned char) -1;
        }
    } else {
        unsigned char val;
        PyObject *tmp = __Pyx_PyNumber_IntOrLong(x);
        if (!tmp) return (unsigned char) -1;
        val = __Pyx_PyInt_As_unsigned_char(tmp);
        Py_DECREF(tmp);
        return val;
    }
raise_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "value too large to convert to unsigned char");
    return (unsigned char) -1;
raise_neg_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "can't convert negative value to unsigned char");
    return (unsigned char) -1;
}

/* CIntFromPy */
        static CYTHON_INLINE short __Pyx_PyInt_As_short(PyObject *x) {
    const short neg_one = (short) -1, const_zero = (short) 0;
    const int is_unsigned = neg_one > const_zero;
#if PY_MAJOR_VERSION < 3
    if (likely(PyInt_Check(x))) {
        if (sizeof(short) < sizeof(long)) {
            __PYX_VERIFY_RETURN_INT(short, long, PyInt_AS_LONG(x))
        } else {
            long val = PyInt_AS_LONG(x);
            if (is_unsigned && unlikely(val < 0)) {
                goto raise_neg_overflow;
            }
            return (short) val;
        }
    } else
#endif
    if (likely(PyLong_Check(x))) {
        if (is_unsigned) {
#if CYTHON_USE_PYLONG_INTERNALS
            const digit* digits = ((PyLongObject*)x)->ob_digit;
            switch (Py_SIZE(x)) {
                case  0: return (short) 0;
                case  1: __PYX_VERIFY_RETURN_INT(short, digit, digits[0])
                case 2:
                    if (8 * sizeof(short) > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(short, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(short) >= 2 * PyLong_SHIFT) {
                            return (short) (((((short)digits[1]) << PyLong_SHIFT) | (short)digits[0]));
                        }
                    }
                    break;
                case 3:
                    if (8 * sizeof(short) > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(short, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(short) >= 3 * PyLong_SHIFT) {
                            return (short) (((((((short)digits[2]) << PyLong_SHIFT) | (short)digits[1]) << PyLong_SHIFT) | (short)digits[0]));
                        }
                    }
                    break;
                case 4:
                    if (8 * sizeof(short) > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(short, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(short) >= 4 * PyLong_SHIFT) {
                            return (short) (((((((((short)digits[3]) << PyLong_SHIFT) | (short)digits[2]) << PyLong_SHIFT) | (short)digits[1]) << PyLong_SHIFT) | (short)digits[0]));
                        }
                    }
                    break;
            }
#endif
#if CYTHON_COMPILING_IN_CPYTHON
            if (unlikely(Py_SIZE(x) < 0)) {
                goto raise_neg_overflow;
            }
#else
            {
                int result = PyObject_RichCompareBool(x, Py_False, Py_LT);
                if (unlikely(result < 0))
                    return (short) -1;
                if (unlikely(result == 1))
                    goto raise_neg_overflow;
            }
#endif
            if (sizeof(short) <= sizeof(unsigned long)) {
                __PYX_VERIFY_RETURN_INT_EXC(short, unsigned long, PyLong_AsUnsignedLong(x))
#ifdef HAVE_LONG_LONG
            } else if (sizeof(short) <= sizeof(unsigned PY_LONG_LONG)) {
                __PYX_VERIFY_RETURN_INT_EXC(short, unsigned PY_LONG_LONG, PyLong_AsUnsignedLongLong(x))
#endif
            }
        } else {
#if CYTHON_USE_PYLONG_INTERNALS
            const digit* digits = ((PyLongObject*)x)->ob_digit;
            switch (Py_SIZE(x)) {
                case  0: return (short) 0;
                case -1: __PYX_VERIFY_RETURN_INT(short, sdigit, (sdigit) (-(sdigit)digits[0]))
                case  1: __PYX_VERIFY_RETURN_INT(short,  digit, +digits[0])
                case -2:
                    if (8 * sizeof(short) - 1 > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(short, long, -(long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(short) - 1 > 2 * PyLong_SHIFT) {
                            return (short) (((short)-1)*(((((short)digits[1]) << PyLong_SHIFT) | (short)digits[0])));
                        }
                    }
                    break;
                case 2:
                    if (8 * sizeof(short) > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(short, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(short) - 1 > 2 * PyLong_SHIFT) {
                            return (short) ((((((short)digits[1]) << PyLong_SHIFT) | (short)digits[0])));
                        }
                    }
                    break;
                case -3:
                    if (8 * sizeof(short) - 1 > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(short, long, -(long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(short) - 1 > 3 * PyLong_SHIFT) {
                            return (short) (((short)-1)*(((((((short)digits[2]) << PyLong_SHIFT) | (short)digits[1]) << PyLong_SHIFT) | (short)digits[0])));
                        }
                    }
                    break;
                case 3:
                    if (8 * sizeof(short) > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(short, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(short) - 1 > 3 * PyLong_SHIFT) {
                            return (short) ((((((((short)digits[2]) << PyLong_SHIFT) | (short)digits[1]) << PyLong_SHIFT) | (short)digits[0])));
                        }
                    }
                    break;
                case -4:
                    if (8 * sizeof(short) - 1 > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(short, long, -(long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(short) - 1 > 4 * PyLong_SHIFT) {
                            return (short) (((short)-1)*(((((((((short)digits[3]) << PyLong_SHIFT) | (short)digits[2]) << PyLong_SHIFT) | (short)digits[1]) << PyLong_SHIFT) | (short)digits[0])));
                        }
                    }
                    break;
                case 4:
                    if (8 * sizeof(short) > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(short, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(short) - 1 > 4 * PyLong_SHIFT) {
                            return (short) ((((((((((short)digits[3]) << PyLong_SHIFT) | (short)digits[2]) << PyLong_SHIFT) | (short)digits[1]) << PyLong_SHIFT) | (short)digits[0])));
                        }
                    }
                    break;
            }
#endif
            if (sizeof(short) <= sizeof(long)) {
                __PYX_VERIFY_RETURN_INT_EXC(short, long, PyLong_AsLong(x))
#ifdef HAVE_LONG_LONG
            } else if (sizeof(short) <= sizeof(PY_LONG_LONG)) {
                __PYX_VERIFY_RETURN_INT_EXC(short, PY_LONG_LONG, PyLong_AsLongLong(x))
#endif
            }
        }
        {
#if CYTHON_COMPILING_IN_PYPY && !defined(_PyLong_AsByteArray)
            PyErr_SetString(PyExc_RuntimeError,
                            "_PyLong_AsByteArray() not available in PyPy, cannot convert large numbers");
#else
            short val;
            PyObject *v = __Pyx_PyNumber_IntOrLong(x);
 #if PY_MAJOR_VERSION < 3
            if (likely(v) && !PyLong_Check(v)) {
                PyObject *tmp = v;
                v = PyNumber_Long(tmp);
                Py_DECREF(tmp);
            }
 #endif
            if (likely(v)) {
                int one = 1; int is_little = (int)*(unsigned char *)&one;
                unsigned char *bytes = (unsigned char *)&val;
                int ret = _PyLong_AsByteArray((PyLongObject *)v,
                                              bytes, sizeof(val),
                                              is_little, !is_unsigned);
                Py_DECREF(v);
                if (likely(!ret))
                    return val;
            }
#endif
            return (short) -1;
        }
    } else {
        short val;
        PyObject *tmp = __Pyx_PyNumber_IntOrLong(x);
        if (!tmp) return (short) -1;
        val = __Pyx_PyInt_As_short(tmp);
        Py_DECREF(tmp);
        return val;
    }
raise_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "value too large to convert to short");
    return (short) -1;
raise_neg_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "can't convert negative value to short");
    return (short) -1;
}

/* CIntFromPy */
        static CYTHON_INLINE unsigned short __Pyx_PyInt_As_unsigned_short(PyObject *x) {
    const unsigned short neg_one = (unsigned short) -1, const_zero = (unsigned short) 0;
    const int is_unsigned = neg_one > const_zero;
#if PY_MAJOR_VERSION < 3
    if (likely(PyInt_Check(x))) {
        if (sizeof(unsigned short) < sizeof(long)) {
            __PYX_VERIFY_RETURN_INT(unsigned short, long, PyInt_AS_LONG(x))
        } else {
            long val = PyInt_AS_LONG(x);
            if (is_unsigned && unlikely(val < 0)) {
                goto raise_neg_overflow;
            }
            return (unsigned short) val;
        }
    } else
#endif
    if (likely(PyLong_Check(x))) {
        if (is_unsigned) {
#if CYTHON_USE_PYLONG_INTERNALS
            const digit* digits = ((PyLongObject*)x)->ob_digit;
            switch (Py_SIZE(x)) {
                case  0: return (unsigned short) 0;
                case  1: __PYX_VERIFY_RETURN_INT(unsigned short, digit, digits[0])
                case 2:
                    if (8 * sizeof(unsigned short) > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(unsigned short, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(unsigned short) >= 2 * PyLong_SHIFT) {
                            return (unsigned short) (((((unsigned short)digits[1]) << PyLong_SHIFT) | (unsigned short)digits[0]));
                        }
                    }
                    break;
                case 3:
                    if (8 * sizeof(unsigned short) > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(unsigned short, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(unsigned short) >= 3 * PyLong_SHIFT) {
                            return (unsigned short) (((((((unsigned short)digits[2]) << PyLong_SHIFT) | (unsigned short)digits[1]) << PyLong_SHIFT) | (unsigned short)digits[0]));
                        }
                    }
                    break;
                case 4:
                    if (8 * sizeof(unsigned short) > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(unsigned short, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(unsigned short) >= 4 * PyLong_SHIFT) {
                            return (unsigned short) (((((((((unsigned short)digits[3]) << PyLong_SHIFT) | (unsigned short)digits[2]) << PyLong_SHIFT) | (unsigned short)digits[1]) << PyLong_SHIFT) | (unsigned short)digits[0]));
                        }
                    }
                    break;
            }
#endif
#if CYTHON_COMPILING_IN_CPYTHON
            if (unlikely(Py_SIZE(x) < 0)) {
                goto raise_neg_overflow;
            }
#else
            {
                int result = PyObject_RichCompareBool(x, Py_False, Py_LT);
                if (unlikely(result < 0))
                    return (unsigned short) -1;
                if (unlikely(result == 1))
                    goto raise_neg_overflow;
            }
#endif
            if (sizeof(unsigned short) <= sizeof(unsigned long)) {
                __PYX_VERIFY_RETURN_INT_EXC(unsigned short, unsigned long, PyLong_AsUnsignedLong(x))
#ifdef HAVE_LONG_LONG
            } else if (sizeof(unsigned short) <= sizeof(unsigned PY_LONG_LONG)) {
                __PYX_VERIFY_RETURN_INT_EXC(unsigned short, unsigned PY_LONG_LONG, PyLong_AsUnsignedLongLong(x))
#endif
            }
        } else {
#if CYTHON_USE_PYLONG_INTERNALS
            const digit* digits = ((PyLongObject*)x)->ob_digit;
            switch (Py_SIZE(x)) {
                case  0: return (unsigned short) 0;
                case -1: __PYX_VERIFY_RETURN_INT(unsigned short, sdigit, (sdigit) (-(sdigit)digits[0]))
                case  1: __PYX_VERIFY_RETURN_INT(unsigned short,  digit, +digits[0])
                case -2:
                    if (8 * sizeof(unsigned short) - 1 > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(unsigned short, long, -(long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(unsigned short) - 1 > 2 * PyLong_SHIFT) {
                            return (unsigned short) (((unsigned short)-1)*(((((unsigned short)digits[1]) << PyLong_SHIFT) | (unsigned short)digits[0])));
                        }
                    }
                    break;
                case 2:
                    if (8 * sizeof(unsigned short) > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(unsigned short, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(unsigned short) - 1 > 2 * PyLong_SHIFT) {
                            return (unsigned short) ((((((unsigned short)digits[1]) << PyLong_SHIFT) | (unsigned short)digits[0])));
                        }
                    }
                    break;
                case -3:
                    if (8 * sizeof(unsigned short) - 1 > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(unsigned short, long, -(long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(unsigned short) - 1 > 3 * PyLong_SHIFT) {
                            return (unsigned short) (((unsigned short)-1)*(((((((unsigned short)digits[2]) << PyLong_SHIFT) | (unsigned short)digits[1]) << PyLong_SHIFT) | (unsigned short)digits[0])));
                        }
                    }
                    break;
                case 3:
                    if (8 * sizeof(unsigned short) > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(unsigned short, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(unsigned short) - 1 > 3 * PyLong_SHIFT) {
                            return (unsigned short) ((((((((unsigned short)digits[2]) << PyLong_SHIFT) | (unsigned short)digits[1]) << PyLong_SHIFT) | (unsigned short)digits[0])));
                        }
                    }
                    break;
                case -4:
                    if (8 * sizeof(unsigned short) - 1 > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(unsigned short, long, -(long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(unsigned short) - 1 > 4 * PyLong_SHIFT) {
                            return (unsigned short) (((unsigned short)-1)*(((((((((unsigned short)digits[3]) << PyLong_SHIFT) | (unsigned short)digits[2]) << PyLong_SHIFT) | (unsigned short)digits[1]) << PyLong_SHIFT) | (unsigned short)digits[0])));
                        }
                    }
                    break;
                case 4:
                    if (8 * sizeof(unsigned short) > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(unsigned short, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(unsigned short) - 1 > 4 * PyLong_SHIFT) {
                            return (unsigned short) ((((((((((unsigned short)digits[3]) << PyLong_SHIFT) | (unsigned short)digits[2]) << PyLong_SHIFT) | (unsigned short)digits[1]) << PyLong_SHIFT) | (unsigned short)digits[0])));
                        }
                    }
                    break;
            }
#endif
            if (sizeof(unsigned short) <= sizeof(long)) {
                __PYX_VERIFY_RETURN_INT_EXC(unsigned short, long, PyLong_AsLong(x))
#ifdef HAVE_LONG_LONG
            } else if (sizeof(unsigned short) <= sizeof(PY_LONG_LONG)) {
                __PYX_VERIFY_RETURN_INT_EXC(unsigned short, PY_LONG_LONG, PyLong_AsLongLong(x))
#endif
            }
        }
        {
#if CYTHON_COMPILING_IN_PYPY && !defined(_PyLong_AsByteArray)
            PyErr_SetString(PyExc_RuntimeError,
                            "_PyLong_AsByteArray() not available in PyPy, cannot convert large numbers");
#else
            unsigned short val;
            PyObject *v = __Pyx_PyNumber_IntOrLong(x);
 #if PY_MAJOR_VERSION < 3
            if (likely(v) && !PyLong_Check(v)) {
                PyObject *tmp = v;
                v = PyNumber_Long(tmp);
                Py_DECREF(tmp);
            }
 #endif
            if (likely(v)) {
                int one = 1; int is_little = (int)*(unsigned char *)&one;
                unsigned char *bytes = (unsigned char *)&val;
                int ret = _PyLong_AsByteArray((PyLongObject *)v,
                                              bytes, sizeof(val),
                                              is_little, !is_unsigned);
                Py_DECREF(v);
                if (likely(!ret))
                    return val;
            }
#endif
            return (unsigned short) -1;
        }
    } else {
        unsigned short val;
        PyObject *tmp = __Pyx_PyNumber_IntOrLong(x);
        if (!tmp) return (unsigned short) -1;
        val = __Pyx_PyInt_As_unsigned_short(tmp);
        Py_DECREF(tmp);
        return val;
    }
raise_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "value too large to convert to unsigned short");
    return (unsigned short) -1;
raise_neg_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "can't convert negative value to unsigned short");
    return (unsigned short) -1;
}

/* CIntFromPy */
        static CYTHON_INLINE long __Pyx_PyInt_As_long(PyObject *x) {
    const long neg_one = (long) -1, const_zero = (long) 0;
    const int is_unsigned = neg_one > const_zero;
#if PY_MAJOR_VERSION < 3
    if (likely(PyInt_Check(x))) {
        if (sizeof(long) < sizeof(long)) {
            __PYX_VERIFY_RETURN_INT(long, long, PyInt_AS_LONG(x))
        } else {
            long val = PyInt_AS_LONG(x);
            if (is_unsigned && unlikely(val < 0)) {
                goto raise_neg_overflow;
            }
            return (long) val;
        }
    } else
#endif
    if (likely(PyLong_Check(x))) {
        if (is_unsigned) {
#if CYTHON_USE_PYLONG_INTERNALS
            const digit* digits = ((PyLongObject*)x)->ob_digit;
            switch (Py_SIZE(x)) {
                case  0: return (long) 0;
                case  1: __PYX_VERIFY_RETURN_INT(long, digit, digits[0])
                case 2:
                    if (8 * sizeof(long) > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) >= 2 * PyLong_SHIFT) {
                            return (long) (((((long)digits[1]) << PyLong_SHIFT) | (long)digits[0]));
                        }
                    }
                    break;
                case 3:
                    if (8 * sizeof(long) > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) >= 3 * PyLong_SHIFT) {
                            return (long) (((((((long)digits[2]) << PyLong_SHIFT) | (long)digits[1]) << PyLong_SHIFT) | (long)digits[0]));
                        }
                    }
                    break;
                case 4:
                    if (8 * sizeof(long) > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) >= 4 * PyLong_SHIFT) {
                            return (long) (((((((((long)digits[3]) << PyLong_SHIFT) | (long)digits[2]) << PyLong_SHIFT) | (long)digits[1]) << PyLong_SHIFT) | (long)digits[0]));
                        }
                    }
                    break;
            }
#endif
#if CYTHON_COMPILING_IN_CPYTHON
            if (unlikely(Py_SIZE(x) < 0)) {
                goto raise_neg_overflow;
            }
#else
            {
                int result = PyObject_RichCompareBool(x, Py_False, Py_LT);
                if (unlikely(result < 0))
                    return (long) -1;
                if (unlikely(result == 1))
                    goto raise_neg_overflow;
            }
#endif
            if (sizeof(long) <= sizeof(unsigned long)) {
                __PYX_VERIFY_RETURN_INT_EXC(long, unsigned long, PyLong_AsUnsignedLong(x))
#ifdef HAVE_LONG_LONG
            } else if (sizeof(long) <= sizeof(unsigned PY_LONG_LONG)) {
                __PYX_VERIFY_RETURN_INT_EXC(long, unsigned PY_LONG_LONG, PyLong_AsUnsignedLongLong(x))
#endif
            }
        } else {
#if CYTHON_USE_PYLONG_INTERNALS
            const digit* digits = ((PyLongObject*)x)->ob_digit;
            switch (Py_SIZE(x)) {
                case  0: return (long) 0;
                case -1: __PYX_VERIFY_RETURN_INT(long, sdigit, (sdigit) (-(sdigit)digits[0]))
                case  1: __PYX_VERIFY_RETURN_INT(long,  digit, +digits[0])
                case -2:
                    if (8 * sizeof(long) - 1 > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, long, -(long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) - 1 > 2 * PyLong_SHIFT) {
                            return (long) (((long)-1)*(((((long)digits[1]) << PyLong_SHIFT) | (long)digits[0])));
                        }
                    }
                    break;
                case 2:
                    if (8 * sizeof(long) > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) - 1 > 2 * PyLong_SHIFT) {
                            return (long) ((((((long)digits[1]) << PyLong_SHIFT) | (long)digits[0])));
                        }
                    }
                    break;
                case -3:
                    if (8 * sizeof(long) - 1 > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, long, -(long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) - 1 > 3 * PyLong_SHIFT) {
                            return (long) (((long)-1)*(((((((long)digits[2]) << PyLong_SHIFT) | (long)digits[1]) << PyLong_SHIFT) | (long)digits[0])));
                        }
                    }
                    break;
                case 3:
                    if (8 * sizeof(long) > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) - 1 > 3 * PyLong_SHIFT) {
                            return (long) ((((((((long)digits[2]) << PyLong_SHIFT) | (long)digits[1]) << PyLong_SHIFT) | (long)digits[0])));
                        }
                    }
                    break;
                case -4:
                    if (8 * sizeof(long) - 1 > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, long, -(long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) - 1 > 4 * PyLong_SHIFT) {
                            return (long) (((long)-1)*(((((((((long)digits[3]) << PyLong_SHIFT) | (long)digits[2]) << PyLong_SHIFT) | (long)digits[1]) << PyLong_SHIFT) | (long)digits[0])));
                        }
                    }
                    break;
                case 4:
                    if (8 * sizeof(long) > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) - 1 > 4 * PyLong_SHIFT) {
                            return (long) ((((((((((long)digits[3]) << PyLong_SHIFT) | (long)digits[2]) << PyLong_SHIFT) | (long)digits[1]) << PyLong_SHIFT) | (long)digits[0])));
                        }
                    }
                    break;
            }
#endif
            if (sizeof(long) <= sizeof(long)) {
                __PYX_VERIFY_RETURN_INT_EXC(long, long, PyLong_AsLong(x))
#ifdef HAVE_LONG_LONG
            } else if (sizeof(long) <= sizeof(PY_LONG_LONG)) {
                __PYX_VERIFY_RETURN_INT_EXC(long, PY_LONG_LONG, PyLong_AsLongLong(x))
#endif
            }
        }
        {
#if CYTHON_COMPILING_IN_PYPY && !defined(_PyLong_AsByteArray)
            PyErr_SetString(PyExc_RuntimeError,
                            "_PyLong_AsByteArray() not available in PyPy, cannot convert large numbers");
#else
            long val;
            PyObject *v = __Pyx_PyNumber_IntOrLong(x);
 #if PY_MAJOR_VERSION < 3
            if (likely(v) && !PyLong_Check(v)) {
                PyObject *tmp = v;
                v = PyNumber_Long(tmp);
                Py_DECREF(tmp);
            }
 #endif
            if (likely(v)) {
                int one = 1; int is_little = (int)*(unsigned char *)&one;
                unsigned char *bytes = (unsigned char *)&val;
                int ret = _PyLong_AsByteArray((PyLongObject *)v,
                                              bytes, sizeof(val),
                                              is_little, !is_unsigned);
                Py_DECREF(v);
                if (likely(!ret))
                    return val;
            }
#endif
            return (long) -1;
        }
    } else {
        long val;
        PyObject *tmp = __Pyx_PyNumber_IntOrLong(x);
        if (!tmp) return (long) -1;
        val = __Pyx_PyInt_As_long(tmp);
        Py_DECREF(tmp);
        return val;
    }
raise_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "value too large to convert to long");
    return (long) -1;
raise_neg_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "can't convert negative value to long");
    return (long) -1;
}

/* CIntFromPy */
        static CYTHON_INLINE unsigned long __Pyx_PyInt_As_unsigned_long(PyObject *x) {
    const unsigned long neg_one = (unsigned long) -1, const_zero = (unsigned long) 0;
    const int is_unsigned = neg_one > const_zero;
#if PY_MAJOR_VERSION < 3
    if (likely(PyInt_Check(x))) {
        if (sizeof(unsigned long) < sizeof(long)) {
            __PYX_VERIFY_RETURN_INT(unsigned long, long, PyInt_AS_LONG(x))
        } else {
            long val = PyInt_AS_LONG(x);
            if (is_unsigned && unlikely(val < 0)) {
                goto raise_neg_overflow;
            }
            return (unsigned long) val;
        }
    } else
#endif
    if (likely(PyLong_Check(x))) {
        if (is_unsigned) {
#if CYTHON_USE_PYLONG_INTERNALS
            const digit* digits = ((PyLongObject*)x)->ob_digit;
            switch (Py_SIZE(x)) {
                case  0: return (unsigned long) 0;
                case  1: __PYX_VERIFY_RETURN_INT(unsigned long, digit, digits[0])
                case 2:
                    if (8 * sizeof(unsigned long) > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(unsigned long, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(unsigned long) >= 2 * PyLong_SHIFT) {
                            return (unsigned long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        }
                    }
                    break;
                case 3:
                    if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(unsigned long, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(unsigned long) >= 3 * PyLong_SHIFT) {
                            return (unsigned long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        }
                    }
                    break;
                case 4:
                    if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(unsigned long, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(unsigned long) >= 4 * PyLong_SHIFT) {
                            return (unsigned long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        }
                    }
                    break;
            }
#endif
#if CYTHON_COMPILING_IN_CPYTHON
            if (unlikely(Py_SIZE(x) < 0)) {
                goto raise_neg_overflow;
            }
#else
            {
                int result = PyObject_RichCompareBool(x, Py_False, Py_LT);
                if (unlikely(result < 0))
                    return (unsigned long) -1;
                if (unlikely(result == 1))
                    goto raise_neg_overflow;
            }
#endif
            if (sizeof(unsigned long) <= sizeof(unsigned long)) {
                __PYX_VERIFY_RETURN_INT_EXC(unsigned long, unsigned long, PyLong_AsUnsignedLong(x))
#ifdef HAVE_LONG_LONG
            } else if (sizeof(unsigned long) <= sizeof(unsigned PY_LONG_LONG)) {
                __PYX_VERIFY_RETURN_INT_EXC(unsigned long, unsigned PY_LONG_LONG, PyLong_AsUnsignedLongLong(x))
#endif
            }
        } else {
#if CYTHON_USE_PYLONG_INTERNALS
            const digit* digits = ((PyLongObject*)x)->ob_digit;
            switch (Py_SIZE(x)) {
                case  0: return (unsigned long) 0;
                case -1: __PYX_VERIFY_RETURN_INT(unsigned long, sdigit, (sdigit) (-(sdigit)digits[0]))
                case  1: __PYX_VERIFY_RETURN_INT(unsigned long,  digit, +digits[0])
                case -2:
                    if (8 * sizeof(unsigned long) - 1 > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(unsigned long, long, -(long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(unsigned long) - 1 > 2 * PyLong_SHIFT) {
                            return (unsigned long) (((unsigned long)-1)*(((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])));
                        }
                    }
                    break;
                case 2:
                    if (8 * sizeof(unsigned long) > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(unsigned long, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(unsigned long) - 1 > 2 * PyLong_SHIFT) {
                            return (unsigned long) ((((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])));
                        }
                    }
                    break;
                case -3:
                    if (8 * sizeof(unsigned long) - 1 > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(unsigned long, long, -(long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(unsigned long) - 1 > 3 * PyLong_SHIFT) {
                            return (unsigned long) (((unsigned long)-1)*(((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])));
                        }
                    }
                    break;
                case 3:
                    if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(unsigned long, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(unsigned long) - 1 > 3 * PyLong_SHIFT) {
                            return (unsigned long) ((((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])));
                        }
                    }
                    break;
                case -4:
                    if (8 * sizeof(unsigned long) - 1 > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(unsigned long, long, -(long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(unsigned long) - 1 > 4 * PyLong_SHIFT) {
                            return (unsigned long) (((unsigned long)-1)*(((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])));
                        }
                    }
                    break;
                case 4:
                    if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(unsigned long, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(unsigned long) - 1 > 4 * PyLong_SHIFT) {
                            return (unsigned long) ((((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])));
                        }
                    }
                    break;
            }
#endif
            if (sizeof(unsigned long) <= sizeof(long)) {
                __PYX_VERIFY_RETURN_INT_EXC(unsigned long, long, PyLong_AsLong(x))
#ifdef HAVE_LONG_LONG
            } else if (sizeof(unsigned long) <= sizeof(PY_LONG_LONG)) {
                __PYX_VERIFY_RETURN_INT_EXC(unsigned long, PY_LONG_LONG, PyLong_AsLongLong(x))
#endif
            }
        }
        {
#if CYTHON_COMPILING_IN_PYPY && !defined(_PyLong_AsByteArray)
            PyErr_SetString(PyExc_RuntimeError,
                            "_PyLong_AsByteArray() not available in PyPy, cannot convert large numbers");
#else
            unsigned long val;
            PyObject *v = __Pyx_PyNumber_IntOrLong(x);
 #if PY_MAJOR_VERSION < 3
            if (likely(v) && !PyLong_Check(v)) {
                PyObject *tmp = v;
                v = PyNumber_Long(tmp);
                Py_DECREF(tmp);
            }
 #endif
            if (likely(v)) {
                int one = 1; int is_little = (int)*(unsigned char *)&one;
                unsigned char *bytes = (unsigned char *)&val;
                int ret = _PyLong_AsByteArray((PyLongObject *)v,
                                              bytes, sizeof(val),
                                              is_little, !is_unsigned);
                Py_DECREF(v);
                if (likely(!ret))
                    return val;
            }
#endif
            return (unsigned long) -1;
        }
    } else {
        unsigned long val;
        PyObject *tmp = __Pyx_PyNumber_IntOrLong(x);
        if (!tmp) return (unsigned long) -1;
        val = __Pyx_PyInt_As_unsigned_long(tmp);
        Py_DECREF(tmp);
        return val;
    }
raise_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "value too large to convert to unsigned long");
    return (unsigned long) -1;
raise_neg_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "can't convert negative value to unsigned long");
    return (unsigned long) -1;
}

/* FastTypeChecks */
        #if CYTHON_COMPILING_IN_CPYTHON
static int __Pyx_InBases(PyTypeObject *a, PyTypeObject *b) {
    while (a) {
        a = a->tp_base;
        if (a == b)
            return 1;
    }
    return b == &PyBaseObject_Type;
}
static CYTHON_INLINE int __Pyx_IsSubtype(PyTypeObject *a, PyTypeObject *b) {
    PyObject *mro;
    if (a == b) return 1;
    mro = a->tp_mro;
    if (likely(mro)) {
        Py_ssize_t i, n;
        n = PyTuple_GET_SIZE(mro);
        for (i = 0; i < n; i++) {
            if (PyTuple_GET_ITEM(mro, i) == (PyObject *)b)
                return 1;
        }
        return 0;
    }
    return __Pyx_InBases(a, b);
}
#if PY_MAJOR_VERSION == 2
static int __Pyx_inner_PyErr_GivenExceptionMatches2(PyObject *err, PyObject* exc_type1, PyObject* exc_type2) {
    PyObject *exception, *value, *tb;
    int res;
    __Pyx_PyThreadState_declare
    __Pyx_PyThreadState_assign
    __Pyx_ErrFetch(&exception, &value, &tb);
    res = exc_type1 ? PyObject_IsSubclass(err, exc_type1) : 0;
    if (unlikely(res == -1)) {
        PyErr_WriteUnraisable(err);
        res = 0;
    }
    if (!res) {
        res = PyObject_IsSubclass(err, exc_type2);
        if (unlikely(res == -1)) {
            PyErr_WriteUnraisable(err);
            res = 0;
        }
    }
    __Pyx_ErrRestore(exception, value, tb);
    return res;
}
#else
static CYTHON_INLINE int __Pyx_inner_PyErr_GivenExceptionMatches2(PyObject *err, PyObject* exc_type1, PyObject *exc_type2) {
    int res = exc_type1 ? __Pyx_IsSubtype((PyTypeObject*)err, (PyTypeObject*)exc_type1) : 0;
    if (!res) {
        res = __Pyx_IsSubtype((PyTypeObject*)err, (PyTypeObject*)exc_type2);
    }
    return res;
}
#endif
static CYTHON_INLINE int __Pyx_PyErr_GivenExceptionMatches(PyObject *err, PyObject* exc_type) {
    if (likely(err == exc_type)) return 1;
    if (likely(PyExceptionClass_Check(err))) {
        return __Pyx_inner_PyErr_GivenExceptionMatches2(err, NULL, exc_type);
    }
    return PyErr_GivenExceptionMatches(err, exc_type);
}
static CYTHON_INLINE int __Pyx_PyErr_GivenExceptionMatches2(PyObject *err, PyObject *exc_type1, PyObject *exc_type2) {
    if (likely(err == exc_type1 || err == exc_type2)) return 1;
    if (likely(PyExceptionClass_Check(err))) {
        return __Pyx_inner_PyErr_GivenExceptionMatches2(err, exc_type1, exc_type2);
    }
    return (PyErr_GivenExceptionMatches(err, exc_type1) || PyErr_GivenExceptionMatches(err, exc_type2));
}
#endif

/* FetchCommonType */
        static PyTypeObject* __Pyx_FetchCommonType(PyTypeObject* type) {
    PyObject* fake_module;
    PyTypeObject* cached_type = NULL;
    fake_module = PyImport_AddModule((char*) "_cython_" CYTHON_ABI);
    if (!fake_module) return NULL;
    Py_INCREF(fake_module);
    cached_type = (PyTypeObject*) PyObject_GetAttrString(fake_module, type->tp_name);
    if (cached_type) {
        if (!PyType_Check((PyObject*)cached_type)) {
            PyErr_Format(PyExc_TypeError,
                "Shared Cython type %.200s is not a type object",
                type->tp_name);
            goto bad;
        }
        if (cached_type->tp_basicsize != type->tp_basicsize) {
            PyErr_Format(PyExc_TypeError,
                "Shared Cython type %.200s has the wrong size, try recompiling",
                type->tp_name);
            goto bad;
        }
    } else {
        if (!PyErr_ExceptionMatches(PyExc_AttributeError)) goto bad;
        PyErr_Clear();
        if (PyType_Ready(type) < 0) goto bad;
        if (PyObject_SetAttrString(fake_module, type->tp_name, (PyObject*) type) < 0)
            goto bad;
        Py_INCREF(type);
        cached_type = type;
    }
done:
    Py_DECREF(fake_module);
    return cached_type;
bad:
    Py_XDECREF(cached_type);
    cached_type = NULL;
    goto done;
}

/* PyObjectCallMethod1 */
        static PyObject* __Pyx__PyObject_CallMethod1(PyObject* method, PyObject* arg) {
    PyObject *result = NULL;
#if CYTHON_UNPACK_METHODS
    if (likely(PyMethod_Check(method))) {
        PyObject *self = PyMethod_GET_SELF(method);
        if (likely(self)) {
            PyObject *args;
            PyObject *function = PyMethod_GET_FUNCTION(method);
            #if CYTHON_FAST_PYCALL
            if (PyFunction_Check(function)) {
                PyObject *args[2] = {self, arg};
                result = __Pyx_PyFunction_FastCall(function, args, 2);
                goto done;
            }
            #endif
            #if CYTHON_FAST_PYCCALL
            if (__Pyx_PyFastCFunction_Check(function)) {
                PyObject *args[2] = {self, arg};
                result = __Pyx_PyCFunction_FastCall(function, args, 2);
                goto done;
            }
            #endif
            args = PyTuple_New(2);
            if (unlikely(!args)) goto done;
            Py_INCREF(self);
            PyTuple_SET_ITEM(args, 0, self);
            Py_INCREF(arg);
            PyTuple_SET_ITEM(args, 1, arg);
            Py_INCREF(function);
            result = __Pyx_PyObject_Call(function, args, NULL);
            Py_DECREF(args);
            Py_DECREF(function);
            return result;
        }
    }
#endif
    result = __Pyx_PyObject_CallOneArg(method, arg);
    goto done;
done:
    return result;
}
static PyObject* __Pyx_PyObject_CallMethod1(PyObject* obj, PyObject* method_name, PyObject* arg) {
    PyObject *method, *result = NULL;
    method = __Pyx_PyObject_GetAttrStr(obj, method_name);
    if (unlikely(!method)) goto done;
    result = __Pyx__PyObject_CallMethod1(method, arg);
done:
    Py_XDECREF(method);
    return result;
}

/* CoroutineBase */
        #include <structmember.h>
#include <frameobject.h>
#define __Pyx_Coroutine_Undelegate(gen) Py_CLEAR((gen)->yieldfrom)
static int __Pyx_PyGen__FetchStopIterationValue(CYTHON_UNUSED PyThreadState *__pyx_tstate, PyObject **pvalue) {
    PyObject *et, *ev, *tb;
    PyObject *value = NULL;
    __Pyx_ErrFetch(&et, &ev, &tb);
    if (!et) {
        Py_XDECREF(tb);
        Py_XDECREF(ev);
        Py_INCREF(Py_None);
        *pvalue = Py_None;
        return 0;
    }
    if (likely(et == PyExc_StopIteration)) {
        if (!ev) {
            Py_INCREF(Py_None);
            value = Py_None;
        }
#if PY_VERSION_HEX >= 0x030300A0
        else if (Py_TYPE(ev) == (PyTypeObject*)PyExc_StopIteration) {
            value = ((PyStopIterationObject *)ev)->value;
            Py_INCREF(value);
            Py_DECREF(ev);
        }
#endif
        else if (unlikely(PyTuple_Check(ev))) {
            if (PyTuple_GET_SIZE(ev) >= 1) {
#if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
                value = PyTuple_GET_ITEM(ev, 0);
                Py_INCREF(value);
#else
                value = PySequence_ITEM(ev, 0);
#endif
            } else {
                Py_INCREF(Py_None);
                value = Py_None;
            }
            Py_DECREF(ev);
        }
        else if (!__Pyx_TypeCheck(ev, (PyTypeObject*)PyExc_StopIteration)) {
            value = ev;
        }
        if (likely(value)) {
            Py_XDECREF(tb);
            Py_DECREF(et);
            *pvalue = value;
            return 0;
        }
    } else if (!__Pyx_PyErr_GivenExceptionMatches(et, PyExc_StopIteration)) {
        __Pyx_ErrRestore(et, ev, tb);
        return -1;
    }
    PyErr_NormalizeException(&et, &ev, &tb);
    if (unlikely(!PyObject_TypeCheck(ev, (PyTypeObject*)PyExc_StopIteration))) {
        __Pyx_ErrRestore(et, ev, tb);
        return -1;
    }
    Py_XDECREF(tb);
    Py_DECREF(et);
#if PY_VERSION_HEX >= 0x030300A0
    value = ((PyStopIterationObject *)ev)->value;
    Py_INCREF(value);
    Py_DECREF(ev);
#else
    {
        PyObject* args = __Pyx_PyObject_GetAttrStr(ev, __pyx_n_s_args);
        Py_DECREF(ev);
        if (likely(args)) {
            value = PySequence_GetItem(args, 0);
            Py_DECREF(args);
        }
        if (unlikely(!value)) {
            __Pyx_ErrRestore(NULL, NULL, NULL);
            Py_INCREF(Py_None);
            value = Py_None;
        }
    }
#endif
    *pvalue = value;
    return 0;
}
static CYTHON_INLINE
void __Pyx_Coroutine_ExceptionClear(__pyx_CoroutineObject *self) {
    PyObject *exc_type = self->exc_type;
    PyObject *exc_value = self->exc_value;
    PyObject *exc_traceback = self->exc_traceback;
    self->exc_type = NULL;
    self->exc_value = NULL;
    self->exc_traceback = NULL;
    Py_XDECREF(exc_type);
    Py_XDECREF(exc_value);
    Py_XDECREF(exc_traceback);
}
#define __Pyx_Coroutine_AlreadyRunningError(gen)  (__Pyx__Coroutine_AlreadyRunningError(gen), (PyObject*)NULL)
static void __Pyx__Coroutine_AlreadyRunningError(CYTHON_UNUSED __pyx_CoroutineObject *gen) {
    const char *msg;
    if (0) {
    #ifdef __Pyx_Coroutine_USED
    } else if (__Pyx_Coroutine_CheckExact((PyObject*)gen)) {
        msg = "coroutine already executing";
    #endif
    #ifdef __Pyx_AsyncGen_USED
    } else if (__Pyx_AsyncGen_CheckExact((PyObject*)gen)) {
        msg = "async generator already executing";
    #endif
    } else {
        msg = "generator already executing";
    }
    PyErr_SetString(PyExc_ValueError, msg);
}
#define __Pyx_Coroutine_NotStartedError(gen)  (__Pyx__Coroutine_NotStartedError(gen), (PyObject*)NULL)
static void __Pyx__Coroutine_NotStartedError(CYTHON_UNUSED PyObject *gen) {
    const char *msg;
    if (0) {
    #ifdef __Pyx_Coroutine_USED
    } else if (__Pyx_Coroutine_CheckExact(gen)) {
        msg = "can't send non-None value to a just-started coroutine";
    #endif
    #ifdef __Pyx_AsyncGen_USED
    } else if (__Pyx_AsyncGen_CheckExact(gen)) {
        msg = "can't send non-None value to a just-started async generator";
    #endif
    } else {
        msg = "can't send non-None value to a just-started generator";
    }
    PyErr_SetString(PyExc_TypeError, msg);
}
#define __Pyx_Coroutine_AlreadyTerminatedError(gen, value, closing)  (__Pyx__Coroutine_AlreadyTerminatedError(gen, value, closing), (PyObject*)NULL)
static void __Pyx__Coroutine_AlreadyTerminatedError(CYTHON_UNUSED PyObject *gen, PyObject *value, CYTHON_UNUSED int closing) {
    #ifdef __Pyx_Coroutine_USED
    if (!closing && __Pyx_Coroutine_CheckExact(gen)) {
        PyErr_SetString(PyExc_RuntimeError, "cannot reuse already awaited coroutine");
    } else
    #endif
    if (value) {
        #ifdef __Pyx_AsyncGen_USED
        if (__Pyx_AsyncGen_CheckExact(gen))
            PyErr_SetNone(__Pyx_PyExc_StopAsyncIteration);
        else
        #endif
        PyErr_SetNone(PyExc_StopIteration);
    }
}
static
PyObject *__Pyx_Coroutine_SendEx(__pyx_CoroutineObject *self, PyObject *value, int closing) {
    __Pyx_PyThreadState_declare
    PyThreadState *tstate;
    PyObject *retval;
    assert(!self->is_running);
    if (unlikely(self->resume_label == 0)) {
        if (unlikely(value && value != Py_None)) {
            return __Pyx_Coroutine_NotStartedError((PyObject*)self);
        }
    }
    if (unlikely(self->resume_label == -1)) {
        return __Pyx_Coroutine_AlreadyTerminatedError((PyObject*)self, value, closing);
    }
#if CYTHON_FAST_THREAD_STATE
    __Pyx_PyThreadState_assign
    tstate = __pyx_tstate;
#else
    tstate = __Pyx_PyThreadState_Current;
#endif
    if (self->exc_type) {
#if CYTHON_COMPILING_IN_PYPY || CYTHON_COMPILING_IN_PYSTON
#else
        if (self->exc_traceback) {
            PyTracebackObject *tb = (PyTracebackObject *) self->exc_traceback;
            PyFrameObject *f = tb->tb_frame;
            Py_XINCREF(tstate->frame);
            assert(f->f_back == NULL);
            f->f_back = tstate->frame;
        }
#endif
        __Pyx_ExceptionSwap(&self->exc_type, &self->exc_value,
                            &self->exc_traceback);
    } else {
        __Pyx_Coroutine_ExceptionClear(self);
        __Pyx_ExceptionSave(&self->exc_type, &self->exc_value, &self->exc_traceback);
    }
    self->is_running = 1;
    retval = self->body((PyObject *) self, tstate, value);
    self->is_running = 0;
    return retval;
}
static CYTHON_INLINE void __Pyx_Coroutine_ResetFrameBackpointer(__pyx_CoroutineObject *self) {
    if (likely(self->exc_traceback)) {
#if CYTHON_COMPILING_IN_PYPY || CYTHON_COMPILING_IN_PYSTON
#else
        PyTracebackObject *tb = (PyTracebackObject *) self->exc_traceback;
        PyFrameObject *f = tb->tb_frame;
        Py_CLEAR(f->f_back);
#endif
    }
}
static CYTHON_INLINE
PyObject *__Pyx_Coroutine_MethodReturn(CYTHON_UNUSED PyObject* gen, PyObject *retval) {
    if (unlikely(!retval)) {
        __Pyx_PyThreadState_declare
        __Pyx_PyThreadState_assign
        if (!__Pyx_PyErr_Occurred()) {
            PyObject *exc = PyExc_StopIteration;
            #ifdef __Pyx_AsyncGen_USED
            if (__Pyx_AsyncGen_CheckExact(gen))
                exc = __Pyx_PyExc_StopAsyncIteration;
            #endif
            __Pyx_PyErr_SetNone(exc);
        }
    }
    return retval;
}
static CYTHON_INLINE
PyObject *__Pyx_Coroutine_FinishDelegation(__pyx_CoroutineObject *gen) {
    PyObject *ret;
    PyObject *val = NULL;
    __Pyx_Coroutine_Undelegate(gen);
    __Pyx_PyGen__FetchStopIterationValue(__Pyx_PyThreadState_Current, &val);
    ret = __Pyx_Coroutine_SendEx(gen, val, 0);
    Py_XDECREF(val);
    return ret;
}
static PyObject *__Pyx_Coroutine_Send(PyObject *self, PyObject *value) {
    PyObject *retval;
    __pyx_CoroutineObject *gen = (__pyx_CoroutineObject*) self;
    PyObject *yf = gen->yieldfrom;
    if (unlikely(gen->is_running))
        return __Pyx_Coroutine_AlreadyRunningError(gen);
    if (yf) {
        PyObject *ret;
        gen->is_running = 1;
        #ifdef __Pyx_Generator_USED
        if (__Pyx_Generator_CheckExact(yf)) {
            ret = __Pyx_Coroutine_Send(yf, value);
        } else
        #endif
        #ifdef __Pyx_Coroutine_USED
        if (__Pyx_Coroutine_CheckExact(yf)) {
            ret = __Pyx_Coroutine_Send(yf, value);
        } else
        #endif
        #ifdef __Pyx_AsyncGen_USED
        if (__pyx_PyAsyncGenASend_CheckExact(yf)) {
            ret = __Pyx_async_gen_asend_send(yf, value);
        } else
        #endif
        #if CYTHON_COMPILING_IN_CPYTHON && PY_VERSION_HEX >= 0x03030000 && (defined(__linux__) || PY_VERSION_HEX >= 0x030600B3)
        if (PyGen_CheckExact(yf)) {
            ret = _PyGen_Send((PyGenObject*)yf, value == Py_None ? NULL : value);
        } else
        #endif
        #if CYTHON_COMPILING_IN_CPYTHON && PY_VERSION_HEX >= 0x03050000 && defined(PyCoro_CheckExact) && (defined(__linux__) || PY_VERSION_HEX >= 0x030600B3)
        if (PyCoro_CheckExact(yf)) {
            ret = _PyGen_Send((PyGenObject*)yf, value == Py_None ? NULL : value);
        } else
        #endif
        {
            if (value == Py_None)
                ret = Py_TYPE(yf)->tp_iternext(yf);
            else
                ret = __Pyx_PyObject_CallMethod1(yf, __pyx_n_s_send, value);
        }
        gen->is_running = 0;
        if (likely(ret)) {
            return ret;
        }
        retval = __Pyx_Coroutine_FinishDelegation(gen);
    } else {
        retval = __Pyx_Coroutine_SendEx(gen, value, 0);
    }
    return __Pyx_Coroutine_MethodReturn(self, retval);
}
static int __Pyx_Coroutine_CloseIter(__pyx_CoroutineObject *gen, PyObject *yf) {
    PyObject *retval = NULL;
    int err = 0;
    #ifdef __Pyx_Generator_USED
    if (__Pyx_Generator_CheckExact(yf)) {
        retval = __Pyx_Coroutine_Close(yf);
        if (!retval)
            return -1;
    } else
    #endif
    #ifdef __Pyx_Coroutine_USED
    if (__Pyx_Coroutine_CheckExact(yf)) {
        retval = __Pyx_Coroutine_Close(yf);
        if (!retval)
            return -1;
    } else
    if (__Pyx_CoroutineAwait_CheckExact(yf)) {
        retval = __Pyx_CoroutineAwait_Close((__pyx_CoroutineAwaitObject*)yf);
        if (!retval)
            return -1;
    } else
    #endif
    #ifdef __Pyx_AsyncGen_USED
    if (__pyx_PyAsyncGenASend_CheckExact(yf)) {
        retval = __Pyx_async_gen_asend_close(yf, NULL);
    } else
    if (__pyx_PyAsyncGenAThrow_CheckExact(yf)) {
        retval = __Pyx_async_gen_athrow_close(yf, NULL);
    } else
    #endif
    {
        PyObject *meth;
        gen->is_running = 1;
        meth = __Pyx_PyObject_GetAttrStr(yf, __pyx_n_s_close);
        if (unlikely(!meth)) {
            if (!PyErr_ExceptionMatches(PyExc_AttributeError)) {
                PyErr_WriteUnraisable(yf);
            }
            PyErr_Clear();
        } else {
            retval = PyObject_CallFunction(meth, NULL);
            Py_DECREF(meth);
            if (!retval)
                err = -1;
        }
        gen->is_running = 0;
    }
    Py_XDECREF(retval);
    return err;
}
static PyObject *__Pyx_Generator_Next(PyObject *self) {
    __pyx_CoroutineObject *gen = (__pyx_CoroutineObject*) self;
    PyObject *yf = gen->yieldfrom;
    if (unlikely(gen->is_running))
        return __Pyx_Coroutine_AlreadyRunningError(gen);
    if (yf) {
        PyObject *ret;
        gen->is_running = 1;
        #ifdef __Pyx_Generator_USED
        if (__Pyx_Generator_CheckExact(yf)) {
            ret = __Pyx_Generator_Next(yf);
        } else
        #endif
        #if CYTHON_COMPILING_IN_CPYTHON && PY_VERSION_HEX >= 0x03030000 && (defined(__linux__) || PY_VERSION_HEX >= 0x030600B3)
        if (PyGen_CheckExact(yf)) {
            ret = _PyGen_Send((PyGenObject*)yf, NULL);
        } else
        #endif
            ret = Py_TYPE(yf)->tp_iternext(yf);
        gen->is_running = 0;
        if (likely(ret)) {
            return ret;
        }
        return __Pyx_Coroutine_FinishDelegation(gen);
    }
    return __Pyx_Coroutine_SendEx(gen, Py_None, 0);
}
static PyObject *__Pyx_Coroutine_Close(PyObject *self) {
    __pyx_CoroutineObject *gen = (__pyx_CoroutineObject *) self;
    PyObject *retval, *raised_exception;
    PyObject *yf = gen->yieldfrom;
    int err = 0;
    if (unlikely(gen->is_running))
        return __Pyx_Coroutine_AlreadyRunningError(gen);
    if (yf) {
        Py_INCREF(yf);
        err = __Pyx_Coroutine_CloseIter(gen, yf);
        __Pyx_Coroutine_Undelegate(gen);
        Py_DECREF(yf);
    }
    if (err == 0)
        PyErr_SetNone(PyExc_GeneratorExit);
    retval = __Pyx_Coroutine_SendEx(gen, NULL, 1);
    if (unlikely(retval)) {
        const char *msg;
        Py_DECREF(retval);
        if ((0)) {
        #ifdef __Pyx_Coroutine_USED
        } else if (__Pyx_Coroutine_CheckExact(self)) {
            msg = "coroutine ignored GeneratorExit";
        #endif
        #ifdef __Pyx_AsyncGen_USED
        } else if (__Pyx_AsyncGen_CheckExact(self)) {
#if PY_VERSION_HEX < 0x03060000
            msg = "async generator ignored GeneratorExit - might require Python 3.6+ finalisation (PEP 525)";
#else
            msg = "async generator ignored GeneratorExit";
#endif
        #endif
        } else {
            msg = "generator ignored GeneratorExit";
        }
        PyErr_SetString(PyExc_RuntimeError, msg);
        return NULL;
    }
    raised_exception = PyErr_Occurred();
    if (likely(!raised_exception || __Pyx_PyErr_GivenExceptionMatches2(raised_exception, PyExc_GeneratorExit, PyExc_StopIteration))) {
        if (raised_exception) PyErr_Clear();
        Py_INCREF(Py_None);
        return Py_None;
    }
    return NULL;
}
static PyObject *__Pyx__Coroutine_Throw(PyObject *self, PyObject *typ, PyObject *val, PyObject *tb,
                                        PyObject *args, int close_on_genexit) {
    __pyx_CoroutineObject *gen = (__pyx_CoroutineObject *) self;
    PyObject *yf = gen->yieldfrom;
    if (unlikely(gen->is_running))
        return __Pyx_Coroutine_AlreadyRunningError(gen);
    if (yf) {
        PyObject *ret;
        Py_INCREF(yf);
        if (__Pyx_PyErr_GivenExceptionMatches(typ, PyExc_GeneratorExit) && close_on_genexit) {
            int err = __Pyx_Coroutine_CloseIter(gen, yf);
            Py_DECREF(yf);
            __Pyx_Coroutine_Undelegate(gen);
            if (err < 0)
                return __Pyx_Coroutine_MethodReturn(self, __Pyx_Coroutine_SendEx(gen, NULL, 0));
            goto throw_here;
        }
        gen->is_running = 1;
        if (0
        #ifdef __Pyx_Generator_USED
            || __Pyx_Generator_CheckExact(yf)
        #endif
        #ifdef __Pyx_Coroutine_USED
            || __Pyx_Coroutine_CheckExact(yf)
        #endif
            ) {
            ret = __Pyx__Coroutine_Throw(yf, typ, val, tb, args, close_on_genexit);
        #ifdef __Pyx_Coroutine_USED
        } else if (__Pyx_CoroutineAwait_CheckExact(yf)) {
            ret = __Pyx__Coroutine_Throw(((__pyx_CoroutineAwaitObject*)yf)->coroutine, typ, val, tb, args, close_on_genexit);
        #endif
        } else {
            PyObject *meth = __Pyx_PyObject_GetAttrStr(yf, __pyx_n_s_throw);
            if (unlikely(!meth)) {
                Py_DECREF(yf);
                if (!PyErr_ExceptionMatches(PyExc_AttributeError)) {
                    gen->is_running = 0;
                    return NULL;
                }
                PyErr_Clear();
                __Pyx_Coroutine_Undelegate(gen);
                gen->is_running = 0;
                goto throw_here;
            }
            if (likely(args)) {
                ret = PyObject_CallObject(meth, args);
            } else {
                ret = PyObject_CallFunctionObjArgs(meth, typ, val, tb, NULL);
            }
            Py_DECREF(meth);
        }
        gen->is_running = 0;
        Py_DECREF(yf);
        if (!ret) {
            ret = __Pyx_Coroutine_FinishDelegation(gen);
        }
        return __Pyx_Coroutine_MethodReturn(self, ret);
    }
throw_here:
    __Pyx_Raise(typ, val, tb, NULL);
    return __Pyx_Coroutine_MethodReturn(self, __Pyx_Coroutine_SendEx(gen, NULL, 0));
}
static PyObject *__Pyx_Coroutine_Throw(PyObject *self, PyObject *args) {
    PyObject *typ;
    PyObject *val = NULL;
    PyObject *tb = NULL;
    if (!PyArg_UnpackTuple(args, (char *)"throw", 1, 3, &typ, &val, &tb))
        return NULL;
    return __Pyx__Coroutine_Throw(self, typ, val, tb, args, 1);
}
static int __Pyx_Coroutine_traverse(__pyx_CoroutineObject *gen, visitproc visit, void *arg) {
    Py_VISIT(gen->closure);
    Py_VISIT(gen->classobj);
    Py_VISIT(gen->yieldfrom);
    Py_VISIT(gen->exc_type);
    Py_VISIT(gen->exc_value);
    Py_VISIT(gen->exc_traceback);
    return 0;
}
static int __Pyx_Coroutine_clear(PyObject *self) {
    __pyx_CoroutineObject *gen = (__pyx_CoroutineObject *) self;
    Py_CLEAR(gen->closure);
    Py_CLEAR(gen->classobj);
    Py_CLEAR(gen->yieldfrom);
    Py_CLEAR(gen->exc_type);
    Py_CLEAR(gen->exc_value);
    Py_CLEAR(gen->exc_traceback);
#ifdef __Pyx_AsyncGen_USED
    if (__Pyx_AsyncGen_CheckExact(self)) {
        Py_CLEAR(((__pyx_PyAsyncGenObject*)gen)->ag_finalizer);
    }
#endif
    Py_CLEAR(gen->gi_name);
    Py_CLEAR(gen->gi_qualname);
    Py_CLEAR(gen->gi_modulename);
    return 0;
}
static void __Pyx_Coroutine_dealloc(PyObject *self) {
    __pyx_CoroutineObject *gen = (__pyx_CoroutineObject *) self;
    PyObject_GC_UnTrack(gen);
    if (gen->gi_weakreflist != NULL)
        PyObject_ClearWeakRefs(self);
    if (gen->resume_label >= 0) {
        PyObject_GC_Track(self);
#if PY_VERSION_HEX >= 0x030400a1 && CYTHON_USE_TP_FINALIZE
        if (PyObject_CallFinalizerFromDealloc(self))
#else
        Py_TYPE(gen)->tp_del(self);
        if (self->ob_refcnt > 0)
#endif
        {
            return;
        }
        PyObject_GC_UnTrack(self);
    }
#ifdef __Pyx_AsyncGen_USED
    if (__Pyx_AsyncGen_CheckExact(self)) {
        /* We have to handle this case for asynchronous generators
           right here, because this code has to be between UNTRACK
           and GC_Del. */
        Py_CLEAR(((__pyx_PyAsyncGenObject*)self)->ag_finalizer);
    }
#endif
    __Pyx_Coroutine_clear(self);
    PyObject_GC_Del(gen);
}
static void __Pyx_Coroutine_del(PyObject *self) {
    PyObject *error_type, *error_value, *error_traceback;
    __pyx_CoroutineObject *gen = (__pyx_CoroutineObject *) self;
    __Pyx_PyThreadState_declare
    if (gen->resume_label < 0) {
        return;
    }
#if !CYTHON_USE_TP_FINALIZE
    assert(self->ob_refcnt == 0);
    self->ob_refcnt = 1;
#endif
    __Pyx_PyThreadState_assign
    __Pyx_ErrFetch(&error_type, &error_value, &error_traceback);
#ifdef __Pyx_AsyncGen_USED
    if (__Pyx_AsyncGen_CheckExact(self)) {
        __pyx_PyAsyncGenObject *agen = (__pyx_PyAsyncGenObject*)self;
        PyObject *finalizer = agen->ag_finalizer;
        if (finalizer && !agen->ag_closed) {
            PyObject *res = __Pyx_PyObject_CallOneArg(finalizer, self);
            if (unlikely(!res)) {
                PyErr_WriteUnraisable(self);
            } else {
                Py_DECREF(res);
            }
            __Pyx_ErrRestore(error_type, error_value, error_traceback);
            return;
        }
    }
#endif
    if (unlikely(gen->resume_label == 0 && !error_value)) {
#ifdef __Pyx_Coroutine_USED
#ifdef __Pyx_Generator_USED
    if (!__Pyx_Generator_CheckExact(self))
#endif
        {
        PyObject_GC_UnTrack(self);
#if PY_MAJOR_VERSION >= 3  || defined(PyErr_WarnFormat)
        if (unlikely(PyErr_WarnFormat(PyExc_RuntimeWarning, 1, "coroutine '%.50S' was never awaited", gen->gi_qualname) < 0))
            PyErr_WriteUnraisable(self);
#else
        {PyObject *msg;
        char *cmsg;
        #if CYTHON_COMPILING_IN_PYPY
        msg = NULL;
        cmsg = (char*) "coroutine was never awaited";
        #else
        char *cname;
        PyObject *qualname;
        qualname = gen->gi_qualname;
        cname = PyString_AS_STRING(qualname);
        msg = PyString_FromFormat("coroutine '%.50s' was never awaited", cname);
        if (unlikely(!msg)) {
            PyErr_Clear();
            cmsg = (char*) "coroutine was never awaited";
        } else {
            cmsg = PyString_AS_STRING(msg);
        }
        #endif
        if (unlikely(PyErr_WarnEx(PyExc_RuntimeWarning, cmsg, 1) < 0))
            PyErr_WriteUnraisable(self);
        Py_XDECREF(msg);}
#endif
        PyObject_GC_Track(self);
        }
#endif
    } else {
        PyObject *res = __Pyx_Coroutine_Close(self);
        if (unlikely(!res)) {
            if (PyErr_Occurred())
                PyErr_WriteUnraisable(self);
        } else {
            Py_DECREF(res);
        }
    }
    __Pyx_ErrRestore(error_type, error_value, error_traceback);
#if !CYTHON_USE_TP_FINALIZE
    assert(self->ob_refcnt > 0);
    if (--self->ob_refcnt == 0) {
        return;
    }
    {
        Py_ssize_t refcnt = self->ob_refcnt;
        _Py_NewReference(self);
        self->ob_refcnt = refcnt;
    }
#if CYTHON_COMPILING_IN_CPYTHON
    assert(PyType_IS_GC(self->ob_type) &&
           _Py_AS_GC(self)->gc.gc_refs != _PyGC_REFS_UNTRACKED);
    _Py_DEC_REFTOTAL;
#endif
#ifdef COUNT_ALLOCS
    --Py_TYPE(self)->tp_frees;
    --Py_TYPE(self)->tp_allocs;
#endif
#endif
}
static PyObject *
__Pyx_Coroutine_get_name(__pyx_CoroutineObject *self)
{
    PyObject *name = self->gi_name;
    if (unlikely(!name)) name = Py_None;
    Py_INCREF(name);
    return name;
}
static int
__Pyx_Coroutine_set_name(__pyx_CoroutineObject *self, PyObject *value)
{
    PyObject *tmp;
#if PY_MAJOR_VERSION >= 3
    if (unlikely(value == NULL || !PyUnicode_Check(value))) {
#else
    if (unlikely(value == NULL || !PyString_Check(value))) {
#endif
        PyErr_SetString(PyExc_TypeError,
                        "__name__ must be set to a string object");
        return -1;
    }
    tmp = self->gi_name;
    Py_INCREF(value);
    self->gi_name = value;
    Py_XDECREF(tmp);
    return 0;
}
static PyObject *
__Pyx_Coroutine_get_qualname(__pyx_CoroutineObject *self)
{
    PyObject *name = self->gi_qualname;
    if (unlikely(!name)) name = Py_None;
    Py_INCREF(name);
    return name;
}
static int
__Pyx_Coroutine_set_qualname(__pyx_CoroutineObject *self, PyObject *value)
{
    PyObject *tmp;
#if PY_MAJOR_VERSION >= 3
    if (unlikely(value == NULL || !PyUnicode_Check(value))) {
#else
    if (unlikely(value == NULL || !PyString_Check(value))) {
#endif
        PyErr_SetString(PyExc_TypeError,
                        "__qualname__ must be set to a string object");
        return -1;
    }
    tmp = self->gi_qualname;
    Py_INCREF(value);
    self->gi_qualname = value;
    Py_XDECREF(tmp);
    return 0;
}
static __pyx_CoroutineObject *__Pyx__Coroutine_New(
            PyTypeObject* type, __pyx_coroutine_body_t body, PyObject *closure,
            PyObject *name, PyObject *qualname, PyObject *module_name) {
    __pyx_CoroutineObject *gen = PyObject_GC_New(__pyx_CoroutineObject, type);
    if (unlikely(!gen))
        return NULL;
    return __Pyx__Coroutine_NewInit(gen, body, closure, name, qualname, module_name);
}
static __pyx_CoroutineObject *__Pyx__Coroutine_NewInit(
            __pyx_CoroutineObject *gen, __pyx_coroutine_body_t body, PyObject *closure,
            PyObject *name, PyObject *qualname, PyObject *module_name) {
    gen->body = body;
    gen->closure = closure;
    Py_XINCREF(closure);
    gen->is_running = 0;
    gen->resume_label = 0;
    gen->classobj = NULL;
    gen->yieldfrom = NULL;
    gen->exc_type = NULL;
    gen->exc_value = NULL;
    gen->exc_traceback = NULL;
    gen->gi_weakreflist = NULL;
    Py_XINCREF(qualname);
    gen->gi_qualname = qualname;
    Py_XINCREF(name);
    gen->gi_name = name;
    Py_XINCREF(module_name);
    gen->gi_modulename = module_name;
    PyObject_GC_Track(gen);
    return gen;
}

/* PatchModuleWithCoroutine */
            static PyObject* __Pyx_Coroutine_patch_module(PyObject* module, const char* py_code) {
#if defined(__Pyx_Generator_USED) || defined(__Pyx_Coroutine_USED)
    int result;
    PyObject *globals, *result_obj;
    globals = PyDict_New();  if (unlikely(!globals)) goto ignore;
    result = PyDict_SetItemString(globals, "_cython_coroutine_type",
    #ifdef __Pyx_Coroutine_USED
        (PyObject*)__pyx_CoroutineType);
    #else
        Py_None);
    #endif
    if (unlikely(result < 0)) goto ignore;
    result = PyDict_SetItemString(globals, "_cython_generator_type",
    #ifdef __Pyx_Generator_USED
        (PyObject*)__pyx_GeneratorType);
    #else
        Py_None);
    #endif
    if (unlikely(result < 0)) goto ignore;
    if (unlikely(PyDict_SetItemString(globals, "_module", module) < 0)) goto ignore;
    if (unlikely(PyDict_SetItemString(globals, "__builtins__", __pyx_b) < 0)) goto ignore;
    result_obj = PyRun_String(py_code, Py_file_input, globals, globals);
    if (unlikely(!result_obj)) goto ignore;
    Py_DECREF(result_obj);
    Py_DECREF(globals);
    return module;
ignore:
    Py_XDECREF(globals);
    PyErr_WriteUnraisable(module);
    if (unlikely(PyErr_WarnEx(PyExc_RuntimeWarning, "Cython module failed to patch module with custom type", 1) < 0)) {
        Py_DECREF(module);
        module = NULL;
    }
#else
    py_code++;
#endif
    return module;
}

/* PatchGeneratorABC */
            #ifndef CYTHON_REGISTER_ABCS
#define CYTHON_REGISTER_ABCS 1
#endif
#if defined(__Pyx_Generator_USED) || defined(__Pyx_Coroutine_USED)
static PyObject* __Pyx_patch_abc_module(PyObject *module);
static PyObject* __Pyx_patch_abc_module(PyObject *module) {
    module = __Pyx_Coroutine_patch_module(
        module, ""
"if _cython_generator_type is not None:\n"
"    try: Generator = _module.Generator\n"
"    except AttributeError: pass\n"
"    else: Generator.register(_cython_generator_type)\n"
"if _cython_coroutine_type is not None:\n"
"    try: Coroutine = _module.Coroutine\n"
"    except AttributeError: pass\n"
"    else: Coroutine.register(_cython_coroutine_type)\n"
    );
    return module;
}
#endif
static int __Pyx_patch_abc(void) {
#if defined(__Pyx_Generator_USED) || defined(__Pyx_Coroutine_USED)
    static int abc_patched = 0;
    if (CYTHON_REGISTER_ABCS && !abc_patched) {
        PyObject *module;
        module = PyImport_ImportModule((PY_MAJOR_VERSION >= 3) ? "collections.abc" : "collections");
        if (!module) {
            PyErr_WriteUnraisable(NULL);
            if (unlikely(PyErr_WarnEx(PyExc_RuntimeWarning,
                    ((PY_MAJOR_VERSION >= 3) ?
                        "Cython module failed to register with collections.abc module" :
                        "Cython module failed to register with collections module"), 1) < 0)) {
                return -1;
            }
        } else {
            module = __Pyx_patch_abc_module(module);
            abc_patched = 1;
            if (unlikely(!module))
                return -1;
            Py_DECREF(module);
        }
        module = PyImport_ImportModule("backports_abc");
        if (module) {
            module = __Pyx_patch_abc_module(module);
            Py_XDECREF(module);
        }
        if (!module) {
            PyErr_Clear();
        }
    }
#else
    if ((0)) __Pyx_Coroutine_patch_module(NULL, NULL);
#endif
    return 0;
}

/* Generator */
            static PyMethodDef __pyx_Generator_methods[] = {
    {"send", (PyCFunction) __Pyx_Coroutine_Send, METH_O,
     (char*) PyDoc_STR("send(arg) -> send 'arg' into generator,\nreturn next yielded value or raise StopIteration.")},
    {"throw", (PyCFunction) __Pyx_Coroutine_Throw, METH_VARARGS,
     (char*) PyDoc_STR("throw(typ[,val[,tb]]) -> raise exception in generator,\nreturn next yielded value or raise StopIteration.")},
    {"close", (PyCFunction) __Pyx_Coroutine_Close, METH_NOARGS,
     (char*) PyDoc_STR("close() -> raise GeneratorExit inside generator.")},
    {0, 0, 0, 0}
};
static PyMemberDef __pyx_Generator_memberlist[] = {
    {(char *) "gi_running", T_BOOL, offsetof(__pyx_CoroutineObject, is_running), READONLY, NULL},
    {(char*) "gi_yieldfrom", T_OBJECT, offsetof(__pyx_CoroutineObject, yieldfrom), READONLY,
     (char*) PyDoc_STR("object being iterated by 'yield from', or None")},
    {0, 0, 0, 0, 0}
};
static PyGetSetDef __pyx_Generator_getsets[] = {
    {(char *) "__name__", (getter)__Pyx_Coroutine_get_name, (setter)__Pyx_Coroutine_set_name,
     (char*) PyDoc_STR("name of the generator"), 0},
    {(char *) "__qualname__", (getter)__Pyx_Coroutine_get_qualname, (setter)__Pyx_Coroutine_set_qualname,
     (char*) PyDoc_STR("qualified name of the generator"), 0},
    {0, 0, 0, 0, 0}
};
static PyTypeObject __pyx_GeneratorType_type = {
    PyVarObject_HEAD_INIT(0, 0)
    "generator",
    sizeof(__pyx_CoroutineObject),
    0,
    (destructor) __Pyx_Coroutine_dealloc,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    Py_TPFLAGS_DEFAULT | Py_TPFLAGS_HAVE_GC | Py_TPFLAGS_HAVE_FINALIZE,
    0,
    (traverseproc) __Pyx_Coroutine_traverse,
    0,
    0,
    offsetof(__pyx_CoroutineObject, gi_weakreflist),
    0,
    (iternextfunc) __Pyx_Generator_Next,
    __pyx_Generator_methods,
    __pyx_Generator_memberlist,
    __pyx_Generator_getsets,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
#if CYTHON_USE_TP_FINALIZE
    0,
#else
    __Pyx_Coroutine_del,
#endif
    0,
#if CYTHON_USE_TP_FINALIZE
    __Pyx_Coroutine_del,
#elif PY_VERSION_HEX >= 0x030400a1
    0,
#endif
};
static int __pyx_Generator_init(void) {
    __pyx_GeneratorType_type.tp_getattro = PyObject_GenericGetAttr;
    __pyx_GeneratorType_type.tp_iter = PyObject_SelfIter;
    __pyx_GeneratorType = __Pyx_FetchCommonType(&__pyx_GeneratorType_type);
    if (unlikely(!__pyx_GeneratorType)) {
        return -1;
    }
    return 0;
}

/* CheckBinaryVersion */
            static int __Pyx_check_binary_version(void) {
    char ctversion[4], rtversion[4];
    PyOS_snprintf(ctversion, 4, "%d.%d", PY_MAJOR_VERSION, PY_MINOR_VERSION);
    PyOS_snprintf(rtversion, 4, "%s", Py_GetVersion());
    if (ctversion[0] != rtversion[0] || ctversion[2] != rtversion[2]) {
        char message[200];
        PyOS_snprintf(message, sizeof(message),
                      "compiletime version %s of module '%.100s' "
                      "does not match runtime version %s",
                      ctversion, __Pyx_MODULE_NAME, rtversion);
        return PyErr_WarnEx(NULL, message, 1);
    }
    return 0;
}

/* FunctionExport */
            static int __Pyx_ExportFunction(const char *name, void (*f)(void), const char *sig) {
    PyObject *d = 0;
    PyObject *cobj = 0;
    union {
        void (*fp)(void);
        void *p;
    } tmp;
    d = PyObject_GetAttrString(__pyx_m, (char *)"__pyx_capi__");
    if (!d) {
        PyErr_Clear();
        d = PyDict_New();
        if (!d)
            goto bad;
        Py_INCREF(d);
        if (PyModule_AddObject(__pyx_m, (char *)"__pyx_capi__", d) < 0)
            goto bad;
    }
    tmp.fp = f;
#if PY_VERSION_HEX >= 0x02070000
    cobj = PyCapsule_New(tmp.p, sig, 0);
#else
    cobj = PyCObject_FromVoidPtrAndDesc(tmp.p, (void *)sig, 0);
#endif
    if (!cobj)
        goto bad;
    if (PyDict_SetItemString(d, name, cobj) < 0)
        goto bad;
    Py_DECREF(cobj);
    Py_DECREF(d);
    return 0;
bad:
    Py_XDECREF(cobj);
    Py_XDECREF(d);
    return -1;
}

/* ModuleImport */
            #ifndef __PYX_HAVE_RT_ImportModule
#define __PYX_HAVE_RT_ImportModule
static PyObject *__Pyx_ImportModule(const char *name) {
    PyObject *py_name = 0;
    PyObject *py_module = 0;
    py_name = __Pyx_PyIdentifier_FromString(name);
    if (!py_name)
        goto bad;
    py_module = PyImport_Import(py_name);
    Py_DECREF(py_name);
    return py_module;
bad:
    Py_XDECREF(py_name);
    return 0;
}
#endif

/* TypeImport */
            #ifndef __PYX_HAVE_RT_ImportType
#define __PYX_HAVE_RT_ImportType
static PyTypeObject *__Pyx_ImportType(const char *module_name, const char *class_name,
    size_t size, int strict)
{
    PyObject *py_module = 0;
    PyObject *result = 0;
    PyObject *py_name = 0;
    char warning[200];
    Py_ssize_t basicsize;
#ifdef Py_LIMITED_API
    PyObject *py_basicsize;
#endif
    py_module = __Pyx_ImportModule(module_name);
    if (!py_module)
        goto bad;
    py_name = __Pyx_PyIdentifier_FromString(class_name);
    if (!py_name)
        goto bad;
    result = PyObject_GetAttr(py_module, py_name);
    Py_DECREF(py_name);
    py_name = 0;
    Py_DECREF(py_module);
    py_module = 0;
    if (!result)
        goto bad;
    if (!PyType_Check(result)) {
        PyErr_Format(PyExc_TypeError,
            "%.200s.%.200s is not a type object",
            module_name, class_name);
        goto bad;
    }
#ifndef Py_LIMITED_API
    basicsize = ((PyTypeObject *)result)->tp_basicsize;
#else
    py_basicsize = PyObject_GetAttrString(result, "__basicsize__");
    if (!py_basicsize)
        goto bad;
    basicsize = PyLong_AsSsize_t(py_basicsize);
    Py_DECREF(py_basicsize);
    py_basicsize = 0;
    if (basicsize == (Py_ssize_t)-1 && PyErr_Occurred())
        goto bad;
#endif
    if (!strict && (size_t)basicsize > size) {
        PyOS_snprintf(warning, sizeof(warning),
            "%s.%s size changed, may indicate binary incompatibility. Expected %zd, got %zd",
            module_name, class_name, basicsize, size);
        if (PyErr_WarnEx(NULL, warning, 0) < 0) goto bad;
    }
    else if ((size_t)basicsize != size) {
        PyErr_Format(PyExc_ValueError,
            "%.200s.%.200s has the wrong size, try recompiling. Expected %zd, got %zd",
            module_name, class_name, basicsize, size);
        goto bad;
    }
    return (PyTypeObject *)result;
bad:
    Py_XDECREF(py_module);
    Py_XDECREF(result);
    return NULL;
}
#endif

/* InitStrings */
            static int __Pyx_InitStrings(__Pyx_StringTabEntry *t) {
    while (t->p) {
        #if PY_MAJOR_VERSION < 3
        if (t->is_unicode) {
            *t->p = PyUnicode_DecodeUTF8(t->s, t->n - 1, NULL);
        } else if (t->intern) {
            *t->p = PyString_InternFromString(t->s);
        } else {
            *t->p = PyString_FromStringAndSize(t->s, t->n - 1);
        }
        #else
        if (t->is_unicode | t->is_str) {
            if (t->intern) {
                *t->p = PyUnicode_InternFromString(t->s);
            } else if (t->encoding) {
                *t->p = PyUnicode_Decode(t->s, t->n - 1, t->encoding, NULL);
            } else {
                *t->p = PyUnicode_FromStringAndSize(t->s, t->n - 1);
            }
        } else {
            *t->p = PyBytes_FromStringAndSize(t->s, t->n - 1);
        }
        #endif
        if (!*t->p)
            return -1;
        if (PyObject_Hash(*t->p) == -1)
            PyErr_Clear();
        ++t;
    }
    return 0;
}

static CYTHON_INLINE PyObject* __Pyx_PyUnicode_FromString(const char* c_str) {
    return __Pyx_PyUnicode_FromStringAndSize(c_str, (Py_ssize_t)strlen(c_str));
}
static CYTHON_INLINE const char* __Pyx_PyObject_AsString(PyObject* o) {
    Py_ssize_t ignore;
    return __Pyx_PyObject_AsStringAndSize(o, &ignore);
}
#if __PYX_DEFAULT_STRING_ENCODING_IS_ASCII || __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT
#if !CYTHON_PEP393_ENABLED
static const char* __Pyx_PyUnicode_AsStringAndSize(PyObject* o, Py_ssize_t *length) {
    char* defenc_c;
    PyObject* defenc = _PyUnicode_AsDefaultEncodedString(o, NULL);
    if (!defenc) return NULL;
    defenc_c = PyBytes_AS_STRING(defenc);
#if __PYX_DEFAULT_STRING_ENCODING_IS_ASCII
    {
        char* end = defenc_c + PyBytes_GET_SIZE(defenc);
        char* c;
        for (c = defenc_c; c < end; c++) {
            if ((unsigned char) (*c) >= 128) {
                PyUnicode_AsASCIIString(o);
                return NULL;
            }
        }
    }
#endif
    *length = PyBytes_GET_SIZE(defenc);
    return defenc_c;
}
#else
static CYTHON_INLINE const char* __Pyx_PyUnicode_AsStringAndSize(PyObject* o, Py_ssize_t *length) {
    if (unlikely(__Pyx_PyUnicode_READY(o) == -1)) return NULL;
#if __PYX_DEFAULT_STRING_ENCODING_IS_ASCII
    if (likely(PyUnicode_IS_ASCII(o))) {
        *length = PyUnicode_GET_LENGTH(o);
        return PyUnicode_AsUTF8(o);
    } else {
        PyUnicode_AsASCIIString(o);
        return NULL;
    }
#else
    return PyUnicode_AsUTF8AndSize(o, length);
#endif
}
#endif
#endif
static CYTHON_INLINE const char* __Pyx_PyObject_AsStringAndSize(PyObject* o, Py_ssize_t *length) {
#if __PYX_DEFAULT_STRING_ENCODING_IS_ASCII || __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT
    if (
#if PY_MAJOR_VERSION < 3 && __PYX_DEFAULT_STRING_ENCODING_IS_ASCII
            __Pyx_sys_getdefaultencoding_not_ascii &&
#endif
            PyUnicode_Check(o)) {
        return __Pyx_PyUnicode_AsStringAndSize(o, length);
    } else
#endif
#if (!CYTHON_COMPILING_IN_PYPY) || (defined(PyByteArray_AS_STRING) && defined(PyByteArray_GET_SIZE))
    if (PyByteArray_Check(o)) {
        *length = PyByteArray_GET_SIZE(o);
        return PyByteArray_AS_STRING(o);
    } else
#endif
    {
        char* result;
        int r = PyBytes_AsStringAndSize(o, &result, length);
        if (unlikely(r < 0)) {
            return NULL;
        } else {
            return result;
        }
    }
}
static CYTHON_INLINE int __Pyx_PyObject_IsTrue(PyObject* x) {
   int is_true = x == Py_True;
   if (is_true | (x == Py_False) | (x == Py_None)) return is_true;
   else return PyObject_IsTrue(x);
}
static PyObject* __Pyx_PyNumber_IntOrLongWrongResultType(PyObject* result, const char* type_name) {
#if PY_MAJOR_VERSION >= 3
    if (PyLong_Check(result)) {
        if (PyErr_WarnFormat(PyExc_DeprecationWarning, 1,
                "__int__ returned non-int (type %.200s).  "
                "The ability to return an instance of a strict subclass of int "
                "is deprecated, and may be removed in a future version of Python.",
                Py_TYPE(result)->tp_name)) {
            Py_DECREF(result);
            return NULL;
        }
        return result;
    }
#endif
    PyErr_Format(PyExc_TypeError,
                 "__%.4s__ returned non-%.4s (type %.200s)",
                 type_name, type_name, Py_TYPE(result)->tp_name);
    Py_DECREF(result);
    return NULL;
}
static CYTHON_INLINE PyObject* __Pyx_PyNumber_IntOrLong(PyObject* x) {
#if CYTHON_USE_TYPE_SLOTS
  PyNumberMethods *m;
#endif
  const char *name = NULL;
  PyObject *res = NULL;
#if PY_MAJOR_VERSION < 3
  if (likely(PyInt_Check(x) || PyLong_Check(x)))
#else
  if (likely(PyLong_Check(x)))
#endif
    return __Pyx_NewRef(x);
#if CYTHON_USE_TYPE_SLOTS
  m = Py_TYPE(x)->tp_as_number;
  #if PY_MAJOR_VERSION < 3
  if (m && m->nb_int) {
    name = "int";
    res = m->nb_int(x);
  }
  else if (m && m->nb_long) {
    name = "long";
    res = m->nb_long(x);
  }
  #else
  if (likely(m && m->nb_int)) {
    name = "int";
    res = m->nb_int(x);
  }
  #endif
#else
  if (!PyBytes_CheckExact(x) && !PyUnicode_CheckExact(x)) {
    res = PyNumber_Int(x);
  }
#endif
  if (likely(res)) {
#if PY_MAJOR_VERSION < 3
    if (unlikely(!PyInt_Check(res) && !PyLong_Check(res))) {
#else
    if (unlikely(!PyLong_CheckExact(res))) {
#endif
        return __Pyx_PyNumber_IntOrLongWrongResultType(res, name);
    }
  }
  else if (!PyErr_Occurred()) {
    PyErr_SetString(PyExc_TypeError,
                    "an integer is required");
  }
  return res;
}
static CYTHON_INLINE Py_ssize_t __Pyx_PyIndex_AsSsize_t(PyObject* b) {
  Py_ssize_t ival;
  PyObject *x;
#if PY_MAJOR_VERSION < 3
  if (likely(PyInt_CheckExact(b))) {
    if (sizeof(Py_ssize_t) >= sizeof(long))
        return PyInt_AS_LONG(b);
    else
        return PyInt_AsSsize_t(x);
  }
#endif
  if (likely(PyLong_CheckExact(b))) {
    #if CYTHON_USE_PYLONG_INTERNALS
    const digit* digits = ((PyLongObject*)b)->ob_digit;
    const Py_ssize_t size = Py_SIZE(b);
    if (likely(__Pyx_sst_abs(size) <= 1)) {
        ival = likely(size) ? digits[0] : 0;
        if (size == -1) ival = -ival;
        return ival;
    } else {
      switch (size) {
         case 2:
           if (8 * sizeof(Py_ssize_t) > 2 * PyLong_SHIFT) {
             return (Py_ssize_t) (((((size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
           }
           break;
         case -2:
           if (8 * sizeof(Py_ssize_t) > 2 * PyLong_SHIFT) {
             return -(Py_ssize_t) (((((size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
           }
           break;
         case 3:
           if (8 * sizeof(Py_ssize_t) > 3 * PyLong_SHIFT) {
             return (Py_ssize_t) (((((((size_t)digits[2]) << PyLong_SHIFT) | (size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
           }
           break;
         case -3:
           if (8 * sizeof(Py_ssize_t) > 3 * PyLong_SHIFT) {
             return -(Py_ssize_t) (((((((size_t)digits[2]) << PyLong_SHIFT) | (size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
           }
           break;
         case 4:
           if (8 * sizeof(Py_ssize_t) > 4 * PyLong_SHIFT) {
             return (Py_ssize_t) (((((((((size_t)digits[3]) << PyLong_SHIFT) | (size_t)digits[2]) << PyLong_SHIFT) | (size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
           }
           break;
         case -4:
           if (8 * sizeof(Py_ssize_t) > 4 * PyLong_SHIFT) {
             return -(Py_ssize_t) (((((((((size_t)digits[3]) << PyLong_SHIFT) | (size_t)digits[2]) << PyLong_SHIFT) | (size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
           }
           break;
      }
    }
    #endif
    return PyLong_AsSsize_t(b);
  }
  x = PyNumber_Index(b);
  if (!x) return -1;
  ival = PyInt_AsSsize_t(x);
  Py_DECREF(x);
  return ival;
}
static CYTHON_INLINE PyObject * __Pyx_PyInt_FromSize_t(size_t ival) {
    return PyInt_FromSize_t(ival);
}


#endif /* Py_PYTHON_H */
